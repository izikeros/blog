
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/stylesheet/style.min.css">



        <link id="pygments-light-theme" rel="stylesheet" type="text/css"
              href="https://www.safjan.com/theme/pygments/github.min.css">



    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/solid.css">

        <link rel="stylesheet" type="text/css"
              href="https://www.safjan.com/styles/custom.css">

        <link href="https://www.safjan.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Krystian Safjan's Blog Atom">

        <link href="https://www.safjan.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="Krystian Safjan's Blog RSS">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117080232-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-117080232-1');
</script>
<!-- End of Google tag (gtag.js) -->



    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="In the field of machine learning, it is common to use a single algorithm to train a model and make predictions. However, there are situations where using a single model may not be sufficient. This is where ensemble learning comes in, which …"/>
    <meta name="keywords" content="machine-learning, model-stacking, bagging, ensembling, boosting, data, prediction, artificial-intelligence, AI, models, complexity">
    <meta expr:content="2023-02-24 00:00:00+01:00" itemprop='datePublished'/>
    <meta expr:content="2023-02-24 00:00:00+01:00" itemprop='dateModified'/>
    <meta property="article:modified_time" content="2023-02-24 00:00:00+01:00"/>
    <meta property="article:published_time" content="2023-02-24 00:00:00+01:00"/>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Model Ensembling - Stacking, Bagging, and Boosting",
  "datePublished": "2023-02-24 00:00:00+01:00",
  "dateModified": "2023-02-24 00:00:00+01:00"
}



    </script>



  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Model Ensembling - Stacking, Bagging, and Boosting"/>
  <meta property="og:description" content="In the field of machine learning, it is common to use a single algorithm to train a model and make predictions. However, there are situations where using a single model may not be sufficient. This is where ensemble learning comes in, which …"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://www.safjan.com/drafts/model-stacking-bagging-ensembling-boosting-expert.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-02-24 00:00:00+01:00"/>
  <meta property="article:modified_time" content="2023-02-24 00:00:00+01:00"/>
  <meta property="article:author" content="https://www.safjan.com/author/krystian-safjan/">
  <meta property="article:section" content="note"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="model-stacking"/>
  <meta property="article:tag" content="bagging"/>
  <meta property="article:tag" content="ensembling"/>
  <meta property="article:tag" content="boosting"/>
  <meta property="article:tag" content="data"/>
  <meta property="article:tag" content="prediction"/>
  <meta property="article:tag" content="artificial-intelligence"/>
  <meta property="article:tag" content="AI"/>
  <meta property="article:tag" content="models"/>
  <meta property="article:tag" content="complexity"/>
  <meta property="og:image" content="/images/profile_new.jpg">

    <meta name="twitter:card" content="summary"/>
    <meta property="twitter:image" content="/images/profile_new.jpg">

    <meta name="twitter:label1" content="Est. reading time"/>
    <meta name="twitter:data1" content="4 min."/>
    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:description" content=""/>
    <meta name="twitter:title" content="Model Ensembling - Stacking, Bagging, and Boosting"/>


    <title>    Model Ensembling - Stacking, Bagging, and Boosting
</title>


<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body class="light-theme">
<aside>
    <div>
        <a href="https://www.safjan.com/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="https://www.safjan.com/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some  <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>




        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<style>
    .button {
        background-color: yellow;
        color: black;
        border: none;
        padding: 10px 20px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
        border-radius: 20px;
    }

    .center {
        text-align: center;
    }

    .container {
        display: grid;
        grid-template-columns: 1fr 1fr;
    }

    .left-col {
    }

    .right-col {
    }

    .image {
        border-radius: 0;
        width: 100%;
    }

    .book-list {
        padding-top:0;
        padding-bottom: 0;
        text-align:left;
        box-sizing: border-box;
        display: block;
        list-style-image: url(/images/shortcode-tick.webp);
        margin-block-start: 1em;
        margin-block-end: 1em;
        margin-inline-start:0;
        margin-inline-end:0;
        padding-inline-start:40px;
    }

    .book-list li {
        font-weight: bold;
    }

    @media (max-width: 600px) {
        .container {
            grid-template-columns: 1fr;
        }
    }

</style>
<div class="container">
    <div class="left-col">
        <a href="https://gumroad.com/">
            <img src="/images/mlop_interview_book_cover_3D_300px.jpg" class="image" alt="Interview Book Cover">
        </a>

        <div class="center">
            <a href="https://gumroad.com/">
                <button class="button">Get for $0.99</button>
            </a>
        </div>
    </div>
    <div class="right-col">
        <div>
            <ul class="book-list">
                <li>PDF, ePUB, mobi format ebook, no DRM</li>
                <li>50 questions and answers</li>
                <li>Stories from real projects</li>
                <li>100 multiple choice quizz questions</li>
                <li>178 pages</li>
            </ul>
        </div>
    </div>
</div>
</aside>
<main>

        <nav>
            <a href="https://www.safjan.com/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/tags.html">Tags</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>

                <a href="https://www.safjan.com/feeds/all.atom.xml">Atom</a>

                <a href="https://www.safjan.com/feeds/all.rss.xml">RSS</a>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-02-24 


                <br/>
            </p>
            <h1 id="model-stacking-bagging-ensembling-boosting-expert">Model Ensembling - Stacking, Bagging, and Boosting</h1>
            <div class="header-underline"></div>



        </header>


        <div>
            <p>In the field of machine learning, it is common to use a single algorithm to train a model and make predictions. However, there are situations where using a single model may not be sufficient. This is where ensemble learning comes in, which involves combining multiple models to improve performance. In this blog post, we will discuss some of the most popular ensemble methods, namely model stacking, bagging, and boosting.</p>
<h2>Ensembling</h2>
<p>Ensembling, also known as model averaging, is an ensemble learning technique that involves combining the predictions of multiple models to generate a final prediction. The idea behind ensembling is to reduce the bias of a single model by training multiple models on different subsets of the training data.</p>
<p>The process of ensembling involves the following steps:</p>
<ol>
<li>Train multiple models on different subsets of the training data.</li>
<li>Generate predictions for the test data using each of the models.</li>
<li>Combine the predictions of the models using a weighted average or majority vote.</li>
</ol>
<p>Ensembling has been shown to be effective in improving the accuracy of models and reducing the risk of overfitting. One of the challenges of ensembling is finding the right set of models to use and determining the appropriate weights for combining the predictions.</p>
<h2>Model Stacking</h2>
<p>Model stacking, also known as stacked generalization, is an ensemble learning technique that involves training multiple models and then combining their outputs using another model. The idea behind model stacking is to learn a meta-model that can effectively combine the predictions of multiple base models.</p>
<p>The process of model stacking involves the following steps:</p>
<ol>
<li>Split the training data into two or more parts. The first part is used to train the base models, while the second part is used to train the meta-model.</li>
<li>Train multiple base models on the first part of the data.</li>
<li>Generate predictions for the second part of the data using the base models.</li>
<li>Use the predictions generated by the base models as input to train the meta-model.</li>
<li>Use the meta-model to generate the final predictions.</li>
</ol>
<p>Model stacking has been shown to be effective in many applications, such as image classification and natural language processing. One of the challenges of model stacking is finding the right set of base models to use. In addition, it can be computationally expensive to train multiple models and then train the meta-model.</p>
<h2>Bagging</h2>
<p>Bootstrap aggregating, or bagging for short, is an ensemble learning technique that involves creating multiple models by resampling the training data. The idea behind bagging is to reduce the variance of a single model by training multiple models on different subsets of the training data.</p>
<p>The process of bagging involves the following steps:</p>
<ol>
<li>Randomly sample a subset of the training data with replacement.</li>
<li>Train a model on the subset of the training data.</li>
<li>Repeat steps 1 and 2 multiple times to generate multiple models.</li>
<li>Use the average or majority vote of the predictions generated by the models as the final prediction.</li>
</ol>
<p>Bagging has been shown to be effective in reducing overfitting and improving the generalization performance of models. One of the most popular bagging algorithms is the random forest, which combines bagging with decision trees. Random forests have been used in many applications, such as image classification and bioinformatics.</p>
<h2>Boosting</h2>
<p>Boosting is an ensemble learning technique that involves creating a sequence of models, where each model is trained to correct the errors of the previous model. The idea behind boosting is to reduce the bias of a single model by combining multiple weak models into a strong model.</p>
<p>The process of boosting involves the following steps:</p>
<ol>
<li>Train a base model on the training data.</li>
<li>Generate predictions for the training data using the base model.</li>
<li>Identify the training examples that were incorrectly classified by the base model. </li>
<li>Assign higher weights to the misclassified training examples and lower weights to the correctly classified training examples.</li>
<li>Train a new model on the training data with the updated weights.</li>
<li>Repeat steps 2 to 5 multiple times to generate a sequence of models.</li>
<li>Combine the predictions of the sequence of models using a weighted average or majority vote.</li>
</ol>
<p>Boosting has been shown to be effective in improving the accuracy of models and reducing the bias of weak models. One of the most popular boosting algorithms is the AdaBoost algorithm, which combines boosting with decision trees. AdaBoost has been used in many applications, such as face detection and object recognition.</p>
<h2>Summary of differences</h2>
<p>Although all of these techniques involve combining multiple models to improve the accuracy of predictions, there are some key differences between them. Here are the main differences:</p>
<ul>
<li><strong>Base Models</strong>: Model stacking and ensembling can use different types of models as base models, while bagging and boosting typically use a single type of model, such as decision trees.</li>
<li><strong>Sampling Technique</strong>: Bagging and boosting use sampling techniques to generate multiple training sets, while model stacking and ensembling typically use the entire training set for each base model.</li>
<li><strong>Training Method</strong>: Model stacking combines the predictions of the base models using another model, while bagging and ensembling combine the predictions directly. Boosting generates a sequence of models, where each subsequent model tries to correct the errors of the previous model.</li>
<li><strong>Prediction Method</strong>: Bagging and ensembling use majority voting to make predictions, while model stacking and boosting use weighted averaging or voting. Boosting can also use a combination of both weighted averaging and voting.</li>
<li><strong>Overfitting</strong>: Bagging and boosting are designed to reduce overfitting by generating multiple models with different training sets or weights. Model stacking and ensembling can potentially overfit if the base models are too complex or highly correlated.</li>
<li><strong>Hyperparameter Tuning</strong>: All of these techniques require tuning of hyperparameters, but the approach to hyperparameter tuning may differ. Grid search is a common approach to hyperparameter tuning, but Bayesian optimization can also be used to reduce the number of evaluations needed.</li>
<li><strong>Model Interpretability</strong>: Bagging and boosting can be difficult to interpret due to the large number of base models, while model stacking and ensembling can be more interpretable because they use a smaller number of models. Feature importance measures and visualization techniques can be used to help interpret the models.</li>
</ul>
<p>Understanding the differences between these techniques can help to choose the most appropriate technique for a particular problem and data set.
| Technique   | Base Models       | Sampling Technique    | Training Method       | Prediction Method           | Overfitting  | Hyperparameter Tuning | Model Interpretability |
|-------------|------------------|-----------------------|-----------------------|------------------------------|--------------|-----------------------|------------------------|
| Model       | Multiple         | None                  | Stacking               | Weighted Average             | Low          | Grid Search           | Feature Importance     |
| Stacking    |                  |                       |                       |                              |              |                       | Partial Dependence     |
| Bagging     | Multiple         | Bootstrap Aggregating | Parallel              | Majority Vote                | Low          | Grid Search           | Feature Importance     |
| Ensembling  | Multiple         | None                  | Parallel              | Weighted Average             | Low          | Grid Search           | Feature Importance     |
| Boosting    | Multiple         | Weighted Sampling     | Sequential            | Weighted Average or Voting  | Low          | Bayesian Optimization | Feature Importance     |</p>
<h2>Advanced Topics</h2>
<h3>Regularization</h3>
<p>One of the challenges of ensemble learning is overfitting, which occurs when the models are too complex and fit the training data too well. To address this issue, regularization techniques can be used to limit the complexity of the models and reduce the risk of overfitting.</p>
<p>One popular regularization technique is dropout, which involves randomly dropping out units in a neural network during training. Dropout has been shown to be effective in reducing overfitting and improving the generalization performance of neural networks.</p>
<h3>Hyperparameter Tuning</h3>
<p>Ensemble learning involves multiple models, each with its own set of hyperparameters. Tuning the hyperparameters of each model can be a challenging and time-consuming task. One approach to hyperparameter tuning is to use grid search, which involves trying all possible combinations of hyperparameters and selecting the best combination based on a validation set.</p>
<p>Another approach to hyperparameter tuning is to use Bayesian optimization, which involves constructing a probabilistic model of the objective function and using it to guide the search for the optimal hyperparameters. Bayesian optimization has been shown to be effective in reducing the number of evaluations needed to find the optimal hyperparameters.</p>
<h3>Model Interpretability</h3>
<p>Ensemble learning can improve the accuracy of models, but it can also make the models more complex and difficult to interpret. Understanding how the ensemble of models works and what features are important can be a challenging task.</p>
<p>One approach to model interpretability is to use feature importance measures, which quantify the contribution of each feature to the predictions of the model. Random forests, for example, provide a feature importance measure based on the decrease in impurity when a feature is used to split a node.</p>
<p>Another approach to model interpretability is to use visualization techniques, such as partial dependence plots and feature interaction plots. These plots can help to understand the relationship between the features and the predictions of the model.</p>
<h2>Conclusion</h2>
<p>Ensemble learning is a powerful technique for improving the accuracy and robustness of machine learning models. Model stacking, bagging, ensembling, and boosting are some of the most popular ensemble methods. Each method has its own strengths and weaknesses, and the choice of method depends on the specific problem and data set. Advanced topics in ensemble learning include regularization, hyperparameter tuning, and model interpretability. By using these techniques, it is possible to build more accurate and interpretable machine learning models.</p>
        </div>


        <div class="tag-cloud">
            <p>
                    <br/><br/>Tags:&nbsp;
                        <a href="https://www.safjan.com/tag/machine-learning/">machine-learning</a>
                        <a href="https://www.safjan.com/tag/model-stacking/">model-stacking</a>
                        <a href="https://www.safjan.com/tag/bagging/">bagging</a>
                        <a href="https://www.safjan.com/tag/ensembling/">ensembling</a>
                        <a href="https://www.safjan.com/tag/boosting/">boosting</a>
                        <a href="https://www.safjan.com/tag/data/">data</a>
                        <a href="https://www.safjan.com/tag/prediction/">prediction</a>
                        <a href="https://www.safjan.com/tag/artificial-intelligence/">artificial-intelligence</a>
                        <a href="https://www.safjan.com/tag/ai/">AI</a>
                        <a href="https://www.safjan.com/tag/models/">models</a>
                        <a href="https://www.safjan.com/tag/complexity/">complexity</a>
            </p>
        </div>


  <div class="neighbors">
  </div>

            <div class="related-posts">
                <h4>You might enjoy</h4>
                <ul class="related-posts">
                        <li><a href="https://www.safjan.com/model-stacking-bagging-ensembling-boosting-5yo/">Model Stacking, Bagging, Ensembling, and Boosting Explained with LEGO metaphor</a></li>
                        <li><a href="https://www.safjan.com/contextual_understanding-speech-to-text/">Contextual Understanding in Automated Speech-to-Text Transcription: Machine Learning Techniques and Challenges</a></li>
                        <li><a href="https://www.safjan.com/features-with-strong-correlation/">List of features with strongest correlation</a></li>
                        <li><a href="https://www.safjan.com/impact_of_google_search_and_llms_on_methal_capabilities/">The Impact of Search Engines and AI Generative Models on Mental and Cognitive Capabilities</a></li>
                        <li><a href="https://www.safjan.com/top-10-python-libraries-for-document-classification/">Top 10 Python Libraries for Document Classification</a></li>
                </ul>
            </div>


    </article>

    <footer>
<p>
  &copy; 2023 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
</main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Krystian Safjan's Blog ",
  "url" : "https://www.safjan.com",
  "image": "/images/profile_new.jpg",
  "description": ""
}
</script>

</body>
</html>