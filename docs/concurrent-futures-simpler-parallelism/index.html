
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="color-scheme" content="light dark"/>
    <script>
      (function() {
        var theme = localStorage.getItem('theme-preference');
        if (theme === 'dark' || theme === 'light') {
          document.documentElement.setAttribute('data-theme', theme);
        }
      })();
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/stylesheet/style.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/pygments/github.min.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/solid.css">

    <link rel="stylesheet" href="http://127.0.0.1:8000/pagefind/pagefind-ui.css">

        <link rel="stylesheet" type="text/css"
              href="http://127.0.0.1:8000/styles/custom.css">








    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="The High-Level Approach Introduced in Python 3.2 via PEP 3148, concurrent.futures gives you a unified interface for running code in parallel. Instead of wrestling with threads and processes directly, you get executors that handle the messy details. You submit tasks …"/>
    <meta name="keywords" content="python, concurrency, parallelism, threading, multiprocessing, performance">


  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Simpler Parallelism with concurrent.futures"/>
  <meta property="og:description" content="The High-Level Approach Introduced in Python 3.2 via PEP 3148, concurrent.futures gives you a unified interface for running code in parallel. Instead of wrestling with threads and processes directly, you get executors that handle the messy details. You submit tasks …"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="http://127.0.0.1:8000/concurrent-futures-simpler-parallelism/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2025-09-21 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2025-09-21 00:00:00+02:00"/>
  <meta property="article:author" content="http://127.0.0.1:8000/author/krystian-safjan/"/>
  <meta property="article:section" content="note"/>
  <meta property="article:tag" content="python, concurrency, parallelism, threading, multiprocessing, performance"/>
  <meta property="og:image" content="/images/profile_new.jpg"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:image" content="/images/profile_new.jpg"/>
    <meta name="twitter:image:alt" content="Krystian Safjan's Blog"/>


    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:creator" content="@izikeros"/>
    <meta name="twitter:title" content="Simpler Parallelism with concurrent.futures"/>
    <meta name="twitter:description" content="The High-Level Approach Introduced in Python 3.2 via PEP 3148, concurrent.futures gives you a unified interface for running code in parallel. Instead of wrestling with threads and processes..."/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://127.0.0.1:8000/concurrent-futures-simpler-parallelism/"
  },
  "headline": "Simpler Parallelism with concurrent.futures",
  "datePublished": "2025-09-21T00:00:00+02:00",
  "dateModified": "2025-09-21T00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Krystian Safjan",
    "url": "http://127.0.0.1:8000/author/krystian-safjan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Krystian Safjan's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/profile_new.jpg"
    }  },
"image": "/images/profile_new.jpg",  "url": "http://127.0.0.1:8000/concurrent-futures-simpler-parallelism/",
  "description": "The High-Level Approach Introduced in Python 3.2 via PEP 3148, concurrent.futures gives you a unified interface for running code in parallel. Instead of..."
}
</script>

    <title>    Simpler Parallelism with concurrent.futures
</title>



<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body>
<div id="reading-progress" class="reading-progress"></div>
<aside>
    <div>
        <a href="http://127.0.0.1:8000/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="http://127.0.0.1:8000/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>


        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<div class="promo-box">
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-image">
        <img src="/images/mlop_interview_book_cover_3D_300px.jpg" alt="MLOps Interview Book Cover">
    </a>
    
    <p class="promo-box-headline">Ace Your MLOps Interview</p>
    
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-cta">
        Get for $2.99
    </a>
    
    <p class="promo-box-features">50 Q&A • PDF/ePUB/mobi</p>
</div>
</aside>
<main>

        <nav>
            <a href="http://127.0.0.1:8000/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>



            <div id="search" class="nav-search"></div>
            <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">
                <i class="fas fa-sun"></i>
                <i class="fas fa-moon"></i>
            </button>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2025-09-21 


                <br/>
            </p>
            <h1 id="concurrent-futures-simpler-parallelism">Simpler Parallelism with concurrent.futures</h1>
            <div class="header-underline"></div>



        </header>


<nav class="series-nav" aria-label="Article series navigation">
    <div class="series-header">
        <span class="series-label">Part of series:</span>
        <strong class="series-name"></strong>
    </div>
    <ol class="series-list">
    </ol>
</nav>

        <details class="toc-details" id="toc-container">
            <summary>Table of Contents</summary>
            <nav class="toc" aria-label="Table of Contents">
                <ul class="toc-list"></ul>
            </nav>
        </details>

        <div class="article-content">
            <h2 id="the-high-level-approach">The High-Level Approach</h2>
<p>Introduced in Python 3.2 via PEP 3148, <code>concurrent.futures</code> gives you a unified interface for running code in parallel. Instead of wrestling with threads and processes directly, you get executors that handle the messy details. You submit tasks, get back futures, and collect results when they're ready.</p>
<p>The module provides two main executors: <code>ThreadPoolExecutor</code> for I/O-bound work and <code>ProcessPoolExecutor</code> for CPU-bound tasks. Both share the same API, which means you can swap them out with minimal code changes.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">fetch_url</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;https://example.com&#39;</span><span class="p">,</span>
    <span class="s1">&#39;https://python.org&#39;</span><span class="p">,</span>
    <span class="s1">&#39;https://github.com&#39;</span>
<span class="p">]</span>

<span class="c1"># Context manager handles cleanup automatically</span>
<span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">fetch_url</span><span class="p">,</span> <span class="n">urls</span><span class="p">)</span>

<span class="k">for</span> <span class="n">url</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">urls</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2"> bytes&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The executor manages a pool of workers for you. You don't create threads manually or worry about joining them. The context manager ensures everything gets cleaned up properly, even if exceptions occur.</p>
<h2 id="working-with-futures">Working with Futures</h2>
<p>The real power shows up when you need more control than <code>map()</code> provides. The <code>submit()</code> method returns a Future object immediately, letting you track individual tasks and handle them independently.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span><span class="p">,</span> <span class="n">as_completed</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;delay&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">items</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;delay&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;delay&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="s1">&#39;delay&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">}</span>
<span class="p">]</span>

<span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="c1"># Submit all tasks, get futures back</span>
    <span class="n">future_to_item</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">process_item</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span> <span class="n">item</span> 
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span>
    <span class="p">}</span>

    <span class="c1"># Process results as they complete</span>
    <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">future_to_item</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">future_to_item</span><span class="p">[</span><span class="n">future</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result_id</span><span class="p">,</span> <span class="n">result_value</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Item </span><span class="si">{</span><span class="n">result_id</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Item </span><span class="si">{</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The <code>as_completed()</code> function is particularly useful because it yields futures as soon as they finish, rather than in submission order. This means you can start processing early results while slower tasks are still running.</p>
<p>You can also wait for specific conditions using <code>wait()</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">wait</span><span class="p">,</span> <span class="n">FIRST_COMPLETED</span><span class="p">,</span> <span class="n">ALL_COMPLETED</span>

<span class="c1"># Submit multiple tasks</span>
<span class="n">futures</span> <span class="o">=</span> <span class="p">[</span><span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">slow_function</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

<span class="c1"># Wait for the first one to finish</span>
<span class="n">done</span><span class="p">,</span> <span class="n">pending</span> <span class="o">=</span> <span class="n">wait</span><span class="p">(</span><span class="n">futures</span><span class="p">,</span> <span class="n">return_when</span><span class="o">=</span><span class="n">FIRST_COMPLETED</span><span class="p">)</span>
<span class="n">fastest_result</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">done</span><span class="p">))</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

<span class="c1"># Cancel the rest if you only needed one result</span>
<span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">pending</span><span class="p">:</span>
    <span class="n">future</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>
</code></pre></div>

<p>The Future objects themselves provide several useful methods. You can check if a task is done with <code>.done()</code>, cancel pending tasks with <code>.cancel()</code>, and attach callbacks with <code>.add_done_callback()</code> that fire when the task completes.</p>
<h2 id="when-each-executor-makes-sense">When Each Executor Makes Sense</h2>
<p><code>ThreadPoolExecutor</code> works best for I/O-bound operations where your code spends time waiting. Network requests, file I/O, database queries—these are all good candidates. Python's Global Interpreter Lock (GIL) doesn't hurt you here because threads release the GIL during I/O operations.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="k">def</span> <span class="nf">query_database</span><span class="p">(</span><span class="n">db_path</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">db_path</span><span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">results</span>

<span class="n">databases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;users.db&#39;</span><span class="p">,</span> <span class="s1">&#39;orders.db&#39;</span><span class="p">,</span> <span class="s1">&#39;inventory.db&#39;</span><span class="p">]</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT COUNT(*) FROM main_table&quot;</span>

<span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">db</span><span class="p">:</span> <span class="n">query_database</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">query</span><span class="p">),</span> 
        <span class="n">databases</span>
    <span class="p">)</span>
</code></pre></div>

<p><code>ProcessPoolExecutor</code> is your choice for CPU-intensive work like data processing, image manipulation, or mathematical computations. Each process gets its own Python interpreter and memory space, bypassing the GIL completely.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ProcessPoolExecutor</span>
<span class="kn">import</span> <span class="nn">hashlib</span>

<span class="k">def</span> <span class="nf">hash_file</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
    <span class="n">hasher</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">()</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">4096</span><span class="p">),</span> <span class="sa">b</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
            <span class="n">hasher</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">hasher</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>

<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;large_file1.bin&#39;</span><span class="p">,</span> <span class="s1">&#39;large_file2.bin&#39;</span><span class="p">,</span> <span class="s1">&#39;large_file3.bin&#39;</span><span class="p">]</span>

<span class="k">with</span> <span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">digest</span> <span class="ow">in</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">hash_file</span><span class="p">,</span> <span class="n">files</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">digest</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Don't use <code>ProcessPoolExecutor</code> for quick tasks or when you're passing large amounts of data. Spawning processes and serializing data between them has significant overhead. If your tasks take less than 0.1 seconds, the overhead probably exceeds the benefit.</p>
<p>Avoid threads for pure CPU-bound work. The GIL means only one thread executes Python bytecode at a time, so you won't get parallel execution. You might even see slower performance due to context switching overhead.</p>
<h2 id="the-subtle-bits">The Subtle Bits</h2>
<p>The <code>max_workers</code> parameter matters more than you might think. Too few workers and you're not utilizing available resources. Too many and you waste memory while adding context-switching overhead. For I/O-bound work, you can often use more workers than CPU cores. For CPU-bound work, using more processes than cores typically doesn't help.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ProcessPoolExecutor</span>

<span class="c1"># Good default for CPU-bound work</span>
<span class="k">with</span> <span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">())</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">cpu_intensive_function</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># For I/O-bound work, you might go higher</span>
<span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">fetch_url</span><span class="p">,</span> <span class="n">urls</span><span class="p">)</span>
</code></pre></div>

<p>When using <code>ProcessPoolExecutor</code>, remember that arguments and return values must be picklable. This means you can't pass lambdas, local functions, or objects with unpicklable attributes. If you need to share configuration, consider using <code>functools.partial()</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">concurrent.futures</span> <span class="kn">import</span> <span class="n">ProcessPoolExecutor</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="k">def</span> <span class="nf">process_with_config</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="c1"># Use config dict to guide processing</span>
    <span class="k">return</span> <span class="n">item</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;multiplier&#39;</span><span class="p">]</span>

<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;multiplier&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="c1"># Wrong - lambdas aren&#39;t picklable</span>
<span class="c1"># with ProcessPoolExecutor() as executor:</span>
<span class="c1">#     results = executor.map(lambda x: process_with_config(x, config), data)</span>

<span class="c1"># Right - use partial to bind the config argument</span>
<span class="k">with</span> <span class="n">ProcessPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">process_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">process_with_config</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">process_func</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</code></pre></div>

<p>Exception handling requires attention because exceptions happen in worker threads or processes, not your main thread. Always wrap <code>.result()</code> calls in try-except blocks. If you use <code>map()</code>, exceptions won't raise until you iterate over the results.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">might_fail</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Negative values not allowed&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>

<span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">might_fail</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>  <span class="c1"># Exception raises here, not during map()</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The executors don't automatically time out. If a task hangs, it'll block forever unless you specify a timeout:</p>
<div class="highlight"><pre><span></span><code><span class="n">future</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">potentially_slow_function</span><span class="p">,</span> <span class="n">arg</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>  <span class="c1"># Wait max 5 seconds</span>
<span class="k">except</span> <span class="ne">TimeoutError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function took too long&quot;</span><span class="p">)</span>
    <span class="n">future</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>  <span class="c1"># Won&#39;t stop already-running tasks</span>
</code></pre></div>

<p>One common mistake is thinking <code>.cancel()</code> will stop running tasks. It only prevents pending tasks from starting. Once a task begins execution, cancellation doesn't interrupt it. If you need interruptible tasks, you'll need to implement that logic yourself, typically using threading events or multiprocessing shared values.</p>
<p>The module handles resource cleanup well through context managers, but if you don't use them, call <code>.shutdown(wait=True)</code> explicitly. This ensures all pending tasks complete and resources get released. Forgetting this can leave threads or processes hanging around.</p>
        </div>


        <div class="article-tags">
            <span class="tags-label">Tags:</span>
                <a href="http://127.0.0.1:8000/tag/python-concurrency-parallelism-threading-multiprocessing-performance/" class="article-tag">python, concurrency, parallelism, threading, multiprocessing, performance</a>
        </div>









    </article>

    <footer>
<p>
  &copy; 2026 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>    </footer>
</main>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "Krystian Safjan's Blog",
  "url": "http://127.0.0.1:8000",
"image": "/images/profile_new.jpg",  "description": ""
}
</script>


<script src="http://127.0.0.1:8000/pagefind/pagefind-ui.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', function() {
        new PagefindUI({
            element: "#search",
            showSubResults: false,
            showImages: false,
            basePath: "http://127.0.0.1:8000/pagefind/"
        });
    });
</script>

<script src="http://127.0.0.1:8000/theme/js/theme-switcher.js"></script>
</body>
</html>