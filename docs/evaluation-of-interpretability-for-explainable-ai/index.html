
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="color-scheme" content="light dark"/>
    <script>
      (function() {
        var theme = localStorage.getItem('theme-preference');
        if (theme === 'dark' || theme === 'light') {
          document.documentElement.setAttribute('data-theme', theme);
        }
      })();
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/stylesheet/style.css">


    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/pygments/github.min.css">


    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/solid.css">

    <link rel="stylesheet" href="https://www.safjan.com/pagefind/pagefind-ui.css">

        <link rel="stylesheet" type="text/css"
              href="https://www.safjan.com/styles/custom.css">

        <link href="https://www.safjan.com/feeds/all.atom.xml?utm_source=rss&utm_medium=feed&utm_campaign=rss-feed" type="application/atom+xml" rel="alternate"
              title="Krystian Safjan's Blog Atom">

        <link href="https://www.safjan.com/feeds/all.rss.xml?utm_source=rss&utm_medium=feed&utm_campaign=rss-feed" type="application/rss+xml" rel="alternate"
              title="Krystian Safjan's Blog RSS">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RM2PKDCCYM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RM2PKDCCYM');
</script>
<!-- End of Google tag (gtag.js) -->



    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models."/>
    <meta name="keywords" content="rai, interpretability, xai, explainability, ai, machine-learning, model, responsible-ai">


  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Evaluation of Interpretability for Explainable AI"/>
  <meta property="og:description" content="Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://www.safjan.com/evaluation-of-interpretability-for-explainable-ai/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2020-11-05 00:00:00+01:00"/>
  <meta property="article:modified_time" content="2023-01-19 00:00:00+01:00"/>
  <meta property="article:author" content="https://www.safjan.com/author/krystian-safjan/"/>
  <meta property="article:section" content="Responsible AI"/>
  <meta property="article:tag" content="rai"/>
  <meta property="article:tag" content="interpretability"/>
  <meta property="article:tag" content="xai"/>
  <meta property="article:tag" content="explainability"/>
  <meta property="article:tag" content="ai"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="model"/>
  <meta property="article:tag" content="responsible-ai"/>
  <meta property="og:image" content="https://www.safjan.com//images/head/AI_gray-haired_1_640.jpg"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="https://www.safjan.com//images/head/AI_gray-haired_1_640.jpg"/>
    <meta name="twitter:image:alt" content="Evaluation of Interpretability for Explainable AI"/>


    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:creator" content="@izikeros"/>
    <meta name="twitter:title" content="Evaluation of Interpretability for Explainable AI"/>
    <meta name="twitter:description" content="Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models."/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.safjan.com/evaluation-of-interpretability-for-explainable-ai/"
  },
  "headline": "Evaluation of Interpretability for Explainable AI",
  "datePublished": "2020-11-05T00:00:00+01:00",
  "dateModified": "2023-01-19T00:00:00+01:00",
  "author": {
    "@type": "Person",
    "name": "Krystian Safjan",
    "url": "https://www.safjan.com/author/krystian-safjan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Krystian Safjan's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/profile_new.jpg"
    }  },
"image": "https://www.safjan.com//images/head/AI_gray-haired_1_640.jpg",  "url": "https://www.safjan.com/evaluation-of-interpretability-for-explainable-ai/",
  "description": "Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models.",
  "articleSection": "Responsible AI",
  "inLanguage": "en",
  "keywords": "rai, interpretability, xai, explainability, ai, machine-learning, model, responsible-ai",
  "wordCount": 452,
  "speakable": {
    "@type": "SpeakableSpecification",
    "cssSelector": ["article h1", ".summary", ".tldr", "article \u003e p:first-of-type"]
  }}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "https://www.safjan.com/"
    },
    {
      "@type": "ListItem",
      "position": 2,
      "name": "Responsible AI",
      "item": "https://www.safjan.com/category/responsible-ai.html"
    },
    {
      "@type": "ListItem",
      "position": 3,
      "name": "Evaluation of Interpretability for Explainable AI"
    }
  ]
}
</script>



<meta name="ai:summary" content="Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models.">

<meta name="ai:topics" content="rai, interpretability, xai, explainability, ai, machine-learning, model, responsible-ai">



<meta name="ai:word-count" content="452">
<meta name="ai:reading-time" content="2 min">

<meta name="ai:section" content="Responsible AI">



<meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">

    <title>    Evaluation of Interpretability for Explainable AI
</title>



<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body>
<div id="reading-progress" class="reading-progress"></div>
<aside>
    <div>
        <a href="https://www.safjan.com/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="https://www.safjan.com/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist and Team Leader writing about Machine Learning, MLOps, and Python</p>


        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<div class="promo-box">
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-image">
        <img src="/images/mlop_interview_book_cover_3D_300px.jpg" alt="MLOps Interview Book Cover">
    </a>
    
    <p class="promo-box-headline">Ace Your MLOps Interview</p>
    
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-cta">
        Get for $2.99
    </a>
    
    <p class="promo-box-features">50 Q&A • PDF/ePUB/mobi</p>
</div>
</aside>
<main>

        <nav>
            <a href="https://www.safjan.com/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>

                <a href="https://www.safjan.com/feeds/all.atom.xml">Atom</a>

                <a href="https://www.safjan.com/feeds/all.rss.xml">RSS</a>

            <div id="search" class="nav-search"></div>
            <button type="button" id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">
                <i class="fas fa-sun"></i>
                <i class="fas fa-moon"></i>
            </button>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2020-11-05 


                <br/>
            </p>
            <h1 id="evaluation-of-interpretability-for-explainable-ai">Evaluation of Interpretability for Explainable AI</h1>
            <div class="header-underline"></div>
                <div class="summary"><p>Learn about the evaluation of interpretability in machine learning with this guide. Discover different levels and methods for assessing the explainability of models.</p></div>

                <div style="width: 100%; padding-bottom: 30px; position: relative;">
                    <a href="https://www.safjan.com/evaluation-of-interpretability-for-explainable-ai/">
                        <img style="width: 100%; "
                             src="/images/head/AI_gray-haired_1_640.jpg" alt="Evaluation of Interpretability for Explainable AI">
                    </a>
                </div>


        </header>




        <div class="article-content">
            <p>Interpretability in machine learning is a complex and multifaceted topic. It refers to the ability of a model to explain its decisions and predictions to humans in a way that is understandable and meaningful. However, there is currently no agreed-upon definition or method for measuring interpretability.</p>
<!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" -->

<ul>
<li><a href="#three-levels-of-evaluating-interpretability">Three levels of evaluating interpretability</a></li>
<li><a href="#application-level">Application level</a></li>
<li><a href="#human-level">Human level</a></li>
<li><a href="#function-level">Function level</a></li>
</ul>
<!-- /MarkdownTOC -->

<h2 id="three-levels-of-evaluating-interpretability">Three levels of evaluating interpretability</h2>
<p>Doshi-Velez and Kim (2017) propose a framework for evaluating interpretability at three levels: application level, human level, and function level.</p>
<p><img alt="taxonomy of evaluation interpretability - three levels" src="/images/evaluation_of_interpretability/taxonomy_of_evaluation_interpretability.png">
<strong>Figure 1. Taxonomy of evaluation approaches for interpretability, source: Doshi-Velez and Kim (2017)</strong></p>
<h3 id="application-level">Application level</h3>
<p>At the application level, interpretability is evaluated by <strong>testing the explanation in the context of the real-world task for which the model was developed</strong>. For example, in the case of a fracture detection software that uses machine learning to locate and mark fractures in X-rays, radiologists would test the software directly to evaluate the model. This approach requires a well-designed experimental setup and an understanding of how to assess the quality of the explanations. A good baseline for this evaluation is always how well a human would perform at explaining the same decision.</p>
<h3 id="human-level">Human level</h3>
<p>The human level evaluation is a simplified version of the application level evaluation. <strong>Instead of testing with domain experts, experiments are conducted with laypersons</strong>. This approach is more cost-effective and allows for more testers to participate. For example, a user might be shown different explanations and asked to choose the best one.</p>
<h3 id="function-level">Function level</h3>
<p>The function level evaluation <strong>does not require human participation</strong>. This approach is best suited for models that have already been evaluated at the human level by others. For example, it may be known that decision trees are well understood by end-users. In this case, a proxy for explanation quality might be the depth of the tree. Shorter trees would receive a higher explainability score. However, it is important to ensure that the predictive performance of the tree remains good and does not decrease too much compared to a larger tree.</p>
<h2 id="tools-and-methods-for-interpretability">Tools and methods for Interpretability</h2>
<p>It's also worth noting that there are other approaches for evaluating interpretability, like using intrinsic and extrinsic evaluation metrics, as well as using techniques like saliency maps, LIME, SHAP, etc. These methods allow us to understand the feature importance and decision path of a model and evaluate the interpretability of a model.</p>
<p>Overall, the evaluation of interpretability is an active area of research, and there is no one-size-fits-all approach.</p>
<p><strong>References:</strong></p>
<ul>
<li>Doshi-Velez, Finale, and Been Kim. “Towards a rigorous science of interpretable machine learning,” no. Ml: 1–13. <a href="http://arxiv.org/abs/1702.08608">http://arxiv.org/abs/1702.08608</a>( 2017).</li>
<li>Christoph Molnar, Interpretable Machine Learning. A Guide for Making Black Box Models Explainable (2019). Available <a href="http://leanpub.com/interpretable-machine-learning">here</a>.</li>
</ul>
<p><em>Any comments or suggestions? <a href="mailto:ksafjan@gmail.com?subject=Blog+post">Let me know</a>.</em></p>
        </div>




            <div class="bibtex-note">
                <p><b>To cite this article:</b></p>
                <pre>@article{Saf2020Evaluation,
    author  = {Krystian Safjan},
    title   = {Evaluation of Interpretability for Explainable AI},
    journal = {Krystian's Safjan Blog},
    year    = {2020},
}</pre>
            </div>
        <div class="article-tags">
            <span class="tags-label">Tags:</span>
                <a href="https://www.safjan.com/tag/rai/" class="article-tag">rai</a>
                <a href="https://www.safjan.com/tag/interpretability/" class="article-tag">interpretability</a>
                <a href="https://www.safjan.com/tag/xai/" class="article-tag">xai</a>
                <a href="https://www.safjan.com/tag/explainability/" class="article-tag">explainability</a>
                <a href="https://www.safjan.com/tag/ai/" class="article-tag">ai</a>
                <a href="https://www.safjan.com/tag/machine-learning/" class="article-tag">machine-learning</a>
                <a href="https://www.safjan.com/tag/model/" class="article-tag">model</a>
                <a href="https://www.safjan.com/tag/responsible-ai/" class="article-tag">responsible-ai</a>
        </div>











    </article>

    <footer>
<p>
  &copy; 2026 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>    </footer>
</main>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "Krystian Safjan's Blog",
  "url": "https://www.safjan.com",
"image": "/images/profile_new.jpg",  "description": ""
}
</script>


<script src="https://www.safjan.com/pagefind/pagefind-ui.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', function() {
        new PagefindUI({
            element: "#search",
            showSubResults: false,
            showImages: false,
            basePath: "https://www.safjan.com/pagefind/"
        });
    });
</script>

<script src="https://www.safjan.com/theme/js/theme-switcher.js"></script>
</body>
</html>