
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/stylesheet/style.min.css">



        <link id="pygments-light-theme" rel="stylesheet" type="text/css"
              href="https://www.safjan.com/theme/pygments/github.min.css">



    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/solid.css">

        <link rel="stylesheet" type="text/css"
              href="https://www.safjan.com/styles/custom.css">

        <link href="https://www.safjan.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Krystian Safjan's Blog Atom">

        <link href="https://www.safjan.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="Krystian Safjan's Blog RSS">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RM2PKDCCYM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RM2PKDCCYM');
</script>
<!-- End of Google tag (gtag.js) -->



    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Explore the powerful technique of Inverted File Product Quantization (IVFPQ) for similarity search. By combining the benefits of product quantization and an inverted file system."/>
    <meta name="keywords" content="machine-learning, python">
    <meta expr:content="2023-06-08 00:00:00+02:00" itemprop='datePublished'/>
    <meta expr:content="2023-06-08 00:00:00+02:00" itemprop='dateModified'/>
    <meta property="article:modified_time" content="2023-06-08 00:00:00+02:00"/>
    <meta property="article:published_time" content="2023-06-08 00:00:00+02:00"/>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Similarity search using IVFPQ",
  "datePublished": "2023-06-08 00:00:00+02:00",
  "dateModified": "2023-06-08 00:00:00+02:00"
}








    </script>



  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Similarity search using IVFPQ"/>
  <meta property="og:description" content="Explore the powerful technique of Inverted File Product Quantization (IVFPQ) for similarity search. By combining the benefits of product quantization and an inverted file system."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://www.safjan.com/similarity-search-using-ivfpq/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-06-08 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2023-06-08 00:00:00+02:00"/>
  <meta property="article:author" content="https://www.safjan.com/author/krystian-safjan/">
  <meta property="article:section" content="Machine Learning"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="python"/>
  <meta property="og:image" content="https://www.safjan.com//images/head/ivfpq.jpg">

    <meta name="twitter:card" content="summary"/>
    <meta property="twitter:image" content="https://www.safjan.com//images/head/ivfpq.jpg">

    <meta name="twitter:label1" content="Est. reading time"/>
    <meta name="twitter:data1" content="4 min."/>
    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:description" content="<p>Explore the powerful technique of Inverted File Product Quantization (IVFPQ) for similarity search. By combining the benefits of product quantization and an inverted file system.</p>"/>
    <meta name="twitter:title" content="Similarity search using IVFPQ"/>


    <title>    Similarity search using IVFPQ
</title>


<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body class="light-theme">
<aside>
    <div>
        <a href="https://www.safjan.com/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="https://www.safjan.com/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some  <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>




        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<style>
    .button {
        background-color: yellow;
        color: black;
        border: none;
        padding: 10px 20px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
        border-radius: 20px;
    }

    .center {
        text-align: center;
    }

    .container {
        display: grid;
        grid-template-columns: 1fr 1fr;
    }

    .left-col {
    }

    .right-col {
    }

    .image {
        border-radius: 0;
        width: 100%;
    }

    .book-list {
        padding-top:0;
        padding-bottom: 0;
        text-align:left;
        box-sizing: border-box;
        display: block;
        list-style-image: url(/images/shortcode-tick.webp);
        margin-block-start: 1em;
        margin-block-end: 1em;
        margin-inline-start:0;
        margin-inline-end:0;
        padding-inline-start:40px;
    }

    .book-list li {
        font-weight: bold;
    }

    @media (max-width: 600px) {
        .container {
            grid-template-columns: 1fr;
        }
    }

</style>
<div class="container">
    <div class="left-col">
        <a href="https://ksafjanuser.gumroad.com/l/mlops">
            <img src="/images/mlop_interview_book_cover_3D_300px.jpg" class="image" alt="Interview Book Cover">
        </a>

        <div class="center">
            <a href="https://ksafjanuser.gumroad.com/l/mlops">
                <button class="button">Get for $2.99</button>
            </a>
        </div>
    </div>
    <div class="right-col">
        <div>
            <ul class="book-list">
                <li>PDF, ePUB, mobi format ebook, no DRM</li>
                <li>50 questions and answers</li>
                <li>Stories from real projects</li>
                <li>92 multiple choice quiz questions</li>
                <li>80 pages</li>
            </ul>
        </div>
    </div>
</div>
</aside>
<main>

        <nav>
            <a href="https://www.safjan.com/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/tags.html">Tags</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>

                <a href="https://www.safjan.com/feeds/all.atom.xml">Atom</a>

                <a href="https://www.safjan.com/feeds/all.rss.xml">RSS</a>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-06-08 



                    <span id="post-share-links">
    &nbsp;&nbsp;&nbsp;Share on:
    <a href="https://twitter.com/intent/tweet?text=Similarity%20search%20using%20IVFPQ&url=https%3A//www.safjan.com/similarity-search-using-ivfpq/&hashtags=machine-learning,python" target="_blank" title="Share on Twitter">Twitter</a>
    |
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//www.safjan.com/similarity-search-using-ivfpq/" target="_blank" title="Share on Facebook">Facebook</a>
    |
    <a href="https://news.ycombinator.com/submitlink?t=Similarity%20search%20using%20IVFPQ&u=https%3A//www.safjan.com/similarity-search-using-ivfpq/" target="_blank" title="Share on HackerNews">HackerNews</a>
    |
    <a href="https://www.reddit.com/submit?url=https%3A//www.safjan.com/similarity-search-using-ivfpq/&title=Similarity%20search%20using%20IVFPQ" target="_blank" title="Share via Reddit">Reddit</a>
  </span>
                <br/>
            </p>
            <h1 id="similarity-search-using-ivfpq">Similarity search using IVFPQ</h1>
            <div class="header-underline"></div>
                <p class="summary"><p>Explore the powerful technique of Inverted File Product Quantization (IVFPQ) for similarity search. By combining the benefits of product quantization and an inverted file system.</p></p>

                <div style="width: 100%; padding-bottom: 30px; position: relative;">
                    <a href="https://www.safjan.com/similarity-search-using-ivfpq/">
                        <img style="width: 100%; "
                             src="/images/head/ivfpq.jpg" alt="">
                    </a>
                </div>


        </header>


        <div>
            <h1>Unlocking the Power of Similarity Search using IVFPQ (Inverted File Product Quantization)</h1>
<h2>Introduction</h2>
<p>As the world generates more data than ever before, the need for efficient search algorithms has become indispensable. The field of similarity search focuses on finding the most similar elements in a large dataset, given a query element. Applications of similarity search range from image and video retrieval, to recommendation systems, and even natural language processing.</p>
<p>One particularly powerful technique for similarity search is Inverted File Product Quantization (IVFPQ). IVFPQ allows us to handle large-scale datasets by compressing the data and using an inverted file system for efficient indexing and retrieval. In this blog post, we'll dive into the details of how IVFPQ works, its advantages, and how to implement it in Python using the popular Faiss library.</p>
<h2>Understanding Inverted File Product Quantization (IVFPQ)</h2>
<blockquote>
<p><strong>Product Quantization (PQ)</strong> is a vector quantization technique that allows us to compress high-dimensional vectors into a compact form, while preserving the relative distances between them. In a nutshell, PQ works by dividing a high-dimensional vector into subvectors and quantizing each subvector independently.</p>
</blockquote>
<p>Inverted File Product Quantization (IVFPQ) is an extension of PQ that adds an inverted file system on top of the basic PQ structure. </p>
<blockquote>
<p>The <strong>inverted file system</strong> is essentially an index that maps each quantized vector to a list of database vectors that fall in the same quantization cell.</p>
</blockquote>
<p>The key advantage of IVFPQ is that it allows us to perform similarity search with a reduced number of distance computations, making it a highly efficient technique for large-scale datasets.</p>
<h2>Implementing IVFPQ in Python using Faiss</h2>
<p>Now that we have a basic understanding of IVFPQ, let's see how to implement it in Python using the Faiss library. Faiss is a popular library developed by Facebook AI Research that provides efficient implementations of several similarity search techniques, including IVFPQ.</p>
<p>Let's start by installing the Faiss library:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>faiss
</code></pre></div>

<p>Next, let's generate some random data to work with. For this example, we'll create a dataset of 10,000 128-dimensional vectors:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">dimension</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_vectors</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Generate random data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">num_vectors</span><span class="p">,</span> <span class="n">dimension</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div>

<p>Now, let's create an IVFPQ index using Faiss:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">faiss</span>

<span class="c1"># Initialize the IVFPQ index</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexIVFPQ</span><span class="p">(</span><span class="n">quantizer</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

<span class="c1"># Train the index</span>
<span class="n">index</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Add data to the index</span>
<span class="n">index</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

<p>In the code above, we first create a quantizer using Faiss's IndexFlatL2. This is a basic L2 distance index that will be used for coarse quantization. Next, we create the IVFPQ index by passing the quantizer, the dimension of the vectors, the number of coarse quantization cells (100), the number of subquantizers (16), and the number of bits per subquantizer (8).</p>
<p>We then train the index using our dataset and add the data to the index.</p>
<p>Finally, let's perform a similarity search using our IVFPQ index. We'll generate a random query vector and find the top 10 most similar vectors in our dataset:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Generate a random query vector</span>
<span class="n">query</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">dimension</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Perform the similarity search</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

<span class="c1"># Print the results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 10 most similar vectors:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">distance</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">distances</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. Index: </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">, Distance: </span><span class="si">{</span><span class="n">distance</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The search method returns two arrays: one containing the distances between the query vector and the closest vectors in the dataset, and another containing the indices of those vectors. We can then print the results to see the top 10 most similar vectors.</p>
<div class="highlight"><pre><span></span><code>Top 10 most similar vectors: 
1. Index: 1548, Distance: 12.515710830688477 
2. Index: 3764, Distance: 14.528205871582031 
3. Index: 5173, Distance: 14.70742416381836 
4. Index: 5930, Distance: 14.80669116973877 
5. Index: 9472, Distance: 15.031980514526367 
6. Index: 5696, Distance: 15.204572677612305 
7. Index: 587, Distance: 15.735445022583008 
8. Index: 816, Distance: 15.76244831085205 
9. Index: 3032, Distance: 15.773483276367188 
10. Index: 3776, Distance: 16.045366287231445
</code></pre></div>

<h2>Conclusion</h2>
<p>In this blog post, we've explored the powerful technique of Inverted File Product Quantization (IVFPQ) for similarity search. By combining the benefits of product quantization and an inverted file system, IVFPQ provides a highly efficient method for searching large-scale datasets. We also demonstrated how to implement IVFPQ in Python using the Faiss library, showcasing its ease of use and effectiveness.</p>
<p>If you're working with large-scale datasets and need an efficient way to perform similarity search, give IVFPQ a try and see the benefits for yourself!</p>
<h2>Related reading</h2>
<ul>
<li><a href="https://towardsdatascience.com/similarity-search-with-ivfpq-9c6348fd4db3">Similarity Search with IVFPQ. Find out how the inverted file index… | by Peggy Chang | Towards Data Science</a></li>
<li><a href="https://www.pinecone.io/learn/series/faiss">Faiss: The Missing Manual | Pinecone</a></li>
<li>D. Baranchuk, et al., <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1802.02422.pdf">Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors</a> (2018), <em>ECCV</em></li>
<li>Y. Matsui, et al., <a href="https://link.zhihu.com/?target=https%3A//www.jstage.jst.go.jp/article/mta/6/1/6_2/_pdf">A Survey of Product Quantization</a> (2018), <em>ITE Trans. on MTA</em></li>
<li>T. Ge, et. al., <a href="https://link.zhihu.com/?target=http%3A//kaiminghe.com/publications/pami13opq.pdf">Optimized Product Quantization</a> (2014), <em>TPAMI</em></li>
<li>H. Jégou, et al., <a href="https://link.zhihu.com/?target=https%3A//lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf">Product quantization for nearest neighbor search</a> (2010), <em>TPAMI</em></li>
<li>A. Babenko, V. Lempitsky, The Inverted Multi-Index (2012), CVPR</li>
<li>H. Jégou, et al., Searching in One Billion Vectors: Re-rank with Source Coding (2011), ICASSP</li>
<li>Y. Malkov, D. Yashunin, Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs (2016), IEEE Transactions on Pattern Analysis and Machine Intelligence</li>
<li>Y. Malkov et al., Approximate Nearest Neighbor Search Small World Approach (2011), International Conference on Information and Communication Technologies &amp; Applications</li>
<li>Y. Malkov et al., Scalable Distributed Algorithm for Approximate Nearest Neighbor Search Problem in High Dimensional General Metric Spaces (2012), Similarity Search and Applications, pp. 132-147</li>
<li>Y. Malkov et al., Approximate nearest neighbor algorithm based on navigable small world graphs (2014), Information Systems, vol. 45, pp. 61-68</li>
</ul>
        </div>




            <div class="bibtex-note">
                <p><b>To cite this article:</b></p>
                <pre>@article{Saf2023Similarity,
    author  = {Krystian Safjan},
    title   = {Similarity search using IVFPQ},
    journal = {Krystian's Safjan Blog},
    year    = {2023},
}</pre>
            </div>
        <div class="tag-cloud">
            <p>
                    <br/><br/>Tags:&nbsp;
                        <a href="https://www.safjan.com/tag/machine-learning/">machine-learning</a>
                        <a href="https://www.safjan.com/tag/python/">python</a>
            </p>
        </div>








            <div class="related-posts">
                <h4>You might enjoy</h4>
                <ul class="related-posts">
                        <li><a href="https://www.safjan.com/python-dependency-injection-for-the-testability/">Harnessing the Power of Dependency Injection for Improved Testability in Python</a></li>
                        <li><a href="https://www.safjan.com/the-role-and-responsibilities-of-a-forward-deployed-engineer/">The Role and Responsibilities of a Forward Deployed Engineer - Bridging the Gap Between Software Products and Customer Needs</a></li>
                        <li><a href="https://www.safjan.com/the-best-vector-databases-for-storing-embeddings/">The Best Vector Databases for Storing Embeddings</a></li>
                        <li><a href="https://www.safjan.com/attacking-differential-privacy-using-the-correlation-between-the-features/">Attacking Differential Privacy Using the Correlation Between the Features</a></li>
                        <li><a href="https://www.safjan.com/measure-quality-of-embeddings-intrinsic-vs-extrinsic/">Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?</a></li>
                </ul>
            </div>

  <div class="neighbors">
    <a class="btn float-left" href="https://www.safjan.com/the-best-vector-databases-for-storing-embeddings/" title="The Best Vector Databases for Storing Embeddings">
      <i class="fa fa-angle-left"></i> Previous Post
    </a>
    <a class="btn float-right" href="https://www.safjan.com/how-to-count-tokens/" title="How to Count Tokens - Tokenization With Tiktoken.">
      Next Post <i class="fa fa-angle-right"></i>
    </a>
  </div>


    </article>

    <footer>
<p>
  &copy; 2023 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
</main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Krystian Safjan's Blog ",
  "url" : "https://www.safjan.com",
  "image": "/images/profile_new.jpg",
  "description": ""
}
</script>

</body>
</html>