
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="color-scheme" content="light dark"/>
    <script>
      (function() {
        var theme = localStorage.getItem('theme-preference');
        if (theme === 'dark' || theme === 'light') {
          document.documentElement.setAttribute('data-theme', theme);
        }
      })();
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/stylesheet/style.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/pygments/github.min.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/solid.css">

    <link rel="stylesheet" href="http://127.0.0.1:8000/pagefind/pagefind-ui.css">

        <link rel="stylesheet" type="text/css"
              href="http://127.0.0.1:8000/styles/custom.css">








    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Discover how the LIME method can help you understand the important factors behind your model&#39;s predictions in a simple, intuitive way."/>
    <meta name="keywords" content="machine-learning, python, lime, xai, explainable-ai">


  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="LIME - Understanding How This Method for Explainable AI Works"/>
  <meta property="og:description" content="Discover how the LIME method can help you understand the important factors behind your model&#39;s predictions in a simple, intuitive way."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="http://127.0.0.1:8000/how-the-lime-method-for-explainable-ai-works/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-04-14 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2023-04-14 00:00:00+02:00"/>
  <meta property="article:author" content="http://127.0.0.1:8000/author/krystian-safjan/"/>
  <meta property="article:section" content="Responsible AI"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="python"/>
  <meta property="article:tag" content="lime"/>
  <meta property="article:tag" content="xai"/>
  <meta property="article:tag" content="explainable-ai"/>
  <meta property="og:image" content="http://127.0.0.1:8000//images/head/lime.jpg"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="http://127.0.0.1:8000//images/head/lime.jpg"/>
    <meta name="twitter:image:alt" content="LIME - Understanding How This Method for Explainable AI Works"/>


    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:creator" content="@izikeros"/>
    <meta name="twitter:title" content="LIME - Understanding How This Method for Explainable AI Works"/>
    <meta name="twitter:description" content="Discover how the LIME method can help you understand the important factors behind your model's predictions in a simple, intuitive way."/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://127.0.0.1:8000/how-the-lime-method-for-explainable-ai-works/"
  },
  "headline": "LIME - Understanding How This Method for Explainable AI Works",
  "datePublished": "2023-04-14T00:00:00+02:00",
  "dateModified": "2023-04-14T00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Krystian Safjan",
    "url": "http://127.0.0.1:8000/author/krystian-safjan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Krystian Safjan's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/profile_new.jpg"
    }  },
"image": "http://127.0.0.1:8000//images/head/lime.jpg",  "url": "http://127.0.0.1:8000/how-the-lime-method-for-explainable-ai-works/",
  "description": "Discover how the LIME method can help you understand the important factors behind your model's predictions in a simple, intuitive way."
}
</script>

    <title>    LIME - Understanding How This Method for Explainable AI Works
</title>



<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body>
<div id="reading-progress" class="reading-progress"></div>
<aside>
    <div>
        <a href="http://127.0.0.1:8000/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="http://127.0.0.1:8000/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>


        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<div class="promo-box">
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-image">
        <img src="/images/mlop_interview_book_cover_3D_300px.jpg" alt="MLOps Interview Book Cover">
    </a>
    
    <p class="promo-box-headline">Ace Your MLOps Interview</p>
    
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-cta">
        Get for $2.99
    </a>
    
    <p class="promo-box-features">50 Q&A • PDF/ePUB/mobi</p>
</div>
</aside>
<main>

        <nav>
            <a href="http://127.0.0.1:8000/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>



            <div id="search" class="nav-search"></div>
            <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">
                <i class="fas fa-sun"></i>
                <i class="fas fa-moon"></i>
            </button>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-04-14 


                    <span class="share-icons">
                        <a href="https://twitter.com/intent/tweet?text=LIME%20-%20Understanding%20How%20This%20Method%20for%20Explainable%20AI%20Works&url=http%3A//127.0.0.1%3A8000/how-the-lime-method-for-explainable-ai-works/&via=izikeros&hashtags=machine-learning,python,lime,xai,explainable-ai" target="_blank" title="Share on Twitter" class="share-icon"><i class="fab fa-twitter"></i></a>
                        <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//127.0.0.1%3A8000/how-the-lime-method-for-explainable-ai-works/" target="_blank" title="Share on Facebook" class="share-icon"><i class="fab fa-facebook"></i></a>
                        <a href="https://news.ycombinator.com/submitlink?t=LIME%20-%20Understanding%20How%20This%20Method%20for%20Explainable%20AI%20Works&u=http%3A//127.0.0.1%3A8000/how-the-lime-method-for-explainable-ai-works/" target="_blank" title="Share on Hacker News" class="share-icon"><i class="fab fa-hacker-news"></i></a>
                        <a href="https://www.reddit.com/submit?url=http%3A//127.0.0.1%3A8000/how-the-lime-method-for-explainable-ai-works/&title=LIME%20-%20Understanding%20How%20This%20Method%20for%20Explainable%20AI%20Works" target="_blank" title="Share on Reddit" class="share-icon"><i class="fab fa-reddit"></i></a>
                    </span>
                <br/>
            </p>
            <h1 id="how-the-lime-method-for-explainable-ai-works">LIME - Understanding How This Method for Explainable AI Works</h1>
            <div class="header-underline"></div>
                <p class="summary"><p>Discover how the LIME method can help you understand the important factors behind your model's predictions in a simple, intuitive way.</p></p>

                <div style="width: 100%; padding-bottom: 30px; position: relative;">
                    <a href="http://127.0.0.1:8000/how-the-lime-method-for-explainable-ai-works/">
                        <img style="width: 100%; "
                             src="/images/head/lime.jpg" alt="">
                    </a>
                </div>


        </header>



        <details class="toc-details" id="toc-container">
            <summary>Table of Contents</summary>
            <nav class="toc" aria-label="Table of Contents">
                <ul class="toc-list"></ul>
            </nav>
        </details>

        <div class="article-content">
            <p>Artificial intelligence (AI) has revolutionized the way we live and work, but it can sometimes be difficult to understand how AI algorithms reach their decisions. This is where explainable AI (XAI) comes in. XAI is the process of making AI models transparent and understandable to humans. One popular XAI method is Local Interpretable Model-Agnostic Explanations (LIME). In this blog post, we will explore how LIME works and why it is an important tool for XAI.</p>
<h2 id="the-need-for-explainable-ai">The need for Explainable AI</h2>
<p>One of the main criticisms of AI is its "black box" nature. Many AI models, such as deep neural networks, are complex and difficult to interpret. When these models are used in high-stakes applications like healthcare or finance, it is important to understand how the AI arrived at its decision. This is where XAI comes in. XAI provides a framework for understanding how an AI model makes decisions, increasing trust and accountability.</p>
<h2 id="lime-a-local-interpretable-model-agnostic-explanation-method">LIME: A Local Interpretable Model-Agnostic Explanation Method</h2>
<p>LIME is a popular XAI method that provides local, interpretable explanations for individual predictions made by any machine learning model. LIME was introduced in 2016 in the paper <a href="https://arxiv.org/abs/1602.04938">“Why Should I Trust You?”: Explaining the Predictions of Any Classifier”</a> by Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin, and has since become a widely used method for XAI.</p>
<p>LIME works by creating a simpler, interpretable model that approximates the behavior of the complex model. The simpler model is trained on local data points, and the resulting model is used to explain the decision of the complex model. The process involves the following steps:</p>
<ol>
<li>Selecting an instance to explain</li>
<li>Perturbing the instance to create a dataset of similar instances</li>
<li>Weighting the similar instances based on their similarity to the instance to explain</li>
<li>Training a local, interpretable model on the weighted dataset</li>
<li>Using the local model to generate explanations for the complex model's decision</li>
</ol>
<p>Let's explore each of these steps in more detail.</p>
<h3 id="step-1-selecting-an-instance-to-explain">Step 1: Selecting an instance to explain</h3>
<p>The first step in the LIME process is selecting an instance to explain. This could be an individual data point or an entire dataset. For example, if we are working with a healthcare AI model, we may want to explain the decision to recommend a certain treatment for a specific patient.</p>
<h3 id="step-2-perturbing-the-instance-to-create-a-dataset-of-similar-instances">Step 2: Perturbing the instance to create a dataset of similar instances</h3>
<p>Once we have selected the instance to explain, we perturb it to create a dataset of similar instances. This involves making small changes to the instance while keeping its label (i.e. the prediction of the complex model) the same. The purpose of this step is to create a diverse set of instances that are similar to the instance we want to explain.</p>
<h3 id="step-3-weighting-the-similar-instances-based-on-their-similarity-to-the-instance-to-explain">Step 3: Weighting the similar instances based on their similarity to the instance to explain</h3>
<p>After we have created a dataset of similar instances, we need to weight them based on their similarity to the instance we want to explain. This is done using a kernel function, which assigns a weight to each instance based on its distance to the instance to explain. The kernel function can be any function that measures similarity, such as the Gaussian kernel.</p>
<h3 id="step-4-training-a-local-interpretable-model-on-the-weighted-dataset">Step 4: Training a local, interpretable model on the weighted dataset</h3>
<p>Now that we have a weighted dataset, we can train a local, interpretable model on it. The purpose of this model is to approximate the behavior of the complex model in the local region around the instance we want to explain. The local model should be simple enough to be easily interpretable, but accurate enough to capture the important features of the complex model.</p>
<p>The choice of local model depends on the problem domain and the complexity of the complex model. Some common choices include linear models, decision trees, and rule-based models.</p>
<h3 id="step-5-using-the-local-model-to-generate-explanations-for-the-complex-models-decision">Step 5: Using the local model to generate explanations for the complex model's decision</h3>
<p>Once we have trained the local model, we can use it to generate explanations for the complex model's decision. This is done by analyzing the coefficients of the local model and identifying the features that contributed the most to the prediction. These features can be presented to the user as a list of important factors that influenced the decision.</p>
<h2 id="advantages-of-lime">Advantages of LIME</h2>
<p>LIME has several advantages over other XAI methods. One of the main advantages is its model-agnostic nature. LIME can be used to explain the decisions of any machine learning model, regardless of its complexity or the algorithm used. This makes it a versatile tool for XAI.</p>
<p>Another advantage of LIME is its ability to generate local explanations. By creating a local model that approximates the behavior of the complex model, LIME is able to generate explanations that are tailored to specific instances. This can be useful in situations where the explanation for a decision needs to be customized for a particular user or context.</p>
<h2 id="limitations-of-lime">Limitations of LIME</h2>
<p>Despite its many advantages, LIME also has some limitations. One of the main limitations is the need for human input in the kernel function. The choice of kernel function and its parameters can have a significant impact on the explanations generated by LIME. This means that the user needs to have some domain knowledge and expertise in selecting an appropriate kernel function.</p>
<p>Another limitation of LIME is its sensitivity to perturbations. LIME works by perturbing the instance to create a dataset of similar instances. However, small changes to the instance can result in significantly different explanations. This means that the explanations generated by LIME may not always be robust to changes in the input.</p>
<h2 id="conclusion">Conclusion</h2>
<p>LIME is a powerful tool for XAI that provides local, interpretable explanations for individual predictions made by any machine learning model. By creating a simpler, interpretable model that approximates the behavior of the complex model, LIME is able to generate explanations that are tailored to specific instances. However, LIME also has some limitations, such as its sensitivity to perturbations and the need for human input in the kernel function. Despite these limitations, LIME remains an important tool for XAI and is widely used in industry and academia.</p>
<p><em>Any comments or suggestions? <a href="mailto:ksafjan@gmail.com?subject=Blog+post">Let me know</a>.</em></p>
        </div>




            <div class="bibtex-note">
                <p><b>To cite this article:</b></p>
                <pre>@article{Saf2023LIME,
    author  = {Krystian Safjan},
    title   = {LIME - Understanding How This Method for Explainable AI Works},
    journal = {Krystian's Safjan Blog},
    year    = {2023},
}</pre>
            </div>
        <div class="article-tags">
            <span class="tags-label">Tags:</span>
                <a href="http://127.0.0.1:8000/tag/machine-learning/" class="article-tag">machine-learning</a>
                <a href="http://127.0.0.1:8000/tag/python/" class="article-tag">python</a>
                <a href="http://127.0.0.1:8000/tag/lime/" class="article-tag">lime</a>
                <a href="http://127.0.0.1:8000/tag/xai/" class="article-tag">xai</a>
                <a href="http://127.0.0.1:8000/tag/explainable-ai/" class="article-tag">explainable-ai</a>
        </div>





            <div class="related-posts">
                <h4 class="related-posts-title">You might also like</h4>
                <div class="related-posts-grid">
                        <a href="http://127.0.0.1:8000/are-lime-explanations-any-useful/" class="related-post-card">
                            <span class="related-post-title">Are LIME Explanations Any Useful?</span>
                            <span class="related-post-date">Apr 18, 2023</span>
                        </a>
                        <a href="http://127.0.0.1:8000/how-the-shap-method-for-explainable-ai-works/" class="related-post-card">
                            <span class="related-post-title">SHAP - Understanding How This Method for Explainable AI Works</span>
                            <span class="related-post-date">Apr 14, 2023</span>
                        </a>
                        <a href="http://127.0.0.1:8000/lime-tutorial/" class="related-post-card">
                            <span class="related-post-title">LIME Tutorial</span>
                            <span class="related-post-date">Apr 14, 2023</span>
                        </a>
                        <a href="http://127.0.0.1:8000/attacking-differential-privacy-using-the-correlation-between-the-features/" class="related-post-card">
                            <span class="related-post-title">Attacking Differential Privacy Using the Correlation Between the Features</span>
                            <span class="related-post-date">Apr 19, 2023</span>
                        </a>
                </div>
            </div>




    </article>

    <footer>
<p>
  &copy; 2026 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>    </footer>
</main>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "Krystian Safjan's Blog",
  "url": "http://127.0.0.1:8000",
"image": "/images/profile_new.jpg",  "description": ""
}
</script>


<script src="http://127.0.0.1:8000/pagefind/pagefind-ui.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', function() {
        new PagefindUI({
            element: "#search",
            showSubResults: false,
            showImages: false
        });
    });
</script>

<script src="http://127.0.0.1:8000/theme/js/theme-switcher.js"></script>
</body>
</html>