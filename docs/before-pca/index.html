
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/stylesheet/style.min.css">



        <link id="pygments-light-theme" rel="stylesheet" type="text/css"
              href="https://www.safjan.com/theme/pygments/github.min.css">



    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/solid.css">

        <link rel="stylesheet" type="text/css"
              href="https://www.safjan.com/styles/custom.css">

        <link href="https://www.safjan.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Krystian Safjan's Blog Atom">

        <link href="https://www.safjan.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="Krystian Safjan's Blog RSS">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RM2PKDCCYM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RM2PKDCCYM');
</script>
<!-- End of Google tag (gtag.js) -->



    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Principal Component Analysis (PCA) is a popular technique used for dimensionality reduction. It involves transforming a dataset into a new coordinate system that consists of principal components, which are linear combinations of the original features. PCA is useful for reducing the number …"/>
    <meta name="keywords" content="data-preprocessing, pca, dimensionality-reduction, python, interpretability, categorical-variables, multicollinearity, imbalanced-data">
    <meta expr:content="2023-02-20 00:00:00+01:00" itemprop='datePublished'/>
    <meta expr:content="2023-02-20 00:00:00+01:00" itemprop='dateModified'/>
    <meta property="article:modified_time" content="2023-02-20 00:00:00+01:00"/>
    <meta property="article:published_time" content="2023-02-20 00:00:00+01:00"/>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Checks and Data preprocessing steps before applying PCA",
  "datePublished": "2023-02-20 00:00:00+01:00",
  "dateModified": "2023-02-20 00:00:00+01:00"
}








    </script>



  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Checks and Data preprocessing steps before applying PCA"/>
  <meta property="og:description" content="Principal Component Analysis (PCA) is a popular technique used for dimensionality reduction. It involves transforming a dataset into a new coordinate system that consists of principal components, which are linear combinations of the original features. PCA is useful for reducing the number …"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://www.safjan.com/before-pca/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-02-20 00:00:00+01:00"/>
  <meta property="article:modified_time" content="2023-02-20 00:00:00+01:00"/>
  <meta property="article:author" content="https://www.safjan.com/author/krystian-safjan/">
  <meta property="article:section" content="note"/>
  <meta property="article:tag" content="data-preprocessing"/>
  <meta property="article:tag" content="pca"/>
  <meta property="article:tag" content="dimensionality-reduction"/>
  <meta property="article:tag" content="python"/>
  <meta property="article:tag" content="interpretability"/>
  <meta property="article:tag" content="categorical-variables"/>
  <meta property="article:tag" content="multicollinearity"/>
  <meta property="article:tag" content="imbalanced-data"/>
  <meta property="og:image" content="/images/profile_new.jpg">

    <meta name="twitter:card" content="summary"/>
    <meta property="twitter:image" content="/images/profile_new.jpg">

    <meta name="twitter:label1" content="Est. reading time"/>
    <meta name="twitter:data1" content="4 min."/>
    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:description" content=""/>
    <meta name="twitter:title" content="Checks and Data preprocessing steps before applying PCA"/>


    <title>    Checks and Data preprocessing steps before applying PCA
</title>


<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body class="light-theme">
<aside>
    <div>
        <a href="https://www.safjan.com/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="https://www.safjan.com/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some  <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>




        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<style>
    .button {
        background-color: yellow;
        color: black;
        border: none;
        padding: 10px 20px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
        border-radius: 20px;
    }

    .center {
        text-align: center;
    }

    .container {
        display: grid;
        grid-template-columns: 1fr 1fr;
    }

    .left-col {
    }

    .right-col {
    }

    .image {
        border-radius: 0;
        width: 100%;
    }

    .book-list {
        padding-top:0;
        padding-bottom: 0;
        text-align:left;
        box-sizing: border-box;
        display: block;
        list-style-image: url(/images/shortcode-tick.webp);
        margin-block-start: 1em;
        margin-block-end: 1em;
        margin-inline-start:0;
        margin-inline-end:0;
        padding-inline-start:40px;
    }

    .book-list li {
        font-weight: bold;
    }

    @media (max-width: 600px) {
        .container {
            grid-template-columns: 1fr;
        }
    }

</style>
<div class="container">
    <div class="left-col">
        <a href="https://ksafjanuser.gumroad.com/l/mlops">
            <img src="/images/mlop_interview_book_cover_3D_300px.jpg" class="image" alt="Interview Book Cover">
        </a>

        <div class="center">
            <a href="https://ksafjanuser.gumroad.com/l/mlops">
                <button class="button">Get for $2.99</button>
            </a>
        </div>
    </div>
    <div class="right-col">
        <div>
            <ul class="book-list">
                <li>PDF, ePUB, mobi format ebook, no DRM</li>
                <li>50 questions and answers</li>
                <li>Stories from real projects</li>
                <li>92 multiple choice quiz questions</li>
                <li>80 pages</li>
            </ul>
        </div>
    </div>
</div>
</aside>
<main>

        <nav>
            <a href="https://www.safjan.com/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/tags.html">Tags</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>

                <a href="https://www.safjan.com/feeds/all.atom.xml">Atom</a>

                <a href="https://www.safjan.com/feeds/all.rss.xml">RSS</a>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-02-20 



                    <span id="post-share-links">
    &nbsp;&nbsp;&nbsp;Share on:
    <a href="https://twitter.com/intent/tweet?text=Checks%20and%20Data%20preprocessing%20steps%20before%20applying%20PCA&url=https%3A//www.safjan.com/before-pca/&hashtags=data-preprocessing,pca,dimensionality-reduction,python,interpretability,categorical-variables,multicollinearity,imbalanced-data" target="_blank" title="Share on Twitter">Twitter</a>
    |
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//www.safjan.com/before-pca/" target="_blank" title="Share on Facebook">Facebook</a>
    |
    <a href="https://news.ycombinator.com/submitlink?t=Checks%20and%20Data%20preprocessing%20steps%20before%20applying%20PCA&u=https%3A//www.safjan.com/before-pca/" target="_blank" title="Share on HackerNews">HackerNews</a>
    |
    <a href="https://www.reddit.com/submit?url=https%3A//www.safjan.com/before-pca/&title=Checks%20and%20Data%20preprocessing%20steps%20before%20applying%20PCA" target="_blank" title="Share via Reddit">Reddit</a>
  </span>
                <br/>
            </p>
            <h1 id="before-pca">Checks and Data preprocessing steps before applying PCA</h1>
            <div class="header-underline"></div>



        </header>


        <div>
            <p>Principal Component Analysis (PCA) is a popular technique used for dimensionality reduction. It involves transforming a dataset into a new coordinate system that consists of principal components, which are linear combinations of the original features. PCA is useful for reducing the number of features in a dataset, while still retaining most of the information.</p>
<!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" -->

<ul>
<li><a href="#preparations-to-pca">Preparations to PCA</a><ul>
<li><a href="#data-cleaning">Data Cleaning</a></li>
<li><a href="#data-standardization">Data Standardization</a></li>
<li><a href="#feature-selection">Feature Selection</a></li>
<li><a href="#check-for-linearity">Check for Linearity</a></li>
<li><a href="#determine-the-number-of-components">Determine the number of components</a></li>
<li><a href="#interpret-the-components">Interpret the components</a></li>
<li><a href="#consider-the-trade-off-between-dimensionality-reduction-and-interpretability">Consider the trade-off between dimensionality reduction and interpretability</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#extra-steps">Extra steps</a><ul>
<li><a href="#handle-categorical-variables">Handle categorical variables</a></li>
<li><a href="#address-multicollinearity">Address multicollinearity</a></li>
<li><a href="#handle-imbalanced-data">Handle imbalanced data</a></li>
</ul>
</li>
</ul>
<!-- /MarkdownTOC -->

<p><a id="preparations-to-pca"></a></p>
<h2>Preparations to PCA</h2>
<p>Before applying PCA to a dataset, it's important to consider the following steps:</p>
<p><a id="data-cleaning"></a></p>
<h3>Data Cleaning</h3>
<p>Before any analysis, we need to check the dataset for missing values, outliers, and any other data quality issues. These issues can affect the accuracy of the PCA model. If we have missing values, we can either remove the corresponding records or impute the missing values. If we have outliers, we may want to remove them or transform them to reduce their impact on the analysis.</p>
<p><a id="data-standardization"></a></p>
<h3>Data Standardization</h3>
<p>PCA is sensitive to the scale of the data, so we need to standardize the data before applying PCA. Standardization involves scaling the data so that each feature has a mean of 0 and a standard deviation of 1. This step is important because PCA will give more importance to features with larger variances.</p>
<p><a id="feature-selection"></a></p>
<h3>Feature Selection</h3>
<p>Before applying PCA, it's a good idea to perform feature selection to remove any irrelevant or redundant features. This can help to improve the performance of the PCA model and reduce the computational complexity. Feature selection can be performed using techniques such as correlation analysis, feature importance, or model-based selection.</p>
<p><a id="check-for-linearity"></a></p>
<h3>Check for Linearity</h3>
<p>PCA assumes that the relationships between the features are linear. It's important to check for linearity before applying PCA, as non-linear relationships can lead to inaccurate results. We can check for linearity using scatter plots or other visualization techniques.</p>
<p>Once we have completed these steps, we can apply PCA to the pre-processed data. Here's an example of how to perform PCA using the scikit-learn library in Python:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Load the dataset</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>

<span class="c1"># Data standardization</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Perform PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>

<span class="c1"># Visualize the results</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p>In this example, we load the iris dataset, standardize the data, perform PCA, and visualize the results. We can see that the first two principal components capture most of the variation in the data.</p>
<p>In conclusion, before applying PCA to a dataset for dimensionality reduction, we need to perform data cleaning, data standardization, feature selection, and check for linearity. These steps can help to improve the accuracy of the PCA model and ensure that we are getting the most out of the data.</p>
<p><a id="determine-the-number-of-components"></a></p>
<h3>Determine the number of components</h3>
<p>Before applying PCA, it's important to decide on the number of principal components to retain. This depends on the amount of variance we want to preserve in the data. A common approach is to choose the number of components that explain a certain percentage of the total variance, such as 95% or 99%. We can use the <code>explained_variance_ratio_</code> attribute of the PCA model to determine the proportion of variance explained by each component.</p>
<p><a id="interpret-the-components"></a></p>
<h3>Interpret the components</h3>
<p>After applying PCA, it's important to interpret the principal components to understand the relationships between the original features. Each principal component is a linear combination of the original features, so we can examine the loadings of each component to determine which features are most strongly associated with that component. We can use the <code>components_</code> attribute of the PCA model to access the loadings.</p>
<p><a id="consider-the-trade-off-between-dimensionality-reduction-and-interpretability"></a></p>
<h3>Consider the trade-off between dimensionality reduction and interpretability</h3>
<p>While PCA can be a useful tool for reducing the dimensionality of a dataset, it's important to consider the trade-off between dimensionality reduction and interpretability. When we reduce the number of features, we may lose some of the original information and make it more difficult to interpret the results. We can use domain knowledge and visualization techniques to help us interpret the results.</p>
<p>Here's an example of how to interpret the principal components using the iris dataset:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Interpret the components</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PC</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">feature</span><span class="p">,</span><span class="w"> </span><span class="n">coef</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">zip</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span><span class="w"> </span><span class="n">component</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>This code prints out the loadings for each principal component. We can see that the first principal component is strongly associated with sepal length and petal length, while the second principal component is strongly associated with petal width.</p>
<p><a id="conclusion"></a></p>
<h2>Conclusion</h2>
<p>Before applying PCA for dimensionality reduction, we need to determine the number of components to retain, interpret the principal components, and consider the trade-off between dimensionality reduction and interpretability. PCA can be a powerful tool for reducing the dimensionality of a dataset, but it's important to use it judiciously and interpret the results carefully.</p>
<p><a id="extra-steps"></a></p>
<h2>Extra steps</h2>
<p>Here are a few more pre-processing steps that can be useful before applying PCA.</p>
<p><a id="handle-categorical-variables"></a></p>
<h3>Handle categorical variables</h3>
<p>PCA is designed to work with continuous numerical data, so if our dataset contains categorical variables, we need to convert them to numerical values before applying PCA. This can be done using techniques such as one-hot encoding or label encoding. One-hot encoding creates a binary variable for each category, while label encoding assigns a numerical value to each category.</p>
<p><a id="address-multicollinearity"></a></p>
<h3>Address multicollinearity</h3>
<p>If our dataset contains features that are highly correlated with each other, this can lead to multicollinearity, which can affect the accuracy of the PCA model. We can check for multicollinearity using techniques such as correlation analysis or variance inflation factors (VIF). If we find that our dataset has high multicollinearity, we may want to consider removing some of the correlated features.</p>
<p><a id="handle-imbalanced-data"></a></p>
<h3>Handle imbalanced data</h3>
<p>If our dataset is imbalanced, with some classes having many more observations than others, this can affect the accuracy of the PCA model. We can use techniques such as oversampling or undersampling to balance the classes before applying PCA.</p>
<p>Here's an example of how to handle categorical variables using one-hot encoding:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Load the dataset</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>

<span class="c1"># One-hot encoding</span>
<span class="n">data_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">])</span>
</code></pre></div>

<p>In this example, we use the <code>get_dummies()</code> function from pandas to convert the categorical variable 'category' into binary variables.</p>
        </div>


        <div class="tag-cloud">
            <p>
                    <br/><br/>Tags:&nbsp;
                        <a href="https://www.safjan.com/tag/data-preprocessing/">data-preprocessing</a>
                        <a href="https://www.safjan.com/tag/pca/">pca</a>
                        <a href="https://www.safjan.com/tag/dimensionality-reduction/">dimensionality-reduction</a>
                        <a href="https://www.safjan.com/tag/python/">python</a>
                        <a href="https://www.safjan.com/tag/interpretability/">interpretability</a>
                        <a href="https://www.safjan.com/tag/categorical-variables/">categorical-variables</a>
                        <a href="https://www.safjan.com/tag/multicollinearity/">multicollinearity</a>
                        <a href="https://www.safjan.com/tag/imbalanced-data/">imbalanced-data</a>
            </p>
        </div>








            <div class="related-posts">
                <h4>You might enjoy</h4>
                <ul class="related-posts">
                        <li><a href="https://www.safjan.com/demystifying-perplexity-assessing-dimensionality-reduction-with-pca/">Demystifying Perplexity: Assessing Dimensionality Reduction with PCA</a></li>
                        <li><a href="https://www.safjan.com/tsne-tutorial/">Unleashing the Power of T-SNE for Dimensionality Reduction in Python</a></li>
                        <li><a href="https://www.safjan.com/script-to-python-package-using-poetry-and-pycharm/">Script to Python package using Poetry (and PyCharm)</a></li>
                        <li><a href="https://www.safjan.com/bash-rename-mutliple-image-files-to-match-pattern-with-sequence-number/">Bash - rename multiple image files to match pattern with sequence number</a></li>
                        <li><a href="https://www.safjan.com/the-role-and-responsibilities-of-a-forward-deployed-engineer/">The Role and Responsibilities of a Forward Deployed Engineer - Bridging the Gap between Software Products and Customer Needs</a></li>
                </ul>
            </div>

  <div class="neighbors">
    <a class="btn float-left" href="https://www.safjan.com/eli5-tutorial/" title="Understanding AI with ELI5 - Demystifying Decisions (tutorial)">
      <i class="fa fa-angle-left"></i> Previous Post
    </a>
    <a class="btn float-right" href="https://www.safjan.com/anchor-explanations/" title="Explainable AI - Anchor Explanations">
      Next Post <i class="fa fa-angle-right"></i>
    </a>
  </div>


    </article>

    <footer>
<p>
  &copy; 2023 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
</main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Krystian Safjan's Blog ",
  "url" : "https://www.safjan.com",
  "image": "/images/profile_new.jpg",
  "description": ""
}
</script>

</body>
</html>