<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Krystian Safjan's Blog</title><link href="https://www.safjan.com/" rel="alternate"></link><link href="https://www.safjan.com/feeds/all.atom.xml" rel="self"></link><id>https://www.safjan.com/</id><updated>2024-10-03T00:00:00+02:00</updated><subtitle>Data Scientist | Researcher | Team Leader&lt;br&gt;&lt;br&gt; working at Ernst &amp;amp; Young and writing about &lt;a href="/category/machine-learning.html"&gt;Data Science and Visualization&lt;/a&gt;, on &lt;a href="/category/machine-learning.html"&gt;Machine Learning, Deep Learning&lt;/a&gt; and &lt;a href="/tag/nlp/"&gt;NLP&lt;/a&gt;. There are also some  &lt;a href="/category/howto.html"&gt;howto&lt;/a&gt; posts on tools and workflows.</subtitle><entry><title>Quick Ways to Disable GitHub Actions Workflows Without Deletion</title><link href="https://www.safjan.com/quick-ways-to-disable-github-actions-workflows-without-deletion/" rel="alternate"></link><published>2024-10-03T00:00:00+02:00</published><updated>2024-10-03T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-10-03:/quick-ways-to-disable-github-actions-workflows-without-deletion/</id><summary type="html">&lt;p&gt;GitHub Actions workflows are powerful automation tools, but sometimes you need to temporarily disable them. Here are three simple methods to pause a workflow without deleting its YAML file:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Comment out the file: Add '#' at the start of each line in the …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;GitHub Actions workflows are powerful automation tools, but sometimes you need to temporarily disable them. Here are three simple methods to pause a workflow without deleting its YAML file:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Comment out the file: Add '#' at the start of each line in the workflow file.&lt;/li&gt;
&lt;li&gt;Use manual triggers: Replace existing triggers with &lt;code&gt;on: workflow_dispatch&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Add a false condition: Insert &lt;code&gt;if: false&lt;/code&gt; under the &lt;code&gt;jobs&lt;/code&gt; key.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Example of method 3&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;My Workflow&lt;/span&gt;

&lt;span class="nt"&gt;on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;push&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;branches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;main&lt;/span&gt;&lt;span class="p p-Indicator"&gt;]&lt;/span&gt;

&lt;span class="nt"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;if&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;false&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# This disables the entire workflow&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;runs-on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ubuntu-latest&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;actions/checkout@v2&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;# ... rest of the job steps&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="github"></category><category term="github-actions"></category><category term="workflow"></category><category term="ci"></category><category term="yaml"></category></entry><entry><title>Pandas Categorical - Benefits and Use Cases</title><link href="https://www.safjan.com/pandas-categorical-benefits-and-use-cases/" rel="alternate"></link><published>2024-10-01T00:00:00+02:00</published><updated>2024-10-01T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-10-01:/pandas-categorical-benefits-and-use-cases/</id><summary type="html">&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Memory efficiency&lt;/strong&gt;: Uses less memory for data with limited unique values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved performance&lt;/strong&gt;: Faster computations and aggregations, especially for large datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meaningful order&lt;/strong&gt;: Allows custom ordering of categories for sorting and plotting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type safety&lt;/strong&gt;: Ensures only predefined categories can be …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Memory efficiency&lt;/strong&gt;: Uses less memory for data with limited unique values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improved performance&lt;/strong&gt;: Faster computations and aggregations, especially for large datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meaningful order&lt;/strong&gt;: Allows custom ordering of categories for sorting and plotting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type safety&lt;/strong&gt;: Ensures only predefined categories can be assigned, preventing errors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Faster groupby operations&lt;/strong&gt;: Improves performance when grouping data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These benefits are most noticeable with large datasets and columns having a limited number of unique values that repeat frequently.&lt;/p&gt;
&lt;p&gt;Using pandas categorical data type instead of int or string can be beneficial in several scenarios. Here are some reasons and examples where using categorical is better:&lt;/p&gt;
&lt;h2&gt;1. Memory efficiency&lt;/h2&gt;
&lt;p&gt;For datasets with a limited number of unique values that repeat frequently, categorical data uses less memory than int or string.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Create a large DataFrame with repeated values&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;status&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;active&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;inactive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)})&lt;/span&gt;

&lt;span class="c1"&gt;# Compare memory usage&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;String dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;status&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;memory_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; MB&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Categorical dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;status&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;memory_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.2f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; MB&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Outcome:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;64.00&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;MB&lt;/span&gt;
&lt;span class="nx"&gt;Categorical&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;1.00&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;MB&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;2. Improved performance&lt;/h2&gt;
&lt;p&gt;Categorical data can lead to faster computations and aggregations, especially for large datasets.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="c1"&gt;# Create a large DataFrame with repeated values&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;green&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yellow&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)})&lt;/span&gt;

&lt;span class="c1"&gt;# Compare performance for value_counts()&lt;/span&gt;
&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;String dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.4f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; seconds&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;color&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Categorical dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.4f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; seconds&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Outcome:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;0.0779&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;seconds&lt;/span&gt;
&lt;span class="nx"&gt;Categorical&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;0.0090&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;seconds&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3. Meaningful order&lt;/h2&gt;
&lt;p&gt;Categorical data allows you to specify a custom order for the categories, which is useful for sorting and plotting.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;size&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;small&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;medium&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;large&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;small&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;large&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;medium&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]})&lt;/span&gt;

&lt;span class="c1"&gt;# Create an ordered categorical column&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;size_cat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;size&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;small&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;medium&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;large&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ordered&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Sort by the categorical column&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;size_cat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Plot with a meaningful order&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;size_cat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kind&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;4. Type safety&lt;/h2&gt;
&lt;p&gt;Categorical data ensures that only predefined categories can be assigned, preventing data entry errors.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fruit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apple&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;banana&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cherry&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fruit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fruit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apple&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;banana&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cherry&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# This will raise a ValueError&lt;/span&gt;
&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orange&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Error: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;5. Improved groupby operations&lt;/h2&gt;
&lt;p&gt;Categorical data can speed up groupby operations, especially when there are many groups.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="c1"&gt;# Create a large DataFrame with repeated values&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;B&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;D&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;E&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="c1"&gt;# Compare performance for groupby operation&lt;/span&gt;
&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;String dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.4f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; seconds&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;category&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Categorical dtype: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.4f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; seconds&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;0.1000&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;seconds&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="nx"&gt;Categorical&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;0.0198&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;seconds&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="pandas"></category></entry><entry><title>Audio Notifications in Jupyter Notebooks Across Platforms</title><link href="https://www.safjan.com/audio-notifications-in-jupyter-notebooks-across-platforms/" rel="alternate"></link><published>2024-09-13T00:00:00+02:00</published><updated>2024-09-13T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-09-13:/audio-notifications-in-jupyter-notebooks-across-platforms/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Enhancing Your Notebook Experience with Sound Notifications&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When working with long-running operations in Jupyter notebooks or other interactive computing environments, it's often helpful to have audible notifications to alert you when tasks are complete. This is particularly useful when you're multitasking or …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Enhancing Your Notebook Experience with Sound Notifications&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When working with long-running operations in Jupyter notebooks or other interactive computing environments, it's often helpful to have audible notifications to alert you when tasks are complete. This is particularly useful when you're multitasking or working on time-consuming processes. In this post, we'll explore various methods to implement sound notifications across different platforms, with a special focus on macOS.&lt;/p&gt;
&lt;h2&gt;1. The Beepy Package: Cross-Platform Simplicity&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;beepy&lt;/code&gt; package offers a straightforward, cross-platform solution for playing notification sounds in Python. It's easy to install and use, making it an excellent choice for beginners and experienced users alike.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;beepy&lt;/span&gt;

&lt;span class="c1"&gt;# Play a notification sound&lt;/span&gt;
&lt;span class="n"&gt;beepy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;beep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sound&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;beepy&lt;/code&gt; package comes with several pre-defined sounds, identified by numbers 1-7. Here's a quick reference:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;'coin'&lt;/li&gt;
&lt;li&gt;'robot_error'&lt;/li&gt;
&lt;li&gt;'error'&lt;/li&gt;
&lt;li&gt;'ping'&lt;/li&gt;
&lt;li&gt;'ready'&lt;/li&gt;
&lt;li&gt;'success'&lt;/li&gt;
&lt;li&gt;'wilhelm'&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To use &lt;code&gt;beepy&lt;/code&gt;, first install it via pip:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install beepy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, you can easily integrate it into your notebook cells:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;

&lt;span class="c1"&gt;# Simulate a long-running operation&lt;/span&gt;
&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Play a notification sound&lt;/span&gt;
&lt;span class="n"&gt;beepy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;beep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sound&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# &amp;#39;ready&amp;#39; sound&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Operation complete!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;2. MacOS 'say' Command: Text-to-Speech Notifications&lt;/h2&gt;
&lt;p&gt;For macOS users, the built-in &lt;code&gt;say&lt;/code&gt; command provides a unique way to create custom voice notifications. This method turns text into speech, allowing for more informative alerts.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;notify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;say &amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;notify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;#39;m done now with the data processing task.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can customize the voice and speaking rate:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;say -v Samantha -r 200 &amp;quot;Your analysis is complete&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3. MacOS 'afplay' Command: System Sound Playback&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;afplay&lt;/code&gt; command in macOS allows you to play system sounds or custom audio files. First, you can list available system sounds:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Library&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Sounds&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, play a specific sound:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_sound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sound_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;afplay /System/Library/Sounds/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;sound_name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;.aiff&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;play_sound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hero&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;4. Playsound Library: Another Cross-Platform Option&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;playsound&lt;/code&gt; library offers a simple, cross-platform solution for playing sound files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;playsound&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;playsound&lt;/span&gt;

&lt;span class="c1"&gt;# Play an MP3 file&lt;/span&gt;
&lt;span class="n"&gt;playsound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;path/to/your/soundfile.mp3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Install it using pip:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install playsound
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;5. Windows-Specific Solution: Winsound&lt;/h2&gt;
&lt;p&gt;For Windows users, the built-in &lt;code&gt;winsound&lt;/code&gt; module provides a platform-specific option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;winsound&lt;/span&gt;

&lt;span class="c1"&gt;# Play a system sound&lt;/span&gt;
&lt;span class="n"&gt;winsound&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PlaySound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;SystemExclamation&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;winsound&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SND_ALIAS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Play a custom WAV file&lt;/span&gt;
&lt;span class="n"&gt;winsound&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PlaySound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;path/to/your/sound.wav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;winsound&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SND_FILENAME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;6. Web-Based Notebooks: JavaScript Audio&lt;/h2&gt;
&lt;p&gt;For web-based notebooks like Google Colab, you can use JavaScript to play audio:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Javascript&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;display&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Javascript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;        var audio = new Audio(&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;        audio.play();&lt;/span&gt;
&lt;span class="s2"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://example.com/notification.mp3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Happy coding, and may your long-running operations always end with a satisfying ding!&lt;/p&gt;</content><category term="note"></category><category term="jupyter-notebooks"></category><category term="audio-notifications"></category><category term="python"></category><category term="macos"></category><category term="windows"></category><category term="cross-platform"></category><category term="beepy"></category><category term="text-to-speech"></category><category term="afplay"></category><category term="playsound"></category><category term="winsound"></category><category term="javascript-audio"></category><category term="productivity"></category><category term="long-running-operations"></category><category term="workflow-enhancement"></category><category term="coding-alerts"></category><category term="custom-notifications"></category><category term="system-sounds"></category><category term="multiplatform-development"></category><category term="interactive-computing"></category></entry><entry><title>Notes on using ripgrep for projects with python, jupyter (ipynb) notebooks and markdown files</title><link href="https://www.safjan.com/notes-on-using-ripgrep-for-projects-with-python-jupyter-ipynb-notebooks-and/" rel="alternate"></link><published>2024-09-13T00:00:00+02:00</published><updated>2024-09-13T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-09-13:/notes-on-using-ripgrep-for-projects-with-python-jupyter-ipynb-notebooks-and/</id><summary type="html">&lt;p&gt;Notes on using ripgrep (rg) mainly for use cases as a Python developer working with .py, .ipynb, and .md files:&lt;/p&gt;
&lt;h2&gt;Basic search&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;path/to/search
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search only Python files&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;--type&lt;span class="w"&gt; &lt;/span&gt;py&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search Jupyter notebooks&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;--type-add&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ipynb:*.ipynb …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Notes on using ripgrep (rg) mainly for use cases as a Python developer working with .py, .ipynb, and .md files:&lt;/p&gt;
&lt;h2&gt;Basic search&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;path/to/search
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search only Python files&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;--type&lt;span class="w"&gt; &lt;/span&gt;py&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search Jupyter notebooks&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;--type-add&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ipynb:*.ipynb&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--type&lt;span class="w"&gt; &lt;/span&gt;ipynb&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search Markdown files&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;--type&lt;span class="w"&gt; &lt;/span&gt;md&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Case-insensitive search&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search for whole words&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;-w&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;word&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Show context around matches&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;-C&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# 3 lines before and after&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search for multiple patterns&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern1|pattern2|pattern3&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Exclude specific directories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;   &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--glob&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;!{venv,__pycache__}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search for Python functions&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;def \w+\(&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;```&lt;/span&gt;

&lt;span class="c1"&gt;## Search for Markdown headers&lt;/span&gt;
&lt;span class="sb"&gt;```&lt;/span&gt;sh
&lt;span class="w"&gt;    &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;^#{1,6} .+&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;```&lt;/span&gt;

&lt;span class="c1"&gt;## Count matches&lt;/span&gt;
&lt;span class="sb"&gt;```&lt;/span&gt;sh
&lt;span class="w"&gt;    &lt;/span&gt;rg&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;```&lt;/span&gt;

&lt;span class="c1"&gt;## Display only the filenames where a pattern appears&lt;/span&gt;

To&lt;span class="w"&gt; &lt;/span&gt;display&lt;span class="w"&gt; &lt;/span&gt;only&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;filenames&lt;span class="w"&gt; &lt;/span&gt;where&lt;span class="w"&gt; &lt;/span&gt;a&lt;span class="w"&gt; &lt;/span&gt;pattern&lt;span class="w"&gt; &lt;/span&gt;appears,&lt;span class="w"&gt; &lt;/span&gt;you&lt;span class="w"&gt; &lt;/span&gt;can&lt;span class="w"&gt; &lt;/span&gt;use&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;-l&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;or&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;--files-with-matches&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;option&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;ripgrep.&lt;span class="w"&gt; &lt;/span&gt;Here&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s&lt;span class="w"&gt; &lt;/span&gt;how&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;it:

&lt;span class="sb"&gt;```&lt;/span&gt;sh
rg&lt;span class="w"&gt; &lt;/span&gt;-l&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;pattern&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Search for files with a specific name pattern&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;rg --files -g "*.py"&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Use AND logic for multiple patterns:&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;rg "pattern1" | rg "pattern2"&lt;/code&gt;&lt;/p&gt;</content><category term="note"></category><category term="ripgrep"></category><category term="grep"></category><category term="search"></category><category term="code-search"></category><category term="python-project"></category><category term="developer-tools"></category></entry><entry><title>VSCode problem - import could not be resolved from the source (Pylance)</title><link href="https://www.safjan.com/vscode-problem-import-could-not-be-resolved-from-the-source-pylance/" rel="alternate"></link><published>2024-09-10T00:00:00+02:00</published><updated>2024-09-10T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-09-10:/vscode-problem-import-could-not-be-resolved-from-the-source-pylance/</id><summary type="html">&lt;h2&gt;Problem description&lt;/h2&gt;
&lt;p&gt;In Visual Studio Code (VSCode), I'm working with a Jupyter notebook (.ipynb file) and encountering a linter warning related to the pandas library. Specifically, when I try to import pandas, I see the following warning:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Import &amp;quot;pandas&amp;quot; could not be …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h2&gt;Problem description&lt;/h2&gt;
&lt;p&gt;In Visual Studio Code (VSCode), I'm working with a Jupyter notebook (.ipynb file) and encountering a linter warning related to the pandas library. Specifically, when I try to import pandas, I see the following warning:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Import &amp;quot;pandas&amp;quot; could not be resolved from the source Pylance
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This warning appears as a squiggly underline beneath the import statement, and hovering over it displays the full error message.&lt;/p&gt;
&lt;p&gt;Important context:
1. I'm using VSCode as my integrated development environment (IDE).
2. The file I'm working on is a Jupyter notebook, not a regular Python script.
3. I have pandas installed in a virtual environment (virtualenv) that I've set up for this project.
4. Pylance, which is Microsoft's static type checking tool for Python, is raising this warning.
5. Despite the warning, the code runs without errors when I execute the cell.
6. This issue is specifically occurring within the notebook interface in VSCode, not in a regular Python file.&lt;/p&gt;
&lt;p&gt;The discrepancy between the successful execution and the linter warning suggests a potential misconfiguration in how VSCode or Pylance is interpreting my project setup, particularly in relation to the virtual environment or the notebook context.&lt;/p&gt;
&lt;h2&gt;Potential origins and troubleshooting steps&lt;/h2&gt;
&lt;p&gt;This issue often occurs when VSCode isn't correctly recognizing your virtual environment or the installed packages. &lt;/p&gt;
&lt;h3&gt;1. VSCode not using the correct Python interpreter:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure VSCode is using the Python interpreter from your virtualenv.&lt;/li&gt;
&lt;li&gt;Open the Command Palette (Ctrl+Shift+P) and select "Python: Select Interpreter".&lt;/li&gt;
&lt;li&gt;Choose the interpreter from your virtualenv.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Virtualenv not activated:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Make sure your virtualenv is activated in the terminal you're using within VSCode.&lt;/li&gt;
&lt;li&gt;You can activate it manually or set up VSCode to automatically activate it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Pandas not installed in the virtualenv:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Double-check that pandas is installed in your virtualenv.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;pip list&lt;/code&gt; in the terminal to verify.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Pylance configuration:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pylance might not be configured to recognize your virtualenv.&lt;/li&gt;
&lt;li&gt;Check your VSCode settings (settings.json) for Python and Pylance-related configurations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;5. Caching issues:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Sometimes VSCode or Pylance caches can cause issues.&lt;/li&gt;
&lt;li&gt;Try reloading the VSCode window (Ctrl+Shift+P, then "Developer: Reload Window").&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Options for fixing the problem:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Manually select the correct interpreter:
   Use the "Python: Select Interpreter" command as mentioned above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure python.pythonPath:
   In settings.json, set "python.pythonPath" to the path of your virtualenv's Python executable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a .env file:
   In your project root, create a .env file with &lt;code&gt;PYTHONPATH=/path/to/your/virtualenv/lib/python3.x/site-packages&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update Pylance settings:
   In settings.json, add or update:
   &lt;code&gt;json
   "python.analysis.extraPaths": ["/path/to/your/virtualenv/lib/python3.x/site-packages"]&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reinstall pandas:
   Activate your virtualenv and run &lt;code&gt;pip uninstall pandas&lt;/code&gt; followed by &lt;code&gt;pip install pandas&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update VSCode and extensions:
   Ensure VSCode and the Python extension are up to date.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you've tried these steps and still face issues, you might want to check for any conflicting extensions or consider creating a new virtualenv to rule out environment-specific problems.&lt;/p&gt;</content><category term="note"></category><category term="vscode"></category><category term="jupyter-notebook"></category><category term="pandas"></category><category term="pylance"></category><category term="python"></category><category term="virtualenv"></category><category term="linter-warning"></category><category term="import-error"></category><category term="troubleshooting"></category><category term="ide-configuration"></category><category term="python-environment"></category><category term="static-analysis"></category><category term="data-science"></category><category term="development-tools"></category><category term="coding-issues"></category></entry><entry><title>How to Remove Diacritics and Sanitize Strings in Python</title><link href="https://www.safjan.com/how-to-remove-diacritics-and-sanitize-strings-in-python/" rel="alternate"></link><published>2024-08-30T00:00:00+02:00</published><updated>2024-08-30T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-08-30:/how-to-remove-diacritics-and-sanitize-strings-in-python/</id><summary type="html">&lt;p&gt;When working with international text data, you often need to convert characters with diacritical marks (like accents, umlauts, or other language-specific symbols) to their basic Latin equivalents. This process, known as diacritic removal or string sanitization, can be crucial for tasks such …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working with international text data, you often need to convert characters with diacritical marks (like accents, umlauts, or other language-specific symbols) to their basic Latin equivalents. This process, known as diacritic removal or string sanitization, can be crucial for tasks such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improving search functionality&lt;/li&gt;
&lt;li&gt;Normalizing data for analysis&lt;/li&gt;
&lt;li&gt;Ensuring compatibility with systems that only support ASCII characters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this guide, we'll show you how to easily sanitize strings in Python using the &lt;code&gt;unidecode&lt;/code&gt; library.&lt;/p&gt;
&lt;h2&gt;Step 1: Install the unidecode Library&lt;/h2&gt;
&lt;p&gt;First, you need to install the &lt;code&gt;unidecode&lt;/code&gt; library. Open your terminal or command prompt and run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install unidecode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Step 2: Import the Library&lt;/h2&gt;
&lt;p&gt;In your Python script, import the &lt;code&gt;unidecode&lt;/code&gt; module:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unidecode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Step 3: Create a Sanitization Function&lt;/h2&gt;
&lt;p&gt;Define a function that will sanitize your strings:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sanitize_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;unidecode&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unidecode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function takes a string as input and returns the sanitized version.&lt;/p&gt;
&lt;h2&gt;Step 4: Use the Function&lt;/h2&gt;
&lt;p&gt;Now you can use this function to sanitize any string. Here's an example with various languages:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Example usage&lt;/span&gt;
&lt;span class="n"&gt;examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;Łódź&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# Polish&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;España&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# Spanish&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;München&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# German&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;François&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# French&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;Νίκος&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# Greek&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;Россия&amp;quot;&lt;/span&gt;  &lt;span class="c1"&gt;# Russian&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;examples&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;sanitized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sanitize_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Original: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sanitized: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;sanitized&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Step 5: Run the Script&lt;/h2&gt;
&lt;p&gt;When you run this script, you'll see output like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;Łó&lt;/span&gt;&lt;span class="n"&gt;dź&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Lodz&lt;/span&gt;

&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;España&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Espana&lt;/span&gt;

&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;München&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Munchen&lt;/span&gt;

&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;François&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Francois&lt;/span&gt;

&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;Νίκος&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nikos&lt;/span&gt;

&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;Россия&lt;/span&gt;
&lt;span class="n"&gt;Sanitized&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Rossiia&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Alternative Libraries&lt;/h2&gt;
&lt;p&gt;While &lt;code&gt;unidecode&lt;/code&gt; is comprehensive, you might also explore alternatives like &lt;code&gt;unicodedata&lt;/code&gt; from the Python standard library for more control over the process.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="nlp"></category><category term="sanitize"></category><category term="sanitization"></category><category term="diacritics"></category><category term="accent"></category><category term="umlaut"></category><category term="unidecode"></category></entry><entry><title>Implementing Sentence Boundary Detection in Python for Improved Text Chunking</title><link href="https://www.safjan.com/implementing-sentence-boundary-detection-in-python-for-improved-text-chunkin/" rel="alternate"></link><published>2024-08-30T00:00:00+02:00</published><updated>2024-08-30T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-08-30:/implementing-sentence-boundary-detection-in-python-for-improved-text-chunkin/</id><summary type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation"&gt;Sentence boundary detection&lt;/a&gt; also known as Sentence boundary disambiguation (SBD) is a crucial preprocessing step for many natural language processing tasks, including text chunking. This guide will walk you through implementing a robust SBD system in Python, utilizing state-of-the-art techniques and libraries …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation"&gt;Sentence boundary detection&lt;/a&gt; also known as Sentence boundary disambiguation (SBD) is a crucial preprocessing step for many natural language processing tasks, including text chunking. This guide will walk you through implementing a robust SBD system in Python, utilizing state-of-the-art techniques and libraries.&lt;/p&gt;
&lt;h2&gt;1. Understanding the Challenge&lt;/h2&gt;
&lt;p&gt;Accurate SBD is non-trivial due to ambiguities in punctuation usage. For instance, periods can indicate abbreviations, decimals, or sentence boundaries. A sophisticated SBD system must handle these nuances.&lt;/p&gt;
&lt;h2&gt;2. Choosing the Right Tools&lt;/h2&gt;
&lt;p&gt;We'll use &lt;a href="https://spacy.io/"&gt;spaCy&lt;/a&gt;, a powerful NLP library in Python, for its efficiency and accuracy in SBD tasks.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;spacy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3. Loading a Pre-trained Model&lt;/h2&gt;
&lt;p&gt;spaCy offers pre-trained models with varying levels of complexity. For optimal performance, we'll use the large English model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;nlp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spacy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en_core_web_lg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;4. Implementing the SBD Function&lt;/h2&gt;
&lt;p&gt;Let's create a function that takes a text input and returns a list of sentences:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;detect_sentence_boundaries&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sents&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;5. Handling Edge Cases&lt;/h2&gt;
&lt;p&gt;To improve accuracy, we'll implement custom rules for common edge cases:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;preprocess_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Handle ellipsis&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;\.{3,}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;ellipsis&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Handle common abbreviations&lt;/span&gt;
    &lt;span class="n"&gt;abbr_pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;\b([A-Z]\.)+[A-Z]?\b&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abbr_pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;dot&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;postprocess_sentences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;lt;ellipsis&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;...&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;lt;dot&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;improved_sentence_detection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;preprocessed_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preprocess_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;detect_sentence_boundaries&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;preprocessed_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;postprocess_sentences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Handle common abbreviations - explanation&lt;/h2&gt;
&lt;p&gt;This part of the code is designed to handle common abbreviations in the text to prevent them from being mistakenly identified as sentence boundaries. Let's break it down:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The regular expression pattern:
   &lt;code&gt;python
   abbr_pattern = r'\b([A-Z]\.)+[A-Z]?\b'&lt;/code&gt;
   This pattern matches:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\b&lt;/code&gt;: A word boundary&lt;/li&gt;
&lt;li&gt;&lt;code&gt;([A-Z]\.)&lt;/code&gt;: A capital letter followed by a period, grouped&lt;/li&gt;
&lt;li&gt;&lt;code&gt;+&lt;/code&gt;: One or more occurrences of the previous group&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[A-Z]?&lt;/code&gt;: Optionally followed by another capital letter&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;\b&lt;/code&gt;: Another word boundary&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The substitution:
   &lt;code&gt;python
   text = re.sub(abbr_pattern, lambda m: m.group().replace('.', '&amp;lt;dot&amp;gt;'), text)&lt;/code&gt;
   This replaces all matches of the pattern in the text. For each match, it applies a lambda function that replaces all periods (&lt;code&gt;.&lt;/code&gt;) with &lt;code&gt;&amp;lt;dot&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here are some examples of how this works:&lt;/p&gt;
&lt;p&gt;Example 1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;I work for the U.S. Government. It&amp;#39;s a good job.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abbr_pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;dot&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Output: &amp;quot;I work for the U&amp;lt;dot&amp;gt;S&amp;lt;dot&amp;gt; Government. It&amp;#39;s a good job.&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Example 2:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;He has a Ph.D. in Computer Science. He also has an M.A.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abbr_pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;dot&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Output: &amp;quot;He has a Ph&amp;lt;dot&amp;gt;D&amp;lt;dot&amp;gt; in Computer Science. He also has an M&amp;lt;dot&amp;gt;A&amp;lt;dot&amp;gt;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Example 3:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Visit the U.S.A. for your vacation. Don&amp;#39;t forget your I.D.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abbr_pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;lt;dot&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Output: &amp;quot;Visit the U&amp;lt;dot&amp;gt;S&amp;lt;dot&amp;gt;A&amp;lt;dot&amp;gt; for your vacation. Don&amp;#39;t forget your I&amp;lt;dot&amp;gt;D&amp;lt;dot&amp;gt;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In these examples, the abbreviations are modified so that their periods are replaced with &lt;code&gt;&amp;lt;dot&amp;gt;&lt;/code&gt;. This prevents the sentence boundary detection algorithm from mistaking these periods as sentence endings.&lt;/p&gt;
&lt;p&gt;The advantage of this approach is that it preserves the structure of common abbreviations while making them distinct from sentence-ending periods. Later in the process, these &lt;code&gt;&amp;lt;dot&amp;gt;&lt;/code&gt; placeholders can be replaced back with actual periods, maintaining the original text's integrity while improving sentence boundary detection accuracy.&lt;/p&gt;
&lt;h2&gt;6. Integrating with Text Chunking&lt;/h2&gt;
&lt;p&gt;Now, let's integrate our SBD function into a text chunking pipeline:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;chunk_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_chunk_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;improved_sentence_detection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;chunks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;current_chunk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_chunk_size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;current_chunk&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;chunks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_chunk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="n"&gt;current_chunk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;current_chunk&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;chunks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;current_chunk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;chunks&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;7. Optimizing Performance&lt;/h2&gt;
&lt;p&gt;Chunking large amount of text can take significant amount of time. For large-scale applications, consider the following optimizations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use spaCy's &lt;code&gt;pipe()&lt;/code&gt; method for batch processing.&lt;/li&gt;
&lt;li&gt;Implement multiprocessing for parallel sentence detection.&lt;/li&gt;
&lt;li&gt;Fine-tune the spaCy model on your specific domain if needed.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;See also: &lt;a href="https://spacy.io/api/sentencizer/"&gt;Sentencizer&lt;/a&gt; - Pipeline component for rule-based sentence boundary detection&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;8. Evaluating the System&lt;/h2&gt;
&lt;p&gt;To assess the quality of your SBD implementation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use standard datasets like &lt;a href="https://huggingface.co/datasets/eriktks/conll2003"&gt;CoNLL-2003&lt;/a&gt; for benchmarking.&lt;/li&gt;
&lt;li&gt;Implement metrics such as &lt;a href="https://en.wikipedia.org/wiki/F-score"&gt;F1 score&lt;/a&gt; for boundary detection accuracy.&lt;/li&gt;
&lt;li&gt;Conduct error analysis to identify and address remaining issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Certainly. Here's an additional section on working with non-English texts for our article:&lt;/p&gt;
&lt;h2&gt;9. Working with Non-English Texts&lt;/h2&gt;
&lt;p&gt;Implementing sentence boundary detection for non-English texts presents unique challenges due to varying punctuation rules, writing systems, and linguistic structures. Here's how to adapt our approach for multilingual support:&lt;/p&gt;
&lt;h3&gt;9.1 Using Language-Specific Models&lt;/h3&gt;
&lt;p&gt;spaCy offers models for various languages. Load the appropriate model based on the input language:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_language_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;spacy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;_core_news_lg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;OSError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Model for &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; not found. Downloading...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;spacy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;_core_news_lg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;spacy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;_core_news_lg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;de_nlp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_language_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;de&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# German&lt;/span&gt;
&lt;span class="n"&gt;ja_nlp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_language_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ja&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Japanese&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;9.2 Handling Script-Specific Challenges&lt;/h3&gt;
&lt;p&gt;Different writing systems require tailored approaches:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;unicodedata&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;detect_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;scripts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unicodedata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;scripts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scripts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scripts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;scripts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;preprocess_by_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;detect_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;CJK&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# For Chinese, Japanese, Korean&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;。&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;！&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;!&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;？&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;?&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ARABIC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# For Arabic and Persian&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;؟&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;?&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Add more script-specific rules as needed&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;postprocess_by_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;CJK&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ARABIC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;lt;stop&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;9.3 Implementing a Multilingual SBD Function&lt;/h3&gt;
&lt;p&gt;Combine the above approaches into a unified multilingual SBD function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;multilingual_sbd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;nlp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_language_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lang_code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;script&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;detect_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;preprocessed_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preprocess_by_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;preprocess_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;preprocessed_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sent&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sents&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;cleaned_sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;postprocess_by_script&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;postprocess_sentences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cleaned_sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;german_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Hallo Welt! Wie geht es dir? Dr. Müller ist hier.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;german_sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multilingual_sbd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;german_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;de&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;japanese_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;こんにちは世界！お元気ですか？山田先生がいらっしゃいました。&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;japanese_sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multilingual_sbd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;japanese_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ja&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;9.4 Handling Bidirectional Text&lt;/h3&gt;
&lt;p&gt;For languages with right-to-left script, such as Arabic or Hebrew, ensure proper handling:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;bidi.algorithm&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;bidi&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;handle_bidi_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;bidi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Incorporate this into the multilingual_sbd function for relevant scripts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;9.5 Fine-tuning for Specific Languages&lt;/h3&gt;
&lt;p&gt;If the pre-trained models don't perform well for your specific use case, consider fine-tuning:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Collect a dataset of sentences in your target language.&lt;/li&gt;
&lt;li&gt;Use spaCy's training API to fine-tune the model on your dataset.&lt;/li&gt;
&lt;li&gt;Evaluate the fine-tuned model against a held-out test set.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_custom_sbd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;nlp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spacy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;blank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sbd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_pipe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;sentencizer&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;losses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annotations&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_doc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;example&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Example&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sgd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;nlp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_disk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;9.6 Evaluating Multilingual Performance&lt;/h3&gt;
&lt;p&gt;To ensure your multilingual SBD system performs well across languages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create or obtain evaluation datasets for each supported language.&lt;/li&gt;
&lt;li&gt;Implement language-specific evaluation metrics when necessary.&lt;/li&gt;
&lt;li&gt;Conduct regular cross-lingual evaluations to maintain quality across all supported languages.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This guide has provided a comprehensive approach to implementing sentence boundary detection (SBD) in Python, focusing on improving text chunking accuracy. We've covered core SBD techniques, edge case handling, integration with text chunking, performance optimization, and expansion into multilingual support. By combining pre-trained models with custom rules and language-specific adaptations, this system offers a robust solution for diverse NLP applications. As you apply these techniques, remember to continuously evaluate and refine your implementation to meet the specific needs of your projects and to adapt to the evolving landscape of natural language processing.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;h2&gt;- &lt;a href="https://github.com/topics/sentence-boundary-detection"&gt;sentence-boundary-detection · GitHub Topics · GitHub&lt;/a&gt;&lt;/h2&gt;</content><category term="note"></category><category term="Python"></category><category term="NLP"></category><category term="sentence-boundary-detection"></category><category term="text-chunking"></category><category term="spaCy"></category><category term="preprocessing"></category><category term="edge-cases"></category><category term="abbreviations"></category><category term="ellipsis"></category><category term="performance-optimization"></category><category term="multiprocessing"></category><category term="evaluation"></category><category term="multilingual-support"></category><category term="language-models"></category><category term="script-detection"></category><category term="non-English-texts"></category><category term="bidirectional-text"></category><category term="fine-tuning"></category><category term="CJK-languages"></category><category term="Arabic"></category><category term="Unicode"></category><category term="regular-expressions"></category><category term="machine-learning"></category><category term="text-analysis"></category><category term="data-preprocessing"></category><category term="NLP-pipeline"></category><category term="language-detection"></category><category term="model-training"></category><category term="cross-lingual-evaluation"></category></entry><entry><title>Bash Parameter Expansion With Default Value</title><link href="https://www.safjan.com/bash-parameter-expansion-with-default-value/" rel="alternate"></link><published>2024-08-01T00:00:00+02:00</published><updated>2024-08-01T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-08-01:/bash-parameter-expansion-with-default-value/</id><summary type="html">&lt;h2&gt;Bash parameter expansion with default value&lt;/h2&gt;
&lt;p&gt;Bash parameter expansion with default value is a useful feature for handling variables that may or may not be set. The syntax is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;-default&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This expands to the value of &lt;code&gt;variable&lt;/code&gt; if it's set and …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Bash parameter expansion with default value&lt;/h2&gt;
&lt;p&gt;Bash parameter expansion with default value is a useful feature for handling variables that may or may not be set. The syntax is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;variable&lt;/span&gt;&lt;span class="p"&gt;-default&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This expands to the value of &lt;code&gt;variable&lt;/code&gt; if it's set and not null. If &lt;code&gt;variable&lt;/code&gt; is unset or null, it expands to &lt;code&gt;default&lt;/code&gt;. It's commonly used to provide fallback values for environment variables or function parameters, improving script robustness and readability.&lt;/p&gt;
&lt;p&gt;A slight variation is &lt;code&gt;${variable:-default}&lt;/code&gt;, which uses the default even if &lt;code&gt;variable&lt;/code&gt; is set but empty.&lt;/p&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Basic usage:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;USER&lt;/span&gt;&lt;span class="p"&gt;-anonymous&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This prints the value of USER if set, otherwise "anonymous".&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In a script:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nv"&gt;NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;World&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hello, &lt;/span&gt;&lt;span class="nv"&gt;$NAME&lt;/span&gt;&lt;span class="s2"&gt;!&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This script greets the first argument, defaulting to "World" if no argument is provided.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;With environment variables:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;BACKUP_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CUSTOM_BACKUP_DIR&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/var/backups&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
cp&lt;span class="w"&gt; &lt;/span&gt;important_file.txt&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$BACKUP_DIR&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This uses a custom backup directory if set, otherwise defaults to "/var/backups".&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Function parameters:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;greet&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;greeting&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hello&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;2&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Guest&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$greeting&lt;/span&gt;&lt;span class="s2"&gt;, &lt;/span&gt;&lt;span class="nv"&gt;$name&lt;/span&gt;&lt;span class="s2"&gt;!&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

greet&lt;span class="w"&gt;                 &lt;/span&gt;&lt;span class="c1"&gt;# Output: Hello, Guest!&lt;/span&gt;
greet&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hi&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="c1"&gt;# Output: Hi, Guest!&lt;/span&gt;
greet&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hey&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Alice&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="c1"&gt;# Output: Hey, Alice!&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Nested default values:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;FOO&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;BAR&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;default&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This uses FOO if set, otherwise BAR if set, otherwise "default".&lt;/p&gt;
&lt;h2&gt;Use cases&lt;/h2&gt;
&lt;p&gt;Here's a list of situations where bash parameter expansion with default values can be particularly useful:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Script arguments&lt;/strong&gt;: Provide default values for optional command-line arguments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configuration management&lt;/strong&gt;: Set default configuration values that can be overridden by environment variables.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Function parameters&lt;/strong&gt;: Define default values for optional function parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fallback paths&lt;/strong&gt;: Specify default file or directory paths when custom locations aren't provided.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User customization&lt;/strong&gt;: Allow users to customize behavior through environment variables without modifying scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Default usernames&lt;/strong&gt;: Provide a default username when one isn't specified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;API tokens&lt;/strong&gt;: Use a default or test API token when a custom one isn't provided.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Temporary directories&lt;/strong&gt;: Set a default temp directory location that can be overridden.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logging levels&lt;/strong&gt;: Specify a default logging level that can be changed via an environment variable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Database connections&lt;/strong&gt;: Provide default database credentials that can be overridden for different environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Default timeouts&lt;/strong&gt;: Set default timeout values for operations that can be customized.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fallback commands&lt;/strong&gt;: Use alternative commands if preferred ones aren't available on the system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Default language or locale settings&lt;/strong&gt;: Specify default language settings that can be overridden.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build environments&lt;/strong&gt;: Set default build flags or environments that can be customized.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Default resource allocations&lt;/strong&gt;: Specify default CPU or memory allocations that can be adjusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="note"></category><category term="bash"></category><category term="parameter-expansion"></category></entry><entry><title>Rss Traffic Analysis for a Blog</title><link href="https://www.safjan.com/rss-traffic-analysis-for-a-blog/" rel="alternate"></link><published>2024-08-01T00:00:00+02:00</published><updated>2024-08-01T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-08-01:/rss-traffic-analysis-for-a-blog/</id><summary type="html">&lt;p&gt;To track traffic coming from RSS/Atom feeds and gather information about your feed consumption, you can use a combination of Google Analytics and some additional methods. Here's how you can approach this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;UTM parameters in RSS/Atom feed links:&lt;/strong&gt;
   Add UTM …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;To track traffic coming from RSS/Atom feeds and gather information about your feed consumption, you can use a combination of Google Analytics and some additional methods. Here's how you can approach this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;UTM parameters in RSS/Atom feed links:&lt;/strong&gt;
   Add UTM parameters to the links in your RSS/Atom feed. This will help you track traffic from feed readers in Google Analytics.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Example:
   &lt;code&gt;https://yourblog.com/post-title/?utm_source=rss&amp;amp;utm_medium=feed&amp;amp;utm_campaign=rss-feed&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Check Google Analytics:&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Go to Acquisition &amp;gt; All Traffic &amp;gt; Source/Medium&lt;/li&gt;
&lt;li&gt;Look for entries with "rss" or "feed" in the source or medium&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can create a custom segment for RSS traffic to analyze it separately&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use a feed analytics service:&lt;/strong&gt;
   Consider using a dedicated feed analytics service like &lt;a href="https://feedpress.com/"&gt;FeedPress&lt;/a&gt; or &lt;a href="https://feedburner.google.com/"&gt;Feedburner&lt;/a&gt; (discontinued).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Check server logs:&lt;/strong&gt;
   If you have access to your server logs, look for user agents that typically belong to feed readers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use a tracking pixel:&lt;/strong&gt;
   Include a small, invisible image (&lt;a href="https://www.digitalmarketer.com/blog/what-is-tracking-pixel/"&gt;tracking pixel&lt;/a&gt;) in your feed items. Each time the image is loaded, it can be counted as a feed view.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Implement RSS-to-Email:&lt;/strong&gt;
   Services like &lt;a href="https://mailchimp.com/"&gt;Mailchimp&lt;/a&gt; offer RSS-to-Email, which can provide insights into how many subscribers are engaging with your content.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Check feed aggregators:&lt;/strong&gt;
   Some popular feed aggregators like &lt;a href="https://feedly.com/"&gt;Feedly&lt;/a&gt; provide public subscriber counts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Implement a custom tracking solution:&lt;/strong&gt;
   You could create a proxy for your RSS feed that logs requests before serving the actual feed content.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: Tracking RSS usage is not always straightforward, as many feed readers cache content and may not load images or execute JavaScript. The methods above will give you an approximation rather than exact numbers.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="note"></category><category term="rss"></category><category term="atom"></category><category term="analytics"></category><category term="traffic"></category><category term="traffic-sources"></category><category term="google-analytics"></category></entry><entry><title>Borda Count vs. Reciprocal Rank - Choosing the Right Ranking Method for Your Data</title><link href="https://www.safjan.com/borda-count-vs-reciprocal-rank/" rel="alternate"></link><published>2024-07-15T00:00:00+02:00</published><updated>2024-07-15T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-15:/borda-count-vs-reciprocal-rank/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count-and-reciprocal-rank-combining---approach-and-calculation"&gt;Borda count and Reciprocal Rank Combining - approach and calculation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count"&gt;Borda Count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reciprocal-rank"&gt;Reciprocal Rank&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#key-differences"&gt;Key differences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example"&gt;Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-observations"&gt;Key observations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-main-differences"&gt;The main differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#which-one-to-use-and-when"&gt;Which one to use and when?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count-is-better-when"&gt;Borda Count is better when...&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reciprocal-rank-is-better-when"&gt;Reciprocal Rank is better when...&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-considerations"&gt;Additional considerations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="borda-count-and-reciprocal-rank-combining---approach-and-calculation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Borda count …&lt;/h2&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count-and-reciprocal-rank-combining---approach-and-calculation"&gt;Borda count and Reciprocal Rank Combining - approach and calculation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count"&gt;Borda Count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reciprocal-rank"&gt;Reciprocal Rank&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#key-differences"&gt;Key differences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example"&gt;Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-observations"&gt;Key observations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-main-differences"&gt;The main differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#which-one-to-use-and-when"&gt;Which one to use and when?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-count-is-better-when"&gt;Borda Count is better when...&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reciprocal-rank-is-better-when"&gt;Reciprocal Rank is better when...&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-considerations"&gt;Additional considerations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="borda-count-and-reciprocal-rank-combining---approach-and-calculation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Borda count and Reciprocal Rank Combining - approach and calculation&lt;/h2&gt;
&lt;p&gt;Borda count and Reciprocal Rank are both methods used in information retrieval and voting systems to combine rankings, but they differ in their approach and calculation. For details of the calculation see borda_count_python and &lt;a href="https://www.safjan.com/implementing-rank-fusion-in-python/"&gt;Implementing Reciprocal Rank Fusion (RRF) in Python&lt;/a&gt;. In this blog post we will focus on comparison of both algorithms and key differences.&lt;/p&gt;
&lt;p&gt;&lt;a id="borda-count"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Borda Count&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assigns points to each item based on its position in each ranking&lt;/li&gt;
&lt;li&gt;Typically gives n points to the top-ranked item, n-1 to the second, and so on, where n is the number of items&lt;/li&gt;
&lt;li&gt;Sums up the points across all rankings&lt;/li&gt;
&lt;li&gt;Final ranking is determined by the total points, with higher scores ranking better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="reciprocal-rank"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Reciprocal Rank&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Focuses on the position of each item in the rankings&lt;/li&gt;
&lt;li&gt;Calculates the reciprocal of the rank for each item (1/rank)&lt;/li&gt;
&lt;li&gt;Averages these reciprocal ranks across all rankings&lt;/li&gt;
&lt;li&gt;Final ranking is determined by the average reciprocal rank, with higher values ranking better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="key-differences"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Key differences&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Scale&lt;/strong&gt;: Borda count uses a linear scale, while Reciprocal Rank uses a non-linear scale that emphasizes top rankings more heavily.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensitivity&lt;/strong&gt;: Reciprocal Rank is more sensitive to high rankings and less affected by lower rankings compared to Borda count.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Range&lt;/strong&gt;: Borda count scores depend on the number of items, while Reciprocal Rank scores are always between 0 and 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Borda count provides a cumulative score, while Reciprocal Rank gives an average of inverse rankings.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Example&lt;/h2&gt;
&lt;p&gt;This is example that demonstrates both the Borda Count and Reciprocal Rank methods, highlighting their differences. This example will use six different rankings of six items.&lt;/p&gt;
&lt;p&gt;Here's a Python script that will demonstrate this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;borda_count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;n_items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_items&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ranking&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_items&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ranking&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;scores&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reciprocal_rank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;n_items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_items&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ranking&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ranking&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# +1 because ranks start from 0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# New rankings (0-indexed) designed to produce different results&lt;/span&gt;
&lt;span class="n"&gt;rankings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 1&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 2&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 3&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 4&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 5&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  &lt;span class="c1"&gt;# Ranking 6&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;borda_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;borda_count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rr_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reciprocal_rank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Borda Count Scores:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;borda_scores&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Item &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Reciprocal Rank Scores:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rr_scores&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Item &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.4f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Borda Count Ranking:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;borda_scores&lt;/span&gt;&lt;span class="p"&gt;)[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Reciprocal Rank Ranking:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rr_scores&lt;/span&gt;&lt;span class="p"&gt;)[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here's the output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Borda Count Scores:
Item 0: 27.0
Item 1: 29.0
Item 2: 28.0
Item 3: 24.0
Item 4: 12.0
Item 5: 6.0

Reciprocal Rank Scores:
Item 0: 0.5972
Item 1: 0.4861
Item 2: 0.4583
Item 3: 0.5417
Item 4: 0.2000
Item 5: 0.1667

Borda Count Ranking:
[1 2 0 3 4 5]

Reciprocal Rank Ranking:
[0 3 1 2 4 5]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="key-observations"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Key observations&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Borda Count Ranking: [1 2 0 3 4 5]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Item 1 has the highest score, followed by 2, 0, 3, 4, and 5.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reciprocal Rank Ranking: [0 3 1 2 4 5]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Item 0 has the highest score, followed by 3, 1, 2, 4, and 5.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="the-main-differences"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;The main differences&lt;/h3&gt;
&lt;h4&gt;Top Ranking&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Borda Count ranks item 1 first, while Reciprocal Rank ranks item 0 first.&lt;/li&gt;
&lt;li&gt;This is because Reciprocal Rank gives more weight to the first-place rankings, which item 0 has more of (item 1 has 2 times rank 0, two times rank 1, and item 0 has also 2 times rank 0 but only once rank 1).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Score Distribution&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In Borda Count, (typically) the scores are more evenly distributed, especially among the top items.&lt;/li&gt;
&lt;li&gt;In Reciprocal Rank, (typically) there's a larger gap between the top-ranked items and the rest.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Sensitivity to Top Rankings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Reciprocal Rank is more sensitive to first-place rankings, which benefits item 0.&lt;/li&gt;
&lt;li&gt;Borda Count considers all positions more equally, which benefits item 1 due to its consistent high (but not always first) rankings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This example clearly demonstrates how Borda Count and Reciprocal Rank can produce different final rankings based on their different approaches to scoring. Borda Count tends to favor consistent performance across all ranks, while Reciprocal Rank gives more weight to top rankings, especially first-place finishes.&lt;/p&gt;
&lt;p&gt;&lt;a id="which-one-to-use-and-when"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Which one to use and when?&lt;/h2&gt;
&lt;p&gt;The choice between Borda Count and Reciprocal Rank Combining depends on the specific context and goals of your ranking task. Here are some practical recommendations for when to use each method:&lt;/p&gt;
&lt;p&gt;&lt;a id="borda-count-is-better-when"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Borda Count is better when...&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Equal importance across all ranks&lt;/strong&gt;: You want to give equal weight to all positions in the ranking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Comprehensive evaluation&lt;/strong&gt;: The goal is to reward consistent performance across all ranks, not just top positions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Large number of items&lt;/strong&gt;: Dealing with a large set of items where distinguishing between lower ranks is important.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transparency&lt;/strong&gt;: You need a method that's easy to explain to stakeholders or users.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Voting systems&lt;/strong&gt;: In scenarios like political elections where fairness across all options is crucial.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="reciprocal-rank-is-better-when"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Reciprocal Rank is better when...&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Emphasis on top rankings&lt;/strong&gt;: The top few positions are significantly more important than lower ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Information retrieval&lt;/strong&gt;: Particularly useful in search engine result evaluation where the first few results matter most.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User behavior modeling&lt;/strong&gt;: When modeling scenarios where users typically focus on top results (e.g., web search, recommendations).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sparse data&lt;/strong&gt;: In cases where you have incomplete rankings or only care about the position of relevant items.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Normalization&lt;/strong&gt;: You need scores that are always between 0 and 1, regardless of the number of items.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="additional-considerations"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Additional considerations&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;If you're dealing with expert opinions where being consistently in the top few ranks is crucial, Reciprocal Rank might be more appropriate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For competitions or evaluations where performance across all levels matters, Borda Count could be more suitable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In scenarios where you want to balance between rewarding top performance and consistent overall performance, you might consider using a combination of both methods or a modified version.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your ranking problem involves a mix of complete and partial rankings, Reciprocal Rank might be more flexible.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="summary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;These tables summarize the main properties and key differences between Borda Count and Reciprocal Rank, highlighting how they differ in their approach to combining rankings and the resulting implications for their use in various scenarios.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 1:&lt;/strong&gt; &lt;em&gt;Main Properties of Borda Count and Reciprocal Rank&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Property&lt;/th&gt;
&lt;th&gt;Borda Count&lt;/th&gt;
&lt;th&gt;Reciprocal Rank&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Scoring Method&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Assigns points based on position (n points for top, n-1 for second, etc.)&lt;/td&gt;
&lt;td&gt;Uses reciprocal of rank (1/rank)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Calculation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Sums points across all rankings&lt;/td&gt;
&lt;td&gt;Averages reciprocal ranks across all rankings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Score Range&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Depends on number of items and rankings&lt;/td&gt;
&lt;td&gt;Always between 0 and 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Final Ranking&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Determined by total points (higher is better)&lt;/td&gt;
&lt;td&gt;Determined by average reciprocal rank (higher is better)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Table 2:&lt;/strong&gt; &lt;em&gt;Key Differences between Borda Count and Reciprocal Rank.&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aspect&lt;/th&gt;
&lt;th&gt;Borda Count&lt;/th&gt;
&lt;th&gt;Reciprocal Rank&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Scale&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;td&gt;Non-linear&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Sensitivity to Top Rankings&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Treats all positions with equal weight difference&lt;/td&gt;
&lt;td&gt;More sensitive to top rankings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Lower Ranking Impact&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Significant impact&lt;/td&gt;
&lt;td&gt;Less impact&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Ties Handling&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Can often result in ties&lt;/td&gt;
&lt;td&gt;Less likely to produce ties&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Cumulative score across all rankings&lt;/td&gt;
&lt;td&gt;Average of inverse rankings&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content><category term="note"></category><category term="borda"></category><category term="rank"></category><category term="rank-combining"></category><category term="rank-fussion"></category><category term="reciprocal-rank-fussion"></category><category term="reciprocal-rank-combining"></category></entry><entry><title>RankFlow plot for retriever visual evaluation</title><link href="https://www.safjan.com/rankflow-plot-for-retriever-visual-evaluation/" rel="alternate"></link><published>2024-07-08T00:00:00+02:00</published><updated>2024-07-08T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-08:/rankflow-plot-for-retriever-visual-evaluation/</id><summary type="html">&lt;p&gt;RAG systems depend on high-quality retrieval to surface relevant information. Analyzing how document rankings evolve through multiple re-ranking steps is complex. This article explores ways to collect ranking data and visualize rank changes to optimize retriever effectiveness.&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction-and-problem-statement"&gt;Introduction and problem statement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#inspiration---rank-flow-visualization"&gt;Inspiration - Rank flow visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tracking-the-rank-changes-in-your-rag"&gt;Tracking the rank changes in your RAG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rank-tracking-using-the-structured-logs"&gt;Rank tracking using the structured logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-track-with-struct-logs"&gt;How to track with struct logs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rank-tracking-using-callbacks"&gt;Rank tracking using callbacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-track-retriever-data-with-callbacks"&gt;How to track retriever data with callbacks?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#visualization"&gt;Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;This article discusses the importance of tracking and visualizing rank changes in Retrieval-Augmented Generation (RAG) systems. It introduces the concept of rank flow visualization, which helps analyze how document rankings evolve through different stages of retrieval and re-ranking. The article outlines methods for collecting rank data using structured logging and callbacks, and presents a Python library called 'rankflow' for creating visual representations of these rank changes. This visualization technique enables AI professionals to quickly identify patterns and optimize their RAG systems, ultimately improving the quality of information retrieval and generation.
&lt;a id="introduction-and-problem-statement"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction and problem statement&lt;/h2&gt;
&lt;p&gt;Retrieval-Augmented Generation (RAG) systems are composed of two primary components: the &lt;strong&gt;retriever&lt;/strong&gt; and the &lt;strong&gt;answer generator&lt;/strong&gt;. The overall efficacy of RAG is largely contingent on the quality of the retriever, making it a critical area for optimization and analysis.&lt;/p&gt;
&lt;p&gt;Advanced retrieval mechanisms often process numerous document fragments or nodes, which are initially ranked based on relevance. To enhance result quality, these nodes undergo &lt;strong&gt;multiple re-ranking phases&lt;/strong&gt;, each aimed at surfacing the most pertinent information.&lt;/p&gt;
&lt;p&gt;The re-ranking process can involve a variety of sophisticated techniques, including cross-encoders, bespoke re-ranking algorithms, and boosting systems. These methods serve to refine the rank of search results originating from diverse sources, such as traditional text search algorithms (e.g., BM25) and semantic search based on textual embeddings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tracking the evolving ranks of these document nodes&lt;/strong&gt; across multiple processing stages within the retriever can be a complex and time-consuming endeavor. However, leveraging the human brain's innate capacity for visual information processing offers a solution. By employing appropriate visualization techniques, we can significantly streamline the analysis of node rank fluctuations throughout the various retriever stages.&lt;/p&gt;
&lt;p&gt;This is where tools like rankflow chart (called also bump chart) come into play, offering a &lt;strong&gt;visual representation of rank changes&lt;/strong&gt; that allows for rapid comprehension and insights into the retriever's performance. Such visualizations enable AI professionals to efficiently identify patterns, anomalies, and opportunities for optimization in their RAG systems, ultimately leading to more effective and reliable information retrieval.&lt;/p&gt;
&lt;p&gt;In this article we focus on two aspects of visual analysis of rank changes: collecting data in retriever and generating graphical visualization like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="RankFlow Plot" src="/images/rankflow/rankflow_plot_full.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; RankFlow chart illustrating rank changes in four steps of re-ranking. You can track the given node's rank history visually. For example, Document 4, after hybrid search, initially had a rank of 4. Then, after the Cross-encoder surfaced, it was re-ranked to 1. The Graph re-ranker subsequently placed it at rank 6, and finally, the Booster changed its rank to 0.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="inspiration---rank-flow-visualization"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Inspiration - Rank flow visualization&lt;/h2&gt;
&lt;p&gt;When we started searching information about the tool that could help us to visualize how the ranks are changing, we found &lt;a href="https://labs.polsys.net/tools/rankflow/"&gt;RankFlow&lt;/a&gt; that can do, more or less, the visualization type we were looking for.&lt;/p&gt;
&lt;p&gt;&lt;svg height="300" version="1.1" width="630" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="overflow: hidden; position: relative; top: -0.0546875px;"&gt;&lt;path fill="url('#4130-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M433.5,122Q401.5,122,369.74,206T305.5,290L305.5,239Q337.5,239,369.26,155T433.5,71L433.5,122" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4120-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M293.5,290Q261.5,290,229.5,290T165.5,290L165.5,239Q197.5,239,229.5,239T293.5,239L293.5,290" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4110-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M153.5,290Q121.5,290,89.5,290T25.5,290L25.5,239Q57.5,239,89.5,239T153.5,239L153.5,290" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4100-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M433.5,290Q401.5,290,369.18,178T305.5,66L305.5,15Q337.5,15,369.82,127T433.5,239L433.5,290" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4090-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M293.5,66Q261.5,66,229.5,66T165.5,66L165.5,15Q197.5,15,229.5,15T293.5,15L293.5,66" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4080-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M153.5,66Q121.5,66,89.74,150T25.5,234L25.5,183Q57.5,183,89.26,99T153.5,15L153.5,66" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4070-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M433.5,66Q401.5,66,369.74,150T305.5,234L305.5,183Q337.5,183,369.26,99T433.5,15L433.5,66" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4060-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M293.5,234Q261.5,234,229.5,234T165.5,234L165.5,183Q197.5,183,229.5,183T293.5,183L293.5,234" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4050-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M153.5,234Q121.5,234,89.42,206T25.5,178L25.5,127Q57.5,127,89.58,155T153.5,183L153.5,234" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4040-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M433.5,234Q401.5,234,369.42,206T305.5,178L305.5,127Q337.5,127,369.58,155T433.5,183L433.5,234" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4030-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M293.5,178Q261.5,178,229.5,178T165.5,178L165.5,127Q197.5,127,229.5,127T293.5,127L293.5,178" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4020-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M153.5,178Q121.5,178,89.42,150T25.5,122L25.5,71Q57.5,71,89.58,99T153.5,127L153.5,178" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4010-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M433.5,178Q401.5,178,369.42,150T305.5,122L305.5,71Q337.5,71,369.58,99T433.5,127L433.5,178" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#4000-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M293.5,122Q261.5,122,229.5,122T165.5,122L165.5,71Q197.5,71,229.5,71T293.5,71L293.5,122" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;path fill="url('#3990-rgb_200_0_55_-rgb_200_0_55_')" stroke="#ffffff" d="M153.5,122Q121.5,122,89.42,94T25.5,66L25.5,15Q57.5,15,89.58,43T153.5,71L153.5,122" stroke-width="1px" opacity="1" fill-opacity="1" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); opacity: 0.35; fill-opacity: 1;"&gt;&lt;/path&gt;&lt;desc style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;Created with Raphaël 2.1.2&lt;/desc&gt;&lt;defs style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;linearGradient id="3990-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4000-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4010-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4020-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4030-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4040-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4050-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4060-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4070-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4080-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4090-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4100-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4110-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4120-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;linearGradient id="4130-rgb_200_0_55_-rgb_200_0_55_" x1="0" y1="0" x2="1" y2="0" gradientTransform="matrix(1,0,0,1,0,0)" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;stop offset="0%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;stop offset="100%" stop-color="#c80037" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;/defs&gt;&lt;path fill="none" stroke="#000000" d="M8.5,300.5L8.5,0.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/path&gt;&lt;text x="3" y="291" text-anchor="end" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: end; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;0&lt;/tspan&gt;&lt;/text&gt;&lt;text x="3" y="20" text-anchor="end" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: end; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;5&lt;/tspan&gt;&lt;/text&gt;&lt;text x="13" y="5" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;Step_1&lt;/tspan&gt;&lt;/text&gt;&lt;rect x="13.5" y="15.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="13.5" y="71.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="13.5" y="127.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="13.5" y="183.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="13.5" y="239.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;text x="153" y="5" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;Step_2&lt;/tspan&gt;&lt;/text&gt;&lt;rect x="153.5" y="15.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="153.5" y="71.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="153.5" y="127.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="153.5" y="183.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="153.5" y="239.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;text x="293" y="5" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;Step_3&lt;/tspan&gt;&lt;/text&gt;&lt;rect x="293.5" y="15.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="293.5" y="71.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="293.5" y="127.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="293.5" y="183.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="293.5" y="239.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;text x="433" y="5" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;Step_4&lt;/tspan&gt;&lt;/text&gt;&lt;rect x="433.5" y="15.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="433.5" y="71.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="433.5" y="127.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="433.5" y="183.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;rect x="433.5" y="239.5" width="12" height="51" rx="0" ry="0" fill="#c80037" stroke="#000000" stroke-width="1px" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;&lt;/rect&gt;&lt;text x="27.5" y="41" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="167.5" y="97" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="307.5" y="97" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="447.5" y="153" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="27.5" y="97" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_12_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="167.5" y="153" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_12_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="307.5" y="153" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_12_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="447.5" y="209" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_12_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="27.5" y="153" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_2 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="167.5" y="209" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_2 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="307.5" y="209" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_2 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="447.5" y="41" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_2 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="27.5" y="209" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="167.5" y="41" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="307.5" y="41" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="447.5" y="265" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_1_3 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="27.5" y="265" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="167.5" y="265" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="307.5" y="265" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;text x="447.5" y="97" text-anchor="start" font-family="&amp;quot;Arial&amp;quot;" font-size="10px" stroke="none" fill="#000000" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-family: Arial; font-size: 10px;"&gt;&lt;tspan dy="3.44775390625" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"&gt;doc_2_1 (1)&lt;/tspan&gt;&lt;/text&gt;&lt;/svg&gt; |&lt;/p&gt;
&lt;p&gt;You can create the Excel table that reflect rank of the documents on each step. Note that the RankFlow tool supports also column with values that is responsible for the width of the "ribbon". You can use it to e.g. visualize importance of given node, or how many information from this node was finally used in the generated answer (if you have this type of information at hand).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Step_1&lt;/th&gt;
&lt;th&gt;val_1&lt;/th&gt;
&lt;th&gt;Step_2&lt;/th&gt;
&lt;th&gt;val_2&lt;/th&gt;
&lt;th&gt;Step_3&lt;/th&gt;
&lt;th&gt;val_3&lt;/th&gt;
&lt;th&gt;Step_4&lt;/th&gt;
&lt;th&gt;val_4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;doc_1_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;doc_12_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;doc_2_2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_12_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_12_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;doc_1_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_12_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;doc_2_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_2_1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;doc_1_3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This tool was an appetiser to have something similar implemented in Python. Before going to visualization, let's spent some time on how to collect data required for this visual analysis.&lt;/p&gt;
&lt;p&gt;&lt;a id="tracking-the-rank-changes-in-your-rag"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tracking the rank changes in your RAG&lt;/h2&gt;
&lt;p&gt;This is a separate topic - depending on the architecture of your retriever. I envision two main approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using structured logging&lt;/li&gt;
&lt;li&gt;using callbacks&lt;/li&gt;
&lt;li&gt;using dedicated monitoring/&lt;a href="https://www.safjan.com/open-source-llm-observability-tools-and-platforms/"&gt;Open Source LLM Observability Tools and Platforms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here, we will discuss only first two since they are pretty while skipping the specific observability tools.&lt;/p&gt;
&lt;p&gt;&lt;a id="rank-tracking-using-the-structured-logs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Rank tracking using the structured logs&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;What are the struct logs?&lt;/strong&gt;
Structured logs are a standardized format for logging data where information is organized into consistent, machine-readable fields rather than free-form text. &lt;strong&gt;They typically use formats like JSON or key-value pairs&lt;/strong&gt;, making it easier to parse, search, and analyze log data programmatically. The benefits of using structured logs include improved log consistency, easier data extraction and analysis, better integration with log management tools, and enhanced ability to generate insights and troubleshoot issues in complex systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="how-to-track-with-struct-logs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;How to track with struct logs?&lt;/h3&gt;
&lt;p&gt;&lt;a href=""&gt;Struct log&lt;/a&gt; have the advantage over non-structured log that you can easily, and with more confidentiality, extract data from it without using sophisticated log parsers. In Python, you can use loguru to drop the rank information to the separate log sink after each step that involves some form of reranking and trace e.g. node (chunk) id, new rank, and "label" for the reranking step. In this way you will get a jsonlines log file with all the data you need to create visualization. You can read more about how to use struct logs with loguru in &lt;a href=""&gt;loguru docs&lt;/a&gt; and &lt;a href=""&gt;this&lt;/a&gt; article.&lt;/p&gt;
&lt;p&gt;&lt;a id="rank-tracking-using-callbacks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Rank tracking using callbacks&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;What are the callbacks?&lt;/strong&gt;
Callbacks in programming are functions passed as arguments to other functions, which are then executed at specific points during the execution of the containing function. In the context of machine learning and deep learning frameworks, callbacks are often used to track and log various metrics, execute custom actions, or modify behavior during training or inference.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="how-to-track-retriever-data-with-callbacks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;How to track retriever data with callbacks?&lt;/h3&gt;
&lt;p&gt;Here is an example how you can use callbacks to track re-ranking info in dummy implementation of the retriever with some re-ranking steps.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Callable&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;RankingTracker&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output_file&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;log_ranking&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="n"&gt;ranking&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;score&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;step&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ranking&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ranking&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rankings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;indent&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Retriever&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_relevant_documents&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="c1"&gt;# Simulated retrieval&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Content 1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Content 2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Content 3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cross_encoder_rerank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="c1"&gt;# Simulated cross-encoder re-ranking&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;  &lt;span class="c1"&gt;# Simulate score adjustment&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;custom_rerank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="c1"&gt;# Simulated custom re-ranking&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mf"&gt;1.2&lt;/span&gt;  &lt;span class="c1"&gt;# Simulate score adjustment&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;documents&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rag_retrieval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;retriever&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Retriever&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;rerankers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Callable&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                  &lt;span class="n"&gt;tracker&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;RankingTracker&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Document&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="c1"&gt;# Initial retrieval&lt;/span&gt;
    &lt;span class="n"&gt;docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;retriever&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_relevant_documents&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tracker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_ranking&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;initial_retrieval&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Apply each re-ranker&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reranker&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rerankers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reranker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;query&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reranker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="vm"&gt;__code__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;co_varnames&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;reranker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tracker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_ranking&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;rerank_step_&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;docs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;docs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this code above:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We define a simple &lt;code&gt;Document&lt;/code&gt; class to represent our documents.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;RankingTracker&lt;/code&gt; class is responsible for logging rankings at each step and writing them to a file.&lt;/li&gt;
&lt;li&gt;We have a basic &lt;code&gt;Retriever&lt;/code&gt; class that simulates initial document retrieval.&lt;/li&gt;
&lt;li&gt;Two re-ranking functions are defined: &lt;code&gt;cross_encoder_rerank&lt;/code&gt; and &lt;code&gt;custom_rerank&lt;/code&gt;. These simulate different re-ranking strategies.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;rag_retrieval&lt;/code&gt; function orchestrates the entire process:&lt;ul&gt;
&lt;li&gt;It first retrieves documents using the retriever.&lt;/li&gt;
&lt;li&gt;Then it applies each re-ranker in sequence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;After each step, it logs the current ranking using the tracker&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is the usage, with steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the tracker and retriever.&lt;/li&gt;
&lt;li&gt;Call &lt;code&gt;rag_retrieval&lt;/code&gt; with the query, retriever, list of re-rankers, and tracker.&lt;/li&gt;
&lt;li&gt;Print the final rankings.&lt;/li&gt;
&lt;li&gt;Flush the tracked rankings to a file.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;tracker&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RankingTracker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ranking_results.json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;retriever&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Retriever&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;What is the capital of France?&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;final_docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rag_retrieval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;retriever&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cross_encoder_rerank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;custom_rerank&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;tracker&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Print final rankings&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Final document rankings:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;final_docs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ID: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;, Score: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Save all rankings to file&lt;/span&gt;
    &lt;span class="n"&gt;tracker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="visualization"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Visualization&lt;/h2&gt;
&lt;p&gt;For the visualization part you can use small Python library &lt;a href="https://pypi.org/project/rankflow/"&gt;rankflow&lt;/a&gt; (disclaimer: I'm the author) that is able to produce this type of visualization:
&lt;img alt="RankFlow Plot" src="/images/rankflow/rankflow_plot_full.jpg"&gt;&lt;/p&gt;
&lt;p&gt;First, install it with pip:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;rankflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It can accept various input data formats, one, convenient for data scientists is pandas data frame.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;rankflow&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RankFlow&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Doc 1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Doc 2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Doc 3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Step_1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Step_2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Step_3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Step_4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When the DataFrame is ready, then it is time to create RankFlow object and call &lt;code&gt;plot()&lt;/code&gt; method.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RankFlow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# save the plot to png&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;rankflow.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you found this library useful, please star the &lt;a href="https://github.com/izikeros/rankflow"&gt;repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With plotting options you have also some alternatives that you can use or take inspiration to create you own, customized rankflow plot/bump chart. See the references for alternatives.&lt;/p&gt;
&lt;p&gt;&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.vrogue.co/post/how-to-plot-bump-chart-in-r-finnstats"&gt;How To Plot Bump Chart In R Finnstats - vrogue.co&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kartikay-bagla/bump-plot-python"&gt;GitHub - kartikay-bagla/bump-plot-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mplsoccer.readthedocs.io/en/latest/gallery/bumpy_charts/plot_bumpy.html#sphx-glr-gallery-bumpy-charts-plot-bumpy-py"&gt;Bumpy Charts — mplsoccer 1.2.4 documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nbviewer.org/gist/pascal-schetelat/8382651"&gt;Jupyter Notebook Viewer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Machine Learning"></category><category term="retriever"></category><category term="rag"></category><category term="visuallization"></category><category term="rag-evaluation"></category><category term="logging"></category><category term="struct-log"></category><category term="rankflow"></category><category term="observability"></category><category term="callback"></category></entry><entry><title>Best Small Models for Fine Tuning</title><link href="https://www.safjan.com/best-small-models-for-fine-tuning/" rel="alternate"></link><published>2024-07-03T00:00:00+02:00</published><updated>2024-08-01T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-03:/best-small-models-for-fine-tuning/</id><summary type="html">&lt;p&gt;X:fine_tune_small_language_models_LLM_SLM&lt;/p&gt;
&lt;h2&gt;Best models to fine-tune&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ranking:&lt;/strong&gt;
1. llama-3-8b
2. phi-3-4k
3. zephyr-7b-beta
4. llama-3-8b-instruct
5. mistral-7b&lt;/p&gt;
&lt;p&gt;Source: &lt;a href="https://predibase.com/fine-tuning-index"&gt;The Fine-tuning Index - Predibase&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Related Webinar&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;https://www.youtube.com/watch?v=kFdfDJ1fQxY
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href="https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa1NGYXVWNTY1aEI0cV9Qb2F0aGVHdUZWRjVFUXxBQ3Jtc0tsZGJfTFl5SEV0SlZMOXBSRWNiZERxWlA0Q2Zvd0gzSVRSSXY1WnV0eGRFV2w0VGE0WnB2QkFhY3R2YVBMZlM0aVpHb0daMjd4R1dLVkxDeFhJZjMwcDkzWHczcVFleU05aGg2QUExaDhndzZtN1ZIWQ&amp;amp;q=https%3A%2F%2Fpbase.ai%2F3x4JB6G&amp;amp;v=kFdfDJ1fQxY"&gt;https://pbase.ai/3x4JB6G&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this on-demand webinar, Staff Software Engineer …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X:fine_tune_small_language_models_LLM_SLM&lt;/p&gt;
&lt;h2&gt;Best models to fine-tune&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ranking:&lt;/strong&gt;
1. llama-3-8b
2. phi-3-4k
3. zephyr-7b-beta
4. llama-3-8b-instruct
5. mistral-7b&lt;/p&gt;
&lt;p&gt;Source: &lt;a href="https://predibase.com/fine-tuning-index"&gt;The Fine-tuning Index - Predibase&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Related Webinar&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;https://www.youtube.com/watch?v=kFdfDJ1fQxY
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href="https://www.youtube.com/redirect?event=video_description&amp;amp;redir_token=QUFFLUhqa1NGYXVWNTY1aEI0cV9Qb2F0aGVHdUZWRjVFUXxBQ3Jtc0tsZGJfTFl5SEV0SlZMOXBSRWNiZERxWlA0Q2Zvd0gzSVRSSXY1WnV0eGRFV2w0VGE0WnB2QkFhY3R2YVBMZlM0aVpHb0daMjd4R1dLVkxDeFhJZjMwcDkzWHczcVFleU05aGg2QUExaDhndzZtN1ZIWQ&amp;amp;q=https%3A%2F%2Fpbase.ai%2F3x4JB6G&amp;amp;v=kFdfDJ1fQxY"&gt;https://pbase.ai/3x4JB6G&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this on-demand webinar, Staff Software Engineer Justin Zhao, and ML Engineer Timothy Wang, lead an in-depth discussion on our findings: &lt;/p&gt;
&lt;p&gt;• How we fine-tuned open-source LLMs that rival GPT-4 
• How you can implement Parameter-Efficient Fine-Tuning (PEFT) methods like Low Rank Adaptation (LoRA) 
• Which tasks are best suited for fine-tuning based on our benchmarks 
• Which popular LLMs—namely Phi, Gemma, and Mistral—perform best and worst across tasks 
• How we implemented an evaluation harness for fine-tuning at scale&lt;/p&gt;</content><category term="note"></category><category term="predibase"></category><category term="evaluation"></category><category term="llm"></category><category term="slm"></category><category term="small-language-models"></category></entry><entry><title>How does QLoRA works?</title><link href="https://www.safjan.com/how-does-qlora-works/" rel="alternate"></link><published>2024-07-03T00:00:00+02:00</published><updated>2024-07-03T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-03:/how-does-qlora-works/</id><summary type="html">&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;QLoRA&lt;/strong&gt; (Quantized Low-Rank Adaptation) is a memory-efficient fine-tuning method for large language models. It uses a frozen 4-bit quantized base model with trainable adapters. During fine-tuning, only the adapters are updated, with gradients backpropagated through the quantized weights. Key innovations …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;QLoRA&lt;/strong&gt; (Quantized Low-Rank Adaptation) is a memory-efficient fine-tuning method for large language models. It uses a frozen 4-bit quantized base model with trainable adapters. During fine-tuning, only the adapters are updated, with gradients backpropagated through the quantized weights. Key innovations include 4-bit NormalFloat quantization, paged optimizers, and double quantization, all of which significantly reduce memory usage. This allows fine-tuning of large models on consumer hardware without compromising performance.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This article outline in brief idea of QLoRA. For the deeper understanding of QLoRA, I highly recommend reading &lt;a href="https://huggingface.co/blog/4bit-transformers-bitsandbytes"&gt;blog post&lt;/a&gt; by the QLoRA authors explaining the QLoRA idea in a clear way.&lt;/p&gt;
&lt;h2&gt;Understanding QLoRA: Efficient Fine-tuning for Large Language Models&lt;/h2&gt;
&lt;p&gt;QLoRA (Quantized Low-Rank Adaptation) is an innovative technique that enables efficient fine-tuning of large language models. It combines several key components to reduce memory usage and computational costs without sacrificing performance. Let's break down how QLoRA works:&lt;/p&gt;
&lt;h3&gt;Core Components&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;4-bit Quantized Base Model&lt;/strong&gt;: QLoRA starts with a pre-trained language model quantized to 4-bit precision. This dramatically reduces memory requirements compared to full-precision models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Low-Rank Adapters&lt;/strong&gt;: Small, trainable modules are added on top of the frozen base model. These adapters capture task-specific information during fine-tuning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;4-bit NormalFloat&lt;/strong&gt;: A novel quantization data type that maintains a normal distribution of values, preserving model quality better than traditional integer quantization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paged Optimizers&lt;/strong&gt;: A memory management technique that efficiently swaps optimizer states between CPU and GPU memory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Double Quantization&lt;/strong&gt;: Further compresses the quantization constants, reducing memory usage even more.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;How It Works?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;The base model is quantized to 4-bit precision and frozen.&lt;/li&gt;
&lt;li&gt;Low-rank adapters are added to each layer of the model.&lt;/li&gt;
&lt;li&gt;During fine-tuning, only the adapters are updated.&lt;/li&gt;
&lt;li&gt;Backpropagation occurs through the 4-bit weights into the adapters.&lt;/li&gt;
&lt;li&gt;Paged optimizers manage memory usage during training.&lt;/li&gt;
&lt;li&gt;Double quantization further reduces memory requirements.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This approach allows for fine-tuning of very large models on consumer-grade hardware, opening up new possibilities for researchers and developers working with state-of-the-art language models.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Full Fine Tuning, LoRA and QLoRA fine tuning compared" src="/images/qlora/qlora_fine_tuning.png"&gt;
&lt;em&gt;Figure from: &lt;a href="https://arxiv.org/abs/2305.14314"&gt;QLoRA paper by Dettmers et al&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Three Innovative Techniques for Memory Efficiency&lt;/h2&gt;
&lt;h3&gt;4-bit NormalFloat (NF4)&lt;/h3&gt;
&lt;p&gt;The QLoRA paper introduces the concept of 4-bit NormalFloat (NF4), a novel &lt;strong&gt;data type&lt;/strong&gt; that is information theoretically &lt;strong&gt;optimal for normally distributed weights&lt;/strong&gt;.
NF4 is used for quantization in QLoRA, which aims to make large language models more accessible by reducing memory usage during fine-tuning. Unlike traditional 4-bit integer or 4-bit floating-point representations, NF4 is specifically designed for normally distributed weights, making it more efficient for certain tasks.&lt;/p&gt;
&lt;h3&gt;Paged Optimizers&lt;/h3&gt;
&lt;p&gt;In the context of QLoRA, paged optimizers are introduced to manage memory spikes during fine-tuning. These optimizers help mitigate memory usage by &lt;strong&gt;efficiently handling memory transfers between the GPU and CPU&lt;/strong&gt;. While the specifics of paged optimizers are not covered extensively in the QLoRA paper, they play a crucial role in achieving memory efficiency.&lt;/p&gt;
&lt;h3&gt;Double Quantization&lt;/h3&gt;
&lt;p&gt;Double quantization is a technique used to reduce the average memory footprint in QLoRA. It involves &lt;strong&gt;quantizing&lt;/strong&gt; not only the &lt;strong&gt;model parameters&lt;/strong&gt; but also the &lt;strong&gt;quantization constants themselves&lt;/strong&gt;. By applying double quantization, QLoRA achieves memory savings without compromising performance.&lt;/p&gt;
&lt;p&gt;These innovations collectively contribute to QLoRA’s ability to fine-tune large language models efficiently while maintaining performance.&lt;/p&gt;
&lt;h1&gt;Further Reading&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://huggingface.co/blog/4bit-transformers-bitsandbytes"&gt;Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA&lt;/a&gt; - blog post by the QLoRA authors explaining the QLoRA idea in a clear way.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2305.14314"&gt;Original QLoRA paper by Dettmers et al&lt;/a&gt; (2023)&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="qlora"></category><category term="lora"></category><category term="low-rank-adaptation"></category><category term="quantisation"></category><category term="weights"></category><category term="adapters"></category><category term="4-bit-normal-float"></category><category term="double-quantisation"></category><category term="training"></category><category term="fine-tuning"></category></entry><entry><title>How to Check Latest Version of Python Package?</title><link href="https://www.safjan.com/how-to-check-latest-version-of-python-package/" rel="alternate"></link><published>2024-07-03T00:00:00+02:00</published><updated>2024-07-03T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-03:/how-to-check-latest-version-of-python-package/</id><summary type="html">&lt;p&gt;Recently, for pip &amp;gt;= 21.2 the syntax &lt;code&gt;pip install pandas==&lt;/code&gt; does not work anymore. There are several methods to get this information in a different way.&lt;/p&gt;
&lt;h2&gt;Use pip&lt;/h2&gt;
&lt;p&gt;There is a new experimental command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;index&lt;span class="w"&gt; &lt;/span&gt;versions&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command shows all …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, for pip &amp;gt;= 21.2 the syntax &lt;code&gt;pip install pandas==&lt;/code&gt; does not work anymore. There are several methods to get this information in a different way.&lt;/p&gt;
&lt;h2&gt;Use pip&lt;/h2&gt;
&lt;p&gt;There is a new experimental command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;index&lt;span class="w"&gt; &lt;/span&gt;versions&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command shows all available versions, with the latest at the top.&lt;/p&gt;
&lt;h2&gt;Use PyPI API and jq&lt;/h2&gt;
&lt;p&gt;Alternatively you can use PyPI API with curl and &lt;a href="https://github.com/jqlang/jq"&gt;jq&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl&lt;span class="w"&gt; &lt;/span&gt;-s&lt;span class="w"&gt; &lt;/span&gt;https://pypi.org/pypi/&amp;lt;package_name&amp;gt;/json&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;jq&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.info.version&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This retrieves the latest version directly from PyPI.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl&lt;span class="w"&gt; &lt;/span&gt;-s&lt;span class="w"&gt; &lt;/span&gt;https://pypi.org/pypi/&amp;lt;package_name&amp;gt;/json&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;jq&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;releases | keys&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For convenience, you can use a shell function. Here's how you can do it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open your shell configuration file (e.g., &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt;) in a text editor.&lt;/li&gt;
&lt;li&gt;Add the following function(s):&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# display the latests version&lt;/span&gt;
pyversion&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;curl&lt;span class="w"&gt; &lt;/span&gt;-s&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https://pypi.org/pypi/&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;/json&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;jq&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.info.version&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# display all versions&lt;/span&gt;
py-all-versions&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;curl&lt;span class="w"&gt; &lt;/span&gt;-s&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https://pypi.org/pypi/&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;/json&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;jq&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;releases | keys&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: using PyPI API + jq is significantly faster than using &lt;code&gt;pip index versions&lt;/code&gt;. using pypi API took ~0.4 s while pip index version took ~2 s.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Using the &lt;code&gt;yolk&lt;/code&gt; package:&lt;/h2&gt;
&lt;p&gt;First, install yolk3k:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;yolk3k
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;yolk&lt;span class="w"&gt; &lt;/span&gt;-V&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="pip"></category><category term="package-version"></category><category term="pypi"></category><category term="pypi-api"></category><category term="jq"></category><category term="curl"></category><category term="yolk"></category><category term="json"></category><category term="python"></category></entry><entry><title>How to Create Animated Gif From Matplotlib Plot in Python?</title><link href="https://www.safjan.com/how-to-create-animated-gif-from-matplotlib-plot-in-python/" rel="alternate"></link><published>2024-07-03T00:00:00+02:00</published><updated>2024-07-03T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-07-03:/how-to-create-animated-gif-from-matplotlib-plot-in-python/</id><summary type="html">&lt;p&gt;Animated visualizations can be a powerful way to showcase data trends over time or illustrate dynamic processes. In this tutorial, we'll learn how to create an animated GIF using Matplotlib in Python. We'll walk through the process step-by-step and provide a working …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Animated visualizations can be a powerful way to showcase data trends over time or illustrate dynamic processes. In this tutorial, we'll learn how to create an animated GIF using Matplotlib in Python. We'll walk through the process step-by-step and provide a working code example that you can adapt for your own projects.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before we begin, make sure you have the following libraries installed:
- matplotlib
- numpy
- pillow (PIL)&lt;/p&gt;
&lt;p&gt;You can install them using pip:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;matplotlib&lt;span class="w"&gt; &lt;/span&gt;numpy&lt;span class="w"&gt; &lt;/span&gt;pillow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Set up the plot&lt;/h2&gt;
&lt;p&gt;First, we'll create a function that generates our plot. In this example, we'll create a simple sine wave that changes frequency over time.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.animation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FuncAnimation&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sine Wave (Frequency: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Save frames as images&lt;/h2&gt;
&lt;p&gt;We'll save each frame of the animation as an individual image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;frames&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;create_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;buf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BytesIO&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Create and save the animated GIF&lt;/h2&gt;
&lt;p&gt;Finally, we'll use Pillow to create the animated GIF from our saved frames:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sine_wave_animation.gif&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;save_all&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;append_images&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:],&lt;/span&gt; 
               &lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Putting it all together:&lt;/p&gt;
&lt;p&gt;Here's the complete code that combines all the steps:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.animation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FuncAnimation&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sine Wave (Frequency: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="c1"&gt;# Create the animation&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Save frames as images&lt;/span&gt;
&lt;span class="n"&gt;frames&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;create_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;buf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BytesIO&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Create and save the animated GIF&lt;/span&gt;
&lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;sine_wave_animation.gif&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;save_all&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;append_images&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:],&lt;/span&gt;
    &lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Animation saved as &amp;#39;sine_wave_animation.gif&amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(Here, you can download this code from GitHub &lt;a href="https://gist.github.com/izikeros/61c18539c80ba8fdd83a1048cde3409f"&gt;Gist&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This code will create an animated GIF showing a sine wave with changing frequency. The resulting GIF will be saved as 'sine_wave_animation.gif' in your current working directory.&lt;/p&gt;</content><category term="note"></category><category term="visualization"></category><category term="animation"></category><category term="matplotlib"></category><category term="python"></category></entry><entry><title>Remove Noise From Screen Recording</title><link href="https://www.safjan.com/remove-noise-from-screen-recording/" rel="alternate"></link><published>2024-06-27T00:00:00+02:00</published><updated>2024-06-27T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-06-27:/remove-noise-from-screen-recording/</id><summary type="html">&lt;p&gt;To remove noise from the speaker audio in your screen capture video, I can recommend a solution using the tools FFmpeg and Audacity as well as some free alternatives. Here's a step-by-step approach.&lt;/p&gt;
&lt;h2&gt;1. Extract the audio with ffmpeg&lt;/h2&gt;
&lt;p&gt;Use FFmpeg to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;To remove noise from the speaker audio in your screen capture video, I can recommend a solution using the tools FFmpeg and Audacity as well as some free alternatives. Here's a step-by-step approach.&lt;/p&gt;
&lt;h2&gt;1. Extract the audio with ffmpeg&lt;/h2&gt;
&lt;p&gt;Use FFmpeg to extract the audio from your video:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ffmpeg&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;input_video.mp4&lt;span class="w"&gt; &lt;/span&gt;-vn&lt;span class="w"&gt; &lt;/span&gt;-acodec&lt;span class="w"&gt; &lt;/span&gt;pcm_s16le&lt;span class="w"&gt; &lt;/span&gt;-ar&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;44100&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-ac&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;output_audio.wav
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;2. Noise reduction with Audacity (Free, open-source)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Import the extracted audio into Audacity&lt;/li&gt;
&lt;li&gt;Select a portion of the audio that contains only background noise&lt;/li&gt;
&lt;li&gt;Go to &lt;code&gt;Effect &amp;gt; Noise Reduction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Click "Get Noise Profile"&lt;/li&gt;
&lt;li&gt;Select the entire audio track&lt;/li&gt;
&lt;li&gt;Go to &lt;code&gt;Effect &amp;gt; Noise Reduction&lt;/code&gt; again&lt;/li&gt;
&lt;li&gt;Adjust settings and preview until satisfied&lt;/li&gt;
&lt;li&gt;Click "OK" to apply&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Export the cleaned audio: &lt;code&gt;File &amp;gt; Export &amp;gt; Export as WAV&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;3. Recombine audio with video:&lt;/h2&gt;
&lt;p&gt;Use FFmpeg to merge the cleaned audio with the original video:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ffmpeg&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;input_video.mp4&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;cleaned_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-c:v&lt;span class="w"&gt; &lt;/span&gt;copy&lt;span class="w"&gt; &lt;/span&gt;-c:a&lt;span class="w"&gt; &lt;/span&gt;aac&lt;span class="w"&gt; &lt;/span&gt;-map&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:v:0&lt;span class="w"&gt; &lt;/span&gt;-map&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;:a:0&lt;span class="w"&gt; &lt;/span&gt;output_video.mp4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Alternative free, video editing tools&lt;/h3&gt;
&lt;h4&gt;1. DaVinci Resolve (Free version)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Powerful video editor with built-in noise reduction&lt;/li&gt;
&lt;li&gt;Import video, separate audio, apply &lt;code&gt;Fairlight FX &amp;gt; Noise Reduction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Export the final video&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Kdenlive (Free, open-source)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Video editor with basic noise reduction capabilities&lt;/li&gt;
&lt;li&gt;Import video, separate audio, apply &lt;code&gt;Audio Effects &amp;gt; Noise Reduction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Export the final video&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Olive Video Editor (Free, open-source)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Another video editor with audio filtering options&lt;/li&gt;
&lt;li&gt;Import video, separate audio, apply audio effects&lt;/li&gt;
&lt;li&gt;Export the final video&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For best results, experiment with different tools and settings. The effectiveness of noise reduction depends on the type and amount of noise in your original recording.&lt;/p&gt;
&lt;h2&gt;Noise removal from CLI alternatives&lt;/h2&gt;
&lt;p&gt;There are CLI (Command Line Interface) tools available for macOS that can help you remove noise from audio. Here are some options:&lt;/p&gt;
&lt;h3&gt;1. FFmpeg with FFmpeg-normalize&lt;/h3&gt;
&lt;p&gt;FFmpeg itself doesn't have advanced noise reduction capabilities, but when combined with FFmpeg-normalize, you can apply some basic noise reduction.&lt;/p&gt;
&lt;p&gt;First, install FFmpeg and FFmpeg-normalize if you haven't already:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;brew&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;ffmpeg
pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;ffmpeg-normalize
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, you can use this command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ffmpeg-normalize&lt;span class="w"&gt; &lt;/span&gt;input_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;output_audio.wav&lt;span class="w"&gt; &lt;/span&gt;--normalization-type&lt;span class="w"&gt; &lt;/span&gt;ebu&lt;span class="w"&gt; &lt;/span&gt;--target-level&lt;span class="w"&gt; &lt;/span&gt;-23&lt;span class="w"&gt; &lt;/span&gt;--audio-codec&lt;span class="w"&gt; &lt;/span&gt;pcm_s16le&lt;span class="w"&gt; &lt;/span&gt;--audio-bitrate&lt;span class="w"&gt; &lt;/span&gt;192k&lt;span class="w"&gt; &lt;/span&gt;--keep-loudness-range-target&lt;span class="w"&gt; &lt;/span&gt;--loudness-range-target&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--true-peak&lt;span class="w"&gt; &lt;/span&gt;-2&lt;span class="w"&gt; &lt;/span&gt;--offset&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command normalizes the audio, which can help reduce some background noise.&lt;/p&gt;
&lt;h3&gt;2. SoX (Sound eXchange)&lt;/h3&gt;
&lt;p&gt;SoX is a powerful command-line audio processing tool that includes noise reduction capabilities.&lt;/p&gt;
&lt;p&gt;Install SoX:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;brew&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;sox
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Use SoX for noise reduction:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sox&lt;span class="w"&gt; &lt;/span&gt;input_audio.wav&lt;span class="w"&gt; &lt;/span&gt;output_audio.wav&lt;span class="w"&gt; &lt;/span&gt;noisered&lt;span class="w"&gt; &lt;/span&gt;noise_profile&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.21
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note: You'll need to create a noise profile first:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sox&lt;span class="w"&gt; &lt;/span&gt;input_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;trim&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.5&lt;span class="w"&gt; &lt;/span&gt;noiseprof&lt;span class="w"&gt; &lt;/span&gt;noise_profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This captures the first 0.5 seconds of the audio as the noise profile.&lt;/p&gt;
&lt;h3&gt;3. AFNI's 3dTcorrMap&lt;/h3&gt;
&lt;p&gt;AFNI is a set of C programs for processing, analyzing, and displaying functional MRI (fMRI) data, but it includes some audio processing tools.&lt;/p&gt;
&lt;p&gt;Install AFNI:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;brew&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;--cask&lt;span class="w"&gt; &lt;/span&gt;afni
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Use 3dTcorrMap for noise reduction:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;3dTcorrMap&lt;span class="w"&gt; &lt;/span&gt;-prefix&lt;span class="w"&gt; &lt;/span&gt;output_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-input&lt;span class="w"&gt; &lt;/span&gt;input_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-mask_only_targets
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;4. RNNoise&lt;/h3&gt;
&lt;p&gt;RNNoise is a noise suppression library based on a recurrent neural network. While it's not a standalone CLI tool, you can use it with FFmpeg if you compile FFmpeg with RNNoise support.&lt;/p&gt;
&lt;p&gt;Here's a general approach (requires advanced setup):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ffmpeg&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;input_audio.wav&lt;span class="w"&gt; &lt;/span&gt;-af&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;arnndn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;./rnnoise-models/sh.rnnn&lt;span class="w"&gt; &lt;/span&gt;output_audio.wav
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; that this requires compiling FFmpeg with RNNoise support, which is a more advanced process.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="note"></category><category term="noise"></category><category term="denoising"></category><category term="video"></category><category term="video-editing"></category><category term="video-processing"></category><category term="audio-processing"></category><category term="postprocessing"></category></entry><entry><title>Measuring Quality and Quantity of Unit Tests in Python Projects - Advanced Strategies</title><link href="https://www.safjan.com/measuring-quality-and-quantity-of-unit-tests-in-python-projects-advanced-strategies/" rel="alternate"></link><published>2024-06-25T00:00:00+02:00</published><updated>2024-06-25T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-06-25:/measuring-quality-and-quantity-of-unit-tests-in-python-projects-advanced-strategies/</id><summary type="html">&lt;p&gt;For Python professionals seeking to elevate their unit testing practices beyond basic code coverage, this guide outlines advanced metrics and approaches. By integrating these strategies, you can gain deeper insights into your test suite's effectiveness and overall code quality.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#metrics-and-methods"&gt;Metrics and methods …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;For Python professionals seeking to elevate their unit testing practices beyond basic code coverage, this guide outlines advanced metrics and approaches. By integrating these strategies, you can gain deeper insights into your test suite's effectiveness and overall code quality.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#metrics-and-methods"&gt;Metrics and methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#1-code-coverage-metrics"&gt;1. Code Coverage Metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-mutation-testing"&gt;2. Mutation Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-cyclomatic-complexity-coverage"&gt;3. Cyclomatic Complexity Coverage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4-test-smell-detection"&gt;4. Test Smell Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5-assertion-density"&gt;5. Assertion Density&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6-test-execution-time"&gt;6. Test Execution Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7-flakiness-score"&gt;7. Flakiness Score&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-code-to-test-ratio"&gt;8. Code to Test Ratio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#9-test-coverage-of-critical-paths"&gt;9. Test Coverage of Critical Paths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-property-based-testing"&gt;10. Property-based Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#11-static-analysis-integration"&gt;11. Static Analysis Integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#12-mocking-coverage"&gt;12. Mocking Coverage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#13-test-suite-cohesion"&gt;13. Test Suite Cohesion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#14-test-design-quality"&gt;14. Test Design Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#15-behavior-driven-development-bdd"&gt;15. Behavior-Driven Development (BDD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#16-test-metrics-and-reporting"&gt;16. Test Metrics and Reporting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools-to-consider"&gt;Tools to Consider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="metrics-and-methods"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Metrics and methods&lt;/h2&gt;
&lt;p&gt;&lt;a id="1-code-coverage-metrics"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;1. Code Coverage Metrics&lt;/h3&gt;
&lt;p&gt;While not sufficient on its own, code coverage remains a fundamental metric. Track:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Line Coverage&lt;/strong&gt;: Percentage of executed lines&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Branch Coverage&lt;/strong&gt;: Percentage of executed branches in control structures&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Path Coverage&lt;/strong&gt;: Percentage of executed unique code paths&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="2-mutation-testing"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2. Mutation Testing&lt;/h3&gt;
&lt;p&gt;This technique introduces small, random changes (mutations) to your code and verifies if tests catch these alterations. Tools like &lt;a href="[boxed/mutmut: Mutation testing system (github.com)](https://github.com/boxed/mutmut)"&gt;mutmut&lt;/a&gt;, &lt;a href="https://github.com/sixty-north/cosmic-ray"&gt;cosmic-ray&lt;/a&gt;, or &lt;a href="https://pitest.org/"&gt;PITest&lt;/a&gt; can automate this process, revealing areas where tests might be insufficient or overly permissive.&lt;/p&gt;
&lt;p&gt;&lt;a id="3-cyclomatic-complexity-coverage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;3. Cyclomatic Complexity Coverage&lt;/h3&gt;
&lt;p&gt;Measure how well your tests cover complex code paths. High cyclomatic complexity often indicates areas more prone to bugs that require thorough testing.&lt;/p&gt;
&lt;p&gt;&lt;a id="4-test-smell-detection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;4. Test Smell Detection&lt;/h3&gt;
&lt;p&gt;Identify common issues in test code that might indicate poor quality:
- &lt;strong&gt;Long Test Methods&lt;/strong&gt;: Overly long tests that are hard to understand and maintain
- &lt;strong&gt;Test Duplication&lt;/strong&gt;: Similar or identical test logic in multiple places
- &lt;strong&gt;Assertion Roulette&lt;/strong&gt;: Multiple assertions in a test without clear messages&lt;/p&gt;
&lt;p&gt;&lt;a id="5-assertion-density"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;5. Assertion Density&lt;/h3&gt;
&lt;p&gt;Calculate the ratio of assertions to lines of test code. A higher density often indicates more thorough testing, though this metric should be used cautiously as it can be manipulated.&lt;/p&gt;
&lt;p&gt;&lt;a id="6-test-execution-time"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;6. Test Execution Time&lt;/h3&gt;
&lt;p&gt;Monitor test execution time to maintain a balance between thoroughness and development speed.&lt;/p&gt;
&lt;p&gt;&lt;a id="7-flakiness-score"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;7. Flakiness Score&lt;/h3&gt;
&lt;p&gt;Track how often tests fail intermittently. Flaky tests can indicate poor test design or underlying code issues.&lt;/p&gt;
&lt;p&gt;&lt;a id="8-code-to-test-ratio"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;8. Code to Test Ratio&lt;/h3&gt;
&lt;p&gt;Compare the amount of production code to test code. While there's no universal ideal ratio, this can provide insights into under-tested areas.&lt;/p&gt;
&lt;p&gt;&lt;a id="9-test-coverage-of-critical-paths"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;9. Test Coverage of Critical Paths&lt;/h3&gt;
&lt;p&gt;Identify and ensure comprehensive testing of the most crucial workflows in your application. Implement risk-based testing to focus more efforts on high-risk or complex areas.&lt;/p&gt;
&lt;p&gt;&lt;a id="10-property-based-testing"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;10. Property-based Testing&lt;/h3&gt;
&lt;p&gt;Use tools like &lt;a href="https://github.com/HypothesisWorks/hypothesis"&gt;Hypothesis&lt;/a&gt; to generate a wide range of inputs and test properties of your code, rather than specific examples.&lt;/p&gt;
&lt;p&gt;&lt;a id="11-static-analysis-integration"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;11. Static Analysis Integration&lt;/h3&gt;
&lt;p&gt;Combine unit test results with static analysis tools like &lt;a href="https://pylint.readthedocs.io/en/latest/"&gt;pylint&lt;/a&gt;, &lt;a href="https://flake8.pycqa.org/en/latest/"&gt;Flake8&lt;/a&gt;, or &lt;a href="https://www.mypy-lang.org/"&gt;mypy&lt;/a&gt; to get a more comprehensive view of code quality and adherence to best practices.&lt;/p&gt;
&lt;p&gt;&lt;a id="12-mocking-coverage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;12. Mocking Coverage&lt;/h3&gt;
&lt;p&gt;Assess how well your tests cover different scenarios when external dependencies are mocked.&lt;/p&gt;
&lt;p&gt;&lt;a id="13-test-suite-cohesion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;13. Test Suite Cohesion&lt;/h3&gt;
&lt;p&gt;Analyze how changes in one part of the codebase affect test results in other parts, indicating how well your tests isolate functionality.&lt;/p&gt;
&lt;p&gt;&lt;a id="14-test-design-quality"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;14. Test Design Quality&lt;/h3&gt;
&lt;p&gt;Evaluate the design and readability of your tests:
- &lt;strong&gt;Test Independence&lt;/strong&gt;: Ensure tests don't depend on each other
- &lt;strong&gt;Clear Naming&lt;/strong&gt;: Use descriptive names that state what is being tested
- &lt;a href="https://methodpoet.com/aaa-in-unit-testing/"&gt;Arrange-Act-Assert (AAA) Pattern&lt;/a&gt;: Structure tests into clear setup, execution, and verification phases&lt;/p&gt;
&lt;p&gt;&lt;a id="15-behavior-driven-development-bdd"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;15. Behavior-Driven Development (BDD)&lt;/h3&gt;
&lt;p&gt;Adopt BDD practices to improve test coverage and clarity using tools like &lt;a href="https://github.com/behave/behave"&gt;Behave&lt;/a&gt; or &lt;a href="https://github.com/pytest-dev/pytest-bdd"&gt;pytest-bdd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="16-test-metrics-and-reporting"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;16. Test Metrics and Reporting&lt;/h3&gt;
&lt;p&gt;Implement metrics and reporting to track and improve test quality:
- &lt;strong&gt;Test Success Rate&lt;/strong&gt;: Measure the percentage of passing tests
- &lt;strong&gt;Test Maintenance&lt;/strong&gt;: Track the effort needed to maintain and update tests
- &lt;strong&gt;Coverage Trends&lt;/strong&gt;: Monitor code coverage over time to prevent degradation&lt;/p&gt;
&lt;p&gt;&lt;a id="tools-to-consider"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tools to Consider&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://coverage.readthedocs.io/"&gt;Coverage.py&lt;/a&gt;: For code coverage&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mutmut.readthedocs.io/en/latest/index.html"&gt;Mutmut&lt;/a&gt;: For mutation testing&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sonarsource.com/products/sonarqube/"&gt;SonarQube&lt;/a&gt;: For static analysis and test smell detection&lt;/li&gt;
&lt;li&gt;&lt;a href="https://allurereport.org/"&gt;Allure&lt;/a&gt;: For test reporting&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="code-coverage"></category><category term="test"></category><category term="testing"></category></entry><entry><title>Improving Code Maintainability - When to Use Standalone Functions Over Static Methods in Python</title><link href="https://www.safjan.com/improving-code-maintainability-when-to-use-standalone-functions-over-static/" rel="alternate"></link><published>2024-06-22T00:00:00+02:00</published><updated>2024-06-22T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-06-22:/improving-code-maintainability-when-to-use-standalone-functions-over-static/</id><summary type="html">&lt;p&gt;When designing and organizing code, developers often face the dilemma of whether to keep a method as part of a class or refactor it into a standalone function. This decision can significantly impact the maintainability, readability, and reusability of the codebase. In …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When designing and organizing code, developers often face the dilemma of whether to keep a method as part of a class or refactor it into a standalone function. This decision can significantly impact the maintainability, readability, and reusability of the codebase. In particular, the choice between converting a method into a static method or a standalone function can have far-reaching consequences. While static methods can help encapsulate utility functions within a class, they still maintain a degree of coupling with the class. On the other hand, standalone functions offer greater flexibility, reusability, and testability, making them an attractive alternative for many scenarios. I will explore the factors that influence this decision and provide guidelines for determining when to refactor a method into a standalone function or mark it as a static method.&lt;/p&gt;
&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;In Python, it is generally better to use standalone functions instead of static methods when the functionality can be used independently of any particular class. &lt;/p&gt;
&lt;h2&gt;Why to use functions?&lt;/h2&gt;
&lt;p&gt;Here are some reasons why:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Code organization&lt;/strong&gt;: Standalone functions can help keep your code organized by separating concerns. When you have a utility function that doesn't depend on any class-specific state or behavior, it makes sense to keep it separate from the class. This improves readability and maintainability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Code reuse&lt;/strong&gt;: Functions can be more easily reused across different modules and projects compared to static methods, which are tied to a specific class.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;: Functions are generally easier to test than static methods, as you don't need to create an instance of the class or worry about its state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Polymorphism&lt;/strong&gt;: Functions can be more easily replaced or mocked for testing or extension purposes, whereas static methods are more tightly coupled to the class.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Functions can be documented using docstrings, which can be easily accessed using help() or third-party tools like Sphinx. Static methods can be documented, but their documentation might be less discoverable.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On the other hand, you might want to keep a method as a static method if:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;It's closely related to the class&lt;/strong&gt;: If a method is closely related to the class and is used to provide additional functionality that's specific to the class, it's better to keep it as a static method.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;It's used as a factory function&lt;/strong&gt;: If a method is used as a factory function to create instances of the class, it's better to keep it as a static method.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;when a method can be implemented and used independently of a class, consider refactoring it to a standalone function. This approach can lead to cleaner, more modular, and more maintainable code.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="function"></category><category term="python-method"></category><category term="idiomatic-python"></category><category term="refactoring"></category><category term="static-method"></category><category term="testability"></category><category term="python-class"></category><category term="flexilility"></category><category term="reusability"></category><category term="code-organization"></category><category term="code-reuse"></category><category term="testing"></category><category term="polymorphysm"></category><category term="docstrings"></category></entry><entry><title>Mastering kwargs in Python - Best Practices for Experienced Developers</title><link href="https://www.safjan.com/mastering-kwargs-in-python-best-practices-for-experienced-developers/" rel="alternate"></link><published>2024-06-13T00:00:00+02:00</published><updated>2024-06-13T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-06-13:/mastering-kwargs-in-python-best-practices-for-experienced-developers/</id><summary type="html">&lt;p&gt;Python's &lt;code&gt;**kwargs&lt;/code&gt; is a powerful tool that allows developers to pass a variable number of keyword arguments to a function. It's particularly useful when you need to create flexible APIs or when working with configuration dictionaries. However, the use of &lt;code&gt;**kwargs&lt;/code&gt; comes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Python's &lt;code&gt;**kwargs&lt;/code&gt; is a powerful tool that allows developers to pass a variable number of keyword arguments to a function. It's particularly useful when you need to create flexible APIs or when working with configuration dictionaries. However, the use of &lt;code&gt;**kwargs&lt;/code&gt; comes with its own set of challenges. In this article, we'll delve into the potential pitfalls of using &lt;code&gt;**kwargs&lt;/code&gt; and how to mitigate them, helping you write more idiomatic and robust Python code.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#1-loss-of-clarity"&gt;1. Loss of Clarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-typos-in-argument-names"&gt;2. Typos in Argument Names&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-difficulty-in-refactoring"&gt;3. Difficulty in Refactoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4-incompatibility-with-static-type-checking"&gt;4. Incompatibility with Static Type Checking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5-introspection-limitations"&gt;5. Introspection Limitations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6-performance-overhead"&gt;6. Performance Overhead&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7-security-risks"&gt;7. Security Risks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-default-values-and-none-checks"&gt;8. Default Values and None Checks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;
&lt;p&gt;&lt;a id="1-loss-of-clarity"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1. Loss of Clarity&lt;/h2&gt;
&lt;p&gt;The first challenge with &lt;code&gt;**kwargs&lt;/code&gt; is that it can make your code less clear. When a function accepts &lt;code&gt;**kwargs&lt;/code&gt;, it's not immediately apparent what arguments it expects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use explicit parameters where possible and reserve &lt;code&gt;**kwargs&lt;/code&gt; for truly dynamic cases. Always document the expected keyword arguments using docstrings.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Process data based on the provided format and additional options.&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;    data: The data to be processed.&lt;/span&gt;
&lt;span class="sd"&gt;    format: The format of the data. Default is &amp;#39;csv&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;    **kwargs: Additional options to control the data processing.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on format and kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="2-typos-in-argument-names"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;2. Typos in Argument Names&lt;/h2&gt;
&lt;p&gt;Misspelled keyword argument names will not raise an error, which can lead to hard-to-trace bugs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_graph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;titel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Misspelled &amp;#39;title&amp;#39;&lt;/span&gt;
    &lt;span class="c1"&gt;# Plot graph with title&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Implement argument validation within the function to check for required parameters and raise errors for unexpected arguments.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_graph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Missing required argument &amp;#39;title&amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Plot graph with title&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="3-difficulty-in-refactoring"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;3. Difficulty in Refactoring&lt;/h2&gt;
&lt;p&gt;Refactoring tools may not be able to update keyword arguments automatically, as they are not explicitly defined in the function signature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="c1"&gt;# Later in the code&lt;/span&gt;
&lt;span class="n"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Misspelled &amp;#39;data&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Limit the use of &lt;code&gt;**kwargs&lt;/code&gt; to cases where it's truly beneficial. When refactoring, manually verify and update the usage of functions that accept &lt;code&gt;**kwargs&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="c1"&gt;# Later in the code&lt;/span&gt;
&lt;span class="n"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="4-incompatibility-with-static-type-checking"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;4. Incompatibility with Static Type Checking&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;**kwargs&lt;/code&gt; can make it harder to use static type checking, as the types of the passed arguments are not explicit.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use Python's type hints to specify the expected types of the keyword arguments, and use &lt;code&gt;TypedDict&lt;/code&gt; when you expect a dictionary with a specific structure.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TypedDict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Optional&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ProcessDataKwargs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TypedDict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;validate&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt;
    &lt;span class="n"&gt;preprocess&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Optional&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;callable&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ProcessDataKwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="5-introspection-limitations"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;5. Introspection Limitations&lt;/h2&gt;
&lt;p&gt;Tools and IDEs may not provide accurate autocompletion or parameter hints for functions that use &lt;code&gt;**kwargs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Provide clear documentation and consider using wrapper functions with explicit parameters for common use cases.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Process data based on the provided format and additional options.&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;    data: The data to be processed.&lt;/span&gt;
&lt;span class="sd"&gt;    format: The format of the data. Default is &amp;#39;csv&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;    **kwargs: Additional options to control the data processing.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# Process data based on format and kwargs&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_csv_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    A wrapper function for processing CSV data.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="6-performance-overhead"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;6. Performance Overhead&lt;/h2&gt;
&lt;p&gt;Functions that use &lt;code&gt;**kwargs&lt;/code&gt; have a slight performance overhead because of the dictionary packing and unpacking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calculate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Perform calculation&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is usually not significant, but for performance-critical code, consider using explicit parameters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calculate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;option&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Perform calculation&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="7-security-risks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;7. Security Risks&lt;/h2&gt;
&lt;p&gt;If &lt;code&gt;**kwargs&lt;/code&gt; is used to pass user input to functions or classes (like ORM queries), it can lead to security vulnerabilities if not properly sanitized.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Always validate and sanitize user input before passing it to functions that use &lt;code&gt;**kwargs&lt;/code&gt;. Use explicit parameters for sensitive operations.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Validate and sanitize username and password&lt;/span&gt;
    &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="8-default-values-and-none-checks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;8. Default Values and None Checks&lt;/h2&gt;
&lt;p&gt;It can be unclear whether a &lt;code&gt;None&lt;/code&gt; value for a keyword argument was intentional or if the argument was omitted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problematic Usage:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;preprocess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;preprocess&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_preprocess&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# If &amp;#39;preprocess&amp;#39; is explicitly set to None, default_preprocess will still be used&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Mitigation Advice:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use sentinel objects or explicit checks to differentiate between &lt;code&gt;None&lt;/code&gt; as a default value and &lt;code&gt;None&lt;/code&gt; as an intentional argument.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;preprocess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;preprocess&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;preprocess&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;default_preprocess&lt;/span&gt;
    &lt;span class="c1"&gt;# Now if &amp;#39;preprocess&amp;#39; is explicitly set to None, None will be used&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In conclusion, while &lt;code&gt;**kwargs&lt;/code&gt; provides flexibility, it should be used judiciously and with consideration of the potential drawbacks. By following the best practices outlined in this article, you can harness the power of &lt;code&gt;**kwargs&lt;/code&gt; to write cleaner, more maintainable, and idiomatic Python code. Happy coding!&lt;/p&gt;
&lt;h2&gt;Related articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://softwareengineering.stackexchange.com/questions/384743/how-can-i-resolve-this-kwargs-antipattern"&gt;python - How can I resolve this **kwargs antipattern? - Software Engineering Stack Exchange&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.slingacademy.com/article/python-typing-a-function-with-args-and-kwargs/"&gt;Python: Typing a function with *args and **kwargs - Sling Academy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="python"></category><category term="kwargs"></category><category term="idiomatic-python"></category><category term="clean-code"></category><category term="refactoring"></category><category term="static-type-checking"></category><category term="security-risk"></category></entry><entry><title>How to add HuggingFace model to ollama</title><link href="https://www.safjan.com/how-to-add-huggingface-model-to-ollama/" rel="alternate"></link><published>2024-06-12T00:00:00+02:00</published><updated>2024-06-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-06-12:/how-to-add-huggingface-model-to-ollama/</id><summary type="html">&lt;p&gt;Create directory where you will be storying your HuggingFace LLMs. Ollama keeps their models in &lt;code&gt;~/ollama&lt;/code&gt;. I have created &lt;code&gt;~/.ollama_hf_llms&lt;/code&gt; to store my downloaded models.&lt;/p&gt;
&lt;h2&gt;Download the weights&lt;/h2&gt;
&lt;p&gt;Download weights in GGUF or .... format from the model page on HuggingFace. Put the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Create directory where you will be storying your HuggingFace LLMs. Ollama keeps their models in &lt;code&gt;~/ollama&lt;/code&gt;. I have created &lt;code&gt;~/.ollama_hf_llms&lt;/code&gt; to store my downloaded models.&lt;/p&gt;
&lt;h2&gt;Download the weights&lt;/h2&gt;
&lt;p&gt;Download weights in GGUF or .... format from the model page on HuggingFace. Put the weights in the location you meant for these HuggingFace models (in my case: &lt;code&gt;~/.ollama_hf_llms&lt;/code&gt;).  The simpliest way to download the weights is to download the using browser alternatively you can use &lt;code&gt;git-lfs&lt;/code&gt; (see section extras). Note that the weights are often in size of tens of gigabytes - so be patient when downloading. As an example, you can download weights of the model ......&lt;/p&gt;
&lt;h2&gt;Create model file&lt;/h2&gt;
&lt;p&gt;In the folder where you store the weights create modelfile.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you can create unique "AI pesonalities" by customizing model parameters and prompt in the Modelfile&lt;/li&gt;
&lt;li&gt;important: use the right prompt format for the given model&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;./laserxtral.q5_k_m.gguf&lt;/span&gt;
TEMPLATE&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;{{ if .System }}### Instruction:&lt;/span&gt;
&lt;span class="o"&gt;{{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;.System&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;}}&lt;/span&gt;
&lt;span class="o"&gt;{{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;end&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;}}&lt;/span&gt;
&lt;span class="c"&gt;### Input:&lt;/span&gt;
&lt;span class="o"&gt;{{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;.Prompt&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;}}&lt;/span&gt;
&lt;span class="c"&gt;### Response:&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
SYSTEM&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;You are Laserxtral, a helpful and uncensored AI assistant.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
PARAMETER&lt;span class="w"&gt; &lt;/span&gt;num_ctx&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;8192&lt;/span&gt;
PARAMETER&lt;span class="w"&gt; &lt;/span&gt;stop&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;### Input&amp;quot;&lt;/span&gt;
PARAMETER&lt;span class="w"&gt; &lt;/span&gt;stop&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;### Response&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Run the model&lt;/h2&gt;
&lt;p&gt;Laserxtral is ready to run, so let’s load it up into Ollama and give it a spin.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ollama&lt;span class="w"&gt; &lt;/span&gt;create&lt;span class="w"&gt; &lt;/span&gt;laserxtral&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;laserxtral.Modelfile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will transfer the data to .ollama folder&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You can also download the weights using git LFS&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://2point0.ai/posts/run-models-from-hugging-face-in-ollama"&gt;How to run models from Hugging Face in Ollama ⋮ 2point0.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://2point0.ai/posts/discovering-lesser-known-llms-with-hugging-face"&gt;Discovering lesser-known LLMs with Hugging Face ⋮ 2point0.ai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I’d recommend following along at &lt;a href="https://www.reddit.com/r/LocalLLaMA/"&gt;/r/LocalLLaMA&lt;/a&gt; which often has discussions about new models, and I’d caution against paying too much attention to the various leaderboards on Hugging Face spaces which are easily gamed by fine-tuning specifically for the leaderboard. For those off-the-beaten track models, make sure you follow &lt;a href="https://huggingface.co/TheBloke"&gt;TheBloke&lt;/a&gt; and &lt;a href="https://huggingface.co/LoneStriker"&gt;LoneStriker&lt;/a&gt; who prolifically churn out GGUF quants for all sorts of under-the-radar models.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://2point0.ai/posts/create-unique-ai-personalities-with-ollama"&gt;Easily create unique AI personalities with Ollama ⋮ 2point0.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="ollama"></category><category term="huggingface"></category><category term="llm"></category><category term="oss-llm"></category><category term="os-llm"></category><category term="open-source"></category></entry><entry><title>RAGAS metrics cheat sheet</title><link href="https://www.safjan.com/ragas-metrics-cheat-sheet/" rel="alternate"></link><published>2024-05-31T00:00:00+02:00</published><updated>2024-05-31T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-05-31:/ragas-metrics-cheat-sheet/</id><summary type="html">&lt;p&gt;Here is a cheat sheet with the RAGAS metrics and their brief description and indication what input data is needed to calculate given metrics. Note that the descriptions are oversimplified, they just serve are reminder. For the metrics definitions please visit &lt;a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html"&gt;RAGAS …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here is a cheat sheet with the RAGAS metrics and their brief description and indication what input data is needed to calculate given metrics. Note that the descriptions are oversimplified, they just serve are reminder. For the metrics definitions please visit &lt;a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html"&gt;RAGAS documentation page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="RAGAS metrics cheat sheet - JPG version" src="/images/ragas_metrics_cheat_sheet/RAGAS_metrics_cheat_sheet_v1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Download &lt;a href="/pdfs/RAGAS_metrics_cheat_sheet_v1.pdf"&gt;PDF version&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="RAGAS"></category><category term="RAG-evaluation"></category><category term="consistency"></category><category term="relevancy"></category><category term="precision"></category><category term="faithfulness"></category><category term="answer-relevance"></category><category term="context-relevancy"></category><category term="context-precision"></category><category term="context-recall"></category><category term="context-entities-recall"></category><category term="answer-semantic-similarity"></category><category term="answer-correctness"></category><category term="harmfulness"></category><category term="malicousness"></category><category term="coherence"></category><category term="correctness"></category><category term="conciseness"></category></entry><entry><title>Use Decouple With Pydantic or Python Dataclass to Manage Configuration in Python App</title><link href="https://www.safjan.com/use-decouple-with-pydantic-or-python-dataclass-to-manage-configuration-in-py/" rel="alternate"></link><published>2024-04-19T00:00:00+02:00</published><updated>2024-04-19T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-04-19:/use-decouple-with-pydantic-or-python-dataclass-to-manage-configuration-in-py/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/python-configuration-management/"&gt;Python - Configuration Management&lt;/a&gt;&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#usage"&gt;Basic Usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-pydantic-or-dataclass"&gt;Add pydantic or dataclass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-pydantic"&gt;Using &lt;code&gt;pydantic&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-dataclass"&gt;Using &lt;code&gt;dataclass&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advantages-of-using-pydantic-or-dataclass"&gt;Advantages of using &lt;code&gt;pydantic&lt;/code&gt; or &lt;code&gt;dataclass&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#should-the-config-be-immutable"&gt;Should the config be immutable?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dataclass--decouple-example"&gt;dataclass + decouple example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="usage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Basic Usage&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;python-decouple&lt;/code&gt; is a viable alternative to &lt;code&gt;python-dotenv&lt;/code&gt; for managing environment variables in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/python-configuration-management/"&gt;Python - Configuration Management&lt;/a&gt;&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#usage"&gt;Basic Usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-pydantic-or-dataclass"&gt;Add pydantic or dataclass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-pydantic"&gt;Using &lt;code&gt;pydantic&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-dataclass"&gt;Using &lt;code&gt;dataclass&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advantages-of-using-pydantic-or-dataclass"&gt;Advantages of using &lt;code&gt;pydantic&lt;/code&gt; or &lt;code&gt;dataclass&lt;/code&gt;:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#should-the-config-be-immutable"&gt;Should the config be immutable?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dataclass--decouple-example"&gt;dataclass + decouple example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="usage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Basic Usage&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;python-decouple&lt;/code&gt; is a viable alternative to &lt;code&gt;python-dotenv&lt;/code&gt; for managing environment variables in Python projects. It allows you to define environment variables in a &lt;code&gt;.env&lt;/code&gt; file and access them in your Python code easily. Here's how you can migrate from &lt;code&gt;python-dotenv&lt;/code&gt; to &lt;code&gt;python-decouple&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Installation&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;First, you need to install &lt;code&gt;python-decouple&lt;/code&gt; if you haven't already:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
   pip install python-decouple&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Create a &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you haven't already, create a &lt;code&gt;.env&lt;/code&gt; file in your project directory and add your environment variables in the format &lt;code&gt;KEY=VALUE&lt;/code&gt;, one per line. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plaintext
   SECRET_KEY=your_secret_key
   DEBUG=True&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Modify your Python code&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Update your Python code to use &lt;code&gt;python-decouple&lt;/code&gt; instead of &lt;code&gt;python-dotenv&lt;/code&gt;. Here's a basic example:&lt;/p&gt;
&lt;p&gt;```python
   # Old code using python-dotenv
   from dotenv import load_dotenv
   import os&lt;/p&gt;
&lt;p&gt;load_dotenv()&lt;/p&gt;
&lt;p&gt;secret_key = os.getenv('SECRET_KEY')
   debug = os.getenv('DEBUG')&lt;/p&gt;
&lt;p&gt;print(f"Secret Key: {secret_key}")
   print(f"Debug Mode: {debug}")
   ```&lt;/p&gt;
&lt;p&gt;Migrate to &lt;code&gt;python-decouple&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```python
   # New code using python-decouple
   from decouple import config&lt;/p&gt;
&lt;p&gt;secret_key = config('SECRET_KEY')
   debug = config('DEBUG', default=False, cast=bool)&lt;/p&gt;
&lt;p&gt;print(f"Secret Key: {secret_key}")
   print(f"Debug Mode: {debug}")
   ```&lt;/p&gt;
&lt;p&gt;In the above example:
   - &lt;code&gt;config('SECRET_KEY')&lt;/code&gt; reads the value of &lt;code&gt;SECRET_KEY&lt;/code&gt; from the &lt;code&gt;.env&lt;/code&gt; file.
   - &lt;code&gt;config('DEBUG', default=False, cast=bool)&lt;/code&gt; reads the value of &lt;code&gt;DEBUG&lt;/code&gt; from the &lt;code&gt;.env&lt;/code&gt; file, with a default value of &lt;code&gt;False&lt;/code&gt; if &lt;code&gt;DEBUG&lt;/code&gt; is not set, and converts it to a boolean.&lt;/p&gt;
&lt;p&gt;&lt;a id="add-pydantic-or-dataclass"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Add pydantic or dataclass&lt;/h2&gt;
&lt;p&gt;Using &lt;code&gt;pydantic&lt;/code&gt; or &lt;code&gt;dataclass&lt;/code&gt; to define a configuration class in your Python project can  lead to more reliable and pythonic code. Both &lt;code&gt;pydantic&lt;/code&gt; and &lt;code&gt;dataclass&lt;/code&gt; provide ways to define data structures with type validation and optional default values. Whether your config should be immutable depends on your specific use case and preferences, but immutability can often lead to safer and more predictable behavior, especially in multi-threaded or concurrent environments.&lt;/p&gt;
&lt;p&gt;Here's how you can use &lt;code&gt;pydantic&lt;/code&gt; and &lt;code&gt;dataclass&lt;/code&gt; to define a configuration class for your project:&lt;/p&gt;
&lt;p&gt;&lt;a id="using-pydantic"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Using &lt;code&gt;pydantic&lt;/code&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydantic&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BaseModel&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AppConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BaseModel&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;secret_key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AppConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;secret_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;your_secret_key&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="using-dataclass"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Using &lt;code&gt;dataclass&lt;/code&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dataclasses&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dataclass&lt;/span&gt;

&lt;span class="nd"&gt;@dataclass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frozen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AppConfig&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;secret_key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;

&lt;span class="c1"&gt;# Usage&lt;/span&gt;
&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AppConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;secret_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;your_secret_key&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="advantages-of-using-pydantic-or-dataclass"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Advantages of using &lt;code&gt;pydantic&lt;/code&gt; or &lt;code&gt;dataclass&lt;/code&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Type validation&lt;/strong&gt;: Both &lt;code&gt;pydantic&lt;/code&gt; and &lt;code&gt;dataclass&lt;/code&gt; allow you to specify the types of your configuration attributes, providing type safety and reducing the risk of runtime errors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Default values&lt;/strong&gt;: You can specify default values for configuration attributes, making it easier to define a set of common configurations while still allowing customization when needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Immutability&lt;/strong&gt; (with &lt;code&gt;frozen=True&lt;/code&gt; in &lt;code&gt;dataclass&lt;/code&gt;): Making the configuration class immutable can prevent accidental modification of configuration values, leading to more predictable behavior, especially in multi-threaded or concurrent environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pythonic syntax&lt;/strong&gt;: Both &lt;code&gt;pydantic&lt;/code&gt; and &lt;code&gt;dataclass&lt;/code&gt; provide a concise and pythonic syntax for defining data structures, making your code more readable and maintainable.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="should-the-config-be-immutable"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Should the config be immutable?&lt;/h3&gt;
&lt;p&gt;Whether your config should be immutable depends on your specific use case and requirements. Here are some considerations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Predictability&lt;/strong&gt;: Immutability can make your code more predictable by preventing accidental changes to configuration values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concurrency&lt;/strong&gt;: In multi-threaded or concurrent environments, immutability can help prevent race conditions and synchronization issues.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt;: Immutable objects are often easier to test since you don't need to worry about side effects from modifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, if you anticipate needing to modify configuration values dynamically at runtime, immutability may not be suitable for your use case. Ultimately, consider your project's requirements and design your configuration class accordingly.&lt;/p&gt;
&lt;p&gt;&lt;a id="dataclass--decouple-example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;dataclass + decouple example&lt;/h2&gt;
&lt;p&gt;Here is an example demonstrating how to combine &lt;code&gt;dataclass&lt;/code&gt; with &lt;code&gt;python-decouple&lt;/code&gt; to manage configuration in a Python project:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;code&gt;python-decouple&lt;/code&gt;&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you haven't already, install &lt;code&gt;python-decouple&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
   pip install python-decouple&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Create a &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in your project directory and add your environment variables:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plaintext
   SECRET_KEY=your_secret_key
   DEBUG=True&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Define a &lt;code&gt;dataclass&lt;/code&gt; for configuration&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Create a Python file (e.g., &lt;code&gt;config.py&lt;/code&gt;) and define a &lt;code&gt;dataclass&lt;/code&gt; for your configuration:&lt;/p&gt;
&lt;p&gt;```python
   from dataclasses import dataclass&lt;/p&gt;
&lt;p&gt;@dataclass
   class AppConfig:
       secret_key: str
       debug: bool
   ```&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Read configuration from &lt;code&gt;.env&lt;/code&gt; using &lt;code&gt;decouple&lt;/code&gt;&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Modify your &lt;code&gt;config.py&lt;/code&gt; file to read the configuration from the &lt;code&gt;.env&lt;/code&gt; file using &lt;code&gt;decouple&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```python
   from dataclasses import dataclass
   from decouple import config&lt;/p&gt;
&lt;p&gt;@dataclass
   class AppConfig:
       secret_key: str = config('SECRET_KEY')
       debug: bool = config('DEBUG', default=False, cast=bool)&lt;/p&gt;
&lt;p&gt;# Create an instance of AppConfig
   config = AppConfig()
   ```&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Usage&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now you can use the &lt;code&gt;AppConfig&lt;/code&gt; class instance in your project to access configuration values:&lt;/p&gt;
&lt;p&gt;```python
   from config import config&lt;/p&gt;
&lt;p&gt;# Access configuration values
   print(f"Secret Key: {config.secret_key}")
   print(f"Debug Mode: {config.debug}")
   ```&lt;/p&gt;
&lt;p&gt;With this setup, you're using &lt;code&gt;dataclass&lt;/code&gt; to define a structured configuration class, and &lt;code&gt;decouple&lt;/code&gt; to read configuration values from the &lt;code&gt;.env&lt;/code&gt; file. This combination allows you to manage your project's configuration in a more organized and pythonic way.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="config"></category><category term="configuration"></category><category term="pydantic"></category><category term="decouple"></category><category term="python-app-config"></category><category term="immutable"></category><category term="casting"></category><category term="env-vars"></category><category term="environmental-variables"></category></entry><entry><title>OSI Approved in license metadata for Python project</title><link href="https://www.safjan.com/osi-approved-in-license-metadata-for-python-project/" rel="alternate"></link><published>2024-04-16T00:00:00+02:00</published><updated>2024-04-16T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-04-16:/osi-approved-in-license-metadata-for-python-project/</id><summary type="html">&lt;p&gt;When it comes to sharing and distributing Python projects, clarity about licensing is crucial. A license tells users what they can and cannot do with your code, impacting everything from contributions to commercial use. The &lt;code&gt;pyproject.toml&lt;/code&gt; file, as outlined in &lt;a href="https://peps.python.org/pep-0518/"&gt;PEP …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;When it comes to sharing and distributing Python projects, clarity about licensing is crucial. A license tells users what they can and cannot do with your code, impacting everything from contributions to commercial use. The &lt;code&gt;pyproject.toml&lt;/code&gt; file, as outlined in &lt;a href="https://peps.python.org/pep-0518/"&gt;PEP 518 – Specifying Minimum Build System Requirements for Python Projects&lt;/a&gt; and enhanced by subsequent PEPs, provides a standardized format for project metadata, including license information. By specifying an "OSI Approved" license in your &lt;code&gt;pyproject.toml&lt;/code&gt;, you not only make your software's terms of use explicit but also ensure you’re adhering to the standards that have become the cornerstone of open-source software.&lt;/p&gt;
&lt;p&gt;In this blog post, we'll dive into the &lt;code&gt;[project]&lt;/code&gt; section of the &lt;code&gt;pyproject.toml&lt;/code&gt; file, where you can define your project's license. We will explore the reasons why including an OSI Approved license in your Python project metadata is not just good practice but also a reflection of your commitment to the open-source community's values.&lt;/p&gt;
&lt;p&gt;Join us as we unpack the benefits of explicit licensing, how it can save you and your users legal headaches, and why it's an essential component of any reputable Python project.&lt;/p&gt;
&lt;h2&gt;OSI Approval&lt;/h2&gt;
&lt;p&gt;"OSI Approved" in the context of a license listed in a &lt;code&gt;pyproject.toml&lt;/code&gt; file for a Python project indicates that the license under which the project is distributed has been approved by the Open Source Initiative (OSI).&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://opensource.org/"&gt;Open Source Initiative&lt;/a&gt; is a non-profit organization that advocates for open-source software and maintains the Open Source Definition. A license that is OSI Approved means that it complies with this definition, which includes a set of criteria to ensure free redistribution, access to source code, and other important freedoms related to software usage and distribution.&lt;/p&gt;
&lt;p&gt;Therefore, if a project's &lt;code&gt;pyproject.toml&lt;/code&gt; specifies a license as "OSI Approved," it implies that the software can be freely used, modified, and shared under the terms that are consistent with the open-source movement, as validated by the OSI's review process. It's a mark of recognition that the software license adheres to open-source principles.&lt;/p&gt;
&lt;h2&gt;Examples of OSI approved licenses&lt;/h2&gt;
&lt;p&gt;The Open Source Initiative (OSI) approves various licenses that comply with their Open Source Definition. Some of the most commonly used OSI approved licenses include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MIT License&lt;/li&gt;
&lt;li&gt;Apache License 2.0&lt;/li&gt;
&lt;li&gt;GNU General Public License (GPL) 2.0 &amp;amp; 3.0&lt;/li&gt;
&lt;li&gt;BSD Licenses (2-clause and 3-clause)&lt;/li&gt;
&lt;li&gt;GNU Lesser General Public License (LGPL)&lt;/li&gt;
&lt;li&gt;Mozilla Public License 2.0&lt;/li&gt;
&lt;li&gt;Eclipse Public License&lt;/li&gt;
&lt;li&gt;GNU Affero General Public License (AGPL)&lt;/li&gt;
&lt;li&gt;Creative Commons Zero v1.0 Universal (CC0)&lt;/li&gt;
&lt;li&gt;Artistic License 2.0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each of these licenses has its own terms and conditions, varying in terms of how redistributions must credit&lt;/p&gt;
&lt;h2&gt;Examples of  licenses without approval from OSI&lt;/h2&gt;
&lt;p&gt;There are several licenses that are not approved by the Open Source Initiative (OSI) either because they have not been submitted for approval, they discriminate against persons or groups, they discriminate against fields of endeavor, they are not technology-neutral, or for other reasons that conflict with the Open Source Definition. Some examples include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Various Creative Commons licenses (excluding CC0):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Licenses such as Creative Commons Attribution-NonCommercial (CC BY-NC), Creative Commons Attribution-NoDerivatives (CC BY-ND), and others are not OSI-approved because they impose restrictions on commercial use or the creation of derivative works, which goes against the Open Source Definition that requires the license to allow modifications and derived works.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JSON License ("The Software shall be used for Good, not Evil"):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The JSON License includes a clause that specifies "The Software shall be used for Good, not Evil," which introduces a subjective and non-legal term. This clause can be interpreted in various ways and thus makes it non-free according to the open-source criteria, which insist on no discrimination against fields of endeavor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Apple Public Source License 1.x:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The earlier versions of the Apple Public Source License were not approved by the OSI due to concerns about the license's compatibility and restrictions on the usage of the covered software. Apple addressed these issues in version 2.0, which was approved by the OSI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Badgeware Licenses (Original Attribution Assurance License, the Honest Public License, etc.):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These licenses require the display of a logo, badge, or attribution in a manner that the OSI considers overly burdensome and not in line with the Open Source Definition's requirements for free redistribution.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Microsoft Limited Public License (Ms-LPL) and the Microsoft Reciprocal License (Ms-RL):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These licenses were specific to Windows and were not technology-neutral, making them incompatible with the OSI's requirement that open-source licenses must not restrict the software to run on a particular operating system or environment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; When using software under a specific license or choosing a license for your own work, checking the current OSI-approved list is advisable for the most up-to-date information.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="note"></category><category term="license"></category><category term="pyproject"></category><category term="osi"></category><category term="open-source-initiative"></category></entry><entry><title>GitHub - Troubleshooting 'Permission to repo.git denied to user'</title><link href="https://www.safjan.com/github-permission-to-repogit-denied-to-user/" rel="alternate"></link><published>2024-03-21T00:00:00+01:00</published><updated>2024-03-21T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-03-21:/github-permission-to-repogit-denied-to-user/</id><summary type="html">&lt;p&gt;When working with GitHub, you might encounter an issue that restricts you from executing a 'git push' operation due to permissions. This post will guide you through solving this problem and help you understand its causes.&lt;/p&gt;
&lt;p&gt;Let's look at the issue in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When working with GitHub, you might encounter an issue that restricts you from executing a 'git push' operation due to permissions. This post will guide you through solving this problem and help you understand its causes.&lt;/p&gt;
&lt;p&gt;Let's look at the issue in focus. You are trying to push to your repository:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;However, the terminal returns an error that resembles:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;ERROR&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Permission&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;USER&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;REPO&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;git&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;denied&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;USER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;fatal&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Could&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sure&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;have&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;correct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;access&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rights&lt;/span&gt;
&lt;span class="n"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This issue often arises when you are operating two GitHub accounts interchangeably on the same machine and are using SSH keys for authorization.&lt;/p&gt;
&lt;p&gt;One straightforward workaround, although not the most efficient, is to simply log out from the conflicting GitHub account, reboot the machine, and then attempt to push again. However, this method is a quick-fix and might not solve the underlying issue.&lt;/p&gt;
&lt;p&gt;The root of this problem often lies within SSH authentication, particularly involving the 'ssh-agent'. The ssh-agent is a program that holds private keys used for public key authentication (RSA, DSA, ECDSA, Ed25519).&lt;/p&gt;
&lt;p&gt;The solution is to clear all identities (SSH keys) stored by the ssh-agent:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ssh-add&lt;span class="w"&gt; &lt;/span&gt;-D
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The command &lt;code&gt;ssh-add -D&lt;/code&gt; deletes all identities from the agent. &lt;/p&gt;
&lt;p&gt;However, if you want to be more precise and remove specific keys, you can specify the file path of the key:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ssh-add&lt;span class="w"&gt; &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/id_rsa
ssh-add&lt;span class="w"&gt; &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/github
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above commands remove the id_rsa and github keys, respectively. &lt;/p&gt;
&lt;p&gt;After cleaning up the stored keys, you can add the required SSH key back to the ssh-agent. This key should correspond to the GitHub account you intend to push to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ssh-add&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/github
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By performing these steps, you can effectively manage your SSH keys and prevent conflicts when working with multiple GitHub accounts on the same machine. &lt;/p&gt;</content><category term="note"></category><category term="git"></category><category term="github"></category><category term="ssh"></category><category term="ssh-key"></category></entry><entry><title>Open Source LLM Observability Tools and Platforms</title><link href="https://www.safjan.com/open-source-llm-observability-tools-and-platforms/" rel="alternate"></link><published>2024-02-22T00:00:00+01:00</published><updated>2024-06-26T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-02-22:/open-source-llm-observability-tools-and-platforms/</id><summary type="html">&lt;p&gt;Managing and monitoring the complex behavior of Large Language Models (LLMs) becomes increasingly crucial. LLMOps and LLM Observability provide essential tools for understanding and controlling these models, ensuring their safe and effective deployment. This article delves into the critical aspects of LLM Observability in the realm of generative AI.&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#llm-observability-in-the-context-of-llmops-for-generative-ai"&gt;LLM Observability in the Context of LLMOps for Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-is-llm-observability"&gt;What is LLM Observability?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#expected-functionalities-of-an-llm-observability-solution"&gt;Expected Functionalities of an LLM Observability Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open-source-llm-observability-tools-and-platforms"&gt;Open Source LLM Observability Tools and Platforms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#non-open-source"&gt;Non-open source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other---related"&gt;Other - related&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="llm-observability-in-the-context-of-llmops-for-generative-ai"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;LLM Observability in the Context of LLMOps for Generative AI&lt;/h2&gt;
&lt;p&gt;AI is transforming the world, and one area where it has made significant strides is in generative models, particularly in the field of Large Language Models (LLMs) like GPT-3 and transformer models. However, as impressive as these models are, managing, monitoring, and understanding their behavior and output remains a challenge. Enter LLMOps, a new field focusing on the management and deployment of LLMs, and a key aspect of this is LLM Observability. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#llm-observability-in-the-context-of-llmops-for-generative-ai"&gt;LLM Observability in the Context of LLMOps for Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-is-llm-observability"&gt;What is LLM Observability?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#expected-functionalities-of-an-llm-observability-solution"&gt;Expected Functionalities of an LLM Observability Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open-source-llm-observability-tools-and-platforms"&gt;Open Source LLM Observability Tools and Platforms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other---related"&gt;Other - related&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="what-is-llm-observability"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What is LLM Observability?&lt;/h2&gt;
&lt;p&gt;LLM Observability is the ability to understand, monitor, and infer the internal state of an LLM from its external outputs. It encompasses several areas including model health monitoring, performance tracking, debugging, and evaluating model fairness and safety. &lt;/p&gt;
&lt;p&gt;In the context of LLMOps, LLM Observability is critical. LLMs are complex and can be unpredictable, producing outputs that range from harmless to potentially harmful or biased. It's therefore essential to have the right tools and methodologies for observing and understanding these models' behaviors in real-time, during training, testing, and after deployment.&lt;/p&gt;
&lt;p&gt;&lt;a id="expected-functionalities-of-an-llm-observability-solution"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Expected Functionalities of an LLM Observability Solution&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Performance Monitoring&lt;/strong&gt;: An observability solution should be able to track and monitor the performance of an LLM in real-time. This includes tracking metrics like accuracy, precision, recall, and F1 score, as well as more specific metrics like perplexity or token costs in the case of language models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Health Monitoring&lt;/strong&gt;: The solution should be capable of monitoring the overall health of the model, identifying and alerting on anomalies or potentially problematic patterns in the model's behavior.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Debugging and Error Tracking&lt;/strong&gt;: If something does go wrong, the solution should provide debugging and error tracking functionalities, helping developers identify, trace, and fix issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fairness, Bias, and Safety Evaluation&lt;/strong&gt;: Given the potential for bias and ethical issues in AI, any observability solution should include features for evaluating fairness and safety, helping ensure that the model's outputs are unbiased and ethically sound.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interpretability&lt;/strong&gt;: LLMs can often be "black boxes", producing outputs without clear reasoning. A good observability solution should help make the model's decision-making process more transparent, providing insights into why a particular output was produced.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integration with Existing LLMOps Tools&lt;/strong&gt;: Finally, the solution should be capable of integrating with existing LLMOps tools and workflows, from model development and training to deployment and maintenance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;LLM Observability is a crucial aspect of LLMOps for generative AI. It provides the &lt;strong&gt;visibility&lt;/strong&gt; and &lt;strong&gt;control&lt;/strong&gt; needed &lt;strong&gt;to effectively manage, deploy, and maintain Large Language Models&lt;/strong&gt;, ensuring they &lt;strong&gt;perform as expected, are free from bias, and are safe to use&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="open-source-llm-observability-tools-and-platforms"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Open Source LLM Observability Tools and Platforms&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/aavetis/azure-openai-logger"&gt;Azure OpenAI Logger&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/aavetis/azure-openai-logger.svg?logo=github"&gt; - "Batteries included" logging solution for your Azure OpenAI instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Azure OpenAI Logger" src="https://github.com/aavetis/azure-openai-logger/raw/main/images/demo.gif"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/deepchecks/deepchecks"&gt;Deepchecks&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/deepchecks/deepchecks.svg?logo=github"&gt; - Tests for Continuous Validation of ML Models &amp;amp; Data. Deepchecks is a Python package for comprehensively validating your machine learning models and data with minimal effort.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/evidentlyai/evidently"&gt;Evidently&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/evidentlyai/evidently.svg?logo=github"&gt; - Evaluate and monitor ML models from validation to production.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Giskard-AI/giskard"&gt;Giskard&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/Giskard-AI/giskard.svg?logo=github"&gt; - Testing framework dedicated to ML models, from tabular to LLMs. Detect risks of biases, performance issues and errors in 4 lines of code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/whylabs/whylogs"&gt;whylogs&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/whylabs/whylogs.svg?logo=github"&gt; - The open standard for data logging&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lunary-ai/lunary"&gt;lunary&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/lunary-ai/lunary.svg?logo=github"&gt; - The production toolkit for LLMs. observability, prompt management, and evaluations.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/traceloop/openllmetry"&gt;openllmetry&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/traceloop/openllmetry.svg?logo=github"&gt; - Open-source observability for your LLM application, based on OpenTelemetry&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Arize-ai/phoenix"&gt;phoenix (Arize Ai)&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/Arize-ai/phoenix.svg?logo=github"&gt; - AI Observability &amp;amp; Evaluation - Evaluate, troubleshoot, and fine-tune your LLM, CV, and NLP models in a notebook.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/langfuse/langfuse"&gt;langfuse&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/langfuse/langfuse.svg?logo=github"&gt; - Open source LLM engineering platform. observability, metrics, evals, prompt management  SDKs + integrations for Typescript, Python&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/whylabs/langkit"&gt;LangKit&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/whylabs/langkit.svg?logo=github"&gt; - An open-source toolkit for monitoring Large Language Models (LLMs).  Extracts signals from prompts &amp;amp; responses, ensuring safety &amp;amp; security. Features include text quality, relevance metrics, &amp;amp; sentiment analysis. Comprehensive tool for LLM observability.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AgentOps-AI/agentops"&gt;agentops&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/AgentOps-AI/agentops.svg?logo=github"&gt; - Python SDK for agent evals and observability&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pezzolabs/pezzo"&gt;pezzo&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/pezzolabs/pezzo.svg?logo=github"&gt; - Open-source, developer-first LLMOps platform designed to streamline prompt design, version management, instant delivery, collaboration, troubleshooting, observability and more.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fiddler-labs/fiddler-auditor"&gt;Fiddler AI&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/fiddler-labs/fiddler-auditor.svg?logo=github"&gt; - Evaluate, monitor, analyse, and improve machine learning and generative models from pre-production to production. Ship more ML and LLMs into production, and monitor ML and LLM metrics like hallucination, PII, and toxicity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Theodo-UK/OmniLog"&gt;OmniLog&lt;/a&gt; - &lt;img alt="github stars shield" src="https://img.shields.io/github/stars/Theodo-UK/OmniLog.svg?logo=github"&gt; - Observability tool for your LLM prompts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="non-open-source"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Non-open source&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.rungalileo.io/galileo/galileo-gen-ai-studio/llm-studio"&gt;Generative AI Studio - Galileo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="other---related"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Other - related&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/great-expectations/great_expectations"&gt;Great Expectations&lt;/a&gt; - Always know what to expect from your data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AgentOps-AI/tokencost"&gt;AgentOps-AI/tokencost&lt;/a&gt; - Easy token price estimates for LLMs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/YANG-DB/observability-prompots"&gt;observability prompts&lt;/a&gt; - LLM observability related prompts&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AstronomerAmber/LLM_Observability"&gt;LLM Observability&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/BoundaryML/baml"&gt;baml&lt;/a&gt;  - A programming language to build strongly-typed LLM functions. Testing and observability included&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/fluxninja/aperture"&gt;aperture&lt;/a&gt; - Rate limiting, caching, and request prioritization for modern workloads&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/llm-monitoring-and-observability-c28121e75c2f"&gt;LLM Monitoring and Observability — A Summary of Techniques and Approaches for Responsible AI | by Josh Poduska | Towards Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.aporia.com/learn/how-to-monitor-large-language-models/"&gt;Monitoring LLMs: Metrics, challenges, &amp;amp; hallucinations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mattcvincent/intro-llm-observability"&gt;mattcvincent/intro-&lt;em&gt;llm&lt;/em&gt;-&lt;em&gt;observability&lt;/em&gt;&lt;/a&gt; - Intro to LLM Observability&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.33rdsquare.com/what-is-perplexity-ai/"&gt;Demystifying Perplexity: An AI Expert‘s Comprehensive Guide - 33rd Square&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://huggingface.co/spaces/evaluate-metric/perplexity"&gt;Perplexity - a Hugging Face Space by evaluate-metric&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2024-06-26: Added summary&lt;/li&gt;
&lt;/ul&gt;</content><category term="Generative AI"></category><category term="observability"></category><category term="mlops"></category><category term="llmops"></category><category term="llm"></category><category term="monitoring"></category><category term="model-monitoring"></category><category term="prompt-management"></category><category term="data-logging"></category><category term="model-logging"></category></entry><entry><title>The Most Powerful Mac Productivity and Automation Apps</title><link href="https://www.safjan.com/the-most-powerful-mac-productivity-and-automation-apps/" rel="alternate"></link><published>2024-01-24T00:00:00+01:00</published><updated>2024-01-24T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-01-24:/the-most-powerful-mac-productivity-and-automation-apps/</id><summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.alfredapp.com/"&gt;Alfred&lt;/a&gt;: A productivity app for Mac OS X, which boosts your efficiency with hotkeys, keywords, text expansion, and more. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://folivora.ai/"&gt;BetterTouchTool&lt;/a&gt;: Allows you to configure many types of gestures for your Mac’s Trackpad, Magic Mouse, and Keyboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.noodlesoft.com/"&gt;Hazel&lt;/a&gt;: A system preference pane …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.alfredapp.com/"&gt;Alfred&lt;/a&gt;: A productivity app for Mac OS X, which boosts your efficiency with hotkeys, keywords, text expansion, and more. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://folivora.ai/"&gt;BetterTouchTool&lt;/a&gt;: Allows you to configure many types of gestures for your Mac’s Trackpad, Magic Mouse, and Keyboard.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.noodlesoft.com/"&gt;Hazel&lt;/a&gt;: A system preference pane that works silently in the background, automatically filing, organizing, and cleaning up your desktop.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://support.apple.com/guide/automator/welcome/mac"&gt;Automator&lt;/a&gt;: A built-in Mac utility for automating tasks. You can create workflows, watch folders, and set up automated actions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.keyboardmaestro.com/"&gt;Keyboard Maestro&lt;/a&gt;: Enhances the power of your keyboard by creating macros that can automate virtually anything on your Mac. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://qsapp.com/"&gt;QuickSilver&lt;/a&gt;: A light, fast, and free Mac application launcher that also replaces your task switcher.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://culturedcode.com/things/"&gt;Things&lt;/a&gt;: Task management software that makes it easy to stay organized and get things done.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ulysses.app/"&gt;Ulysses&lt;/a&gt;: A feature-rich text editor for writers that allows you to manage and organize all your writing in a single app.  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.folivora.ai/bettersnaptool"&gt;BetterSnapTool&lt;/a&gt;: Allows users to quickly and easily manage their window positions and sizes by either dragging them to one of the screen's corners or to the top, left or right side of the screen.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.macbartender.com/"&gt;Bartender&lt;/a&gt;: Lets you organize your menu bar apps by hiding them, rearranging them, or moving them to the Bartender Bar. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://magnet.crowdcafe.com/"&gt;Magnet&lt;/a&gt;: Keeps your workspace organized and allows you to snap application windows in different halves or quarters of your screen.&lt;/li&gt;
&lt;/ol&gt;</content><category term="note"></category><category term="macos"></category><category term="alfred"></category><category term="gestures"></category><category term="hazel"></category><category term="automator"></category><category term="keyboard-maestro"></category></entry><entry><title>Avoid using curl -u “username:secret”!</title><link href="https://www.safjan.com/avoid-using-curl-u-usernamesecret/" rel="alternate"></link><published>2024-01-20T00:00:00+01:00</published><updated>2024-01-20T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-01-20:/avoid-using-curl-u-usernamesecret/</id><summary type="html">&lt;p&gt;When invoking an endpoint guarded by Basic Authentication, you might resort to the -u username:password feature in curl.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -u "jane@examplewebsite.com:mySecretGuard" http://api.myawesomeapp.com/information&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;However, this approach is not the most efficient or secure.&lt;/p&gt;
&lt;p&gt;In executing …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When invoking an endpoint guarded by Basic Authentication, you might resort to the -u username:password feature in curl.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -u "jane@examplewebsite.com:mySecretGuard" http://api.myawesomeapp.com/information&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;However, this approach is not the most efficient or secure.&lt;/p&gt;
&lt;p&gt;In executing this command, the credentials are archived in your shell history, posing a considerable security threat.&lt;/p&gt;
&lt;p&gt;On the bright side, there's a straightforward solution to this issue!&lt;/p&gt;
&lt;p&gt;Now you can generate a file in your home directory titled &lt;code&gt;.netrc&lt;/code&gt; as shown below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;machine&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;api&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;myawesomeapp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;login&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;jane&lt;/span&gt;&lt;span class="nv"&gt;@examplewebsite&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mySecretGuard&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Afterwards, when running the curl command, just include -n and the credentials will be fetched from the file you just created.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -n http://api.myawesomeapp.com/information&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To give you more context, curl is a command-line tool for getting or sending data using URL syntax. It supports various protocols, including but not limited to HTTP, HTTPS, FTP, and FTPS. Curl is widely used for making API requests.&lt;/p&gt;
&lt;p&gt;In addition, the &lt;code&gt;.netrc&lt;/code&gt; file is a special file that stores login and initialisation information used by the auto-login process. It generally resides in the user's home directory. This file can contain information like the name of the machine to which to connect, and any necessary usernames and passwords.&lt;/p&gt;
&lt;p&gt;On a final note, remember that this method works only with the curl command. Other command-line tools may require different approaches to secure authentication. Always prioritise data security by opting for methods that safeguard your login credentials.&lt;/p&gt;</content><category term="note"></category><category term="curl"></category><category term="security"></category><category term="shell-history"></category><category term="netrc"></category></entry><entry><title>HTML5 interactive elements</title><link href="https://www.safjan.com/html5-interactive-elements/" rel="alternate"></link><published>2024-01-04T00:00:00+01:00</published><updated>2024-01-04T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-01-04:/html5-interactive-elements/</id><summary type="html">&lt;h1&gt;HTML5 Interactive Elements: An Overview and Usage Guide&lt;/h1&gt;
&lt;p&gt;HyperText Markup Language (HTML) is the standard markup language for documents designed to be rendered in a web browser. Over the years, HTML has evolved to keep up with the growing need for better …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;HTML5 Interactive Elements: An Overview and Usage Guide&lt;/h1&gt;
&lt;p&gt;HyperText Markup Language (HTML) is the standard markup language for documents designed to be rendered in a web browser. Over the years, HTML has evolved to keep up with the growing need for better structure and interactivity. &lt;/p&gt;
&lt;p&gt;HTML5, the latest version, introduces several interactive tags or elements, which makes building interactive, dynamic web content easier without having to resort to JavaScript or CSS. Let's dive into these interactive elements and have a look at some examples to understand their usage better.&lt;/p&gt;
&lt;h2&gt;The &lt;code&gt;&amp;lt;details&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;summary&amp;gt;&lt;/code&gt; Elements&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;&amp;lt;details&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;summary&amp;gt;&lt;/code&gt; tags allow us to create an interactive widget that the user can open or close. The &lt;code&gt;&amp;lt;summary&amp;gt;&lt;/code&gt; tag is a child of the &lt;code&gt;&amp;lt;details&amp;gt;&lt;/code&gt; tag, representing the summary or brief description of the content in &lt;code&gt;&amp;lt;details&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;details&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;The Solar System&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;The Solar System includes the Sun, the Earth (where you are now!) and all the other planets.&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;details&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;details&gt;
    &lt;summary&gt;The Solar System&lt;/summary&gt;
    &lt;p&gt;The Solar System includes the Sun, the Earth (where you are now!) and all the other planets.&lt;/p&gt;
&lt;/details&gt;

&lt;h2&gt;The &lt;code&gt;&amp;lt;dialog&amp;gt;&lt;/code&gt; Element&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;&amp;lt;dialog&amp;gt;&lt;/code&gt; element presents content in a dialogue box or a window. You can toggle the visibility of the &lt;code&gt;&amp;lt;dialog&amp;gt;&lt;/code&gt; by changing the 'open' attribute.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;dialog&lt;/span&gt; &lt;span class="na"&gt;open&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    This is a dialog box!&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;br&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;button&lt;/span&gt; &lt;span class="na"&gt;onclick&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;this.parentElement.close()&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Close&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;button&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;dialog&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;dialog open&gt;
    This is a dialog box!&lt;br&gt;
    &lt;button onclick="this.parentElement.close()"&gt;Close&lt;/button&gt;
&lt;/dialog&gt;&lt;/p&gt;
&lt;h2&gt;The &lt;code&gt;&amp;lt;datalist&amp;gt;&lt;/code&gt; Element&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;&amp;lt;datalist&amp;gt;&lt;/code&gt; element permits the creation of pre-defined options for an &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; element. User can either select an option or type in their input.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;label&lt;/span&gt; &lt;span class="na"&gt;for&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;browsers&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Choose a browser from the list:&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;label&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="na"&gt;list&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;browsers&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;browser&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;browser&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;datalist&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;browsers&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;option&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Chrome&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;option&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Firefox&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;option&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Internet Explorer&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;option&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Opera&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;option&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Safari&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;datalist&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;label for="browsers"&gt;Choose a browser from the list:&lt;/label&gt;
&lt;input list="browsers" name="browser" id="browser"&gt;
&lt;datalist id="browsers"&gt;
&lt;br&gt;
&lt;option value="Chrome"&gt;
  &lt;option value="Firefox"&gt;
  &lt;option value="Internet Explorer"&gt;
  &lt;option value="Opera"&gt;
  &lt;option value="Safari"&gt;
&lt;/datalist&gt;

## The `&lt;progress&gt;` Element

The `&lt;progress&gt;` element serves to represent the progress of a task. Use the `value` attribute to specify the current progress and the `max` attribute to indicate the progress bar's maximum value.


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;progress&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;70&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;100&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;progress&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



&lt;progress value="70" max="100"&gt;&lt;/progress&gt;

## The `&lt;meter&gt;` Element

The `&lt;meter&gt;` tag is used to represent the scalar measurement within a known range, or a fractional value. This could be the disk usage, the relevance of a query result or any other form of gauge.


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Disk usage: &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meter&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;0.6&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;60%&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



Disk usage: &lt;meter value="0.6"&gt;60%&lt;/meter&gt;

## The `&lt;output&gt;` Element

The `&lt;output&gt;` tag is a container for calculation results. To link the output element with other elements, you can use the `for` attribute. 


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;form&lt;/span&gt; &lt;span class="na"&gt;oninput&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;x.value=parseInt(a.value)+parseInt(b.value)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  0&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;range&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;50&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;100 +
  0&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;input&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;range&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;50&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;100 =
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;output&lt;/span&gt; &lt;span class="na"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;x&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;for&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a b&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;output&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;form&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



&lt;form oninput="x.value=parseInt(a.value)+parseInt(b.value)"&gt;
  0&lt;input type="range" id="a" value="50"&gt;100 +
  0&lt;input type="range" id="b" value="50"&gt;100 =
  &lt;output name="x" for="a b"&gt;&lt;/output&gt;
&lt;/form&gt;

## The `&lt;canvas&gt;` Element

The `&lt;canvas&gt;` tag allows for dynamic and scriptable rendering of shapes and bitmap images. It's a low-level, procedural model that updates a bitmap.


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;canvas&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;myCanvas&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;200&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;100&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;border:1px solid #000000;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;canvas&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;





You can then use JavaScript to interact with this element:


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kd"&gt;var&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;myCanvas&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;2d&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;fillStyle&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;#FF0000&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nx"&gt;ctx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;fillRect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;80&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;canvas id="myCanvas" width="200" height="100" style="border:1px solid #000000;"&gt;
&lt;/canvas&gt;
&lt;script&gt;
var c = document.getElementById("myCanvas");
var ctx = c.getContext("2d");
ctx.fillStyle = "#FF0000";
ctx.fillRect(0, 0, 80, 80);
&lt;/script&gt;



&lt;/p&gt;</content><category term="note"></category><category term="html5"></category></entry><entry><title>entr - run arbitrary command when files change</title><link href="https://www.safjan.com/entr-run-arbitrary-command-when-files-change/" rel="alternate"></link><published>2024-01-01T00:00:00+01:00</published><updated>2024-01-01T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2024-01-01:/entr-run-arbitrary-command-when-files-change/</id><summary type="html">&lt;p&gt;&lt;code&gt;entr&lt;/code&gt; is a UNIX utility which runs arbitrary commands when files change. It helps in automating tasks during development such as rebuilding projects, running tests, or syncing files.&lt;/p&gt;
&lt;p&gt;Here's a simple usage example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ls *.c | entr make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above example, &lt;code&gt;ls …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;code&gt;entr&lt;/code&gt; is a UNIX utility which runs arbitrary commands when files change. It helps in automating tasks during development such as rebuilding projects, running tests, or syncing files.&lt;/p&gt;
&lt;p&gt;Here's a simple usage example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ls *.c | entr make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above example, &lt;code&gt;ls *.c&lt;/code&gt; lists all C files in the directory. This list is piped (&lt;code&gt;|&lt;/code&gt;) into &lt;code&gt;entr&lt;/code&gt;. When any of these files changes, &lt;code&gt;entr&lt;/code&gt; executes the &lt;code&gt;make&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Some key features of &lt;code&gt;entr&lt;/code&gt; include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It frees up developers to focus on the code by automating rebuild tasks.&lt;/li&gt;
&lt;li&gt;It doesn't require a configuration file or a list of tasks to run. It just reruns the command you provide it each time a file changes.&lt;/li&gt;
&lt;li&gt;You can use it with any command that needs to operate on a file. This might be shell commands, like &lt;code&gt;ls&lt;/code&gt; or &lt;code&gt;echo&lt;/code&gt;, or any other CLI tool you have in your system. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional commands for &lt;code&gt;entr&lt;/code&gt; include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-r&lt;/code&gt; : To restart a long running process like a server when a file changes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-p&lt;/code&gt; : Postpone execution until files are updated.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-s&lt;/code&gt; : Evaluate the first argument using the interpreter specified by the SHELL environment variable.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-d&lt;/code&gt; : Track directories recursively and include files that are created after the utility starts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that &lt;code&gt;entr&lt;/code&gt; requires a list of files as input. It does not discover files on its own, it expects to receive a list of files from stdin, which is usually supplied with command line utilities like &lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;find&lt;/code&gt; or &lt;code&gt;git ls-files&lt;/code&gt;.&lt;/p&gt;</content><category term="note"></category><category term="change"></category><category term="watch"></category><category term="watch-files"></category></entry><entry><title>Tverski Similarity Metrics</title><link href="https://www.safjan.com/tverski-similarity-metrics/" rel="alternate"></link><published>2023-12-10T00:00:00+01:00</published><updated>2023-12-10T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-10:/tverski-similarity-metrics/</id><summary type="html">&lt;p&gt;Tversky similarity and &lt;a href="https://www.safjan.com/jaro-winkler-similarity/"&gt;Jaro-Winkler Similarity&lt;/a&gt; similarity are two different similarity metrics that are used to compare strings or sequences. They are designed for specific purposes and have different mathematical formulas and applications.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#tversky-similarity"&gt;Tversky Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#formula"&gt;Formula&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-example"&gt;Python Example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#jaro-winkler-similarity-for-reference"&gt;Jaro-Winkler Similarity (for reference)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Tversky similarity and &lt;a href="https://www.safjan.com/jaro-winkler-similarity/"&gt;Jaro-Winkler Similarity&lt;/a&gt; similarity are two different similarity metrics that are used to compare strings or sequences. They are designed for specific purposes and have different mathematical formulas and applications.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#tversky-similarity"&gt;Tversky Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#formula"&gt;Formula&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-example"&gt;Python Example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#jaro-winkler-similarity-for-reference"&gt;Jaro-Winkler Similarity (for reference)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="tversky-similarity"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tversky Similarity&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Tversky similarity is a metric used to compare sets&lt;/strong&gt;, typically in the context of information retrieval, information retrieval evaluation, and recommendation systems. It was introduced by Amos Tversky in his work on set comparison. Tversky similarity takes into account the &lt;strong&gt;number of common elements&lt;/strong&gt; between two sets as well as the &lt;strong&gt;differences in elements between them&lt;/strong&gt;. It has two parameters, alpha and beta, which control the balance between precision and recall.&lt;/p&gt;
&lt;p&gt;Let's dive into the mathematical formula, explanation, and Python examples for  Tversky similarity.&lt;/p&gt;
&lt;p&gt;&lt;a id="formula"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Formula&lt;/h3&gt;
&lt;p&gt;Tversky similarity measures the similarity between two sets A and B, considering the trade-off between false positives and false negatives. The formula for Tversky similarity is:&lt;/p&gt;
&lt;div class="math"&gt;$$
Tversky(A, B) = \frac{|A \cap B|}{|A \cap B| + \alpha |A - B| + \beta |B - A|}
$$&lt;/div&gt;
&lt;p&gt;Where:
- &lt;span class="math"&gt;\((|A \cap B|)\)&lt;/span&gt; is the size of the intersection of sets A and B.
- &lt;span class="math"&gt;\((|A - B|)\)&lt;/span&gt; is the size of the set difference of A minus B.
- (&lt;span class="math"&gt;\(|B - A|)\)&lt;/span&gt; is the size of the set difference of B minus A.
- &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; are parameters that control the trade-off between precision and recall. When &lt;span class="math"&gt;\(\alpha = \beta = 1\)&lt;/span&gt;, the Tversky similarity becomes the Jaccard similarity.&lt;/p&gt;
&lt;p&gt;&lt;a id="python-example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Python Example&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tversky_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;intersection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intersection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_b&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;a_minus_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;difference&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_b&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;b_minus_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;difference&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;intersection&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;intersection&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;a_minus_b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;b_minus_a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt;

&lt;span class="n"&gt;set1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;apple&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;banana&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;cherry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;set2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;banana&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;cherry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;elderberry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;
&lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;
&lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tversky_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Tversky Similarity:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="jaro-winkler-similarity-for-reference"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Jaro-Winkler Similarity (for reference)&lt;/h2&gt;
&lt;p&gt;Jaro-Winkler similarity is a metric used to compare two strings, often used in record linkage and fuzzy string matching tasks. It was developed by William E. Winkler and Matthew A. Jaro. Jaro-Winkler similarity calculates a score between 0 and 1, where 1 indicates a perfect match and 0 indicates no similarity. It considers the number of matching characters between two strings and the positions of those matching characters. The Jaro-Winkler similarity gives more weight to the common prefix of the strings, making it particularly useful for comparing names and short strings. For more information about Jaro-Winkler similarity see: &lt;a href="https://www.safjan.com/jaro-winkler-similarity/"&gt;Jaro-Winkler Similarity&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="summary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;The main differences between Tversky similarity and Jaro-Winkler similarity are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Application Domain:&lt;/strong&gt; Tversky similarity is used to compare sets, while Jaro-Winkler similarity is used to compare strings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; Tversky similarity has parameters alpha and beta to control precision and recall, while Jaro-Winkler similarity does not have such parameters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Target Data:&lt;/strong&gt; Tversky similarity works with sets of items, while Jaro-Winkler similarity works with individual strings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt; Tversky similarity is commonly used in information retrieval and recommendation systems, while Jaro-Winkler similarity is used in fuzzy string matching and record linkage tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/jaro-winkler-similarity/"&gt;Jaro-Winkler Similarity&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="nlp"></category><category term="text-similarity"></category><category term="string-similarity"></category><category term="similarity-metrics"></category><category term="jaccard"></category><category term="cosine-similarity"></category><category term="levenshtein"></category><category term="word-embeddings"></category><category term="soundex"></category></entry><entry><title>GitHub Search Techniques</title><link href="https://www.safjan.com/github-search-techniques/" rel="alternate"></link><published>2023-12-07T00:00:00+01:00</published><updated>2023-12-07T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-07:/github-search-techniques/</id><summary type="html">&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Name&lt;/strong&gt;: Use "in:name" along with your search term to find repositories with that name. Example: "Ruby-Projects in:name".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Description&lt;/strong&gt;: Use "in:description" along with your search term to find repositories with that term in their description. Example …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Name&lt;/strong&gt;: Use "in:name" along with your search term to find repositories with that name. Example: "Ruby-Projects in:name".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Description&lt;/strong&gt;: Use "in:description" along with your search term to find repositories with that term in their description. Example: "machine learning in:description".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Readme&lt;/strong&gt;: Use "in:readme" along with your search term to find repositories with that term in their README file. Example: "learn ruby in:readme".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Topic&lt;/strong&gt;: Use "in:topic" along with your search term to find repositories with that topic. Example: "mobile development in:topic".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Organization&lt;/strong&gt;: Use "org:" along with your search term to find repositories from a specific organization. Example: "org:Microsoft".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By License&lt;/strong&gt;: Use "license:" along with your search term to find open-source repositories that match a certain license. Example: "license:Apache-2.0".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Stars&lt;/strong&gt;: Use "stars:&amp;gt;" followed by a number to find repositories with that number of stars or more. Example: "stars:&amp;gt;1000".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Date&lt;/strong&gt;: Use "Created" or "Updated" followed by a date in the format "YYYY-MM-DD" to find repositories created or updated after a certain date. Example: "in:date created:&amp;gt;2023-06-01".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Forks&lt;/strong&gt;: Use "forks:&amp;gt;" followed by a number to find repositories that have been forked that number of times or more. Example: "forks:&amp;gt;1000".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search By Language&lt;/strong&gt;: Use "language:" with your search term to find repositories in a specific programming language. Example: "language:ruby".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search by Last Push&lt;/strong&gt;: Use "pushed:&amp;gt;" followed by a date to find repositories updated after a certain date. Example: "pushed:&amp;gt;2023-03-01 rails".&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These techniques can help you quickly find the repositories you need. These search tips can transform the task of searching for repositories into an enjoyable and productive experience.&lt;/p&gt;</content><category term="note"></category><category term="github"></category><category term="search"></category><category term="productivity"></category><category term="code-search"></category><category term="project-search"></category><category term="project-discovery"></category></entry><entry><title>Databricks Curriculum - From Zero to Hero</title><link href="https://www.safjan.com/databricks-curriculum-from-zero-to-hero/" rel="alternate"></link><published>2023-12-04T00:00:00+01:00</published><updated>2023-12-04T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-04:/databricks-curriculum-from-zero-to-hero/</id><summary type="html">&lt;h2&gt;Stage 1: Beginner&lt;/h2&gt;
&lt;h3&gt;Topic 1: Introduction to Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; None&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Understanding of what Databricks is and what it can do.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; As a starting point, you need to understand what Databricks is and why it's used.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of Databricks …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Stage 1: Beginner&lt;/h2&gt;
&lt;h3&gt;Topic 1: Introduction to Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; None&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Understanding of what Databricks is and what it can do.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; As a starting point, you need to understand what Databricks is and why it's used.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of Databricks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about the history and evolution of Databricks&lt;/li&gt;
&lt;li&gt;Understand the benefits and use-cases of Databricks&lt;/li&gt;
&lt;li&gt;Explore the architecture of Databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 2: Setting up Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Introduction to Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to setup and navigate the Databricks environment.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Before you can use Databricks, you need to know how to set it up and navigate the platform.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Databricks account&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Understand the Databricks workspace&lt;/li&gt;
&lt;li&gt;Learn how to create a Databricks cluster&lt;/li&gt;
&lt;li&gt;Learn how to create notebooks and libraries&lt;/li&gt;
&lt;li&gt;Understand how to manage and monitor clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 3: Introduction to Apache Spark&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Setting up Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Understanding of Apache Spark and its importance in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Databricks is built on Apache Spark, so understanding Spark is crucial.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of Apache Spark&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about the history and evolution of Apache Spark&lt;/li&gt;
&lt;li&gt;Understand the architecture of Apache Spark&lt;/li&gt;
&lt;li&gt;Explore the core components of Spark: Spark SQL, Spark Streaming, MLlib, and GraphX&lt;/li&gt;
&lt;li&gt;Understand how Spark integrates with Databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 4: Basic Data Processing with Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Introduction to Apache Spark&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to perform basic data processing tasks in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Data processing is a key function of Databricks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of data processing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn how to load and inspect data in Databricks&lt;/li&gt;
&lt;li&gt;Understand the basic operations on data such as filtering, aggregation, and transformation&lt;/li&gt;
&lt;li&gt;Learn how to visualize data in Databricks&lt;/li&gt;
&lt;li&gt;Understand how to save and export processed data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Stage 2: Intermediate&lt;/h2&gt;
&lt;h3&gt;Topic 5: DataFrames and SQL in Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Basic Data Processing with Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to use DataFrames and SQL for data manipulation in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; DataFrames and SQL are essential tools for data manipulation in Databricks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of DataFrames in Spark&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn how to create DataFrames from different data sources&lt;/li&gt;
&lt;li&gt;Perform operations on DataFrames such as select, filter, and aggregate&lt;/li&gt;
&lt;li&gt;Understand the concept of SQL in Spark&lt;/li&gt;
&lt;li&gt;Learn how to perform SQL queries on DataFrames&lt;/li&gt;
&lt;li&gt;Understand how to convert between DataFrames and SQL&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 6: ETL Processes in Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; DataFrames and SQL in Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Understanding and implementation of ETL processes in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; ETL (Extract, Transform, Load) processes are a key part of data processing in Databricks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of ETL (Extract, Transform, Load)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn how to extract data from different sources in Databricks&lt;/li&gt;
&lt;li&gt;Understand how to transform data using Spark transformations&lt;/li&gt;
&lt;li&gt;Learn how to load data into different destinations&lt;/li&gt;
&lt;li&gt;Perform a complete ETL process on a sample dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 7: Machine Learning with Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; ETL Processes in Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to use Databricks for machine learning tasks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Machine learning is a powerful tool for data analysis, and Databricks provides robust support for machine learning tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of machine learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about the machine learning library in Spark (MLlib)&lt;/li&gt;
&lt;li&gt;Understand the machine learning workflow: data preparation, model training, model evaluation, and model deployment&lt;/li&gt;
&lt;li&gt;Learn how to prepare data for machine learning&lt;/li&gt;
&lt;li&gt;Train and evaluate a machine learning model on a sample dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Stage 3: Advanced&lt;/h2&gt;
&lt;h3&gt;Topic 8: Stream Processing in Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Machine Learning with Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to handle real-time data streams in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Real-time data processing is a critical capability in many data-intensive applications.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand the concept of stream processing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about Spark Streaming and its integration with Databricks&lt;/li&gt;
&lt;li&gt;Understand how to ingest real-time data streams&lt;/li&gt;
&lt;li&gt;Learn how to perform transformations and actions on data streams&lt;/li&gt;
&lt;li&gt;Understand how to output data streams to various destinations&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 9: Advanced Spark Programming in Databricks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Stream Processing in Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Mastery of advanced Spark programming techniques in Databricks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; To fully leverage the power of Databricks, you need to be proficient in advanced Spark programming techniques.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deepen understanding of Spark's core concepts&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about Spark's advanced features such as Spark's Catalyst Optimizer, Tungsten Execution Engine, and GraphX for graph processing&lt;/li&gt;
&lt;li&gt;Understand how to optimize Spark applications for performance&lt;/li&gt;
&lt;li&gt;Learn how to debug and troubleshoot Spark applications&lt;/li&gt;
&lt;li&gt;Understand how to manage and monitor Spark applications in Databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Topic 10: Databricks for Data Science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Advanced Spark Programming in Databricks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enables:&lt;/strong&gt; Ability to use Databricks as a tool for advanced data science tasks.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Databricks is a powerful tool for data science, and mastering its use for these tasks will enable you to tackle complex data science problems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Understand how Databricks can be used for advanced data science tasks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Learn about Databricks' integration with popular data science libraries and tools&lt;/li&gt;
&lt;li&gt;Understand how to perform exploratory data analysis in Databricks&lt;/li&gt;
&lt;li&gt;Learn how to build, evaluate, and tune advanced machine learning models&lt;/li&gt;
&lt;li&gt;Understand how to deploy machine learning models in Databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This curriculum provides a comprehensive path from beginner to advanced user of Databricks. By following this path, you will gain a deep understanding of Databricks and be able to use it effectively for a wide range of data processing and data science tasks.&lt;/p&gt;</content><category term="note"></category><category term="databricks"></category><category term="learning"></category><category term="learn-databricks"></category><category term="databricks-roadmap"></category><category term="databricks-learning-plan"></category></entry><entry><title>Databricks - key concepts</title><link href="https://www.safjan.com/databricks-key-concepts/" rel="alternate"></link><published>2023-12-04T00:00:00+01:00</published><updated>2023-12-04T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-04:/databricks-key-concepts/</id><summary type="html">&lt;script type="module"&gt; import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; mermaid.initialize({ startOnLoad: true }); &lt;/script&gt;

&lt;pre class="mermaid"&gt;
mindmap
Databricks
    Databricks Workspace
    Databricks Runtime
    Databricks File System (DBFS)
    Databricks Clusters
    Databricks Notebooks
    Databricks Jobs
    Databricks Tables
&lt;/pre&gt;

&lt;p&gt;Here are some of the …&lt;/p&gt;</summary><content type="html">&lt;script type="module"&gt; import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; mermaid.initialize({ startOnLoad: true }); &lt;/script&gt;

&lt;pre class="mermaid"&gt;
mindmap
Databricks
    Databricks Workspace
    Databricks Runtime
    Databricks File System (DBFS)
    Databricks Clusters
    Databricks Notebooks
    Databricks Jobs
    Databricks Tables
&lt;/pre&gt;

&lt;p&gt;Here are some of the key features and components of Databricks:&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#databricks-workspace"&gt;Databricks Workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-runtime"&gt;Databricks Runtime&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-file-system-dbfs"&gt;Databricks File System (DBFS)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-clusters"&gt;Databricks Clusters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-notebooks"&gt;Databricks Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-jobs"&gt;Databricks Jobs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#databricks-tables"&gt;Databricks Tables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="databricks-workspace"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Workspace&lt;/h2&gt;
&lt;p&gt;This is the collaborative environment where you can write code, create visualizations, and share your work with others. It supports several languages including Python, SQL, R, and Scala.
Read more: &lt;a href="https://docs.databricks.com/en/administration-guide/workspace/index.html#what-is-a-workspace"&gt;Create and manage your Databricks workspaces | Databricks on AWS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-runtime"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Runtime&lt;/h2&gt;
&lt;p&gt;This is the set of core components that run on the clusters in Databricks. It includes Apache Spark but also includes other enhancements maintained by Databricks like performance optimizations, security, and integration with other tools like Delta Lake and MLflow.
Read more: &lt;a href="https://www.databricks.com/glossary/what-is-databricks-runtime"&gt;What is Databricks Runtime?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-file-system-dbfs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks File System (DBFS)&lt;/h2&gt;
&lt;p&gt;This is a distributed file system installed on Databricks clusters. It allows you to store data and share it across all nodes in a cluster.
Read more: &lt;a href="https://docs.databricks.com/en/dbfs/index.html"&gt;What is the Databricks File System (DBFS)?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-clusters"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Clusters&lt;/h2&gt;
&lt;p&gt;These are the compute resources that run your code. You can create clusters of different sizes and types depending on your workload.
Read more: &lt;a href="https://learn.microsoft.com/en-us/azure/databricks/clusters/"&gt;Compute - Azure Databricks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-notebooks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Notebooks&lt;/h2&gt;
&lt;p&gt;These are collaborative documents that contain code, visualizations, and text. They're great for exploratory data analysis, data science, and machine learning workflows.
Read more: &lt;a href="https://docs.databricks.com/en/notebooks/index.html"&gt;Introduction to Databricks notebooks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-jobs"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Jobs&lt;/h2&gt;
&lt;p&gt;These are the tasks or computations you run on Databricks. You can schedule jobs to run periodically, or run them on demand.
Read more: &lt;a href="https://docs.databricks.com/en/workflows/jobs/create-run-jobs.html"&gt;Create and run Databricks Jobs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="databricks-tables"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Databricks Tables&lt;/h2&gt;
&lt;p&gt;These are the structured data sources that you can query using SQL or data frame APIs in Python, R, and Scala.
Read more: &lt;a href="https://www.databricks.com/product/delta-live-tables"&gt;Delta Live Tables&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="databricks"></category><category term="data-science"></category><category term="notebook"></category><category term="jupyter-notebook"></category><category term="dbfs"></category><category term="databricks-workspace"></category><category term="databricks-runtime"></category><category term="databricks-file-system"></category><category term="databricks-clusters"></category><category term="databricks-notebooks"></category><category term="databricks-jobs"></category><category term="databricks-tables"></category></entry><entry><title>Semantic Type Detection</title><link href="https://www.safjan.com/semantic-type-detection/" rel="alternate"></link><published>2023-12-01T00:00:00+01:00</published><updated>2023-12-01T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-01:/semantic-type-detection/</id><summary type="html">&lt;p&gt;Semantic type detection is an important task in table representation learning, as it involves labeling table columns with standardized semantic types. This can help with &lt;strong&gt;understanding the contents of a table&lt;/strong&gt; and can be used for various applications such as data discovery …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Semantic type detection is an important task in table representation learning, as it involves labeling table columns with standardized semantic types. This can help with &lt;strong&gt;understanding the contents of a table&lt;/strong&gt; and can be used for various applications such as data discovery, data validation, and data integration. By accurately detecting the semantic types of columns, machine learning &lt;strong&gt;models can better understand the relationships between columns&lt;/strong&gt; and &lt;strong&gt;improve their performance&lt;/strong&gt; on tasks like table comprehension and data discovery. Additionally, semantic type detection can help with data integration, as it can help map columns from different sources that may have different naming conventions or formats.&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/table-representation-learning/"&gt;Table Representation Learning&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="llm"></category><category term="generative-ai"></category><category term="table-representation-learning"></category></entry><entry><title>Table Representation Learning</title><link href="https://www.safjan.com/table-representation-learning/" rel="alternate"></link><published>2023-12-01T00:00:00+01:00</published><updated>2023-12-01T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-12-01:/table-representation-learning/</id><summary type="html">&lt;p&gt;Table representation learning is an exciting field that focuses on understanding the structure and relationships within tabular data. This can involve &lt;strong&gt;learning embeddings for individual columns&lt;/strong&gt; or &lt;strong&gt;entire tables&lt;/strong&gt;, and can be used for various applications such as data discovery, data validation …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Table representation learning is an exciting field that focuses on understanding the structure and relationships within tabular data. This can involve &lt;strong&gt;learning embeddings for individual columns&lt;/strong&gt; or &lt;strong&gt;entire tables&lt;/strong&gt;, and can be used for various applications such as data discovery, data validation, and data integration.&lt;/p&gt;
&lt;p&gt;One key aspect of table representation learning is &lt;strong&gt;understanding the semantics of column&lt;/strong&gt;s, which can be used to &lt;strong&gt;generate metadata&lt;/strong&gt; and help with tasks like &lt;strong&gt;table comprehension&lt;/strong&gt; and &lt;strong&gt;data discovery&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;By accurately representing columns and their relationships, table representation learning can help improve machine learning models and enable more complex analysis of tabular data.&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/semantic-type-detection/"&gt;Semantic Type Detection&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="llm"></category><category term="generative-ai"></category><category term="database"></category><category term="table"></category><category term="table-representation-learning"></category></entry><entry><title>Using Mermaid Diagrams in Pelican Blog Post</title><link href="https://www.safjan.com/mermaid-in-pelican-post/" rel="alternate"></link><published>2023-11-28T00:00:00+01:00</published><updated>2023-11-28T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-28:/mermaid-in-pelican-post/</id><summary type="html">&lt;p&gt;Sometimes, you might want to embed the mermaid diagram in your blogpost written in markdown. Here is how to do it.&lt;/p&gt;
&lt;h2&gt;Embed the HTML code (recommended)&lt;/h2&gt;
&lt;p&gt;In your markdown file, you can embed HTML code loading mermaid code and initialising it, then …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometimes, you might want to embed the mermaid diagram in your blogpost written in markdown. Here is how to do it.&lt;/p&gt;
&lt;h2&gt;Embed the HTML code (recommended)&lt;/h2&gt;
&lt;p&gt;In your markdown file, you can embed HTML code loading mermaid code and initialising it, then include mermaid diagram you want.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;module&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mermaid&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kr"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;mermaid&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;initialize&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;startOnLoad&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

Here is a mermaid diagram:
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;mermaid&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
 graph TD 
 A[Client] --&amp;gt; B[Load Balancer] 
 B --&amp;gt; C[Server01] 
 B --&amp;gt; D[Server02]
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;pre&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Extension&lt;/h2&gt;
&lt;p&gt;There is extension, not sure if it works:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/Lee-W/md_mermaid"&gt;Lee-W/md_mermaid&lt;/a&gt; - mermaid extension to add support for mermaid graph inside markdown file. NOTE: you need Markdown&amp;lt;3.2 (e.g. 3.1.1)&lt;/p&gt;</content><category term="note"></category><category term="mermaid"></category><category term="pelican"></category><category term="diagram"></category><category term="graph"></category><category term="plot"></category></entry><entry><title>Store Output of the Command Into Array in Bash</title><link href="https://www.safjan.com/store-output-of-the-command-into-array-in-bash/" rel="alternate"></link><published>2023-11-13T00:00:00+01:00</published><updated>2023-11-13T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-13:/store-output-of-the-command-into-array-in-bash/</id><summary type="html">&lt;p&gt;Both &lt;code&gt;mapfile&lt;/code&gt; and &lt;code&gt;read -a&lt;/code&gt; can be used to store the output of a command or a list of values into an array. However, the &lt;code&gt;mapfile&lt;/code&gt; command is generally preferred when reading lines from a file, while &lt;code&gt;read -a&lt;/code&gt; is well-suited for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Both &lt;code&gt;mapfile&lt;/code&gt; and &lt;code&gt;read -a&lt;/code&gt; can be used to store the output of a command or a list of values into an array. However, the &lt;code&gt;mapfile&lt;/code&gt; command is generally preferred when reading lines from a file, while &lt;code&gt;read -a&lt;/code&gt; is well-suited for reading space-separated values from a string.&lt;/p&gt;
&lt;p&gt;Let's assume that we want to store all directories (top-level) that are located in projects forlder. In other words, keeping all projects (dir names) as array elements.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;projects&lt;/span&gt;&lt;span class="o"&gt;=(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;/projects/*&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Using &amp;#39;find&amp;#39; command with &amp;#39;-print0&amp;#39; to handle directory names with special characters&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;IFS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;read&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;$&amp;#39;\0&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;line&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;projects&lt;/span&gt;&lt;span class="o"&gt;+=(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$line&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;find&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;projects&lt;/span&gt;&lt;span class="p"&gt;[@]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-maxdepth&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-type&lt;span class="w"&gt; &lt;/span&gt;d&lt;span class="w"&gt; &lt;/span&gt;-print0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the provided code, the &lt;code&gt;read&lt;/code&gt; command is used together with some parameters. Here is a brief explanation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;-a&lt;/code&gt; : This option is used when we want to read from input and store it in an array. In the given code snippet, the input is obtained from a subshell command that lists directories (&lt;code&gt;ls -d ${projects[@]}&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;-r&lt;/code&gt; : This option prevents backslash escapes from being interpreted. It helps you to read the strings "as is".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;-d $'\0'&lt;/code&gt; : This tells &lt;code&gt;read&lt;/code&gt; to continue until it encounters a null byte (&lt;code&gt;\0&lt;/code&gt;), which is the delimiter used by &lt;code&gt;find . -print0&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So &lt;code&gt;read -r -d $'\0' line&lt;/code&gt; reads input separated by null characters into the variable &lt;code&gt;line&lt;/code&gt;. This is done inside a &lt;code&gt;while&lt;/code&gt; loop, which continues to perform this reading operation for each directory returned by &lt;code&gt;find&lt;/code&gt;, assigned to the &lt;code&gt;projects&lt;/code&gt; array one by one.&lt;/p&gt;
&lt;p&gt;The while loop structure &lt;code&gt;while IFS= read -r -d $'\0' line; do&lt;/code&gt; is commonly used in shell scripting to read lines from a file (or in this case, results from a command substitution) in a safe manner that preserves whitespace and special characters.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IFS=&lt;/code&gt; is used to temporarily clear the Internal Field Separator variable, which is used by &lt;code&gt;read&lt;/code&gt; to split the input line into separate fields. By clearing it, we ensure that &lt;code&gt;read&lt;/code&gt; treats each line as a whole, even if it includes spaces.&lt;/p&gt;
&lt;p&gt;In this script, the &lt;code&gt;find&lt;/code&gt; command is used, ill-equipped with the &lt;code&gt;-print0&lt;/code&gt; option to output names using a null character as a delimiter, which helps in dealing with directory names that include spaces or other special characters. The &lt;code&gt;-maxdepth 0&lt;/code&gt; option ensures that only the directories (not their subdirectories) are listed. The &lt;code&gt;-type d&lt;/code&gt; filter ensures that only directories are returned.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;while&lt;/code&gt; loop with &lt;code&gt;IFS= read -r -d $'\0'&lt;/code&gt; handles the null delimited output from &lt;code&gt;find&lt;/code&gt;. Within the loop, each line is appended to the &lt;code&gt;projects&lt;/code&gt; array. Lastly, the elements of the &lt;code&gt;projects&lt;/code&gt; array are added to the 'list' array.&lt;/p&gt;</content><category term="note"></category><category term="bash"></category><category term="array"></category><category term="cli"></category><category term="script"></category></entry><entry><title>The Importance of Adding a `py.typed` File to Your Typed Package</title><link href="https://www.safjan.com/the-importance-of-adding-py-typed-file-to-your-typed-package/" rel="alternate"></link><published>2023-11-13T00:00:00+01:00</published><updated>2023-11-13T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-13:/the-importance-of-adding-py-typed-file-to-your-typed-package/</id><summary type="html">&lt;p&gt;For the Python programming, type checking might be an important aspect aspect that ensures the correctness of your code. The &lt;code&gt;mypy&lt;/code&gt; type checker is a powerful tool that uses type annotations to verify your code. However, it might not recognize the type …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For the Python programming, type checking might be an important aspect aspect that ensures the correctness of your code. The &lt;code&gt;mypy&lt;/code&gt; type checker is a powerful tool that uses type annotations to verify your code. However, it might not recognize the type hints provided by your package unless you include a &lt;code&gt;py.typed&lt;/code&gt; file. This is a common oversight that can lead to incorrect package publishing.&lt;/p&gt;
&lt;h2&gt;Understanding &lt;code&gt;py.typed&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;The &lt;code&gt;py.typed&lt;/code&gt; file is a marker file that indicates to type checkers like &lt;code&gt;mypy&lt;/code&gt; that your package comes with type annotations.&lt;/strong&gt; Without this file, the type checker won't use the type hints provided by your package, leading to potential type errors. This requirement is outlined in &lt;a href="https://www.python.org/dev/peps/pep-0561/#packaging-type-information"&gt;PEP-561&lt;/a&gt; and the &lt;a href="https://mypy.readthedocs.io/en/stable/installed_packages.html#making-pep-561-compatible-packages"&gt;mypy documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Adding &lt;code&gt;py.typed&lt;/code&gt; to Your Package&lt;/h2&gt;
&lt;p&gt;Adding a &lt;code&gt;py.typed&lt;/code&gt; file to your package is straightforward. Simply create a &lt;code&gt;py.typed&lt;/code&gt; file in your package directory and include it in your distribution.&lt;/p&gt;
&lt;p&gt;If you're using &lt;a href="https://python-poetry.org/"&gt;poetry&lt;/a&gt;, you can add the following lines under the &lt;code&gt;[tool.poetry]&lt;/code&gt; section of &lt;code&gt;pyproject.toml&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mypackage&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mypackage/py.typed&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For those using &lt;code&gt;setup.py&lt;/code&gt;, you can add &lt;code&gt;package_data&lt;/code&gt; to the &lt;code&gt;setup&lt;/code&gt; call:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;package_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mypackage&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;py.typed&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After adding the &lt;code&gt;py.typed&lt;/code&gt; file, release &lt;a href="https://github.com/whtsky/pixelmatch-py/commit/9c6297cedd10232ffbe23cc54a4e46e76d1fa13a"&gt;a new version for your package&lt;/a&gt;. This will ensure that the type information from your packages works as expected.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you're a Python package maintainer, don't forget to include a &lt;code&gt;py.typed&lt;/code&gt; file in your typed package. This simple step can make a significant difference in ensuring the correctness of your code and the usability of your package. It's a small effort that goes a long way in maintaining the quality and reliability of your Python package.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Credits&lt;/strong&gt; to &lt;a href="https://dev.to/whtsky"&gt;Wu Haotian&lt;/a&gt; for the article &lt;a href="https://dev.to/whtsky/don-t-forget-py-typed-for-your-typed-python-package-2aa3"&gt;Don't forget &lt;code&gt;py.typed&lt;/code&gt; for your typed Python package - DEV Community&lt;/a&gt; - I have learned about this mechanism from that post.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="package"></category><category term="mypy"></category><category term="poetry"></category><category term="typink"></category><category term="type-hints"></category><category term="pep"></category></entry><entry><title>In the Python project made with Poetry shall I add poetry.lock to the git repo or ignore it?</title><link href="https://www.safjan.com/python-project-with-Poetry-add-poetry-lock-to-the-git-repo-or-ignore-it/" rel="alternate"></link><published>2023-11-12T00:00:00+01:00</published><updated>2023-11-12T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-12:/python-project-with-Poetry-add-poetry-lock-to-the-git-repo-or-ignore-it/</id><summary type="html">&lt;p&gt;up:MOC_Python_Project&lt;/p&gt;
&lt;p&gt;In a Python project managed with Poetry, you should definitely add the &lt;code&gt;poetry.lock&lt;/code&gt; file to your Git repository. The &lt;code&gt;poetry.lock&lt;/code&gt; file ensures that all project dependencies are specified with fixed versions, providing deterministic builds across different environments.&lt;/p&gt;
&lt;p&gt;By …&lt;/p&gt;</summary><content type="html">&lt;p&gt;up:MOC_Python_Project&lt;/p&gt;
&lt;p&gt;In a Python project managed with Poetry, you should definitely add the &lt;code&gt;poetry.lock&lt;/code&gt; file to your Git repository. The &lt;code&gt;poetry.lock&lt;/code&gt; file ensures that all project dependencies are specified with fixed versions, providing deterministic builds across different environments.&lt;/p&gt;
&lt;p&gt;By including the &lt;code&gt;poetry.lock&lt;/code&gt; file in your repository, you ensure that anyone cloning or checking out your project will have the exact same versions of the dependencies installed. This guarantees that they will have a consistent development environment and can reproduce the same build and execution results.&lt;/p&gt;
&lt;p&gt;Including the &lt;code&gt;poetry.lock&lt;/code&gt; file also serves as documentation for the specific versions of the dependencies used in your project. This information can be helpful for troubleshooting and debugging purposes.&lt;/p&gt;
&lt;p&gt;When working with Poetry, you can also add the &lt;code&gt;pyproject.toml&lt;/code&gt; file to your Git repository. This file contains the project metadata and the dependencies specified in a readable format, giving a high-level overview of your project's requirements.&lt;/p&gt;
&lt;p&gt;Including both the &lt;code&gt;poetry.lock&lt;/code&gt; and &lt;code&gt;pyproject.toml&lt;/code&gt; files ensures that others can easily set up and work with your project while maintaining consistency across different development environments.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="python-project"></category><category term="poetry"></category><category term="gitignore"></category><category term="git"></category><category term="repo"></category></entry><entry><title>Git change remote origin (replace with new)</title><link href="https://www.safjan.com/Git-change-remote-origin-replace-with-new/" rel="alternate"></link><published>2023-11-11T00:00:00+01:00</published><updated>2023-11-11T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-11:/Git-change-remote-origin-replace-with-new/</id><summary type="html">&lt;h2&gt;Git - Replace remote origin&lt;/h2&gt;
&lt;p&gt;To change the remote origin in Git and replace it with a new one, you can use the following steps:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verify the existing remote origin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Check the current remote URL for the origin repository by running the command …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Git - Replace remote origin&lt;/h2&gt;
&lt;p&gt;To change the remote origin in Git and replace it with a new one, you can use the following steps:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verify the existing remote origin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Check the current remote URL for the origin repository by running the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;-v&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will display the fetch and push URLs for all the remotes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remove the existing remote origin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order to replace the remote origin, you need to remove the current one. Run the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git remote remove origin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This will remove the old origin from your local Git repository.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Add the new remote origin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once you have removed the existing remote origin, you can add the new one by running the command: &lt;code&gt;git remote add origin &amp;lt;new_remote_url&amp;gt;&lt;/code&gt;. Replace &lt;code&gt;&amp;lt;new_remote_url&amp;gt;&lt;/code&gt; with the URL of the new remote repository you want to set as the origin.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verify the changes&lt;/strong&gt;
You can ensure that the new remote origin is set correctly by running&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git remote -v&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Push the branch to the new origin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Finally, you can push your branch to the new remote origin using:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push -u origin &amp;lt;branch_name&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Replace &lt;code&gt;&amp;lt;branch_name&amp;gt;&lt;/code&gt; with the name of the branch you want to push.&lt;/p&gt;
&lt;h2&gt;When you might need to perform this operation&lt;/h2&gt;
&lt;p&gt;There are several situations where you might want to change the remote origin (replace it with a new one) in Git. Some common examples include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Changing the repository hosting provider: If you are migrating your codebase from one hosting provider to another (e.g., from GitHub to GitLab), you would need to update the remote origin URL to point to the new provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moving the repository from a personal account to an organization account: If you initially created a repository under your personal account and later decide to move it to an organization account, you would change the remote origin to point to the new organization repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Renaming the repository: If you decide to change the name of your repository, you may want to update the remote origin URL to reflect the new name.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collaborating with multiple repositories: In some cases, you might want to work with multiple remote repositories, perhaps to collaborate with different teams or maintain several mirrored repositories. Changing the remote origin allows you to switch between these repositories easily.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fixing an incorrect or outdated remote origin: If you accidentally set the wrong remote origin URL or if the previous URL has become outdated, you can change it to point to the correct one.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Remember, changing the remote origin should be done with caution, especially in collaborative environments, as it affects the repository's remote connections. Make sure to communicate the changes to your team and consider any implications before making the switch.&lt;/p&gt;</content><category term="note"></category><category term="git"></category><category term="origin"></category><category term="remote-origin"></category></entry><entry><title>SPLADE sparse vectors - explaination, properties</title><link href="https://www.safjan.com/splade-sparse-vectors/" rel="alternate"></link><published>2023-11-10T00:00:00+01:00</published><updated>2023-12-08T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-10:/splade-sparse-vectors/</id><summary type="html">&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bullet&lt;/span&gt;
&lt;span class="n"&gt;min_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;**Contents**&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;TL; DR&lt;/h2&gt;
&lt;p&gt;SPLADE is a neural retrieval model which learns query/document &lt;strong&gt;sparse&lt;/strong&gt; expansion via the BERT MLM head and sparse regularization. Sparse representations benefit from several advantages compared to dense approaches: efficient use …&lt;/p&gt;</summary><content type="html">&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bullet&lt;/span&gt;
&lt;span class="n"&gt;min_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;**Contents**&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;TL; DR&lt;/h2&gt;
&lt;p&gt;SPLADE is a neural retrieval model which learns query/document &lt;strong&gt;sparse&lt;/strong&gt; expansion via the BERT MLM head and sparse regularization. Sparse representations benefit from several advantages compared to dense approaches: efficient use of inverted index, explicit lexical match, interpretability... They also seem to be better at generalizing on out-of-domain data (BEIR benchmark).&lt;/p&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;I have learned about SPLADE from the article: &lt;a href="https://www.pinecone.io/learn/splade/"&gt;SPLADE for Sparse Vector Search Explained | Pinecone&lt;/a&gt;. Here below are the key concepts from the article (LLM summary)&lt;/p&gt;
&lt;p&gt;The article discusses the evolution of search and recommendation systems, focusing on the shift from traditional "bag of words" methods to modern vector search. It explains how big tech companies like Google, Netflix, and Amazon use vector search to power their systems.&lt;/p&gt;
&lt;p&gt;The traditional &lt;strong&gt;bag of words&lt;/strong&gt; methods transform documents into a set of words, populating a sparse "frequency vector". While these methods are &lt;strong&gt;efficient and interpretable&lt;/strong&gt;, they are &lt;strong&gt;not perfect&lt;/strong&gt; due to their &lt;strong&gt;reliance on exact term matching,&lt;/strong&gt; which doesn't align with human nature.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dense embedding&lt;/strong&gt; models offer a solution by allowing search based on &lt;strong&gt;semantic meaning&lt;/strong&gt;. However, they require &lt;strong&gt;vast amounts of data for fine-tuning&lt;/strong&gt; and don't perform well in niche domains where data is scarce.&lt;/p&gt;
&lt;p&gt;The article introduces a solution to these problems: &lt;strong&gt;a merger of sparse and dense retrieval through hybrid search and learnable sparse embeddings&lt;/strong&gt;. It focuses on &lt;strong&gt;SPLADE&lt;/strong&gt; (Sparse Lexical and Expansion model), a &lt;strong&gt;model that uses a pretrained language model like BERT to enhance sparse vector embedding.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;how it works&lt;/h2&gt;
&lt;p&gt;The idea behind the &lt;strong&gt;Sp&lt;/strong&gt;arse &lt;strong&gt;L&lt;/strong&gt;exical &lt;strong&gt;a&lt;/strong&gt;n&lt;strong&gt;d&lt;/strong&gt; &lt;strong&gt;E&lt;/strong&gt;xpansion models is that a pretrained language model like BERT can identify connections between words/sub-words (called &lt;em&gt;word-pieces&lt;/em&gt; or “terms” in this article) and use that knowledge to enhance our sparse vector embedding.&lt;/p&gt;
&lt;p&gt;This works in two ways, it allows us to weigh the relevance of different terms (something like the will carry less relevance than a less common word like orangutan). And it enables &lt;em&gt;term expansion&lt;/em&gt;: the inclusion of alternative but relevant terms beyond those found in the original sequence.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Term expansion allows us to identify relevant but different terms and use them in the sparse vector retrieval step." src="https://cdn.sanity.io/images/vr8gru94/production/17f0aac1f34b4475121744b672156a611dd8aed6-1029x331.png"&gt;&lt;/p&gt;
&lt;p&gt;Term expansion allows us to identify relevant but different terms and use them in the sparse vector retrieval step.&lt;/p&gt;
&lt;p&gt;The most significant advantage of SPLADE is not necessarily that it can &lt;em&gt;do&lt;/em&gt; term expansion but instead that it can &lt;em&gt;learn&lt;/em&gt; term expansions. Traditional methods required rule-based term expansion which is time-consuming &lt;em&gt;and&lt;/em&gt; fundamentally limited. Whereas SPLADE can use the best language models to learn term expansions and even tweak them based on the sentence context.&lt;/p&gt;
&lt;p&gt;The article also discusses the pros and cons of sparse and dense vectors, the concept of two-stage retrieval, and the drawbacks of this approach. It then delves into the workings of SPLADE, explaining how it builds sparse embeddings and how it can be implemented using Hugging Face and PyTorch or the official SPLADE library.&lt;/p&gt;
&lt;p&gt;The article concludes by acknowledging the &lt;strong&gt;limitations of SPLADE&lt;/strong&gt;, such as its &lt;strong&gt;slower retrieval speed compared to other sparse methods&lt;/strong&gt;, and suggests solutions to these problems. It also highlights the potential of mixing both dense and sparse representations using hybrid search indexes to make vector search more accurate and accessible.&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/tfidf-with-examples/"&gt;TF-IDF with examples&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/naver/splade"&gt;GitHub - naver/splade: SPLADE: sparse neural search (SIGIR21, SIGIR22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[1] T. Formal, B. Piwowarski, S. Clinchant, &lt;a href="https://arxiv.org/abs/2107.05720"&gt;SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking&lt;/a&gt; (2021), SIGIR 21&lt;/p&gt;
&lt;p&gt;[2] T. Formal, C. Lassance, B. Piwowarski, S. Clinchant, &lt;a href="https://export.arxiv.org/abs/2109.10086"&gt;SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval&lt;/a&gt; (2021)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;https://www.linkedin.com/posts/prithivirajdamodaran_%3F%3F%3F%3F%3F%3F-%3F%3F%3F%3F-%3F%3F%3F%3F%3F%3F%3F%3F-activity-7164581754270400512-Aa87?utm_source=share&amp;amp;utm_medium=member_desktop&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="splade"></category><category term="tf-idf"></category><category term="bag-of-words"></category><category term="bert"></category><category term="beir"></category><category term="sparse"></category><category term="text-vectorization"></category></entry><entry><title>TF-IDF with examples</title><link href="https://www.safjan.com/tfidf-with-examples/" rel="alternate"></link><published>2023-11-10T00:00:00+01:00</published><updated>2023-11-10T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-10:/tfidf-with-examples/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/splade-sparse-vectors/"&gt;SPLADE sparse vectors - explaination, properties&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TF-IDF&lt;/strong&gt; stands for &lt;strong&gt;Term Frequency-Inverse Document Frequency&lt;/strong&gt;. It's a numerical statistic used to reflect how important a word is to a document in a collection or corpus. It's often used in information retrieval and text mining …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/splade-sparse-vectors/"&gt;SPLADE sparse vectors - explaination, properties&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TF-IDF&lt;/strong&gt; stands for &lt;strong&gt;Term Frequency-Inverse Document Frequency&lt;/strong&gt;. It's a numerical statistic used to reflect how important a word is to a document in a collection or corpus. It's often used in information retrieval and text mining.&lt;/p&gt;
&lt;p&gt;TF-IDF is composed of two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Term Frequency (TF)&lt;/strong&gt;: This measures the frequency of a word in a document. It's the ratio of the number of times a word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own term frequency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Inverse Document Frequency (IDF)&lt;/strong&gt;: This measures the importance of the word in the entire corpus. The IDF of a rare word is high, whereas the IDF of a frequent word is likely to be low. Thus, words that occur frequently across many documents will have a lower IDF, and rare words will have a high IDF.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The TF-IDF value is calculated by multiplying these two metrics: TF and IDF.&lt;/p&gt;
&lt;h2&gt;Minimal example&lt;/h2&gt;
&lt;h2&gt;High TF-IDF&lt;/h2&gt;
&lt;p&gt;Consider a document containing 100 words wherein the word 'cat' appears 3 times.&lt;/p&gt;
&lt;p&gt;The term frequency (TF) for 'cat' is then (3 / 100) = 0.03.&lt;/p&gt;
&lt;p&gt;Now, assume we have 10 million documents and the word 'cat' appears in one thousand of these. Then, the inverse document frequency (IDF) is calculated as log(10,000,000 / 1,000) = 4.&lt;/p&gt;
&lt;p&gt;So, the TF-IDF weight is the product of these quantities: 0.03 * 4 = 0.12.&lt;/p&gt;
&lt;h3&gt;Low TF-IDF&lt;/h3&gt;
&lt;p&gt;Now, let's consider a common word like 'the'. Assume it appears 20 times in a document of 100 words. So, TF for 'the' is (20/100) = 0.2.&lt;/p&gt;
&lt;p&gt;Assume 'the' appears in 1 million out of 10 million documents. So, IDF for 'the' is log(10,000,000 / 1,000,000) = 1.&lt;/p&gt;
&lt;p&gt;The TF-IDF weight for 'the' is 0.2 * 1 = 0.2.&lt;/p&gt;
&lt;p&gt;Even though 'the' appeared more times than 'cat' in the document, the TF-IDF weight for 'cat' is higher than 'the'. This is because IDF gives a higher weight to words that are less frequent in the corpus, making 'cat' more important than 'the' in the context of our corpus.&lt;/p&gt;
&lt;h2&gt;The formula&lt;/h2&gt;
&lt;p&gt;here is the TF-IDF equation in LaTeX format:&lt;/p&gt;
&lt;p&gt;The term frequency &lt;span class="math"&gt;\(TF\)&lt;/span&gt; is calculated as:&lt;/p&gt;
&lt;div class="math"&gt;$$
TF(t, d) = \frac{f_{t, d}}{\sum_{t' \in d} f_{t', d}}
$$&lt;/div&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(f_{t, d}\)&lt;/span&gt; is the frequency of term &lt;span class="math"&gt;\(t\)&lt;/span&gt; in document &lt;span class="math"&gt;\(d\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;The denominator is the sum of frequencies of all terms in document &lt;span class="math"&gt;\(d\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The inverse document frequency &lt;span class="math"&gt;\(IDF\)&lt;/span&gt; is calculated as:&lt;/p&gt;
&lt;div class="math"&gt;$$
IDF(t, D) = \log \frac{|D|}{|\{d \in D: t \in d\}|}
$$&lt;/div&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(|D|\)&lt;/span&gt; is the total number of documents in the corpus&lt;/li&gt;
&lt;li&gt;The denominator is the number of documents where the term &lt;span class="math"&gt;\(t\)&lt;/span&gt; appears&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, the TF-IDF is calculated as:&lt;/p&gt;
&lt;div class="math"&gt;$$
TFIDF(t, d, D) = TF(t, d) \cdot IDF(t, D)
$$&lt;/div&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(t\)&lt;/span&gt; is the term&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(d\)&lt;/span&gt; is the document&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(D\)&lt;/span&gt; is the corpus (set of all documents)&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="tfidf"></category><category term="tf-idf"></category><category term="bag-of-words"></category><category term="embeddings"></category><category term="text-vectorization"></category><category term="information-retrieval"></category><category term="text-mining"></category></entry><entry><title>Growth Hacking Methodology</title><link href="https://www.safjan.com/growth-hacking-methodology/" rel="alternate"></link><published>2023-11-07T00:00:00+01:00</published><updated>2023-11-07T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-07:/growth-hacking-methodology/</id><summary type="html">&lt;p&gt;Growth Hacking is a marketing strategy primarily used by startups and small businesses, which focuses on rapid growth within a short time frame. It involves experimenting with and implementing creative, low-cost strategies to acquire and retain customers.&lt;/p&gt;
&lt;p&gt;Here are some key points …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Growth Hacking is a marketing strategy primarily used by startups and small businesses, which focuses on rapid growth within a short time frame. It involves experimenting with and implementing creative, low-cost strategies to acquire and retain customers.&lt;/p&gt;
&lt;p&gt;Here are some key points about Growth Hacking:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Experimentation&lt;/strong&gt;: Growth hacking involves constant experimentation across various channels and product development paths to identify the most effective ways to grow a business.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Creativity&lt;/strong&gt;: Growth hackers often use unconventional marketing strategies to get maximum growth. This could include viral marketing, social media, targeted advertising, SEO, email marketing, and more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data-Driven&lt;/strong&gt;: Growth hacking is heavily reliant on data analysis. Growth hackers track and analyze user data to understand behavior, test hypotheses, and make informed decisions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Agility&lt;/strong&gt;: Growth hacking requires agility and adaptability. Growth hackers must be willing to pivot quickly, change strategies, and try new things based on what the data is telling them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Product Development&lt;/strong&gt;: Growth hacking isn't just about marketing. It often involves tweaking the product itself to make it more appealing or to encourage users to spread the word about it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customer Retention&lt;/strong&gt;: While much of growth hacking focuses on customer acquisition, it's also about customer retention. Growth hackers look for ways to increase customer loyalty and encourage repeat business.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Viral Loops&lt;/strong&gt;: Growth hackers often aim to create viral loops, where existing users naturally attract new users, creating a self-perpetuating cycle of growth.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An example of a successful growth hack is Dropbox's referral program. They offered extra storage space to users who referred their friends, which led to a significant increase in user sign-ups. This is a classic example of a growth hack – a simple, cost-effective solution that led to substantial growth.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Book: "Growth Hacker Marketing: A Primer on the Future of PR, Marketing, and Advertising" by Ryan Holiday. This book is a good starting point for understanding the concept of growth hacking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Book: "Hacking Growth: How Today's Fastest-Growing Companies Drive Breakout Success" by Sean Ellis and Morgan Brown. Sean Ellis is the person who coined the term "growth hacking," and this book provides a deep dive into the methodology.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://growthhackers.com/"&gt;GrowthHackers&lt;/a&gt; - An online community where growth hackers share case studies, articles, and resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.quicksprout.com/growth-hacking/"&gt;The Growth Hacking Starter Guide - Real Examples&lt;/a&gt; - An online guide that provides a comprehensive overview of growth hacking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://neilpatel.com/what-is-growth-hacking/"&gt;Growth Hacking Made Simple: Definition&lt;/a&gt; by Neil Patel&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://growthrocks.com/blog/growth-hacking-books/"&gt;Top 17 Growth Hacking Books to Read in 2022&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/criticism-of-the-lean-startup/"&gt;Criticism of the Lean Startup&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="growth-hacking"></category><category term="startup"></category><category term="methodology"></category><category term="business"></category></entry><entry><title>Product Led Growth</title><link href="https://www.safjan.com/product-led-growth/" rel="alternate"></link><published>2023-11-07T00:00:00+01:00</published><updated>2023-11-07T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-07:/product-led-growth/</id><summary type="html">&lt;p&gt;Product Led Growth (PLG) is a business methodology in which the product itself serves as the primary driver of customer acquisition, conversion, and expansion. It's a model that prioritizes product usage as the key growth driver, rather than traditional marketing or sales …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Product Led Growth (PLG) is a business methodology in which the product itself serves as the primary driver of customer acquisition, conversion, and expansion. It's a model that prioritizes product usage as the key growth driver, rather than traditional marketing or sales efforts.&lt;/p&gt;
&lt;p&gt;Here are some key points about Product Led Growth:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User-Centric&lt;/strong&gt;: PLG focuses on the user experience. The product is designed to be so user-friendly and intuitive that it sells itself. The aim is to create a product that users love and can't live without.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Viral Growth&lt;/strong&gt;: PLG often relies on viral growth. This means that current users recommend the product to others, creating a network effect. This can be facilitated by incorporating features that naturally encourage sharing or collaboration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Freemium or Free Trial Models&lt;/strong&gt;: Many PLG companies offer a freemium model or free trial to attract users. This allows users to try the product and see its value before deciding to pay for premium features.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Self-Service&lt;/strong&gt;: PLG products are typically self-service, meaning users can sign up, use, and even upgrade the product without needing to interact with a sales team.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data-Driven&lt;/strong&gt;: PLG companies use data to understand user behavior, identify opportunities for improvement, and make informed decisions. They often use metrics like daily active users (DAU), monthly active users (MAU), and net promoter score (NPS) to measure success.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customer Success Focus&lt;/strong&gt;: In a PLG model, customer success is crucial. Companies need to ensure users are getting maximum value from the product, which often involves providing educational resources, responsive support, and regular product updates.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Examples of successful PLG companies include Slack, Dropbox, and Zoom. These companies have created products that users love, leading to rapid, organic growth.&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/criticism-of-the-lean-startup/"&gt;Criticism of the Lean Startup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/design-thinking/"&gt;Design Thinking&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.productled.org/foundations/what-is-product-led-growth"&gt;What is product-led growth?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.appcues.com/blog/pirate-metric-saas-growth"&gt;Why activation is the most important pirate metric for SaaS growth | Appcues Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="startup"></category><category term="methodology"></category><category term="product-led-growth"></category></entry><entry><title>RAG-Fusion - Enhancing Information Retrieval in Large Language Models</title><link href="https://www.safjan.com/rag-fusion-enhancing-information-retrieval-in-large-language-models/" rel="alternate"></link><published>2023-11-06T00:00:00+01:00</published><updated>2023-11-06T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-06:/rag-fusion-enhancing-information-retrieval-in-large-language-models/</id><summary type="html">&lt;p&gt;In the realm of Large Language Models (LLMs) such as ChatGPT, a new technique known as Retrieval Augmented Generation (RAG) is gaining prominence. This technique is designed to enhance a user's input by incorporating additional information from an external source. This supplementary …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the realm of Large Language Models (LLMs) such as ChatGPT, a new technique known as Retrieval Augmented Generation (RAG) is gaining prominence. This technique is designed to enhance a user's input by incorporating additional information from an external source. This supplementary data is then leveraged by the LLM to enrich the response it generates. In this blog post, we will delve deeper into the core concept of RAG-fusion, which revolves around multiple query generation and re-ranking of results. For other methods that can improve RAG performance see my other &lt;a href="https://www.safjan.com/techniques-to-boost-rag-performance-in-production/"&gt;Techniques to Boost RAG Performance in Production&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;What is RAG-fusion?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;The principle behind RAG-fusion is to generate multiple versions of the user's original query using a LLM, and then re-rank the results to select the most relevant retrieved parts.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: The term RAG in the name of the technique might be a bit misleading since "RAG-fusion" refers only to the first part of RAG - retrieval process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;How it works? For instance, the prompt template for this task might look something like this: "Generate multiple search queries related to: {original_query}", where &lt;code&gt;{original_query}&lt;/code&gt; is a placeholder for the user's original query. This step enables the model to explore different perspectives and interpretations of the original query, thereby broadening the range of potential responses.&lt;/p&gt;
&lt;h2&gt;Re-ranking: A Crucial Step&lt;/h2&gt;
&lt;p&gt;The next vital step in the RAG-fusion process is re-ranking. This step is critical in determining the most pertinent answers to the user's query. The re-ranking process, often referred to as Reciprocal Rank Fusion (RRF), involves collecting ranked search outcomes from multiple strategies.&lt;/p&gt;
&lt;p&gt;Each document is assigned a reciprocal rank score. These scores are then merged to create a new ranking. The underlying principle here is that documents that consistently appear in top positions across diverse search strategies are likely more pertinent and should, therefore, receive a higher rank in the consolidated result.&lt;/p&gt;
&lt;p&gt;&lt;img alt="RAG Fusion" src="https://miro.medium.com/v2/resize:fit:1400/1*tDALPmWxwAPf7UADpZwjWQ@2x.jpeg"&gt;
Figure 1. RAG fusion proces flow for ranking four documents A, B, C, D against three retrieval sources (can be three variants of the original user query). Source of image: &lt;a href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1"&gt;Forget RAG, the Future is RAG-Fusion article by Adrian H. Raudaschl&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Why RAG-fusion Matters?&lt;/h2&gt;
&lt;p&gt;It provides a boost to the LLM's ability to generate more accurate, contextually relevant responses. By considering multiple interpretations of the original query and re-ranking the results, it ensures that the model's output is as closely aligned with the user's intent as possible.&lt;/p&gt;
&lt;p&gt;RAG-fusion might be a powerful technique that brings together the strengths of large language models and advanced information retrieval strategies. By employing multiple query generation and re-ranking, it takes a leap towards making AI-powered systems more responsive, accurate, and user-friendly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE 1:&lt;/strong&gt; For more methods that can improve RAG performance see my other &lt;a href="https://www.safjan.com/techniques-to-boost-rag-performance-in-production/"&gt;Techniques to Boost RAG Performance in Production&lt;/a&gt;.
&lt;strong&gt;NOTE 2:&lt;/strong&gt; This technique is also referred as Query-Rewriting. You can find a section on that on LlamaIndex documentation (&lt;a href="https://docs.llamaindex.ai/en/stable/examples/query_transformations/query_transform_cookbook.html"&gt;Query Transformation Cookbook&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;- X::&lt;a href="https://www.safjan.com/understanding-retrieval-augmented-generation-rag-empowering-llms/"&gt;Understanding Retrieval-Augmented Generation (RAG) empowering LLMs&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2024-03-06: Added RAG fusion paper&lt;/li&gt;
&lt;li&gt;2024-02-01: Add reference to LLamaIndex Query Transform Cookbook&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/html/2402.03367v2"&gt;RAG-Fusion: a New Take on Retrieval-Augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Raudaschl/rag-fusion/tree/master"&gt;GitHub - Raudaschl/rag-fusion&lt;/a&gt; - exemplary implementation&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1"&gt;Forget RAG, the Future is RAG-Fusion | by Adrian H. Raudaschl | Oct, 2023 | Towards Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RAG-fusion in LangChain: &lt;a href="https://python.langchain.com/docs/templates/rag-fusion"&gt;usage&lt;/a&gt;, template &lt;a href="https://github.com/langchain-ai/langchain/tree/master/templates/rag-fusion"&gt;code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/query_transformations/query_transform_cookbook.html"&gt;Query Transformation Cookbook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="llm"></category><category term="information-retrieval"></category><category term="rag"></category><category term="re-ranking"></category><category term="semantic-search"></category></entry><entry><title>What Is the Key Difference Between PCA and SVD?</title><link href="https://www.safjan.com/what-is-the-key-difference-between-pca-and-svd/" rel="alternate"></link><published>2023-11-06T00:00:00+01:00</published><updated>2023-11-06T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-06:/what-is-the-key-difference-between-pca-and-svd/</id><summary type="html">&lt;p&gt;Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) are two matrix factorization methods used in machine learning and data analysis for dimensionality reduction. Though they are used for similar purposes, there are some key differences between the two. The key difference …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) are two matrix factorization methods used in machine learning and data analysis for dimensionality reduction. Though they are used for similar purposes, there are some key differences between the two. The key difference between Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) lies in their respective applications and the matrices they operate on.&lt;/p&gt;
&lt;h2&gt;Dealing with the data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PCA&lt;/strong&gt; primarily deals with the covariance structure of the data. It's a statistical procedure that transforms the coordinates of a dataset into a new coordinate system. In the new system, the first axis corresponds to the first principal component that accounts for the maximum variance in the data. The second axis, perpendicular to the first, aligns with the direction of the second largest variance, and so on. PCA effectively tries to find orthogonal axes (the principal components) along which the variance of the data is maximized.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVD&lt;/strong&gt;, on the other hand, does not rely on a covariance matrix. It is a factorization of the original data matrix, and it decomposes the original data into three matrices. This can be done without computing covariance, and even allows to work with missing data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Computations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Both PCA and SVD involve eigen-decomposition. For PCA, the eigen-decomposition is on the covariance matrix of the data which is a square symmetric matrix of size &lt;code&gt;d x d&lt;/code&gt; (where &lt;code&gt;d&lt;/code&gt; is the number of features). This could be an issue if &lt;code&gt;d&lt;/code&gt; is large, since calculating the covariance matrix and performing subsequent eigen-decomposition could be computationally expensive.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In contrast, SVD performs the decomposition on the data matrix itself (of size &lt;code&gt;n x d&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of observations and &lt;code&gt;d&lt;/code&gt; is the number of features), theoretically making the computation more efficient, especially when &lt;code&gt;d&lt;/code&gt; is much larger than &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, while the two techniques are related (PCA can actually be solved using SVD), they approach the problem of dimensionality reduction differently. PCA focuses on the covariance structure and tries to maximize variance along orthogonal axes, while SVD focuses on matrix factorization and can handle cases where data is missing. However, from an application perspective, they are generally used interchangeably.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PCA is a specific application of SVD, primarily used for dimensionality reduction, while SVD is a more general matrix decomposition technique with broader applications in linear algebra and data analysis.&lt;/strong&gt;&lt;/p&gt;</content><category term="note"></category><category term="PCA"></category><category term="SVD"></category><category term="dimensionality-reduction"></category></entry><entry><title>Choosing technology for the LLM knowledge graph</title><link href="https://www.safjan.com/choosing-technology-for-the-lmm-knowledge-graph/" rel="alternate"></link><published>2023-11-05T00:00:00+01:00</published><updated>2023-11-05T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-05:/choosing-technology-for-the-lmm-knowledge-graph/</id><summary type="html">&lt;p&gt;There are several technologies that can be used to implement a knowledge graph, depending on the specific requirements of your project. Here are three commonly used technologies for implementing knowledge graphs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Resource_Description_Framework"&gt;&lt;strong&gt;Resource Description Framework (RDF)&lt;/strong&gt;&lt;/a&gt; (RDF) is a widely adopted standard for …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;There are several technologies that can be used to implement a knowledge graph, depending on the specific requirements of your project. Here are three commonly used technologies for implementing knowledge graphs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Resource_Description_Framework"&gt;&lt;strong&gt;Resource Description Framework (RDF)&lt;/strong&gt;&lt;/a&gt; (RDF) is a widely adopted standard for representing data in the form of triples (subject-predicate-object). It provides a flexible and extensible way to model graph data. RDF-based technologies like &lt;a href="https://db-engines.com/en/article/RDF+Stores"&gt;RDF stores&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/Triplestore"&gt;triplestores&lt;/a&gt; (e.g., &lt;a href="https://jena.apache.org/"&gt;Apache Jena&lt;/a&gt;, &lt;a href="https://virtuoso.openlinksw.com/"&gt;Virtuoso&lt;/a&gt;, &lt;a href="https://www.stardog.com/"&gt;Stardog&lt;/a&gt;) are commonly used to store and query knowledge graphs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database"&gt;&lt;strong&gt;Graph Databases&lt;/strong&gt;&lt;/a&gt; are purpose-built to store, manage, and query graph data efficiently. These databases are optimized for traversing relationships between entities and provide fast graph-based queries. Examples of popular graph databases include &lt;a href="https://neo4j.com/"&gt;Neo4j&lt;/a&gt;, &lt;a href="https://aws.amazon.com/neptune/"&gt;Amazon Neptune&lt;/a&gt;, and &lt;a href="https://janusgraph.org/"&gt;JanusGraph&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Triplestore"&gt;&lt;strong&gt;Triplestores&lt;/strong&gt;&lt;/a&gt; are specialized databases designed specifically for RDF data. They store and query data using the RDF data model. Triplestores like &lt;a href="https://jena.apache.org/"&gt;Apache Jena&lt;/a&gt;, &lt;a href="https://virtuoso.openlinksw.com/"&gt;Virtuoso&lt;/a&gt;, and &lt;a href="https://www.allegrograph.com/"&gt;AllegroGraph&lt;/a&gt; provide features for storing and querying large-scale RDF knowledge graphs effectively.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Implementing a knowledge graph using these technologies typically involves defining a schema or ontology that describes the entities, their properties, and the semantic relationships between them. The triples or statements representing the data are then stored and indexed by the chosen technology for efficient retrieval and querying.&lt;/p&gt;</content><category term="note"></category><category term="llm"></category><category term="knowledge-graph"></category><category term="rdf"></category><category term="graph-database"></category><category term="neo4j"></category><category term="apache-jena"></category><category term="virtuoso"></category><category term="stardog"></category><category term="amazon-neptune"></category><category term="janusgraph"></category><category term="triplestore"></category><category term="allegrograph"></category></entry><entry><title>Prompt Discovery</title><link href="https://www.safjan.com/prompt-discovery/" rel="alternate"></link><published>2023-11-04T00:00:00+01:00</published><updated>2023-11-04T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-04:/prompt-discovery/</id><summary type="html">&lt;p&gt;Learn prompt discovery to uncover the most effective prompts and combinations thereof to achieve specific tasks, while also considering factors like response quality, model performance, and computational efficiency&lt;/p&gt;</summary><content type="html">&lt;p&gt;Prompt discovery, in the context of large language models and prompt engineering, refers to the systematic process of identifying, optimizing, and fine-tuning prompts that elicit desired responses from the language model. It involves a blend of linguistic, computational, and experimental techniques to formulate prompts that yield accurate and contextually relevant outputs from the model.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of prompt discovery is to uncover the most effective prompts and combinations thereof to achieve specific tasks, while also considering factors like response quality, model performance, and computational efficiency.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In highly technical terms, prompt discovery encompasses several complex problems and activities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Formulation&lt;/strong&gt;: This involves crafting prompts that are clear, unambiguous, and tailored to the desired task. Different phrasings and structures might lead to variations in model behavior, so prompt engineers need to experiment with syntax and semantics to achieve optimal results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Permutations&lt;/strong&gt;: Researchers need to explore various permutations of prompts by altering wording, adding context, or using different query types. Systematically generating and testing different prompt variations is a crucial part of prompt discovery to identify which specific formulations generate the desired outputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fine-tuning Parameters&lt;/strong&gt;: Discovering the ideal fine-tuning parameters for each prompt and model combination is a complex optimization problem. Researchers must experiment with factors like learning rates, batch sizes, and optimization algorithms to fine-tune the model for specific prompts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Benchmarking and Comparison&lt;/strong&gt;: Comparing response quality across different prompt permutations, models, and settings is essential. This involves devising appropriate evaluation metrics to quantitatively assess the performance of the model in response to different prompts and making informed decisions based on these metrics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generalization and Transfer Learning&lt;/strong&gt;: Investigating the extent to which prompts can be generalized across tasks or domains is a challenging problem. Researchers need to explore how prompts can be adapted or transferred to different tasks without sacrificing performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Exploration of Novel Prompts&lt;/strong&gt;: As the field evolves, prompt engineers must continuously come up with innovative prompt formulations that push the boundaries of the model's capabilities. This might involve experimenting with new query structures, linguistic constructs, or contextual cues.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="process" src="/images/prompt_discovery/prompt_discovery_process.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Flowchart illustrating the steps in prompt discovery. Starting with prompt formulation, it progresses through prompt permutations, fine-tuning parameters, benchmarking and comparison, generalization and transfer learning, to the exploration of novel prompts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For prompt discovery, a range of tools, both existing and potentially developed in the future, can be instrumental:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automated Prompt Generation&lt;/strong&gt;: AI-assisted tools that automatically generate prompt variations based on input specifications could expedite the discovery process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Optimization Algorithms&lt;/strong&gt;: Advanced optimization algorithms tailored for prompt discovery, including genetic algorithms or reinforcement learning approaches, could efficiently explore the prompt space.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interactive Prompt Testing Environments&lt;/strong&gt;: User-friendly interfaces that allow prompt engineers to interactively test and fine-tune prompts with real-time model feedback can facilitate rapid iteration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Benchmarking Platforms&lt;/strong&gt;: Comprehensive platforms for benchmarking prompt performance across various tasks, models, and settings could aid in making informed prompt selection decisions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semantic Analysis Tools&lt;/strong&gt;: Tools that provide detailed semantic analysis of prompt-response pairs can help identify patterns and nuances in model behavior, guiding prompt formulation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Understanding Frameworks&lt;/strong&gt;: Advanced NLU frameworks that provide insights into model comprehension and reasoning processes can inform prompt design for better results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transfer Learning Techniques&lt;/strong&gt;: Techniques that enable efficient transfer of knowledge from one prompt to another could support prompt generalization across tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Continuous Model Monitoring&lt;/strong&gt;: Real-time monitoring tools that track model performance in response to different prompts can aid in prompt discovery over time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="mindmap" src="/images/prompt_discovery/prompt_discovery_mindmap.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*Figure 2:&lt;/strong&gt; Mindmap illustrating the key aspects of prompt discovery. It includes formulation, permutations, fine-tuning, benchmarking, generalization, novel prompts, and the different tools involved in the process.&lt;/p&gt;
&lt;p&gt;In summary, prompt discovery is a process that involves intricate prompt formulation, thorough benchmarking, fine-tuning, and adaptation. The tools mentioned above, along with future advancements, will play a vital role in shaping the efficiency and effectiveness of prompt discovery efforts.&lt;/p&gt;</content><category term="Generative AI"></category><category term="machine-learning"></category><category term="generative-ai"></category><category term="prompt"></category><category term="prompt-engineering"></category><category term="prompt-discovery"></category></entry><entry><title>Techniques to Boost RAG Performance in Production</title><link href="https://www.safjan.com/techniques-to-boost-rag-performance-in-production/" rel="alternate"></link><published>2023-11-01T00:00:00+01:00</published><updated>2023-11-04T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-11-01:/techniques-to-boost-rag-performance-in-production/</id><summary type="html">&lt;p&gt;This article discusses several advanced techniques that can be applied at different stages of the RAG pipeline to enhance its performance in a production setting.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Retrieval-Augmented Generation (RAG) is a powerful tool in the domain of machine learning, offering significant potential for improving the quality of text generation in various applications. However, optimizing its performance can be a challenging task. For the introductory text on RAG see my other &lt;a href="https://safjan.com/understanding-retrieval-augmented-generation-rag-empowering-llms/"&gt;article&lt;/a&gt;. This article discusses several advanced techniques that can be applied at different stages of the RAG pipeline to enhance its performance in a production setting.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#leveraging-hybrid-search"&gt;Leveraging Hybrid Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilizing-summaries-for-data-chunks"&gt;Utilizing Summaries for Data Chunks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#applying-query-transformations"&gt;Applying Query Transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#query-compression"&gt;Query Compression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#optimal-chunking-strategy"&gt;Optimal Chunking Strategy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fine-tuning-embedding-models"&gt;Fine-tuning Embedding Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enriching-metadata"&gt;Enriching Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#employing-re-ranking"&gt;Employing Re-ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#addressing-the-lost-in-the-middle-problem"&gt;Addressing the 'Lost in the Middle' Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#meta-data-filtering"&gt;Meta-data Filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#query-routing"&gt;Query Routing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="leveraging-hybrid-search"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Leveraging Hybrid Search&lt;/h2&gt;
&lt;p&gt;Hybrid search, a fusion of semantic search and keyword search, can be employed to retrieve pertinent data from a vector store. This method often yields superior results across a range of use cases. It essentially combines the strength of keyword search (precision) and semantic search (recall), providing a more comprehensive search solution.
dups/hybrid_search&lt;/p&gt;
&lt;p&gt;&lt;a id="utilizing-summaries-for-data-chunks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Utilizing Summaries for Data Chunks&lt;/h2&gt;
&lt;p&gt;An efficient way to enhance the quality of generation and reduce the number of tokens in the input is by summarizing the chunks of data and storing these summaries in the vector store. This technique is especially useful when dealing with data that includes numerous filler words. By summarizing the chunks, we can eliminate these superfluous elements, thereby refining the quality of the input data.
&lt;a id="query-compression"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="applying-query-transformations"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Applying Query Transformations&lt;/h2&gt;
&lt;p&gt;Query transformations can significantly enhance the quality of responses. For instance, if a system does not find relevant context for a query, the LLM can rephrase the query and try again. See the &lt;a href="https://www.safjan.com/rag-fusion-enhancing-information-retrieval-in-large-language-models/"&gt;RAG-Fusion - Enhancing Information Retrieval in Large Language Models&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, the &lt;a href="http://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf"&gt;HyDE&lt;/a&gt; strategy generates a hypothetical response to a query and uses both for embedding lookup, which has been found to dramatically enhance performance.&lt;/p&gt;
&lt;p&gt;Another technique involves breaking down complex queries into sub-queries, a process that LLMs tend to handle better. This approach can be integrated into the RAG system to decompose a query into multiple simpler questions.&lt;/p&gt;
&lt;p&gt;&lt;a id="query-compression"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Query Compression&lt;/h2&gt;
&lt;p&gt;Query compression, (see a tool like &lt;a href="https://www.microsoft.com/en-us/research/project/llmlingua/longllmlingua/"&gt;LongLLMLingua&lt;/a&gt;) is a technique for improving RAG's performance in long context scenarios where large language models often face challenges such as increased computational and financial costs, longer latency, and inferior performance. By enhancing the density and optimizing the position of key information in the input prompt, LongLLMLingua improves LLMs' perception of key information, which in turn, reduces computational load, decreases latency, and improves performance. This strategy ensures that vital information is not lost or diluted in lengthy contexts, thereby enhancing the relevance and quality of the generated output.
&lt;a id="optimal-chunking-strategy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Optimal Chunking Strategy&lt;/h2&gt;
&lt;p&gt;There are multiple strategies that can be applied to chunking see &lt;a href="https://safjan.com/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/#from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques"&gt;Chunking strategies&lt;/a&gt;. One of the aspects can be controlling the chunk overlap. Semantic retrieval may pose a challenge when a selected chunk has meaningful context in adjacent chunks that could be missed. To mitigate this, an overlap of chunks can be implemented, whereby neighboring chunks are also passed to the Language Model (LLM) for generation. This guarantees that the surrounding context is incorporated, thus enhancing the output's quality.&lt;/p&gt;
&lt;p&gt;&lt;a id="fine-tuning-embedding-models"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Fine-tuning Embedding Models&lt;/h2&gt;
&lt;p&gt;While off-the-shelf embedding models such as BERT and Ada may suffice for many use cases, they might not adequately represent specific domains in the vector space, leading to suboptimal retrieval quality. In such instances, it would be advantageous to fine-tune an embedding model using domain-specific data to significantly improve retrieval quality.&lt;/p&gt;
&lt;p&gt;&lt;a id="enriching-metadata"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Enriching Metadata&lt;/h2&gt;
&lt;p&gt;The provision of metadata like source information about the chunks being processed can enhance the LLM's comprehension of the context, leading to a better output generation. This additional layer of information can provide the LLM with a more holistic understanding of the data, enabling it to generate more accurate and relevant responses.&lt;/p&gt;
&lt;p&gt;&lt;a id="employing-re-ranking"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Employing Re-ranking&lt;/h2&gt;
&lt;p&gt;Semantic search may yield top-k results that are too similar to each other. To ensure a wider array of snippets, it is beneficial to &lt;a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html"&gt;re-rank&lt;/a&gt; the results based on other factors such as metadata and keyword matches. This diversification of snippets can lead to a more nuanced and comprehensive context for the LLM to generate responses. Re-ranker can be based on a cross-encoder.&lt;/p&gt;
&lt;p&gt;&lt;a id="addressing-the-lost-in-the-middle-problem"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Addressing the 'Lost in the Middle' Problem&lt;/h2&gt;
&lt;p&gt;LLMs tend not to assign equal weight to all tokens in the input, often overlooking tokens located in the middle. This phenomenon, known as the &lt;a href="https://arxiv.org/abs/2307.03172"&gt;'lost in the middle' problem&lt;/a&gt;, can be addressed by reordering the context snippets to place the most vital snippets at the beginning and end of the input, with less important snippets situated in the middle.&lt;/p&gt;
&lt;p&gt;&lt;a id="meta-data-filtering"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Meta-data Filtering&lt;/h2&gt;
&lt;p&gt;Meta-data, such as date tags, can be added to your chunks to improve retrieval. For example, filtering by recency can be beneficial when querying email history. Recent emails may not necessarily be the most similar from an embedding standpoint, but they are more likely to be relevant.&lt;/p&gt;
&lt;p&gt;&lt;a id="query-routing"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Query Routing&lt;/h2&gt;
&lt;p&gt;Having multiple indexes and routing queries to the appropriate index can be beneficial. For instance, different indexes could handle summarization questions, pointed questions, and date-sensitive questions. Trying to optimize one index for all these behaviors may compromise its effectiveness.&lt;/p&gt;
&lt;p&gt;The performance of RAG in production can be significantly improved by applying a range of techniques, including hybrid search, chunk summarization, overlapping chunks, fine-tuned embedding models, metadata enhancement, re-ranking, addressing the 'lost in the middle' problem, query transformations, meta-data filtering, and query routing. These strategies will help to optimize the RAG pipeline, ensuring higher quality output and improved overall performance.&lt;/p&gt;
&lt;p&gt;&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://llmstack.ai/blog/retrieval-augmented-generation"&gt;Retrieval Augmented Generation (RAG): What, Why and How? | LLMStack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2307.03172"&gt;[2307.03172] Lost in the Middle: How Language Models Use Long Contexts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c"&gt;10 Ways to Improve the Performance of Retrieval Augmented Generation Systems | by Matt Ambrogi | Sep, 2023 | Towards Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hypothetical Document Embeddings (HyDE) - &lt;a href="http://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf"&gt;Precise Zero-Shot Dense Retrieval without Relevance Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sbert.net/examples/applications/retrieve_rerank/README.html"&gt;Retrieve &amp;amp; Re-Rank — Sentence-Transformers documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.llamaindex.ai/improving-rag-effectiveness-with-retrieval-augmented-dual-instruction-tuning-ra-dit-01e73116655d"&gt;Improving RAG effectiveness with Retrieval-Augmented Dual Instruction Tuning (RA-DIT) | by Emanuel Ferreira | Oct, 2023 | LlamaIndex Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/towards-generative-ai/improving-rag-retrieval-augmented-generation-answer-quality-with-re-ranker-55a19931325"&gt;Improving RAG (Retrieval Augmented Generation) Answer Quality with Re-ranker | by Shivam Solanki | Towards Generative AI | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SingleStore (db), finetuning embeddings model, CacheGPT, Nemo-Guardrails, &lt;a href="https://madhukarkumar.medium.com/secrets-to-optimizing-rag-llm-apps-for-better-accuracy-performance-and-lower-cost-da1014127c0a"&gt;Secrets to Optimizing RAG LLM Apps for Better Performance, Accuracy and Lower Costs! | by Madhukar Kumar | madhukarkumar | Sep, 2023 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/run-llama/finetune-embedding"&gt;run-llama/finetune-embedding: Fine-Tuning Embedding for RAG with Synthetic Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zilliztech/GPTCache"&gt;zilliztech/GPTCache: Semantic cache for LLMs. Fully integrated with LangChain and llama_index.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/NVIDIA/NeMo-Guardrails"&gt;NVIDIA/NeMo-Guardrails: NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;library to evaluate the context retrieved from your enterprise corpus of data (how do you know if the context being retrieved is accurate) &lt;a href="https://github.com/explodinggradients/ragas"&gt;GitHub - explodinggradients/ragas: Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LangSmith, introduced by LangChain - a highly effective tool for monitoring and examining the responses between the app and the LLM.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.15123"&gt;[2310.15123] Branch-Solve-Merge Improves Large Language Model Evaluation and Generation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Generative AI"></category><category term="machine-learning"></category><category term="python"></category><category term="rag"></category><category term="llm"></category><category term="retrieval-augmented-generation"></category><category term="re-ranking"></category><category term="lost-in-the-middle"></category></entry><entry><title>Python Expertise Level - Self-Assessment</title><link href="https://www.safjan.com/python-expertise-level-self-assessment/" rel="alternate"></link><published>2023-10-17T00:00:00+02:00</published><updated>2023-10-17T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-10-17:/python-expertise-level-self-assessment/</id><summary type="html">&lt;p&gt;Sometimes you need to assess your own or candidate's level of expertise in Python programming. I have created some statements that roughly corresponds to the various level of expertise. Note that knowing programming language techniques contributes to expertise but does not make …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometimes you need to assess your own or candidate's level of expertise in Python programming. I have created some statements that roughly corresponds to the various level of expertise. Note that knowing programming language techniques contributes to expertise but does not make a great programmer automatically. Knowledge of algorithms and data structures, programming patterns, and software architectures are some other important factors - to mention a few.&lt;/p&gt;
&lt;p&gt;Having that said, I still find useful this simple classification of Python programmers into three categories: beginners, advanced, and experts.&lt;/p&gt;
&lt;h2&gt;Beginners&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Familiar with basic Python syntax and data types (strings, integers, lists, dictionaries).&lt;/li&gt;
&lt;li&gt;Can write simple functions and use control flow statements (if, for, while).&lt;/li&gt;
&lt;li&gt;Understands the concept of variables and variable scope.&lt;/li&gt;
&lt;li&gt;Can use basic Python libraries like &lt;code&gt;math&lt;/code&gt; and &lt;code&gt;random&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Knows how to handle errors and exceptions using try/except blocks.&lt;/li&gt;
&lt;li&gt;Can read from and write to files.&lt;/li&gt;
&lt;li&gt;Understands the basics of object-oriented programming: classes, objects, methods.&lt;/li&gt;
&lt;li&gt;Can use basic string and list methods for manipulation.&lt;/li&gt;
&lt;li&gt;Knows how to use basic Python data structures like lists, tuples, and dictionaries.&lt;/li&gt;
&lt;li&gt;Can write simple Python scripts to automate tasks.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Advanced&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Understands and uses generators and decorators.&lt;/li&gt;
&lt;li&gt;Can write complex functions and classes with multiple methods and attributes.&lt;/li&gt;
&lt;li&gt;Understands and uses list comprehensions and lambda functions.&lt;/li&gt;
&lt;li&gt;Can use regular expressions for pattern matching in strings (note: more regex skill that python)&lt;/li&gt;
&lt;li&gt;Understands and uses context managers for resource management.&lt;/li&gt;
&lt;li&gt;Can use advanced Python data structures like sets and frozensets.&lt;/li&gt;
&lt;li&gt;Understands and uses Python's memory management and optimization techniques.&lt;/li&gt;
&lt;li&gt;Can use Python's built-in functions like &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;reduce()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Understands and uses Python's module and package system.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Experts&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Understands and uses metaclasses and descriptors.&lt;/li&gt;
&lt;li&gt;Can write and understand asynchronous code using &lt;code&gt;asyncio&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Understands and uses Python's concurrency and parallelism features.&lt;/li&gt;
&lt;li&gt;Can use Python's C API to extend Python with C/C++ code.&lt;/li&gt;
&lt;li&gt;Understands and uses Python's dynamic typing system to its full extent.&lt;/li&gt;
&lt;li&gt;Can write and understand complex decorators and context managers.&lt;/li&gt;
&lt;li&gt;Proficient in Python's debugging and profiling, using tools like &lt;code&gt;pdb&lt;/code&gt; for debugging and &lt;code&gt;cProfile&lt;/code&gt; for profiling to optimize their code.&lt;/li&gt;
&lt;li&gt;Have a deep understanding of Python's Global Interpreter Lock (GIL) and how it affects multithreaded programs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is &lt;a href="https://news.ycombinator.com/item?id=38032092"&gt;HN&lt;/a&gt; discussion on this note.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2023-10-30: Remove from Experts: 7. Understands and uses Python's garbage collection system.&lt;/li&gt;
&lt;li&gt;2023-10-30: Remove from Experts: Have a good understanding of Python's internals, such as bytecode, the Python interpreter's execution model, and how Python's data types are implemented at the C level.&lt;/li&gt;
&lt;li&gt;2023-10-30: Remove from Advanced: Can use advanced Python libraries like &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt; not a python std lib.&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="python"></category><category term="programming"></category><category term="interview"></category><category term="job-interview"></category><category term="skills"></category></entry><entry><title>Understanding the Differences in Language Models - Transformers vs. Markov Models</title><link href="https://www.safjan.com/understanding-differences-gpt-transformers-markov-models/" rel="alternate"></link><published>2023-10-07T00:00:00+02:00</published><updated>2023-10-07T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-10-07:/understanding-differences-gpt-transformers-markov-models/</id><summary type="html">&lt;p&gt;This article explores distinguishing details of Markov Models and Transformer-based models like GPT, focusing on how they predict the next character in a sequence. It explores the fundamental differences between these models, with a particular emphasis on how the self-attention mechanism in Transformer models makes a difference compared to the fixed context length in Markov models.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the field of machine learning and natural language processing (NLP), different models have been developed to understand and generate human language. Two such models that have gained significant attention are the Markov Models and the Transformer-based models like GPT (&lt;a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer"&gt;Generative Pretrained Transformer&lt;/a&gt;). While both types of models can predict the next character in a sequence, they differ significantly in their underlying mechanisms and capabilities. This article aims to delve into the intricacies of these models, with a particular focus on how the self-attention mechanism in Transformer models makes a difference compared to the fixed context length in Markov models.&lt;/p&gt;
&lt;h2&gt;Markov Models: A Brief Overview&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Markov_model"&gt;Markov Models&lt;/a&gt;, named after the Russian mathematician &lt;a href="https://en.wikipedia.org/wiki/Andrey_Markov"&gt;Andrey Markov&lt;/a&gt;, are a class of models that predict future states based solely on the current state, disregarding all past states. This property is known as the Markov Property, and it is the fundamental assumption that underlies all Markov models.&lt;/p&gt;
&lt;p&gt;In the context of language modeling, a Markov Model might predict the next word or character in a sentence based on the current word or character. For instance, given the word "The", a Markov Model might predict that the next word is "cat" based on the probability distribution of words that follow "The" in its training data.&lt;/p&gt;
&lt;p&gt;The main limitation of Markov Models is their lack of memory. Since they only consider the current state, they are unable to capture long-term dependencies in a sequence. For example, in the sentence "I grew up in France... I speak fluent ___", a Markov Model might struggle to fill in the blank correctly because the relevant context ("France") is several words back.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Markov Chain text generation" src="/images/transformers_vs_markov/markov_model_text_generation.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; &lt;em&gt;Markov Model might predict  the next word based on the probability distribution of words in its training data. Image Source: &lt;a href="https://jaroslawwiosna.github.io/markov-chain-text/"&gt;markov-chain-text | Modern C++ Markov chain text generator&lt;/a&gt; by Jarosław Wiosna&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Transformer Models: An Introduction&lt;/h2&gt;
&lt;p&gt;Transformer models, on the other hand, were introduced in the seminal paper &lt;a href="https://arxiv.org/abs/1706.03762"&gt;"Attention is All You Need"&lt;/a&gt; by Vaswani et al. (2017). They represent a significant departure from previous sequence-to-sequence models, eschewing recurrent and convolutional layers in favor of self-attention mechanisms.&lt;/p&gt;
&lt;p&gt;GPT, developed by OpenAI, is a prominent example of a Transformer model. It is a generative model that can generate human-like text by predicting the next word in a sequence. Unlike Markov Models, GPT considers the entire context of a sequence when making predictions, allowing it to capture long-term dependencies.&lt;/p&gt;
&lt;h2&gt;The Power of Self-Attention&lt;/h2&gt;
&lt;p&gt;The key innovation of Transformer models is the self-attention mechanism. This mechanism allows the model to weigh the importance of different words in the context when predicting the next word. For instance, in the sentence "The cat, which was black and white, jumped over the ___", the model might assign more importance to "cat" and "jumped" when predicting the next word.&lt;/p&gt;
&lt;p&gt;Self-attention is calculated using the dot product of the query and key vectors, which are learned representations of the input. The resulting attention scores are then used to weight the value vectors, which are also learned representations of the input. This weighted sum forms the output of the self-attention layer.&lt;/p&gt;
&lt;p&gt;The self-attention mechanism allows Transformer models to consider the entire context of a sequence, rather than just the current state. This is a significant advantage over Markov Models, which are limited by their fixed context length.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Transformer model - Context and Attention" src="/images/transformers_vs_markov/transformers_context_and_atention.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; &lt;em&gt;The self-attention mechanism allows Transformer models to consider the entire context of a sequence, rather than just the current state. Image Source:  &lt;a href="https://dzone.com/articles/a-deep-dive-into-the-transformer-architecture-the"&gt;A Deep Dive Into the Transformer Architecture – The Development of Transformer Models&lt;/a&gt; by Kevin Hooke&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Fixed Context Length vs. Variable Context Length&lt;/h2&gt;
&lt;p&gt;Markov Models, due to their inherent design, have a fixed context length. They only consider the current state when making predictions, which limits their ability to capture long-term dependencies. This can lead to less accurate predictions, especially in complex sequences where the relevant context might be several states back.&lt;/p&gt;
&lt;p&gt;Transformer models, on the other hand, have a variable context length. Thanks to the self-attention mechanism, they can consider the entire context of a sequence when making predictions. This allows them to capture long-term dependencies and make more accurate predictions.&lt;/p&gt;
&lt;p&gt;Moreover, the self-attention mechanism allows Transformer models to dynamically adjust the context length based on the input. For instance, in a sentence with many irrelevant words, the model might focus on a few key words, effectively reducing the context length. This dynamic context length is another advantage of Transformer models over Markov Models.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While both Markov Models and Transformer models like GPT can predict the next character in a sequence, they differ significantly in their underlying mechanisms and capabilities. Markov Models, with their fixed context length, are limited in their ability to capture long-term dependencies. Transformer models, with their self-attention mechanism, can consider the entire context of a sequence, allowing them to capture long-term dependencies and make more accurate predictions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &amp;amp; Polosukhin, I. (2017). &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention is all you need&lt;/a&gt;. In Advances in neural information processing systems (pp. 5998-6008).&lt;/li&gt;
&lt;li&gt;Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., &amp;amp; Sutskever, I. (2019). &lt;a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;. OpenAI Blog.&lt;/li&gt;
&lt;li&gt;Bishop, C. M. (2006). &lt;a href="https://www.springer.com/gp/book/9780387310732"&gt;Pattern Recognition and Machine Learning&lt;/a&gt;. Springer.&lt;/li&gt;
&lt;li&gt;Ruder, S. (2019). &lt;a href="http://jalammar.github.io/illustrated-transformer/"&gt;The Illustrated Transformer&lt;/a&gt;. Jay Alammar's Blog.&lt;/li&gt;
&lt;li&gt;Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... &amp;amp; Amodei, D. (2020). &lt;a href="https://arxiv.org/abs/2005.14165"&gt;Language Models are Few-Shot Learners&lt;/a&gt;. In Advances in Neural Information Processing Systems.&lt;/li&gt;
&lt;li&gt;Chollet, F. (2018). &lt;a href="https://www.manning.com/books/deep-learning-with-python"&gt;Deep Learning with Python&lt;/a&gt;. Manning Publications Co.&lt;/li&gt;
&lt;li&gt;Jurafsky, D., &amp;amp; Martin, J. H. (2019). &lt;a href="https://web.stanford.edu/~jurafsky/slp3/"&gt;Speech and Language Processing&lt;/a&gt;. Stanford University.&lt;/li&gt;
&lt;li&gt;Al-Rfou, R., Choe, D., Constant, N., Guo, M., &amp;amp; Jones, L. (2019). &lt;a href="https://arxiv.org/abs/1808.04444"&gt;Character-Level Language Modeling with Deeper Self-Attention&lt;/a&gt;. In Proceedings of the AAAI Conference on Artificial Intelligence.&lt;/li&gt;
&lt;li&gt;Goodfellow, I., Bengio, Y., &amp;amp; Courville, A. (2016). &lt;a href="http://www.deeplearningbook.org/"&gt;Deep Learning&lt;/a&gt;. MIT press.&lt;/li&gt;
&lt;li&gt;Manning, C. D., &amp;amp; Schütze, H. (1999). &lt;a href="https://mitpress.mit.edu/books/foundations-statistical-natural-language-processing"&gt;Foundations of Statistical Natural Language Processing&lt;/a&gt;. MIT Press.&lt;/li&gt;
&lt;li&gt;Jurafsky, D., &amp;amp; Martin, J. H. (2009). &lt;a href="https://www.pearson.com/us/higher-education/program/Jurafsky-Speech-and-Language-Processing-An-Introduction-to-Natural-Language-Processing-Computational-Linguistics-and-Speech-Recognition-2nd-Edition/PGM319216.html"&gt;Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition&lt;/a&gt;. Prentice Hall.&lt;/li&gt;
&lt;li&gt;Jelinek, F. (1997). &lt;a href="https://mitpress.mit.edu/books/statistical-methods-speech-recognition"&gt;Statistical Methods for Speech Recognition&lt;/a&gt;. MIT Press.&lt;/li&gt;
&lt;li&gt;Russell, S., &amp;amp; Norvig, P. (2016). &lt;a href="http://aima.cs.berkeley.edu/"&gt;Artificial Intelligence: A Modern Approach&lt;/a&gt;. Pearson.&lt;/li&gt;
&lt;li&gt;Charniak, E. (1993). &lt;a href="https://mitpress.mit.edu/books/statistical-language-learning"&gt;Statistical Language Learning&lt;/a&gt;. MIT Press.&lt;/li&gt;
&lt;li&gt;Lin, T. (2015). &lt;a href="https://towardsdatascience.com/markov-chains-and-text-generation-162fd4ec8f26"&gt;Markov Chains and Text Generation&lt;/a&gt;. Towards Data Science Blog.&lt;/li&gt;
&lt;li&gt;Goodman, J. (2001). &lt;a href="https://www.microsoft.com/en-us/research/publication/a-bit-of-progress-in-language-modeling/"&gt;A bit of progress in language modeling&lt;/a&gt;. Microsoft Research.&lt;/li&gt;
&lt;li&gt;Rosenfeld, R. (2000). &lt;a href="https://www.cs.cmu.edu/~roni/papers/SLM-hlt01.pdf"&gt;Two Decades of Statistical Language Modeling: Where Do We Go From Here?&lt;/a&gt;. Proceedings of the IEEE.&lt;/li&gt;
&lt;li&gt;Nazarko, K. (2021). &lt;a href="https://towardsdatascience.com/text-generation-gpt-2-lstm-markov-chain-9ea371820e1e"&gt;Word-level text generation using GPT-2, LSTM and Markov Chain&lt;/a&gt;. Towards Data Science Blog.&lt;/li&gt;
&lt;li&gt;Adyatama, A. (2020). &lt;a href="https://algotech.netlify.app/blog/text-generating-with-markov-chains/"&gt;Text Generation with Markov Chains&lt;/a&gt; Algoritma Technical Blog.&lt;/li&gt;
&lt;/ol&gt;</content><category term="Generative AI"></category><category term="machine-learning"></category><category term="transformers"></category><category term="markov-models"></category><category term="attention"></category><category term="self-attention"></category><category term="natural-language-processing"></category><category term="nlp"></category><category term="AI"></category><category term="deep-learning"></category><category term="language-models"></category><category term="GPT"></category></entry><entry><title>How Agile Can Kill Creativity in Data Science team?</title><link href="https://www.safjan.com/how-agile-can-kill-creativity-in-data-science-team/" rel="alternate"></link><published>2023-09-29T00:00:00+02:00</published><updated>2023-09-29T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-29:/how-agile-can-kill-creativity-in-data-science-team/</id><summary type="html">&lt;p&gt;Discover the delicate balance between Agile methodologies and imagination in the domain of data science and analytics. Uncover the impact of Agile approaches on creativity within data science teams. Explore how these practices shape the innovative landscape of data science and analytics.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Agile methodologies can provide numerous benefits to data science and analytics teams, such as quicker delivery, enhanced collaboration, and increased customer satisfaction. However, if not implemented effectively, Agile may unintentionally impede creativity in these teams. Here are a few ways Agile can potentially hinder creativity in data science/analytics.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#potential-problems"&gt;Potential problems&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#tight-deadlines-and-sprints"&gt;Tight deadlines and sprints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#focus-on-deliverables"&gt;Focus on deliverables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lack-of-autonomy"&gt;Lack of autonomy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#constant-and-sudden-changes"&gt;Constant and sudden changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#overemphasis-on-standardized-processes"&gt;Overemphasis on standardized processes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#mitigation"&gt;Mitigation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#complementary-practices"&gt;Complementary practices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#frameworks-tailored-for-data-science-projects"&gt;Frameworks tailored for data science projects&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="potential-problems"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Potential problems&lt;/h2&gt;
&lt;p&gt;&lt;a id="tight-deadlines-and-sprints"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Tight deadlines and sprints&lt;/h3&gt;
&lt;p&gt;Agile typically operates on tight timelines with fixed sprints. This can limit the time available for exploration, experimentation, and creative thinking. The emphasis on adhering to strict schedules may discourage innovative approaches that require more time to develop.&lt;/p&gt;
&lt;p&gt;&lt;a id="focus-on-deliverables"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Focus on deliverables&lt;/h3&gt;
&lt;p&gt;Agile methodologies often prioritize delivering functioning solutions over long-term exploration. This focus on short-term goals can discourage team members from taking the time to explore complex problems creatively, resulting in a more practical, rather than innovative, approach.&lt;/p&gt;
&lt;p&gt;&lt;a id="lack-of-autonomy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Lack of autonomy&lt;/h3&gt;
&lt;p&gt;In some Agile implementations, teams may be closely supervised or required to adhere to preset workflows. This kind of micromanagement limits individual creativity, as team members may not have the freedom to experiment, propose alternative solutions, or take calculated risks.&lt;/p&gt;
&lt;p&gt;&lt;a id="constant-and-sudden-changes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Constant and sudden changes&lt;/h3&gt;
&lt;p&gt;Agile projects often involve iterative development with frequent changes in priorities and requirements. While this adaptability is beneficial in many cases, it can disrupt the creative process and impede the ability to think deeply about problems. Constantly switching gears may hinder the exploration of unconventional solutions.&lt;/p&gt;
&lt;p&gt;&lt;a id="overemphasis-on-standardized-processes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Overemphasis on standardized processes&lt;/h3&gt;
&lt;p&gt;Agile frameworks provide standardized processes and practices that ensure consistency and predictability. While these are essential for efficient project management, a strict adherence to these processes can stifle creativity as it may discourage deviation from the prescribed methods.&lt;/p&gt;
&lt;p&gt;&lt;a id="mitigation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Mitigation&lt;/h2&gt;
&lt;p&gt;&lt;a id="complementary-practices"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Complementary practices&lt;/h3&gt;
&lt;p&gt;To prevent the potential negative impact on creativity, Agile methodologies should be complemented with the following practices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow dedicated time for &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;learning&lt;/strong&gt; outside of fixed sprints.&lt;/li&gt;
&lt;li&gt;Encourage &lt;strong&gt;cross-functional collaboration&lt;/strong&gt; and knowledge sharing to foster creativity.&lt;/li&gt;
&lt;li&gt;Provide opportunities for &lt;strong&gt;innovation-driven initiatives&lt;/strong&gt; alongside project-driven ones.&lt;/li&gt;
&lt;li&gt;Support a &lt;strong&gt;psychologically safe environment&lt;/strong&gt; that allows for experimentation and failure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recognize&lt;/strong&gt; and reward &lt;strong&gt;creative thinking&lt;/strong&gt; and experimentation within the team.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="frameworks-tailored-for-data-science-projects"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Frameworks tailored for data science projects&lt;/h3&gt;
&lt;p&gt;The data science teams need to adapt Agile practices to suit their specific needs and contexts, and to balance the trade-offs between speed, flexibility, and quality. Data science teams can adopt or modify a framework that is tailored for data science projects, such as the &lt;strong&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview"&gt;Team Data Science Process&lt;/a&gt;&lt;/strong&gt; (TDSP) or the &lt;strong&gt;&lt;a href="https://www.datascience-pm.com/agile-data-science/"&gt;Agile Data Science Process&lt;/a&gt;&lt;/strong&gt; These frameworks provide guidance on how to structure, execute, and manage data science projects using Agile principles and practices.&lt;/p&gt;
&lt;p&gt;By adjusting Agile practices to accommodate these considerations, data science/analytics teams can create a balance between efficient project management and fostering creativity and innovation.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview"&gt;What is the Team Data Science Process? - Azure Architecture Center | Microsoft Learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datascience-pm.com/agile-data-science/"&gt;Agile Data Science - Data Science Process Alliance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://eugeneyan.com/writing/data-science-and-agile-what-works-and-what-doesnt/"&gt;Data Science and Agile (What Works, and What Doesn't)&lt;/a&gt; (read about poor resource planning)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.geeksforgeeks.org/agile-methodology-advantages-and-disadvantages/"&gt;Agile Methodology Advantages and Disadvantages - GeeksforGeeks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="Machine Learning"></category><category term="data-science"></category><category term="agile"></category><category term="scrum"></category><category term="SAFe"></category><category term="sprint"></category><category term="deliverables"></category><category term="process"></category><category term="exploration"></category><category term="collaboration"></category><category term="creativity"></category><category term="creative-thinking"></category><category term="agile-data-science-process"></category><category term="team-data-science-process"></category></entry><entry><title>The Right Way to Job-Hop</title><link href="https://www.safjan.com/the-right-way-to-job-hop/" rel="alternate"></link><published>2023-09-29T00:00:00+02:00</published><updated>2023-09-29T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-29:/the-right-way-to-job-hop/</id><summary type="html">&lt;p&gt;NOTE: The text below are the advices extracted from the podcast transcript using LLM.&lt;/p&gt;
&lt;p&gt;Based on the podcast "The right way to Job-hop" &lt;a href="https://stackoverflow.blog/2022/10/11/the-right-way-to-job-hop-ai-generated-pokemon-ep-495/"&gt;transcript&lt;/a&gt;, here are some key pieces of advice on how to do "job hopping" the right way:&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-pieces-of-advice"&gt;Key Pieces …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;NOTE: The text below are the advices extracted from the podcast transcript using LLM.&lt;/p&gt;
&lt;p&gt;Based on the podcast "The right way to Job-hop" &lt;a href="https://stackoverflow.blog/2022/10/11/the-right-way-to-job-hop-ai-generated-pokemon-ep-495/"&gt;transcript&lt;/a&gt;, here are some key pieces of advice on how to do "job hopping" the right way:&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#key-pieces-of-advice"&gt;Key Pieces of Advice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#follow-new-tech-trends"&gt;Follow New Tech Trends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dont-stay-too-long-in-one-place"&gt;Don't Stay Too Long in One Place&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-job-hopping-to-gain-a-variety-of-experience"&gt;Use Job Hopping to Gain a Variety of Experience&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#leave-a-job-for-a-good-reason"&gt;Leave a Job for a Good Reason&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#stay-at-a-job-for-at-least-a-year"&gt;Stay at a Job for at Least a Year&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#be-prepared-to-explain-your-job-hopping"&gt;Be Prepared to Explain Your Job Hopping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#consider-remote-opportunities"&gt;Consider Remote Opportunities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#focus-on-increasing-your-personal-wealth"&gt;Focus on Increasing Your Personal Wealth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ensure-youre-moving-up-with-each-job-change"&gt;Ensure You're Moving Up With Each Job Change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ask-the-right-questions-during-interviews"&gt;Ask the Right Questions During Interviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-pieces-of-advice"&gt;Additional pieces of advice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#understand-the-impact-of-job-hopping-on-your-resume"&gt;Understand the Impact of Job Hopping on Your Resume&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#avoid-short-stints"&gt;Avoid Short Stints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-job-hopping-as-a-negotiation-tool"&gt;Use Job Hopping as a Negotiation Tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#consider-the-company-culture"&gt;Consider the Company Culture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#be-transparent-and-honest"&gt;Be Transparent and Honest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#keep-learning-and-updating-your-skills"&gt;Keep Learning and Updating Your Skills&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#maintain-professional-relationships"&gt;Maintain Professional Relationships&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#consider-the-impact-on-your-long-term-career-goals"&gt;Consider the Impact on Your Long-Term Career Goals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#take-advantage-of-remote-work-opportunities"&gt;Take Advantage of Remote Work Opportunities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#always-leave-on-good-terms-dont-burn-bridges"&gt;Always Leave on Good Terms, Don't Burn Bridges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#evaluate-the-companys-stability"&gt;Evaluate the Company's Stability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#consider-the-impact-on-your-work-life-balance"&gt;Consider the Impact on Your Work-Life Balance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#take-time-to-reflect-on-each-job-change"&gt;Take Time to Reflect on Each Job Change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#be-prepared-for-potential-negative-perceptions"&gt;Be Prepared for Potential Negative Perceptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dont-job-hop-just-for-the-sake-of-it"&gt;Don't Job Hop Just for the Sake of It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#consider-the-benefits-and-drawbacks"&gt;Consider the Benefits and Drawbacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#keep-your-skills-up-to-date"&gt;Keep Your Skills Up to Date&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#network-effectively"&gt;Network Effectively&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="key-pieces-of-advice"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Key Pieces of Advice&lt;/h2&gt;
&lt;p&gt;&lt;a id="follow-new-tech-trends"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Follow New Tech Trends&lt;/h3&gt;
&lt;p&gt;The tech industry is characterized by rapid and constant evolution. As such, it's crucial to stay abreast of emerging technologies and trends. By doing so, you can identify opportunities to gain experience in these new areas, which can enhance your skill set and make you more marketable. Job hopping can be a strategic way to follow these trends, allowing you to move between companies that are at the forefront of these changes, thereby ensuring your skills remain relevant and in-demand.&lt;/p&gt;
&lt;p&gt;&lt;a id="dont-stay-too-long-in-one-place"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Don't Stay Too Long in One Place&lt;/h3&gt;
&lt;p&gt;Unlike many other industries where longevity in a role is often rewarded, the tech industry values adaptability and diverse experience. Given the high demand for tech skills, employers are often willing to offer competitive compensation packages to attract talent, even if the candidate has a history of changing jobs frequently. Therefore, don't hesitate to change jobs every few years if it means advancing your career, gaining new skills, or improving your compensation.&lt;/p&gt;
&lt;p&gt;&lt;a id="use-job-hopping-to-gain-a-variety-of-experience"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Use Job Hopping to Gain a Variety of Experience&lt;/h3&gt;
&lt;p&gt;Job hopping can provide a wealth of diverse experiences. By moving between different companies, roles, and projects, you can acquire a broad range of skills and insights. This variety can not only enhance your professional development and accelerate your career progression but also make you a more attractive candidate to potential employers who value such diverse experience.&lt;/p&gt;
&lt;p&gt;&lt;a id="leave-a-job-for-a-good-reason"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Leave a Job for a Good Reason&lt;/h3&gt;
&lt;p&gt;While job hopping is more accepted in the tech industry, it's still important to have a valid reason for leaving each job. This could be to pursue a new opportunity, acquire new skills, seek a higher salary, or aim for a promotion. Leaving a job without a good reason could raise concerns for potential employers, who may question your commitment or reliability. Therefore, always ensure you can articulate your reasons for job changes in a positive and professional manner.&lt;/p&gt;
&lt;p&gt;&lt;a id="stay-at-a-job-for-at-least-a-year"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Stay at a Job for at Least a Year&lt;/h3&gt;
&lt;p&gt;While frequent job changes can be beneficial, it's advisable to stay at each job for at least a year. This duration allows you sufficient time to fully understand your role, contribute meaningfully to the company, and leave a positive impression. It also demonstrates to future employers that you can commit to a role and see projects through to completion.&lt;/p&gt;
&lt;p&gt;&lt;a id="be-prepared-to-explain-your-job-hopping"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Be Prepared to Explain Your Job Hopping&lt;/h3&gt;
&lt;p&gt;If your resume shows frequent job changes, be prepared to explain this during interviews. Honesty is key here. Focus on the positive aspects of job hopping, such as the diverse skills and experiences you've gained, the opportunities you've had to work on different projects or with different technologies, and how these experiences have contributed to your professional growth.&lt;/p&gt;
&lt;p&gt;&lt;a id="consider-remote-opportunities"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Consider Remote Opportunities&lt;/h3&gt;
&lt;p&gt;The rise of remote work has significantly expanded job opportunities. You can now work for companies based in different cities, states, or even countries without having to relocate. This can make job hopping more convenient and less disruptive to your personal life, while also opening up a wider range of potential job opportunities.&lt;/p&gt;
&lt;p&gt;&lt;a id="focus-on-increasing-your-personal-wealth"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Focus on Increasing Your Personal Wealth&lt;/h3&gt;
&lt;p&gt;While loyalty to an employer is important, it's also crucial to focus on your personal financial growth. If changing jobs can help you achieve higher compensation, whether through a higher salary, better benefits, or equity options, then it's a move worth considering. Remember, your primary professional obligation is to your own career development and financial stability.&lt;/p&gt;
&lt;p&gt;&lt;a id="ensure-youre-moving-up-with-each-job-change"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Ensure You're Moving Up With Each Job Change&lt;/h3&gt;
&lt;p&gt;Each job change should represent a step forward in your career. Whether it's a higher role, more responsibilities, or the opportunity to work with new technologies, each move should contribute to your career progression. This upward trajectory can demonstrate to potential employers your ambition, your ability to take on new challenges, and your commitment to professional growth.&lt;/p&gt;
&lt;p&gt;&lt;a id="ask-the-right-questions-during-interviews"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Ask the Right Questions During Interviews&lt;/h3&gt;
&lt;p&gt;When interviewing for a new job, it's important to ask questions that can help you understand the company's culture and whether it aligns with your values and career goals. This can help you avoid accepting a job that isn't a good fit for you. Ask about the company's values, their approach to work-life balance, opportunities for professional development, and their expectations for the role you're applying for. This can give you a clearer picture of what it would be like to work for the company and help you make an informed decision.&lt;/p&gt;
&lt;p&gt;&lt;a id="additional-pieces-of-advice"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Additional pieces of advice&lt;/h2&gt;
&lt;p&gt;&lt;a id="understand-the-impact-of-job-hopping-on-your-resume"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Understand the Impact of Job Hopping on Your Resume&lt;/h3&gt;
&lt;p&gt;It's important to recognize that the perception of frequent job changes can vary across industries. In the tech sector, it's generally accepted and can even be seen as a sign of adaptability and a desire to acquire diverse skills. However, in other industries, it might raise questions about your stability or commitment. Therefore, when crafting your resume and cover letter, tailor them to address any potential concerns. Highlight the skills and experiences you've gained through job hopping and how they've contributed to your professional growth.&lt;/p&gt;
&lt;p&gt;&lt;a id="avoid-short-stints"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Avoid Short Stints&lt;/h3&gt;
&lt;p&gt;While job hopping can offer numerous benefits, extremely short stints (like three to nine months) at multiple companies can raise red flags for potential employers. It might suggest that you struggle to commit to a role or adapt to a new environment. Aim to stay at each job for at least a year, which shows that you can contribute meaningfully to a company and see projects through to completion.&lt;/p&gt;
&lt;p&gt;&lt;a id="use-job-hopping-as-a-negotiation-tool"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Use Job Hopping as a Negotiation Tool&lt;/h3&gt;
&lt;p&gt;Job hopping can serve as a powerful negotiation tool. If you receive a job offer with a higher salary or better benefits from another company, you can use this as leverage to negotiate better terms with your current employer. This strategy can help you maximize your earning potential and benefits without necessarily having to change jobs.&lt;/p&gt;
&lt;p&gt;&lt;a id="consider-the-company-culture"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Consider the Company Culture&lt;/h3&gt;
&lt;p&gt;Before deciding to hop to a new job, take the time to understand the company's culture. If the company values loyalty and long-term commitment, frequent job hopping might be viewed negatively. Conversely, if the company values diverse experiences and skills, job hopping might be seen as a positive attribute. Understanding a company's culture can help you make informed decisions about job hopping.&lt;/p&gt;
&lt;p&gt;&lt;a id="be-transparent-and-honest"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Be Transparent and Honest&lt;/h3&gt;
&lt;p&gt;During interviews, be transparent and honest about your reasons for job hopping. If you're leaving a job due to dissatisfaction, explain your reasons professionally and constructively. This can demonstrate to potential employers that you're thoughtful about your career decisions and are not simply leaving jobs on a whim.&lt;/p&gt;
&lt;p&gt;&lt;a id="keep-learning-and-updating-your-skills"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Keep Learning and Updating Your Skills&lt;/h3&gt;
&lt;p&gt;The tech industry is characterized by rapid and continuous evolution. Therefore, it's crucial to keep learning and updating your skills to stay relevant. This commitment to continuous learning can make you more attractive to potential employers and open up more opportunities for job hopping.&lt;/p&gt;
&lt;p&gt;&lt;a id="maintain-professional-relationships"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Maintain Professional Relationships&lt;/h3&gt;
&lt;p&gt;Even if you change jobs frequently, it's important to maintain positive relationships with your former employers and colleagues. They can provide valuable references in the future and might even offer you new opportunities. Networking is a key aspect of career development, and maintaining these professional relationships can be beneficial in the long run.&lt;/p&gt;
&lt;p&gt;&lt;a id="consider-the-impact-on-your-long-term-career-goals"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Consider the Impact on Your Long-Term Career Goals&lt;/h3&gt;
&lt;p&gt;While job hopping can provide immediate benefits such as higher pay or a more desirable role, it's important to consider how it aligns with your long-term career goals. If a new job offers valuable experience or skills that align with your long-term objectives, it might be worth making the move. Always consider the long-term implications of job hopping on your career trajectory.&lt;/p&gt;
&lt;p&gt;&lt;a id="take-advantage-of-remote-work-opportunities"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Take Advantage of Remote Work Opportunities&lt;/h3&gt;
&lt;p&gt;The rise of remote work has significantly expanded the job market. This means you can job hop without the geographical constraints that traditionally limited job opportunities. This can allow you to access opportunities in different cities, states, or even countries, broadening your career prospects.&lt;/p&gt;
&lt;p&gt;&lt;a id="always-leave-on-good-terms-dont-burn-bridges"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Always Leave on Good Terms, Don't Burn Bridges&lt;/h3&gt;
&lt;p&gt;Regardless of your reasons for leaving a job, always strive to leave on good terms. This includes giving proper notice, completing all outstanding tasks, and offering to assist with the transition. This will help maintain your professional reputation, which is crucial when job hopping. Leaving on good terms also ensures that you leave a positive lasting impression, which can be beneficial for future job opportunities and references. When leaving a job, it's important to maintain positive relationships with your former colleagues and managers. These relationships can be valuable for networking, references, and potential future collaborations. Always leave on good terms, express gratitude for the experience, and keep the lines of communication open.&lt;/p&gt;
&lt;p&gt;&lt;a id="evaluate-the-companys-stability"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Evaluate the Company's Stability&lt;/h3&gt;
&lt;p&gt;Before making a decision to switch jobs, it's crucial to assess the stability of the prospective company. If the company exhibits signs of instability or has a high employee turnover rate, it might not be the best choice for your next move, even if the job offers a higher salary or better benefits. A stable work environment can provide a sense of security and allow for long-term growth and development.&lt;/p&gt;
&lt;p&gt;&lt;a id="consider-the-impact-on-your-work-life-balance"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Consider the Impact on Your Work-Life Balance&lt;/h3&gt;
&lt;p&gt;Job hopping can sometimes disrupt your work-life balance, particularly if you're constantly adapting to new roles, teams, and work environments. When considering a new job, think about how it will affect your personal life, including your family, hobbies, and personal commitments. Ensure that the new job aligns with your work-life balance goals and won't negatively impact your personal life.&lt;/p&gt;
&lt;p&gt;&lt;a id="take-time-to-reflect-on-each-job-change"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Take Time to Reflect on Each Job Change&lt;/h3&gt;
&lt;p&gt;After each job change, take some time to reflect on your experiences. Consider what you learned, what you liked and disliked, and how these experiences can inform your future career decisions. This reflection can help you understand your career preferences, strengths, and areas for improvement, enabling you to make more informed decisions when job hopping.&lt;/p&gt;
&lt;p&gt;&lt;a id="be-prepared-for-potential-negative-perceptions"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Be Prepared for Potential Negative Perceptions&lt;/h3&gt;
&lt;p&gt;While job hopping is more accepted in the tech industry, it may still be viewed negatively by some people. Be prepared to address any potential negative perceptions during interviews. Explain why job hopping has been beneficial for your career, focusing on the diverse skills and experiences you've gained.&lt;/p&gt;
&lt;p&gt;&lt;a id="dont-job-hop-just-for-the-sake-of-it"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Don't Job Hop Just for the Sake of It&lt;/h3&gt;
&lt;p&gt;While job hopping can offer many benefits, it's important not to do it without a clear purpose. Ensure that each job change aligns with your career goals and offers valuable experience or skills. Aimless job hopping can lead to a disjointed career path and may raise red flags for potential employers.&lt;/p&gt;
&lt;p&gt;&lt;a id="consider-the-benefits-and-drawbacks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Consider the Benefits and Drawbacks&lt;/h3&gt;
&lt;p&gt;Before deciding to job hop, weigh the benefits and drawbacks. While job hopping can offer higher salaries, diverse experiences, and faster career progression, it can also lead to instability, a lack of deep expertise in one area, and potential negative perceptions. Make sure that the benefits outweigh the drawbacks before making a move.&lt;/p&gt;
&lt;p&gt;&lt;a id="keep-your-skills-up-to-date"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Keep Your Skills Up to Date&lt;/h3&gt;
&lt;p&gt;In the fast-paced tech industry, keeping your skills up to date is crucial. By continuously learning and adapting to new technologies and trends, you'll be more attractive to potential employers and better equipped to take on new roles. Consider professional development opportunities, online courses, and industry certifications to keep your skills fresh.&lt;/p&gt;
&lt;p&gt;&lt;a id="network-effectively"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Network Effectively&lt;/h3&gt;
&lt;p&gt;Networking is key when job hopping. Maintain your professional relationships and make new connections in the industry. Attend industry events, join professional organizations, and leverage social media platforms like LinkedIn to expand your network. A strong professional network can open up new opportunities and make job hopping easier and more successful.&lt;/p&gt;</content><category term="note"></category><category term="job"></category><category term="job-search"></category><category term="career"></category><category term="job-hop"></category><category term="personal-development"></category><category term="self-growth"></category></entry><entry><title>LangChain RecursiveCharacterTextSplitter - Split by Tokens instead of characters</title><link href="https://www.safjan.com/langchain-recursivecharactertextsplitter-split-by-tokens-instead-of-characters/" rel="alternate"></link><published>2023-09-27T00:00:00+02:00</published><updated>2023-09-27T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-27:/langchain-recursivecharactertextsplitter-split-by-tokens-instead-of-characters/</id><summary type="html">&lt;h1&gt;LangChain RecursiveCharacterTextSplitter - Split by Tokens instead of Characters&lt;/h1&gt;
&lt;p&gt;The LangChain &lt;a href="https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"&gt;RecursiveCharacterTextSplitter&lt;/a&gt; is a tool that allows you to split text on predefined characters that are considered as a potential division points. By default, the size of the chunk is in characters but …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;LangChain RecursiveCharacterTextSplitter - Split by Tokens instead of Characters&lt;/h1&gt;
&lt;p&gt;The LangChain &lt;a href="https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"&gt;RecursiveCharacterTextSplitter&lt;/a&gt; is a tool that allows you to split text on predefined characters that are considered as a potential division points. By default, the size of the chunk is in characters but by using &lt;code&gt;from_tiktoken_encoder()&lt;/code&gt; method you can easily split to achieve given size of the chunk in tokens instead of characters. This is especially useful since LLMs have context limits expressed in tokens not in characters. This split can be useful in various natural language processing tasks, such as language modeling or text classification.&lt;/p&gt;
&lt;p&gt;To use the RecursiveCharacterTextSplitter, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Import the required module: &lt;code&gt;from langchain.text_splitter import RecursiveCharacterTextSplitter&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the desired chunk size (in tokens): &lt;code&gt;CHUNK_SIZE_TOKENS = 1_500&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instantiate the RecursiveCharacterTextSplitter using the &lt;code&gt;from_tiktoken_encoder&lt;/code&gt; method and provide the chunk size and overlap values:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;text_splitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RecursiveCharacterTextSplitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_tiktoken_encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;chunk_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CHUNK_SIZE_TOKENS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;chunk_overlap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Once the text_splitter object is created, you can use the &lt;code&gt;create_documents&lt;/code&gt; method to split your text into documents. Make sure to pass the text to be split as a parameter in a list format:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;docs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text_splitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_documents&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For alternative solutions and further discussion, you can refer to the following GitHub issue: &lt;a href="https://github.com/langchain-ai/langchain/issues/4678#issuecomment-1704305645"&gt;LangChain Issue #4678&lt;/a&gt;.&lt;/p&gt;</content><category term="note"></category><category term="text-splitting"></category><category term="text-chunking"></category><category term="langchain"></category><category term="RecursiveCharacterTextSplitter"></category><category term="Tokens"></category><category term="Characters"></category><category term="natural-language-processing"></category><category term="language-modeling"></category><category term="chunk-size"></category></entry><entry><title>From Fixed-Size to NLP Chunking - A Deep Dive into Text Chunking Techniques</title><link href="https://www.safjan.com/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/" rel="alternate"></link><published>2023-09-11T00:00:00+02:00</published><updated>2023-11-06T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-11:/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/</id><summary type="html">&lt;p&gt;Discover text chunking - the secret sauce behind accurate search results and smarter language models! By understanding how to effectively chunk text, we can improve the way we index documents, handle user queries, and utilize search results. Ready to uncover the secrets of text chunking?&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Understanding Chunking&lt;/h2&gt;
&lt;p&gt;Chunking is a process that aims to embed a piece of content with as little noise as possible while maintaining semantic relevance[^2]. This process is particularly useful in semantic search, where we index a corpus of documents, each containing valuable information on a specific topic.&lt;/p&gt;
&lt;p&gt;An effective chunking strategy ensures that search results accurately capture the essence of a user's query. If our chunks are too small or too large, it may lead to imprecise search results or missed opportunities to surface relevant content. As a &lt;strong&gt;rule of thumb&lt;/strong&gt;, if the &lt;strong&gt;chunk of text makes sense without the surrounding context to a human&lt;/strong&gt;, it will likely make sense to the language model as well[^2]. Therefore, finding the optimal chunk size for the documents in the corpus is crucial to ensuring that the search results are accurate and relevant.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#factors-influencing-chunking-strategy"&gt;Factors Influencing Chunking Strategy&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#size-of-the-texts-to-be-indexed"&gt;Size of the Texts to be Indexed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#length-and-complexity-of-user-queries"&gt;Length and Complexity of User Queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilization-of-the-retrieved-results-in-the-application"&gt;Utilization of the Retrieved Results in the Application&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#chunking-methods"&gt;Chunking Methods&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#fixed-size-in-characters-overlapping-sliding-window"&gt;Fixed-size (in characters) Overlapping Sliding Window&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fixed-size-in-tokens-overlapping-sliding-window"&gt;Fixed-size (in tokens) Overlapping Sliding Window&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recursive-structure-aware-splitting"&gt;Recursive Structure Aware Splitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#structure-aware-splitting-by-sentence-paragraph-section-chapter"&gt;Structure Aware Splitting (by Sentence, Paragraph, Section, Chapter)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#nlp-chunking-tracking-topic-changes"&gt;NLP Chunking: Tracking Topic Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#content-aware-splitting-markdown-latex-html"&gt;Content-Aware Splitting (Markdown, LaTeX, HTML)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#adding-extra-context-to-the-chunk-metadata-summaries"&gt;Adding Extra Context to the Chunk (metadata, summaries)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#further-reading"&gt;Further Reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="factors-influencing-chunking-strategy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Factors Influencing Chunking Strategy&lt;/h2&gt;
&lt;p&gt;There are three main factors to consider when determining a chunking strategy for a specific use case and application:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The size of the texts to be indexed and chunked&lt;/li&gt;
&lt;li&gt;The length and complexity of user queries&lt;/li&gt;
&lt;li&gt;The utilization of the retrieved results in the application&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="size-of-the-texts-to-be-indexed"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Size of the Texts to be Indexed&lt;/h3&gt;
&lt;p&gt;The chunking unit and size should be adjusted according to the nature of the text. The chunk should be long enough to contain the relevant semantic load. For instance, individual words may not convey a specific message or piece of information, while putting an entire encyclopedia in one chunk may result in a chunk that is "about everything."&lt;/p&gt;
&lt;p&gt;&lt;a id="length-and-complexity-of-user-queries"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Length and Complexity of User Queries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Longer queries&lt;/strong&gt; or those with greater complexity typically &lt;strong&gt;benefit from a smaller chunk length&lt;/strong&gt;. This helps to narrow down the search space and improve the precision of the search results. Smaller chunks allow more focused matching against embeddings, reducing the impact of irrelevant parts within the query.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shorter and simpler queries&lt;/strong&gt; might not require chunking at all, as they can be processed as a single unit. Chunking may introduce unnecessary overhead in these cases, potentially hampering search performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="utilization-of-the-retrieved-results-in-the-application"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Utilization of the Retrieved Results in the Application&lt;/h3&gt;
&lt;p&gt;In cases where search results are only an intermediate step in the whole chain in the app, the size of the chunk might have significant importance for the seamless operation of the application. For example, if results from multiple search queries are the input context for the prompt to the LLM, having small chunks might ease fitting all inputs in the maximum allowed context size for a given LLM. Conversely, if the search result is presented to the user, larger chunks may be more appropriate.&lt;/p&gt;
&lt;p&gt;&lt;a id="chunking-methods"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Chunking Methods&lt;/h2&gt;
&lt;p&gt;There are several methods for chunking text, each with its own advantages and disadvantages. The choice of method depends on the specific requirements of the use case and application.&lt;/p&gt;
&lt;p&gt;&lt;a id="fixed-size-in-characters-overlapping-sliding-window"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Fixed-size (in characters) Overlapping Sliding Window&lt;/h3&gt;
&lt;p&gt;The Fixed-size overlapping sliding window method is a naive approach to text chunking, dividing the text into fixed-size pieces regarded as chunks. In this method, the text is divided based on the count of characters, making it straightforward to implement. The use of overlap in this method aids in preserving the integrity of sentences or thoughts, ensuring they are not cut in the middle. If one window truncates a thought, another window might contain the complete thought.&lt;/p&gt;
&lt;p&gt;However, this method presents certain limitations. One significant drawback is the lack of precise control over the context size. Most language models operate on the basis of tokens rather than characters or words, making this method less efficient. The strict and fixed-size nature of the window might also result in severing words, sentences, or paragraphs in the middle, which could impede comprehension and disrupt the flow of information.&lt;/p&gt;
&lt;p&gt;Furthermore, this method does not take semantics into account, providing no guarantee that the semantic unit of the text capturing a given idea or thought will be accurately encapsulated within a chunk. Consequently, one chunk may not be semantically distinct from another.&lt;/p&gt;
&lt;h4&gt;Use Cases&lt;/h4&gt;
&lt;p&gt;The Fixed-size overlapping sliding window method can be beneficial in certain scenarios. It is especially useful in preliminary exploratory data analysis, where the goal is to obtain a general understanding of the text structure rather than a deep semantic analysis. Additionally, it could be employed in scenarios where the text data does not have a strong semantic structure, such as in certain types of raw data or logs.&lt;/p&gt;
&lt;p&gt;However, for tasks that require semantic understanding and precise context, such as sentiment analysis, question-answering systems, or text summarization, more sophisticated text chunking methods would be more appropriate.&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Counting characters makes implementation easy&lt;/li&gt;
&lt;li&gt;Using overlap helps to avoid having sentences or thoughts cut in the middle - if one window is cutting the thought, perhaps another will have it in one piece.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not precise control of the context size - models work and size the text in tokens not in characters or words&lt;/li&gt;
&lt;li&gt;Having a strict, fixed-size window might lead to cutting words, sentences, or paragraphs in the middle.&lt;/li&gt;
&lt;li&gt;Doesn't take semantics into account, no guarantee that the semantic unit of text capturing the given idea, thought will be accurately captured in the chunk and another chunk will be dedicated to another idea&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preliminary exploratory data analysis where a general understanding of the text is required&lt;/li&gt;
&lt;li&gt;Scenarios where the text does not have a strong semantic structure, such as certain types of raw data or logs&lt;/li&gt;
&lt;li&gt;Not recommended for tasks requiring semantic understanding and precise contexts like sentiment analysis, question-answering systems, or text summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="fixed-size-in-tokens-overlapping-sliding-window"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Fixed-size (in tokens) Overlapping Sliding Window&lt;/h3&gt;
&lt;p&gt;The Fixed-size sliding window method in tokens is another approach to text chunking. Unlike the character-based method, this approach divides the text into chunks based on the count of tokens that came out from the tokenizer, making it more aligned with the way language models operate.&lt;/p&gt;
&lt;p&gt;In this method, the size of the context is more precisely controlled as it works on tokens rather than characters. A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This can make avoiding cutting words in the middle a little better than when counting characters, but the problem still persists. It can still sever sentences or thoughts in the middle, which could disrupt the flow of information. Moreover, similar to the character-based method, this approach does not take semantics into account. There's no guarantee that a chunk accurately captures a unique thought or idea, making the chunks potentially semantically inconsistent.&lt;/p&gt;
&lt;h4&gt;Where to Use It&lt;/h4&gt;
&lt;p&gt;The use cases are similar to the fixed size window based on characters count with one difference - when the count is based on tokens it works better for the tasks where we are limited by the LLM context size.&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More precise control over LLM context size as it operates on tokens, not characters.&lt;/li&gt;
&lt;li&gt;Still, relatively easy to implement&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can still sever sentences or thoughts in the middle&lt;/li&gt;
&lt;li&gt;Does not take semantics into account, hence no guarantee that a chunk accurately captures a unique thought or idea&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For exploratory, initial work with LLMs&lt;/li&gt;
&lt;li&gt;Not recommended for tasks requiring a deep understanding of the semantics and context of the text, like sentiment analysis or text summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="recursive-structure-aware-splitting"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Recursive Structure Aware Splitting&lt;/h3&gt;
&lt;p&gt;Recursive Structure-aware Aware Splitting is a hybrid approach to text chunking, combining elements of the fixed-size sliding window method and the structure-aware splitting method. This method attempts to create chunks of approximately fixed sizes, either in characters or tokens, while also trying to preserve the original units of text such as words, sentences, or paragraphs.&lt;/p&gt;
&lt;p&gt;In this method, the text is recursively split using various separators such as paragraph breaks ("\n\n"), new lines ("\n"), or spaces (" "), moving to the next level of granularity only when necessary. This allows the method to balance the need for a fixed chunk size with the desire to respect the natural linguistic boundaries of the text.&lt;/p&gt;
&lt;p&gt;The major advantage of this method is its flexibility. It provides more precise control over context size compared to fixed-size methods, while also ensuring that semantic units of text are not unnecessarily severed.&lt;/p&gt;
&lt;p&gt;However, this method also has its drawbacks. The complexity of implementation is higher due to the recursive nature of the splitting. There's also the risk of ending up with chunks of highly variable sizes, especially with texts of varying structural complexity.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: &lt;a href="https://www.langchain.com/"&gt;LangChain&lt;/a&gt; has an implementation of &lt;a href="https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"&gt;Recursively split&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Where to Use It&lt;/h4&gt;
&lt;p&gt;Recursive Structure Aware Splitting is particularly useful in tasks where both the granularity of tokens and the preservation of semantic integrity are crucial. This includes tasks such as text summarization, sentiment analysis, and document classification.&lt;/p&gt;
&lt;p&gt;However, due to its complexity, it might not be the best fit for tasks that require quick and simple text chunking, or for tasks involving texts with inconsistent or unclear structural divisions.&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Balances the need for fixed chunk sizes with the preservation of natural linguistic boundaries&lt;/li&gt;
&lt;li&gt;Provides more precise control over the context size&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Higher complexity of implementation due to the recursive nature of the splitting&lt;/li&gt;
&lt;li&gt;Risk of ending up with chunks of highly variable sizes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Useful in tasks where both the granularity of tokens and the preservation of semantic integrity are crucial, such as text summarization, sentiment analysis, and document classification&lt;/li&gt;
&lt;li&gt;Not recommended for tasks requiring quick and simple text chunking, or tasks involving texts with inconsistent or unclear structural divisions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="structure-aware-splitting-by-sentence-paragraph-section-chapter"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Structure Aware Splitting (by Sentence, Paragraph, Section, Chapter)&lt;/h3&gt;
&lt;p&gt;Structure Aware Splitting is an advanced approach to text chunking, which takes into account the inherent structure of the text. Instead of using a fixed-size window, this method divides the text into chunks based on its natural divisions such as sentences, paragraphs, sections, or chapters.&lt;/p&gt;
&lt;p&gt;This method is particularly beneficial as it respects the natural linguistic boundaries of the text, ensuring that words, sentences, and thoughts are not cut in the middle. This aids in preserving the semantic integrity of the information within each chunk.&lt;/p&gt;
&lt;p&gt;However, this method does have certain limitations. Handling text of varying structural complexity might be challenging. For instance, some texts might not have clearly defined sections or chapters, e.g. text extracted from the OCR output, unformatted speech-to-text outputs, text extracted from tables. Also, while it's more semantically aware than the fixed-size methods, it still doesn't guarantee perfect semantic consistency within chunks, especially for larger structural units like sections or chapters.&lt;/p&gt;
&lt;h4&gt;Where to Use It&lt;/h4&gt;
&lt;p&gt;Structure Aware Splitting is highly effective for tasks that require a good understanding of the context and semantics of the text. It is particularly useful for text summarization, sentiment analysis, and document classification tasks.&lt;/p&gt;
&lt;p&gt;However, it might not be the best fit for tasks involving texts that lack defined structural divisions, or for tasks that require a finer granularity, such as word-level Named Entity Recognition (NER).&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Respects natural linguistic boundaries, avoiding severing words, sentences, or thoughts&lt;/li&gt;
&lt;li&gt;Preserves the semantic integrity of information within each chunk&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Challenging to handle text with varying structural complexity&lt;/li&gt;
&lt;li&gt;Does not guarantee perfect semantic consistency within chunks, especially for larger structural units&lt;/li&gt;
&lt;li&gt;We don't have control over chunk size. Chunks from given document might significantly vary in the size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Effective for tasks requiring good understanding of context and semantics, such as text summarization, sentiment analysis, and document classification&lt;/li&gt;
&lt;li&gt;Not recommended for tasks involving texts that lack defined structural divisions, or tasks needing finer granularity, like word-level NER&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="nlp-chunking-tracking-topic-changes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;NLP Chunking: Tracking Topic Changes&lt;/h3&gt;
&lt;p&gt;NLP Chunking with Topic Tracking is a sophisticated approach to text chunking. This method divides the text into chunks based on semantic understanding, specifically by detecting significant shifts in the topics of sentences. If the topic of a sentence significantly differs from the topic of the previous chunk, this sentence is considered the beginning of a new chunk.&lt;/p&gt;
&lt;p&gt;This method has the distinct advantage of maintaining semantic consistency within each chunk. By tracking the changes in topics, this method ensures that each chunk is semantically distinct from the others, thereby capturing the inherent structure and meaning of the text.&lt;/p&gt;
&lt;p&gt;However, this method is not without its challenges. It requires advanced NLP techniques to accurately detect topic shifts, which adds to the complexity of implementation. Additionally, the accuracy of chunking heavily depends on the effectiveness of the topic modeling and detection techniques used.&lt;/p&gt;
&lt;h4&gt;Where to Use It&lt;/h4&gt;
&lt;p&gt;NLP Chunking with Topic Tracking is highly effective for tasks that require an understanding of the semantic context and topic continuity. It is particularly useful for text summarization, sentiment analysis, and document classification tasks.&lt;/p&gt;
&lt;p&gt;This method might not be the best fit for tasks involving texts that have a high degree of topic overlap or for tasks that require simple text chunking without the need for deep semantic understanding.&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maintains semantic consistency within each chunk&lt;/li&gt;
&lt;li&gt;Captures the inherent structure and meaning of the text by tracking topic changes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires advanced NLP techniques, increasing the complexity of implementation&lt;/li&gt;
&lt;li&gt;The accuracy of chunking heavily depends on the effectiveness of the topic modeling and detection techniques used&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Highly effective for tasks requiring semantic context and topic continuity, such as text summarization, sentiment analysis, and document classification&lt;/li&gt;
&lt;li&gt;Not recommended for tasks involving texts with high degrees of topic overlap or tasks requiring simple text chunking without the need for deep semantic understanding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="content-aware-splitting-markdown-latex-html"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Content-Aware Splitting (Markdown, LaTeX, HTML)&lt;/h3&gt;
&lt;p&gt;Content-Aware Splitting is a method of text chunking that focuses on the type and structure of the content, particularly in structured documents like those written in Markdown, LaTeX, or HTML. This method identifies and respects the inherent structure and divisions of the content, such as headings, code blocks, and tables, to create distinct chunks.&lt;/p&gt;
&lt;p&gt;The primary advantage of this method is that it ensures different types of content are not mixed within a single chunk. For instance, a chunk containing a code block will not also contain a part of a table. This helps maintain the integrity and context of the content within each chunk.&lt;/p&gt;
&lt;p&gt;However, this method also presents certain challenges. It requires understanding and parsing the specific syntax of the structured document format, which can increase the complexity of implementation. Moreover, it might not be suitable for documents that lack clear structural divisions or those written in plain text without any specific format.&lt;/p&gt;
&lt;h4&gt;Where to Use It&lt;/h4&gt;
&lt;p&gt;Content Aware Splitting is especially useful when dealing with structured documents or content with clear formatting, such as technical documentation, academic papers, or web pages. It helps ensure that the chunks created are meaningful and contextually consistent.&lt;/p&gt;
&lt;p&gt;However, this method might not be the best fit for unstructured or plain text documents, or for tasks that do not require a deep understanding of the content structure.&lt;/p&gt;
&lt;h4&gt;Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensures different types of content are not mixed within a single chunk&lt;/li&gt;
&lt;li&gt;Respects and maintains the integrity and context of the content within each chunk&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires understanding and parsing the specific syntax of the structured document format&lt;/li&gt;
&lt;li&gt;Might not be suitable for unstructured or plain text documents&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Where to Use It:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Particularly useful for structured documents or content with clear formatting, such as technical documentation, academic papers, or web pages&lt;/li&gt;
&lt;li&gt;Not recommended for unstructured or plain text documents, or tasks that do not require a deep understanding of the content structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="adding-extra-context-to-the-chunk-metadata-summaries"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Adding Extra Context to the Chunk (metadata, summaries)&lt;/h3&gt;
&lt;p&gt;Adding extra context to the chunks in the form of metadata or summaries can significantly enhance the value of each chunk and improve the overall understanding of the text[^3]. Here are two strategies:&lt;/p&gt;
&lt;h4&gt;Adding Metadata to Each Chunk&lt;/h4&gt;
&lt;p&gt;This strategy involves adding relevant metadata to each chunk. Metadata could include information such as the source of the text, the author, the date of publication, or even data about the content of the chunk itself, like its topic or keywords. This extra context can provide valuable insights and make the chunks more meaningful and easier to analyze.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: In the case of the chunks that are vectorized using text embeddings,  be aware, that vector databases typically allow storage of metadata alongside the embedding vectors.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provides additional information about each chunk&lt;/li&gt;
&lt;li&gt;Enhances the value of each chunk, making them more meaningful and easier to analyze&lt;/li&gt;
&lt;li&gt;Can help to produce more effective embeddings by fixing the broader context for the chunk.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires additional processing to generate and attach the metadata&lt;/li&gt;
&lt;li&gt;The usefulness of the metadata depends on its relevance and accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Where to Use It:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Especially useful in tasks that involve analyzing the origin, authorship, or content of the chunks, such as text classification, document clustering, or information retrieval&lt;/li&gt;
&lt;li&gt;Can be used to filter the sources used to provide context to LLMs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can get intuition what is possible by reading llama_index documentation on metadata extraction and usage: &lt;a href="https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor.html"&gt;Metadata Extraction Usage Pattern - LlamaIndex 🦙 0.9.30&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Passing on Chunk Summaries&lt;/h4&gt;
&lt;p&gt;In this strategy, each chunk is summarized, and that summary is passed on to the next chunk. This method provides a 'running context' that can enhance the understanding of the text and maintain the continuity of information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Enhances the understanding of the text by maintaining a running context&lt;/li&gt;
&lt;li&gt;Helps to ensure the continuity of information across chunks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requires advanced NLP techniques to generate accurate and meaningful summaries&lt;/li&gt;
&lt;li&gt;The effectiveness of this method depends on the quality of the summaries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Where to Use It:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Particularly useful in tasks where understanding the continuity and context of the text is crucial, such as text summarization or reading comprehension tasks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Other Experimental Strategies for Adding Context to the Chunks&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Keyword Tagging:&lt;/strong&gt; This method involves identifying and tagging the most important keywords or phrases in each chunk. These tags then serve as a quick reference or summary of the chunk's content. Advanced NLP techniques can be used to identify these keywords based on their relevance and frequency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sentiment Analysis:&lt;/strong&gt; For text that contains opinions or reviews, performing sentiment analysis on each chunk and attaching the sentiment score (positive, negative, neutral) as metadata can provide valuable context. This can be particularly useful in tasks such as customer feedback analysis or social media monitoring.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Entity Recognition:&lt;/strong&gt; Applying Named Entity Recognition (NER) techniques to each chunk can identify and label entities such as names of people, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. This entity information can be added to each chunk, providing valuable context, especially in tasks like information extraction or knowledge graph construction.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Topic Classification:&lt;/strong&gt; Each chunk can be classified into one or more topics using machine learning or NLP techniques. This topic label can provide a quick understanding of what each chunk is about, adding valuable context, especially for tasks like document classification or recommendation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chunk Linking:&lt;/strong&gt; This method involves creating links between related chunks based on shared keywords, entities, or topics. These links can provide a 'map' of the content, showing how different chunks relate to each other. This can be particularly useful in tasks involving large and complex texts, where understanding the overall structure and relations between different parts is important.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;In the field of Natural Language Processing, text chunking emerges as a powerful technique that significantly enhances the performance of semantic search and language models. By breaking down text into manageable, contextually relevant chunks, we can ensure more accurate and meaningful search results.&lt;/p&gt;
&lt;p&gt;The choice of chunking method, whether it's fixed-size, structure-aware, or NLP chunking, depends on the specific requirements of the use case and application. Each method has its own strengths and limitations, and understanding these is crucial to implementing an effective chunking strategy.&lt;/p&gt;
&lt;p&gt;Moreover, adding extra context to the chunks, such as metadata or summaries, can further enhance the value of each chunk and improve the overall understanding of the text. Experimental strategies like keyword tagging, sentiment analysis, entity recognition, topic classification, and chunk linking offer promising avenues for further exploration.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;
&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[^1] &lt;a href="https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/"&gt;Create a CustomGPT And Supercharge your Company with AI  -  Pick the Best LLM - The Abacus.AI Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[^2] &lt;a href="https://www.pinecone.io/learn/chunking-strategies/"&gt;Chunking Strategies for LLM Applications | Pinecone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[^3] &lt;a href="https://actalyst.medium.com/optimize-llm-enterprise-applications-through-embeddings-and-chunking-strategy-1bbdb03bedae"&gt;Optimize LLM Enterprise Applications through Embeddings and Chunking Strategy. | by Actalyst | Aug, 2023 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[^4] &lt;a href="https://vectara.com/grounded-generation-done-right-chunking/"&gt;Retrieval Augmented Generation (RAG) Done Right: Chunking - Vectara&lt;/a&gt; (NLP chunking, compare chunking strategies) + &lt;a href="https://github.com/vectara/example-notebooks/blob/main/notebooks/chunking-demo.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="further-reading"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/aimonks/simple-guide-to-text-chunking-for-your-llm-applications-bddfe8ad7892"&gt;Simple guide to Text Chunking for Your LLM Applications | by NoCode AI | 𝐀𝐈 𝐦𝐨𝐧𝐤𝐬.𝐢𝐨 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2307.03172"&gt;[2307.03172] Lost in the Middle: How Language Models Use Long Contexts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://community.openai.com/t/the-length-of-the-embedding-contents/111471"&gt;The length of the embedding contents - API - OpenAI Developer Forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1"&gt;Building RAG-based LLM Applications for Production (Part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;expanding context, hierarchical search, ...: &lt;a href="https://reframe.is/wiki/Effects-of-Chunk-Sizes-on-Retrieval-Augmented-Generation-RAG-Applications-8b728c36d005434dba39ad19be9b82cc/"&gt;Effects of Chunk Sizes on Retrieval Augmented Generation (RAG) Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.acm.org/doi/10.1007/s10579-013-9250-3"&gt;A novel method for performance evaluation of text chunking | Language Resources and Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.mattambrogi.com/posts/chunk-size-matters/"&gt;Matt Ambrogi&lt;/a&gt; "Chunk Size Matters"&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5"&gt;Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex | by Ravi Theja | Oct, 2023 | LlamaIndex Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;short (4min 25s) overview of chunking methods from Weaviate: &lt;a href="https://www.youtube.com/watch?v=h5id4erwD4s"&gt;Chunking Methods to use Custom Data with LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=8OJC21T2SL4"&gt;The 5 Levels Of Text Splitting For Retrieval - YouTube&lt;/a&gt; (Fixed Size Chunking,  Recursive Chunking, Document Based Chunking, &lt;strong&gt;Semantic Chunking&lt;/strong&gt;, Agentic Chunking - chunking strategy that explore the possibility to use LLM to determine how much and what text should be included in a chunk based on the context.) + &lt;a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb"&gt;notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Visualization of chunking - &lt;a href="https://chunkviz.up.railway.app/"&gt;ChunkViz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.blog/2024/06/06/breaking-up-is-hard-to-do-chunking-in-rag-applications/"&gt;Breaking up is hard to do: Chunking in RAG applications - Stack Overflow&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;size matters: “You are going to compare that with an embedding of your content. If the size of the content that you're embedding is wildly different from the size of the user's query, you're going to have a higher chance of getting a lower similarity score.”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2023-11-06: Added reference: Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex&lt;/li&gt;
&lt;li&gt;2023-11-13: Added video from Weaviate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/"&gt;From Fixed-Size to NLP Chunking - A Deep Dive into Text Chunking Techniques&lt;/a&gt;&lt;/p&gt;</content><category term="Machine Learning"></category><category term="chunking"></category><category term="text-processing"></category><category term="nlp"></category><category term="semantic-search"></category><category term="language-models"></category><category term="fixed-size-chunking"></category><category term="recursive-structure-aware-splitting"></category><category term="structure-aware-splitting"></category><category term="nlp-chunking"></category><category term="content-aware-splitting"></category><category term="metadata"></category><category term="summaries"></category><category term="keyword-tagging"></category><category term="sentiment-analysis"></category><category term="entity-recognition"></category><category term="topic-classification"></category><category term="chunk-linking"></category><category term="llm"></category><category term="rag"></category></entry><entry><title>Criticism of the Lean Startup</title><link href="https://www.safjan.com/criticism-of-the-lean-startup/" rel="alternate"></link><published>2023-09-04T00:00:00+02:00</published><updated>2023-11-07T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-04:/criticism-of-the-lean-startup/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Lean Startup method is still considered a valuable and relevant approach to launching and managing startups. However, it's important to recognize that the business and entrepreneurial landscape is dynamic, and the applicability of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Lean Startup method is still considered a valuable and relevant approach to launching and managing startups. However, it's important to recognize that the business and entrepreneurial landscape is dynamic, and the applicability of any methodology can evolve over time.&lt;/p&gt;
&lt;p&gt;The Lean Startup method, popularized by Eric Ries, emphasizes a systematic and iterative approach to building and scaling a startup by validating assumptions, minimizing waste, and staying agile. Many principles of the Lean Startup, such as customer-centricity, rapid experimentation, and continuous learning, remain highly relevant in today's business environment.&lt;/p&gt;
&lt;p&gt;However, there are some criticisms and challenges associated with the Lean Startup method, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Oversimplification&lt;/strong&gt;: Critics argue that the Lean Startup method can sometimes oversimplify the complexity of building a successful business. While it encourages rapid experimentation, it may not address all the intricacies and industry-specific nuances that startups may encounter.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overemphasis on MVP (Minimum Viable Product)&lt;/strong&gt;: Some argue that an overemphasis on building MVPs can lead to premature scaling or neglecting long-term vision and product quality. In some industries, especially those requiring substantial upfront investment or regulatory compliance, an MVP might not be appropriate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bias Toward Tech Startups&lt;/strong&gt;: The Lean Startup method was initially designed with tech startups in mind and may not be as applicable to businesses in other industries, such as healthcare, biotech, or manufacturing, which have longer development cycles and higher regulatory barriers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Market Saturation&lt;/strong&gt;: In some markets, especially in technology hubs like Silicon Valley, there's a concern that the Lean Startup method has led to an oversaturation of similar ideas and startups, making it more challenging for any single company to stand out.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Evolving Landscape&lt;/strong&gt;: As technology and business landscapes evolve, new methodologies and approaches may emerge that complement or surpass the Lean Startup method. For example, concepts like &lt;a href="https://www.safjan.com/design-thinking/"&gt;Design Thinking&lt;/a&gt;, &lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt; and &lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt; have gained traction in recent years.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To assess the current validity and relevance of the Lean Startup method, it's essential to consider the specific context, industry, and maturity of your startup. While the core principles of customer-centricity, iteration, and learning remain valuable, startups should also be open to adapting and combining methodologies based on their unique circumstances and challenges. Additionally, staying updated with the latest trends and methodologies in entrepreneurship is crucial to making informed decisions.&lt;/p&gt;</content><category term="note"></category><category term="lean"></category><category term="lean-startup"></category><category term="methodology"></category><category term="startup"></category></entry><entry><title>Design Thinking</title><link href="https://www.safjan.com/design-thinking/" rel="alternate"></link><published>2023-09-04T00:00:00+02:00</published><updated>2023-11-07T00:00:00+01:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-04:/design-thinking/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/criticism-of-the-lean-startup/"&gt;Criticism of the Lean Startup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Design thinking is a human-centered and problem-solving approach to innovation and product development that has gained significant traction in the business world in recent years. It places a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/criticism-of-the-lean-startup/"&gt;Criticism of the Lean Startup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/growth-hacking-methodology/"&gt;Growth Hacking Methodology&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/product-led-growth/"&gt;Product Led Growth&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Design thinking is a human-centered and problem-solving approach to innovation and product development that has gained significant traction in the business world in recent years. It places a strong emphasis on empathy, creativity, and iterative processes to tackle complex problems and create user-centric solutions. Here's a comprehensive exploration of design thinking in the context of business and product development:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Design Thinking:&lt;/strong&gt; Design thinking is a methodology that originated in the world of design but has since transcended its origins to become a widely adopted approach in various industries, including technology, healthcare, finance, and more. At its core, design thinking is about understanding and addressing the needs of users or customers by fostering a deep sense of empathy, engaging in creative problem-solving, and iterating on solutions to continuously improve them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key Principles of Design Thinking:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Empathy:&lt;/strong&gt; Design thinking starts with empathizing with the end-users or customers to gain a deep understanding of their needs, desires, and pain points. This empathetic approach helps teams uncover insights that might not be apparent through traditional data analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Define:&lt;/strong&gt; Once user needs are understood, the next step is to define the problem clearly and succinctly. This step involves synthesizing the information gathered during the empathy phase to create a user-centered problem statement.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ideate:&lt;/strong&gt; In this phase, teams brainstorm and generate a wide range of potential solutions without judgment. It's a creative and often collaborative process that encourages thinking outside the box.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prototype:&lt;/strong&gt; Prototyping involves creating low-fidelity representations of the proposed solutions. These prototypes can be anything from simple sketches to interactive mock-ups, depending on the context. The goal is to quickly visualize and test ideas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Test:&lt;/strong&gt; The testing phase involves gathering feedback from users by exposing them to the prototypes. This feedback loop allows teams to refine and improve their solutions based on real-world insights.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Benefits of Design Thinking in Business/Product Development:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;User-Centric Innovation:&lt;/strong&gt; Design thinking places the user at the center of the development process, leading to products and services that genuinely meet user needs and preferences.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enhanced Creativity:&lt;/strong&gt; By encouraging ideation without constraints in the early stages, design thinking fosters creative thinking, which can lead to breakthrough solutions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reduced Risk:&lt;/strong&gt; Iterative testing and prototyping help identify and address issues early in the development process, reducing the risk of costly mistakes later on.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Improved Collaboration:&lt;/strong&gt; Design thinking often involves cross-functional teams collaborating to solve problems, breaking down silos and fostering a culture of cooperation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adaptability:&lt;/strong&gt; The iterative nature of design thinking allows businesses to adapt to changing circumstances and emerging trends more effectively.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Real-World Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Numerous successful companies have embraced design thinking to drive innovation and improve their products and services. For instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Apple:&lt;/strong&gt; Apple is renowned for its commitment to user-centric design. Products like the iPhone and MacBook exemplify how design thinking has been instrumental in creating highly intuitive and visually appealing devices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IBM:&lt;/strong&gt; IBM's design thinking transformation has led to the creation of IBM Design Studios, which apply design thinking principles to a wide range of projects, from software development to organizational strategy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Airbnb:&lt;/strong&gt; Airbnb uses design thinking to create memorable experiences for its users. The platform continuously iterates on its website and app to enhance user satisfaction.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In today's fast-paced and ever-changing business landscape, design thinking offers a structured yet flexible approach to innovation and problem-solving. By prioritizing empathy, creativity, and iterative development, organizations can create products and services that resonate with users, drive growth, and stay adaptable in an increasingly competitive marketplace. As design thinking continues to evolve, it remains a valuable methodology for businesses seeking to stay customer-focused and innovative.&lt;/p&gt;</content><category term="note"></category><category term="startup"></category><category term="design-thinking"></category><category term="methodology"></category></entry><entry><title>Problems with Langchain and how to minimize their impact</title><link href="https://www.safjan.com/problems-with-Langchain-and-how-to-minimize-their-impact/" rel="alternate"></link><published>2023-09-01T00:00:00+02:00</published><updated>2023-10-19T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-09-01:/problems-with-Langchain-and-how-to-minimize-their-impact/</id><summary type="html">&lt;p&gt;Beyond the Hype - LangChain's Hidden Flaws and How to Master AI Development.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://docs.langchain.com/docs/"&gt;LangChain&lt;/a&gt;, a popular framework for building applications with &lt;a href="https://en.wikipedia.org/wiki/Large_language_model"&gt;large language models&lt;/a&gt; (LLMs), has been touted as a game-changer in the world of AI-driven development. However, as more users dive into the library and its capabilities, some have found that it falls short of expectations. In this section, we'll discuss ten issues with LangChain that have left users underwhelmed and questioning its value proposition.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#problems"&gt;Problems&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#1-overly-complex-and-unnecessary-abstractions"&gt;1. Overly complex and unnecessary abstractions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-easy-breakable-and-unreliable"&gt;2. Easy breakable and unreliable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-poor-documentation"&gt;3. Poor documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4-a-high-level-of-abstraction-hinders-customization"&gt;4. A high level of abstraction hinders customization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5-inefficient-token-usage"&gt;5. Inefficient token usage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6-difficult-integration-with-existing-tools"&gt;6. Difficult integration with existing tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7-limited-value-proposition"&gt;7. Limited value proposition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-inconsistent-behavior-and-hidden-details"&gt;8. Inconsistent behavior and hidden details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#9-better-alternatives-available"&gt;9. Better alternatives available&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-primarily-optimized-for-demos"&gt;10. Primarily optimized for demos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#takeaways---how-to-use-the-langchain-right-way"&gt;Takeaways - How to Use the LangChain Right Way?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="problems"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Problems&lt;/h2&gt;
&lt;p&gt;&lt;a id="1-overly-complex-and-unnecessary-abstractions"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;1. Overly complex and unnecessary abstractions&lt;/h3&gt;
&lt;p&gt;LangChain has been criticized for having too many layers of abstraction, making it difficult to understand and modify the underlying code. These layers can lead to confusion, especially for those who are new to LLMs or LangChain itself. The complexity can also make it challenging to adapt the library to specific use cases or integrate it with existing tools and scripts. In some cases, users have found that they can achieve their goals more easily by using simpler, more straightforward code.&lt;/p&gt;
&lt;p&gt;&lt;a id="2-easy-breakable-and-unreliable"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2. Easy breakable and unreliable&lt;/h3&gt;
&lt;p&gt;Some users have found LangChain to be unreliable and difficult to fix due to its complex structure. The framework's fragility can lead to unexpected issues in production systems, making it challenging to maintain and scale applications built with LangChain. Users have reported that the deeper and more complex their application becomes, the more LangChain seems to become a risk to its maintainability.&lt;/p&gt;
&lt;p&gt;&lt;a id="3-poor-documentation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;3. Poor documentation&lt;/h3&gt;
&lt;p&gt;LangChain's documentation has been described as confusing and lacking in key details, making it challenging for users to fully understand the library's capabilities and limitations. The documentation often omits explanations of default parameters and important details, leaving users to piece together information from various sources. This lack of clarity can hinder users' ability to effectively leverage LangChain in their projects.&lt;/p&gt;
&lt;p&gt;&lt;a id="4-a-high-level-of-abstraction-hinders-customization"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;4. A high level of abstraction hinders customization&lt;/h3&gt;
&lt;p&gt;Users have reported that LangChain's high level of abstraction makes it difficult to modify and adapt the library for specific use cases. This can be particularly problematic when users want to make small changes to the default behavior of LangChain or integrate it with other tools and scripts. In these cases, users may find it easier to bypass LangChain altogether and build their own solutions from scratch.&lt;/p&gt;
&lt;p&gt;&lt;a id="5-inefficient-token-usage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;5. Inefficient token usage&lt;/h3&gt;
&lt;p&gt;LangChain has been criticized for inefficient token usage in its API calls, which can result in higher costs. This can be particularly problematic for users who are trying to minimize their expenses while working with LLMs. Some users have found that they can achieve better results with fewer tokens by using custom Python code or other alternative libraries.&lt;/p&gt;
&lt;p&gt;&lt;a id="6-difficult-integration-with-existing-tools"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;6. Difficult integration with existing tools&lt;/h3&gt;
&lt;p&gt;Users have reported difficulties integrating LangChain with their existing Python tools and scripts. This can be especially challenging for those who have complex analytics or other advanced functionality built into their applications. The high level of abstraction in LangChain can make it difficult to interface with these existing tools, forcing users to build workarounds or abandon LangChain in favor of more compatible solutions.&lt;/p&gt;
&lt;p&gt;&lt;a id="7-limited-value-proposition"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;7. Limited value proposition&lt;/h3&gt;
&lt;p&gt;Some users feel that LangChain does not provide enough value compared to the effort required to implement and maintain it. They argue that the library's primary use case is to quickly create demos or prototypes, rather than building production-ready applications. In these cases, users may find it more efficient to build their own solutions or explore alternative libraries that offer a better balance of ease of use and functionality.&lt;/p&gt;
&lt;p&gt;&lt;a id="8-inconsistent-behavior-and-hidden-details"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;8. Inconsistent behavior and hidden details&lt;/h3&gt;
&lt;p&gt;LangChain has been criticized for hiding important details and having inconsistent behavior, which can lead to unexpected issues in production systems. Users have reported that LangChain's default settings and behaviors are often undocumented or poorly explained, making it difficult to predict how the library will behave in different scenarios. This lack of transparency can lead to frustration and wasted time troubleshooting issues that could have been avoided with better documentation.&lt;/p&gt;
&lt;p&gt;&lt;a id="9-better-alternatives-available"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;9. Better alternatives available&lt;/h3&gt;
&lt;p&gt;Users have mentioned other libraries, such as &lt;a href="https://github.com/microsoft/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;, &lt;a href="https://github.com/jerryjliu/llama_index"&gt;LlamaIndex&lt;/a&gt;, &lt;a href="https://haystack.deepset.ai/"&gt;Deepset Haystack&lt;/a&gt; , or &lt;a href="https://github.com/TransformerOptimus/SuperAGI"&gt;SuperAGI&lt;/a&gt;, as more suitable alternatives to LangChain. These alternatives often provide clearer documentation, more flexible customization options, and better integration with existing tools and scripts. In some cases, users have found that they can achieve their goals more easily and efficiently by using these alternative libraries instead of LangChain. See &lt;a href="https://github.com/kyrolabs/awesome-langchain#other-llm-frameworks"&gt;awesome-langchain&lt;/a&gt; for a list of LLM frameworks.&lt;/p&gt;
&lt;p&gt;&lt;a id="10-primarily-optimized-for-demos"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;10. Primarily optimized for demos&lt;/h3&gt;
&lt;p&gt;LangChain has been described as being primarily optimized for quickly creating demos, rather than for building production-ready applications. &lt;a href="https://blog.streamlit.io/langchain-streamlit/"&gt;Partnership&lt;/a&gt; with &lt;a href="https://streamlit.io/generative-ai?ref=blog.streamlit.io"&gt;Streamlit&lt;/a&gt; should ease demo creation even more. While this can be useful for those who want to quickly experiment with LLMs or showcase their ideas, it can be limiting for users who want to build more robust, scalable applications. In these cases, users may find that LangChain's focus on demos and prototypes hinders their ability to build high-quality, production-ready applications.&lt;/p&gt;
&lt;p&gt;&lt;a id="takeaways---how-to-use-the-langchain-right-way"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Takeaways - How to Use the LangChain Right Way?&lt;/h2&gt;
&lt;p&gt;Based on the community comments and experiences shared, here are some pieces of advice on how to create apps using LangChain that will be reliable, easy to maintain and debug:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use LangChain for prototyping and experimentation&lt;/strong&gt;: LangChain can be useful for quickly creating prototypes and validating ideas. However, for more complex and production-level applications, you might want to consider implementing the functionality you need yourself.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Understand the underlying concepts&lt;/strong&gt;: Before using LangChain, make sure to understand the core concepts of LLMs, prompts, and how the different components of the framework interact. This will help you make informed decisions about which parts of LangChain to use and which to replace with custom implementations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Focus on the value of the ecosystem&lt;/strong&gt;: LangChain provides integrations with various tools, indexes, and prompt templates. Leverage these resources to build your application, but be aware of the limitations and potential issues that might arise from using the default settings and abstractions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Be prepared to write custom code&lt;/strong&gt;: LangChain might not cover all use cases or provide the level of control and customization you need for your application. Be prepared to write custom code to better suit your specific requirements and use case.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Keep an eye on alternative tools and libraries&lt;/strong&gt;: As the field of LLMs is rapidly evolving, new tools and libraries are being developed that might better suit your needs. Stay informed about the latest developments and consider using alternative libraries like &lt;a href="https://haystack.deepset.ai/"&gt;Deepset Haystack&lt;/a&gt;, &lt;a href="https://github.com/stanfordnlp/dspy"&gt;DSPy&lt;/a&gt; , or Microsoft tools like &lt;a href="https://learn.microsoft.com/en-us/semantic-kernel/overview/"&gt;semantic-kernel&lt;/a&gt; and &lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt; if they better align with your project requirements. The &lt;a href="https://github.com/kyrolabs/awesome-langchain#other-llm-frameworks"&gt;list&lt;/a&gt; is huge and growing!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learn from LangChain's source code&lt;/strong&gt;: If you find that LangChain's abstractions and documentation are not sufficient for your needs, you can learn from the source code itself. Use the provided prompts and implementation details as inspiration and adapt them to your own project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Consider local LLM models&lt;/strong&gt;: While LangChain primarily focuses on using OpenAI's models, you might want to explore using local LLM models like Llama, Galpaca, Vicuna, or Koala. These models can offer benefits in terms of cost, privacy, and offline capabilities. However, be aware that they might not be as powerful or accurate as GPT-3.5 Turbo.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integrate with existing tools and scripts&lt;/strong&gt;: If you need to interface with existing Python tools or scripts, make sure to understand how LangChain interacts with them and how you can best integrate them into your application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Test and measure the performance of your application&lt;/strong&gt;: When using LangChain, ensure that you thoroughly test your application and measure its performance against different prompts and configurations. This will help you identify potential issues and areas for improvement.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Keep an eye on the costs&lt;/strong&gt;: Be mindful of the API costs associated with using LangChain and consider optimizing your application to reduce the number of API calls and tokens used.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My favourite choice from this list would be #6 - to learn from the LangChain implemented tools and techniques by looking into the code.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In considering LangChain, it's vital to acknowledge its limitations and challenges before embracing it enthusiastically. Although LangChain has garnered significant attention and investment, users have pinpointed various drawbacks that could impede its effectiveness in more intricate, production-ready applications. To make well-informed decisions about LangChain's suitability for their projects, developers should gain an understanding of these issues.
In the ever-evolving landscape of LLM-driven development, assessing the available tools and libraries is crucial to determining which aligns best with your specific needs and requirements. It's worth noting that the ideal solution might not yet exist, necessitating adaptation or customization of existing tools or even the creation of your own to realize your vision for AI-driven applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2023-10-19: Added AutoGen and semantic-kernel, removed GPTi,&lt;/li&gt;
&lt;li&gt;2023-10-19: Added link to list of alternative frameworks&lt;/li&gt;
&lt;/ul&gt;</content><category term="Generative AI"></category><category term="machine-learning"></category><category term="python"></category><category term="langchain"></category><category term="prompt-engineering"></category><category term="tokens"></category><category term="llm"></category><category term="gpt"></category><category term="openai"></category></entry><entry><title>Jaro-Winkler Similarity</title><link href="https://www.safjan.com/jaro-winkler-similarity/" rel="alternate"></link><published>2023-08-29T00:00:00+02:00</published><updated>2023-08-29T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-29:/jaro-winkler-similarity/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#jaro-winkler-similarity"&gt;Jaro-Winkler Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-example"&gt;Python Example:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#valuable-properties-of-jaro-winkler-similarity"&gt;Valuable Properties of Jaro-Winkler Similarity:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendations-for-usage"&gt;Recommendations for Usage:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cases-to-consider-alternatives"&gt;Cases to Consider Alternatives:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="jaro-winkler-similarity"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Jaro-Winkler Similarity&lt;/h2&gt;
&lt;p&gt;Jaro-Winkler similarity is designed to compare two strings, giving more weight to the common prefix of the strings. The formula for Jaro-Winkler similarity is …&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#jaro-winkler-similarity"&gt;Jaro-Winkler Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-example"&gt;Python Example:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#valuable-properties-of-jaro-winkler-similarity"&gt;Valuable Properties of Jaro-Winkler Similarity:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendations-for-usage"&gt;Recommendations for Usage:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cases-to-consider-alternatives"&gt;Cases to Consider Alternatives:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="jaro-winkler-similarity"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Jaro-Winkler Similarity&lt;/h2&gt;
&lt;p&gt;Jaro-Winkler similarity is designed to compare two strings, giving more weight to the common prefix of the strings. The formula for Jaro-Winkler similarity is:&lt;/p&gt;
&lt;div class="math"&gt;$$
JW(s1, s2) = J(s1, s2) + \frac{L \cdot p \cdot (1 - J(s1, s2))}{10}
$$&lt;/div&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(J(s1, s2)\)&lt;/span&gt; is the Jaro similarity between strings (s1) and (s2).&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(L\)&lt;/span&gt; is the length of the common prefix between the strings.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p\)&lt;/span&gt; is a constant scaling factor (typically 0.1) that increases the similarity for strings that share a common prefix.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Jaro similarity &lt;span class="math"&gt;\(J(s1, s2)\)&lt;/span&gt; is calculated as:&lt;/p&gt;
&lt;div class="math"&gt;$$
J(s1, s2) = \frac{m}{\max(\text{len}(s1), \text{len}(s2))}, \quad
$$&lt;/div&gt;
&lt;p&gt;
Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(m\)&lt;/span&gt;  is the number of matching characters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="python-example"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Python Example&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jaro_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;len_s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;len_s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;match_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;len_s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;len_s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="n"&gt;common_chars_s1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;common_chars_s2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;match_distance&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;match_distance&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;len_s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="n"&gt;common_chars_s1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;common_chars_s2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

    &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common_chars_s1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;

    &lt;span class="n"&gt;transpositions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c1&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common_chars_s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;common_chars_s2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;jaro_similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;len_s1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;len_s2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;transpositions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaro_similarity&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jaro_winkler_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;jaro_sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jaro_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;common_prefix_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;common_prefix_len&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

    &lt;span class="n"&gt;jaro_winkler_sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jaro_sim&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common_prefix_len&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;jaro_sim&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaro_winkler_sim&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;string1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;apple&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;string2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;applet&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;jw_similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jaro_winkler_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Jaro-Winkler Similarity:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jw_similarity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Jaro-Winkler Similarity: 0.9722222222222223
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The Jaro-Winkler similarity metric possesses several valuable properties that make it suitable for specific use cases. However, it's important to note that no single similarity metric is universally best for all scenarios. Here are some valuable properties of the Jaro-Winkler metric, as well as recommendations for its usage and instances where other metrics might be more appropriate.
&lt;a id="valuable-properties-of-jaro-winkler-similarity"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Valuable Properties of Jaro-Winkler Similarity&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;String Comparison with Common Prefix:&lt;/strong&gt; The Jaro-Winkler metric gives higher weight to common prefixes, making it effective for comparing strings that often have a prefix or abbreviation. This is particularly useful for names and addresses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adjustable Scaling Factor:&lt;/strong&gt; The Jaro-Winkler metric allows for tuning the impact of the common prefix on the similarity score using the scaling factor &lt;span class="math"&gt;\(p\)&lt;/span&gt;. This allows you to emphasize or de-emphasize the common prefix based on your needs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Simple to Understand and Implement:&lt;/strong&gt; The calculation of Jaro-Winkler similarity involves straightforward string matching and prefix length consideration, making it relatively easy to implement and understand.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="recommendations-for-usage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Recommendations for Usage&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Names and Addresses:&lt;/strong&gt; Jaro-Winkler similarity is highly recommended when comparing names, addresses, and other strings with common prefixes or abbreviations. It's often used in record linkage, deduplication, and fuzzy matching tasks in databases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fuzzy String Matching:&lt;/strong&gt; When dealing with noisy or misspelled data, the Jaro-Winkler metric can be effective in finding approximate matches. It's suitable for scenarios where small typographical errors or variations are common.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Short Texts:&lt;/strong&gt; Jaro-Winkler is well-suited for comparing short texts like product names, usernames, and titles, where the common prefix is an important aspect of similarity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="cases-to-consider-alternatives"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Cases to Consider Alternatives&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Long Texts:&lt;/strong&gt; For comparing long texts or documents, &lt;strong&gt;cosine similarity&lt;/strong&gt; or &lt;strong&gt;Jaccard similarity&lt;/strong&gt; of term frequencies might be more appropriate, as they consider the distribution of terms across the entire text.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semantic Similarity:&lt;/strong&gt; If you're interested in capturing semantic meaning rather than character-level similarity, &lt;strong&gt;word embeddings&lt;/strong&gt;-based metrics like cosine similarity between vector representations might be more suitable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Numerical Data:&lt;/strong&gt; For comparing numerical data, other similarity metrics such as &lt;strong&gt;Euclidean distance&lt;/strong&gt;, &lt;strong&gt;Manhattan distance&lt;/strong&gt;, or &lt;strong&gt;Pearson correlation coefficient&lt;/strong&gt; might be more meaningful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customized Weights:&lt;/strong&gt; If you have specific domain knowledge about feature importance, you might opt for a customized similarity metric that incorporates these weights effectively.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Language-Specific Features:&lt;/strong&gt; If the text includes language-specific features, phonetic differences, or linguistic nuances, other specialized metrics like &lt;strong&gt;Soundex&lt;/strong&gt; or &lt;strong&gt;Levenshtein distance&lt;/strong&gt; might be considered.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some concrete pairs of strings that demonstrate the properties of the Jaro-Winkler similarity metric (&lt;span class="math"&gt;\(p\)&lt;/span&gt;=0.2 if not stated differently):&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Common Prefix Emphasis:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "Michael"&lt;/li&gt;
&lt;li&gt;String 2: "Michelle"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.963&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: The common prefix "Mich" contributes significantly to the similarity score in Jaro-Winkler, resulting in a high similarity even though the rest of the strings differ.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case Sensitivity and Scaling Factor:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "McDonald's"&lt;/li&gt;
&lt;li&gt;String 2: "Mcdonells"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.853&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: The common prefix "Mcdon" is considered due to the case difference. The scaling factor can adjust the impact of this prefix on the similarity score.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No Common Prefix:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "hello"&lt;/li&gt;
&lt;li&gt;String 2: "world"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.433&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: Without a common prefix, the Jaro-Winkler similarity is low, even if the strings share some characters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Short vs. Long Strings:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "AI"&lt;/li&gt;
&lt;li&gt;String 2: "Artificial Intelligence"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.623
Explanation: The short string "AI" has a higher similarity to the beginning of "Artificial Intelligence" due to the common prefix "A".&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Typographical Errors:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "telephone"&lt;/li&gt;
&lt;li&gt;String 2: "telephne"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.967&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: Despite the missing "o," the common prefix "teleph" contributes to a high Jaro-Winkler similarity score.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Short and Noisy Data:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "abacus"&lt;/li&gt;
&lt;li&gt;String 2: "abaxus"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity: 0.956&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: The similarity captures the similarity in the common prefix "aba" and penalizes the difference at the end.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Significance of Scaling Factor:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String 1: "Thompson"&lt;/li&gt;
&lt;li&gt;String 2: "Thomson"&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity with &lt;span class="math"&gt;\(p=0.1\)&lt;/span&gt;: 0.975&lt;/li&gt;
&lt;li&gt;Jaro-Winkler similarity with &lt;span class="math"&gt;\(p=0.2\)&lt;/span&gt;: 0.992&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Explanation: The scaling factor &lt;span class="math"&gt;\(p\)&lt;/span&gt; affects the similarity score. A higher &lt;span class="math"&gt;\(p\)&lt;/span&gt; gives more emphasis to the common prefix, leading to a higher similarity.&lt;/p&gt;
&lt;p&gt;These examples illustrate how the Jaro-Winkler similarity metric behaves based on different characteristics of input strings, such as common prefixes, case sensitivity, typos, length, and the scaling factor &lt;span class="math"&gt;\(p\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Jaro-Winkler similarity is highly valuable when dealing with short strings, names, and addresses, especially when common prefixes play a significant role. However, for longer texts, semantic similarity, numerical data, and specialized linguistic considerations, other metrics might be more appropriate. Always consider the specific characteristics of your data and the goals of your analysis when choosing a similarity metric.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="nlp"></category><category term="text-similarity"></category><category term="string-similarity"></category><category term="similarity-metrics"></category><category term="jaccard"></category><category term="cosine-similarity"></category><category term="levenshtein"></category><category term="word-embeddings"></category><category term="soundex"></category></entry><entry><title>Bearer Token Authentication for API</title><link href="https://www.safjan.com/bearer-token-authentication-for-api/" rel="alternate"></link><published>2023-08-24T00:00:00+02:00</published><updated>2023-08-24T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-24:/bearer-token-authentication-for-api/</id><summary type="html">&lt;h2&gt;Bearer Token Authentication&lt;/h2&gt;
&lt;p&gt;Bearer authentication is a method of API authentication that involves including a "bearer token" in the request header. This token is typically a long string of characters, often encoded in a specific format like JSON Web Token (JWT) or …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Bearer Token Authentication&lt;/h2&gt;
&lt;p&gt;Bearer authentication is a method of API authentication that involves including a "bearer token" in the request header. This token is typically a long string of characters, often encoded in a specific format like JSON Web Token (JWT) or OAuth token. Bearer authentication is commonly used to secure APIs by allowing only authorized users or applications to access protected resources.&lt;/p&gt;
&lt;p&gt;Here's how the process generally works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: The user or application requests access to a protected resource by sending a request to the API server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Token Generation&lt;/strong&gt;: Upon successful authentication, the server generates a bearer token, which serves as proof of the user's or application's identity and permissions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Token Inclusion&lt;/strong&gt;: The generated bearer token is then included in the "Authorization" header of subsequent requests to the API. The header typically looks like this:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Authorization: Bearer &amp;lt;token&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;code&gt;&amp;lt;token&amp;gt;&lt;/code&gt; represents the actual bearer token.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Authorization&lt;/strong&gt;: The API server receives the request and extracts the bearer token from the header. It then validates the token to determine if the user or application is authorized to access the requested resource.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Access Control&lt;/strong&gt;: If the bearer token is valid and the user or application has the necessary permissions, the API server grants access to the requested resource. If the token is invalid or expired, the server denies access.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bearer authentication is often preferred due to its simplicity and ease of implementation. It allows the server to validate the token without needing to store any session information, making it suitable for stateless architectures like RESTful APIs. However, securing bearer tokens is crucial since anyone in possession of a valid token can access the associated resources. This is why HTTPS and token encryption are recommended to protect the token during transmission.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:  bearer tokens should be handled carefully. They can potentially be exposed if not properly secured, and their use should be combined with other security measures, such as &lt;strong&gt;rate limiting&lt;/strong&gt;, &lt;strong&gt;token expiration&lt;/strong&gt;, and regular &lt;strong&gt;token rotation&lt;/strong&gt;, to enhance the overall security of an API.&lt;/p&gt;
&lt;h2&gt;Token Encryption&lt;/h2&gt;
&lt;p&gt;Token encryption plays a crucial role in securing bearer tokens used for API authentication. Encrypting bearer tokens ensures that the token's content remains confidential and tamper-proof while it's being transmitted or stored. Here's an overview of how token encryption works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Token Content&lt;/strong&gt;: Bearer tokens often contain important information such as user identity, permissions, and expiration time. This information should be protected from unauthorized access.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Choose Encryption Algorithm&lt;/strong&gt;: A strong encryption algorithm is selected for securing the token. Common choices include AES (Advanced Encryption Standard) and RSA (Rivest-Shamir-Adleman).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generate Encryption Keys&lt;/strong&gt;: Encryption requires keys: a public key for encryption and a private key for decryption (in the case of asymmetric encryption like RSA) or a shared key (in the case of symmetric encryption like AES). These keys must be kept secret.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Encryption Process&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Asymmetric Encryption (e.g., RSA)&lt;/strong&gt;: If using asymmetric encryption, the sender uses the recipient's public key to encrypt the token. Only the recipient possessing the corresponding private key can decrypt and access the original token.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Symmetric Encryption (e.g., AES)&lt;/strong&gt;: In symmetric encryption, both the sender and receiver share the same secret key. The sender uses this key to encrypt the token, and the recipient uses the same key to decrypt it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transmission&lt;/strong&gt;: The encrypted token can now be safely transmitted over the network. Even if intercepted by malicious actors, the encrypted content should be meaningless without the decryption key.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decryption Process&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Asymmetric Encryption (e.g., RSA)&lt;/strong&gt;: The recipient uses their private key to decrypt the token, revealing its original content.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Symmetric Encryption (e.g., AES)&lt;/strong&gt;: The recipient uses the shared secret key to decrypt the token and access its original content.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Encryption adds an additional layer of security to bearer tokens. Even if an attacker gains access to the encrypted token, they won't be able to decipher its contents without the appropriate decryption key.&lt;/p&gt;
&lt;p&gt;It's important to note a few considerations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Key Management&lt;/strong&gt;: The security of encrypted tokens depends heavily on proper key management. Keys should be stored securely and rotated periodically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Algorithm and Key Length&lt;/strong&gt;: The choice of encryption algorithm and key length impacts the security of the encrypted token. Strong algorithms with sufficient key lengths should be used.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HTTPS&lt;/strong&gt;: While encryption protects the token in transit, using HTTPS (TLS/SSL) for communication further ensures the confidentiality and integrity of the entire data exchange, including the token.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Token Validation&lt;/strong&gt;: Even when using encrypted tokens, the receiving server must still validate the decrypted token to ensure its authenticity, integrity, and authorization.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Combining token encryption with other security practices, such as secure token storage and token expiration, provides a comprehensive approach to securing bearer tokens and API authentication.&lt;/p&gt;</content><category term="note"></category><category term="bearer"></category><category term="bearer-token"></category><category term="authentication"></category><category term="json"></category><category term="api"></category></entry><entry><title>Understanding Retrieval-Augmented Generation (RAG) empowering LLMs</title><link href="https://www.safjan.com/understanding-retrieval-augmented-generation-rag-empowering-llms/" rel="alternate"></link><published>2023-08-24T00:00:00+02:00</published><updated>2023-10-23T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-24:/understanding-retrieval-augmented-generation-rag-empowering-llms/</id><summary type="html">&lt;p&gt;Understand innovative artificial intelligence framework that empower large language models (LLMs) by anchoring them to external knowledge sources with accurate, current information.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;Retrieval augmented generation refers to the method of enhancing a user's input to a large language model (LLM) such as ChatGPT by incorporating extra information obtained from an external source. This additional data can then be utilized by the LLM to enrich the response it produces.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction-understanding-retrieval-augmented-generation-rag"&gt;Introduction: Understanding Retrieval-Augmented Generation (RAG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-need-for-rag-in-large-language-models"&gt;The Need for RAG in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-open-book-approach-of-rag"&gt;The 'Open Book' Approach of RAG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#personalized-and-verifiable-responses-with-rag"&gt;Personalized and Verifiable Responses with RAG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#challenges-and-future-directions"&gt;Challenges and Future Directions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="introduction-understanding-retrieval-augmented-generation-rag"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction: Understanding Retrieval-Augmented Generation (RAG)&lt;/h2&gt;
&lt;p&gt;Retrieval-Augmented Generation, commonly referred to as RAG, and sometimes called Grounded Generation (GG), represents an ingenious integration of pretrained dense retrieval (DPR) and &lt;a href="https://en.wikipedia.org/wiki/Seq2seq"&gt;sequence-to-sequence&lt;/a&gt; models.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Transformer architecture (used in GPT models) is a member of sequence-to-sequence (Seq2Seq) architectures. Seq2Seq models are designed to handle tasks that involve transforming an input sequence into an output sequence, such as machine translation, text summarization, and dialogue generation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The process involves retrieving documents using DPR and subsequently transmitting them to a seq2seq model. Through a process of marginalization, these models then produce desired outputs. The retriever and seq2seq modules commence their operations as pretrained models, and through a joint fine-tuning process, they adapt collaboratively, thus enhancing both retrieval and generation for specific downstream tasks. &lt;strong&gt;This innovative artificial intelligence framework serves as a means to empower large language models (LLMs) by anchoring them to external knowledge sources.&lt;/strong&gt; Consequently, this strategic approach ensures the availability of accurate, current information, thereby granting users valuable insights into the generative mechanisms of these models. For a comprehensive understanding of the RAG technique, we offer an in-depth exploration, commencing with a simplified overview and progressively delving into more intricate technical facets.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Data processing in RAG" src="https://learn.microsoft.com/en-us/azure/machine-learning/media/concept-retrieval-augmented-generation/retrieval-augmented-generation-walkthrough.png?view=azureml-api-2#lightbox"&gt;&lt;/p&gt;
&lt;p&gt;Figure 1. Data processing, storage and referencing in RAG method. Source: &lt;a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2"&gt;Microsoft&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="the-need-for-rag-in-large-language-models"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;The Need for RAG in Large Language Models&lt;/h2&gt;
&lt;p&gt;Large language models, while powerful, can sometimes be inconsistent in their responses. They may provide accurate answers to certain questions but struggle with others, often regurgitating random facts from their training data. This inconsistency stems from the fact that LLMs understand the statistical relationships between words but not their actual meanings.&lt;/p&gt;
&lt;p&gt;To address this issue, researchers have developed the RAG &lt;strong&gt;framework, which improves the quality of LLM-generated responses by grounding the model in external sources of knowledge.&lt;/strong&gt; This approach not only ensures access to the most current and reliable facts but also allows users to verify the model's claims for accuracy and trustworthiness.&lt;/p&gt;
&lt;p&gt;&lt;a id="the-open-book-approach-of-rag"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;The 'Open Book' Approach of RAG&lt;/h2&gt;
&lt;p&gt;RAG operates in &lt;strong&gt;two main phases: retrieval and content generation&lt;/strong&gt;. During the retrieval phase, algorithms search for and retrieve relevant snippets of information based on the user's prompt or question. These facts can come from various sources, such as indexed documents on the internet or a closed-domain enterprise setting for added security and reliability.&lt;/p&gt;
&lt;p&gt;In the generative phase, the LLM uses the retrieved information and its internal representation of training data to synthesize a tailored answer for the user.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This approach is akin to an "open book" exam, where the model can browse through content in a book rather than relying solely on its memory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="RAG Operation" src="/images/retrieval_augmented_generation/RAG.png"&gt;
Figure 2. RAG operation. Information preparation and storage. Augmenting prompt with external information.&lt;/p&gt;
&lt;p&gt;&lt;a id="personalized-and-verifiable-responses-with-rag"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Personalized and Verifiable Responses with RAG&lt;/h2&gt;
&lt;p&gt;RAG allows LLM-powered chatbots to provide more personalized answers without the need for human-written scripts. By reducing the need to continuously train the model on new data, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.&lt;/p&gt;
&lt;p&gt;Moreover, RAG enables LLMs to generate more specific, diverse, and factual language compared to traditional parametric-only seq2seq models. This feature is particularly useful for businesses that require up-to-date information and verifiable responses.&lt;/p&gt;
&lt;p&gt;&lt;a id="challenges-and-future-directions"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Challenges and Future Directions&lt;/h2&gt;
&lt;p&gt;Despite its advantages, RAG is not without its challenges. For instance, &lt;strong&gt;LLMs may struggle to recognize when they don't know the answer&lt;/strong&gt; to a question, leading to incorrect or misleading information. To address this issue, researchers are working on fine-tuning LLMs to recognize unanswerable questions and probe for more detail until they can provide a definitive answer.&lt;/p&gt;
&lt;p&gt;Furthermore, there is ongoing research to improve both the retrieval and generation aspects of RAG. This includes &lt;strong&gt;finding and fetching the most relevant information possible and structuring that information&lt;/strong&gt; to elicit the richest responses from the LLM.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Retrieval-Augmented Generation offers a promising solution to the limitations of large language models by grounding them in external knowledge sources. By adopting RAG, businesses can achieve customized solutions, maintain data relevance, and optimize costs while harnessing the reasoning capabilities of LLMs. As research continues to advance in this area, we can expect even more powerful and efficient language models in the future.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="references"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Original paper &lt;a href="https://arxiv.org/abs/2005.11401"&gt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&lt;/a&gt; by Patrick Lewis et al. (available as &lt;a href="https://paperswithcode.com/method/rag"&gt;paper with code&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Exemplary notebooks on amazon Sagemaker:&lt;ul&gt;
&lt;li&gt;&lt;a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/question_answering_retrieval_augmented_generation/question_answering_jumpstart_knn.html"&gt;Retrieval-Augmented Generation: Question Answering based on Custom Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/question_answering_retrieval_augmented_generation/question_answering_langchain_jumpstart.html"&gt;Retrieval-Augmented Generation: Question Answering based on Custom Dataset with Open-sourced LangChain Library&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python library with RAG implementation: &lt;a href="https://github.com/llmware-ai/llmware"&gt;GitHub - llmware-ai/llmware: Providing enterprise-grade LLM-based development framework, tools and fine-tuned models.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Analytics: &lt;a href="https://www.vectorview.ai/"&gt;Vectorview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Deep-dive into specific use-case of RAG with scaling in mind: &lt;a href="https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1"&gt;Building RAG-based LLM Applications for Production (Part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Good section on possible improvements to RAG: &lt;a href="https://llmstack.ai/blog/retrieval-augmented-generation"&gt;Retrieval Augmented Generation (RAG): What, Why and How? | LLMStack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;General intro to RAG: &lt;a href="https://scriv.ai/guides/retrieval-augmented-generation-overview/"&gt;How do domain-specific chatbots work? An Overview of Retrieval Augmented Generation (RAG) | Scriv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Optimization, async, using summaries: &lt;a href="https://madhukarkumar.medium.com/secrets-to-optimizing-rag-llm-apps-for-better-accuracy-performance-and-lower-cost-da1014127c0a"&gt;Secrets to Optimizing RAG LLM Apps for Better Performance, Accuracy and Lower Costs! | by Madhukar Kumar | madhukarkumar | Sep, 2023 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Check the GitHub for the RAG-related projects: &lt;a href="https://github.com/topics/retrieval-augmented-generation?l=python"&gt;retrieval-augmented-generation · GitHub Topics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/16cbimi/yet_another_rag_system_implementation_details_and/"&gt;Yet another RAG system - implementation details and lessons learned : r/LocalLLaMA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/"&gt;Building and Evaluating Advanced RAG Applications - DeepLearning.AI&lt;/a&gt; - recent course from deeplearning.ai (Andrew Ng). Instructors: Jerry Liu and Anupam Datta.&lt;ul&gt;
&lt;li&gt;In this course, we’ll explore:&lt;ul&gt;
&lt;li&gt;Two advanced retrieval methods: Sentence-window retrieval and auto-merging retrieval that perform better compared to the baseline RAG pipeline.&lt;/li&gt;
&lt;li&gt;Evaluation and experiment tracking: A way evaluate and iteratively improve your RAG pipeline’s performance.&lt;/li&gt;
&lt;li&gt;The RAG triad: Context Relevance, Groundedness, and Answer Relevance, which are methods to evaluate the relevance and truthfulness of your LLM’s response.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/techniques-to-boost-rag-performance-in-production/"&gt;Techniques to Boost RAG Performance in Production&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2023-10-23: Added link to LLMStack&lt;/li&gt;
&lt;li&gt;2023-11-06: Added TLDR section&lt;/li&gt;
&lt;li&gt;2023-11-06: Added ToC&lt;/li&gt;
&lt;/ul&gt;</content><category term="Generative AI"></category><category term="llm"></category><category term="nlp"></category><category term="question-answering"></category><category term="rag"></category><category term="re-ranking"></category><category term="embeddings"></category><category term="Transformers"></category><category term="seq2seq"></category><category term="prompt"></category><category term="pretrained-dense-retrieval"></category></entry><entry><title>Create Self-Hosted Python Package Repository - General Guide</title><link href="https://www.safjan.com/Create%20Self-Hosted%20Python%20Package%20Repository/" rel="alternate"></link><published>2023-08-12T00:00:00+02:00</published><updated>2023-08-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-12:/Create Self-Hosted Python Package Repository/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/lesser-known-python-package-repository-managers/"&gt;Lesser-known Python Package Repository Managers&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/storing-private-python-packages-with-local-nas-and-lightweight-servers/"&gt;Storing Private Python Packages with Local NAS and Lightweight Servers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a self-hosted Python package repository allows you to host and manage your own Python packages, making them accessible to your team or the public …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/lesser-known-python-package-repository-managers/"&gt;Lesser-known Python Package Repository Managers&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/storing-private-python-packages-with-local-nas-and-lightweight-servers/"&gt;Storing Private Python Packages with Local NAS and Lightweight Servers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Creating a self-hosted Python package repository allows you to host and manage your own Python packages, making them accessible to your team or the public without relying on external services like PyPI. Here's a general guide on how to set up a self-hosted Python package repository.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bullet&lt;/span&gt;
&lt;span class="n"&gt;min_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;**Contents**&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;General Guide&lt;/h2&gt;
&lt;h3&gt;Choose a Repository Manager&lt;/h3&gt;
&lt;p&gt;You need a repository manager to host and manage your Python packages. Two popular options are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Devpi&lt;/strong&gt;: A powerful and customizable Python package repository server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artifactory&lt;/strong&gt;: A general-purpose repository manager that can host various types of packages, including Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Set Up a Server&lt;/h3&gt;
&lt;p&gt;You will need a server to host your package repository. This could be a dedicated server, a cloud instance (AWS, GCP, Azure), or even a local machine if the repository is for internal use.&lt;/p&gt;
&lt;h3&gt;Install and Configure the Repository Manager&lt;/h3&gt;
&lt;h4&gt;Devpi&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Install Devpi using pip: &lt;code&gt;pip install devpi-server devpi-web&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Configure Devpi: Follow the instructions in the &lt;a href="https://devpi.net/docs/devpi/devpi/stable/+doc/quickstart-server.html"&gt;official documentation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Artifactory&lt;/h4&gt;
&lt;p&gt;Download and install Artifactory: Follow the instructions on the &lt;a href="https://www.jfrog.com/confluence/display/JFROG/Installing+Artifactory"&gt;Artifactory website&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Create a Virtual Environment (optional but recommended)&lt;/h3&gt;
&lt;p&gt;Set up a Python virtual environment on your server to keep your package repository isolated from the system Python.&lt;/p&gt;
&lt;h3&gt;Upload Packages&lt;/h3&gt;
&lt;p&gt;Once your repository manager is set up, use tools like &lt;code&gt;twine&lt;/code&gt; to upload your Python packages. Make sure to specify your self-hosted repository URL.&lt;/p&gt;
&lt;h3&gt;Accessing Packages&lt;/h3&gt;
&lt;p&gt;To use packages from your self-hosted repository, users can modify their &lt;code&gt;pip.conf&lt;/code&gt; or &lt;code&gt;.pypirc&lt;/code&gt; configuration file to include your repository's URL.&lt;/p&gt;
&lt;h3&gt;Security and Access Control&lt;/h3&gt;
&lt;p&gt;Configure user authentication and access control to restrict who can upload and access packages in your repository.&lt;/p&gt;
&lt;h3&gt;Maintenance and Backup&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Regularly back up your package repository data to prevent data loss.&lt;/li&gt;
&lt;li&gt;Keep your repository manager and server updated with security patches.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Documentation&lt;/h3&gt;
&lt;p&gt;Provide clear documentation to your team on how to access, upload, and manage packages in your self-hosted repository.&lt;/p&gt;
&lt;h2&gt;Artifactory vs. Devpi - pros &amp;amp; cons and setup instructions&lt;/h2&gt;
&lt;p&gt;Let's explore two popular free and open-source options for creating a self-hosted Python package repository: Devpi and Artifactory, along with their pros, cons, use cases, and a tutorial for setting up each.&lt;/p&gt;
&lt;h3&gt;Option 1: Devpi&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Designed specifically for Python package management.&lt;/li&gt;
&lt;li&gt;Provides features like caching, replication, and access control.&lt;/li&gt;
&lt;li&gt;Supports easy package versioning and management.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Limited support for non-Python packages.&lt;/li&gt;
&lt;li&gt;Web interface might not be as polished as other solutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Small to medium-sized teams working exclusively with Python.&lt;/li&gt;
&lt;li&gt;Projects where ease of setup and simple usage is preferred.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install Devpi&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install devpi-server devpi-web
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Create and Configure Devpi Server&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;Initialize a new Devpi server:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;devpi-server --init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Start the Devpi server:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;devpi-server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Create Users and Indexes&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;Create a user:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;devpi use http://localhost:3141
devpi user -c &amp;lt;username&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Create an index:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;devpi index -c &amp;lt;indexname&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Upload and Use Packages&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;Upload a package:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;devpi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;upload&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Install a package from your Devpi index:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;pip&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;install&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="c1"&gt;//localhost:3141/&amp;lt;username&amp;gt;/&amp;lt;indexname&amp;gt;/simple/ &amp;lt;package&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Option 2: Artifactory&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Versatile repository manager supporting multiple package types.&lt;/li&gt;
&lt;li&gt;Robust access control and security features.&lt;/li&gt;
&lt;li&gt;Highly configurable and scalable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More complex setup compared to Devpi.&lt;/li&gt;
&lt;li&gt;Heavier resource requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large organizations with diverse technology stacks.&lt;/li&gt;
&lt;li&gt;Projects needing advanced access control and security features.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install Artifactory&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow the installation guide for &lt;a href="https://www.jfrog.com/confluence/display/JFROG/Installing+Artifactory"&gt;Artifactory Community Edition&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure Artifactory&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access Artifactory's web interface and set up your repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create a Virtual Repository&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a new virtual repository and include a "PyPI" remote repository as a source.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upload Packages&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;twine&lt;/code&gt; to upload your Python packages to your virtual repository:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;twine&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;upload&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Artifactory_URL&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;/&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;repository_name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="o"&gt;/*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Access and Use Packages&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;Configure your pip to use your Artifactory repository as an index:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;pip&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;config&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;global&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;index&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;Artifactory_URL&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;repository_name&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;simple&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Install packages as usual using pip.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Closing thoughts&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Setting up a self-hosted Python package repository requires careful consideration of your team's needs and technical expertise. Choose the option that best aligns with your requirements and resources.&lt;/li&gt;
&lt;li&gt;Remember, setting up and maintaining a self-hosted package repository requires technical expertise and ongoing maintenance. If you're not experienced with server management and administration, consider starting with a simpler approach or seeking help from someone with relevant experience.&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="pypi"></category><category term="python"></category><category term="python-package"></category><category term="package-repository"></category><category term="artifactory"></category><category term="devpi"></category></entry><entry><title>Cookiecutter alternatives</title><link href="https://www.safjan.com/cookiecutter-alternatives/" rel="alternate"></link><published>2023-08-12T00:00:00+02:00</published><updated>2023-08-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-12:/cookiecutter-alternatives/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#alternative-tools-to-cookiecutter-for-scaffolding-projects"&gt;Alternative Tools to Cookiecutter for Scaffolding Projects&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#1-yeoman"&gt;1. &lt;strong&gt;Yeoman&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-hygen"&gt;2. &lt;strong&gt;Hygen&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-plop"&gt;3. &lt;strong&gt;Plop&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4-hyde"&gt;4. &lt;strong&gt;Hyde&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5-slush"&gt;5. &lt;strong&gt;Slush&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6-blueprint"&gt;6. &lt;strong&gt;Blueprint&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7-sao"&gt;7. &lt;strong&gt;Sao&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-plopdown"&gt;8. &lt;strong&gt;Plopdown&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#9-jolt"&gt;9. &lt;strong&gt;Jolt&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-boilr"&gt;10. &lt;strong&gt;Boilr&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendations-for-various-use-cases"&gt;Recommendations for various use-cases&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#use-case-1-rapid-prototyping-and-small-projects---plop"&gt;Use Case 1: Rapid Prototyping and Small Projects - Plop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case-2-large-scale-projects-with-opinionated-conventions---yeoman"&gt;Use Case …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#alternative-tools-to-cookiecutter-for-scaffolding-projects"&gt;Alternative Tools to Cookiecutter for Scaffolding Projects&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#1-yeoman"&gt;1. &lt;strong&gt;Yeoman&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-hygen"&gt;2. &lt;strong&gt;Hygen&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-plop"&gt;3. &lt;strong&gt;Plop&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4-hyde"&gt;4. &lt;strong&gt;Hyde&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5-slush"&gt;5. &lt;strong&gt;Slush&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6-blueprint"&gt;6. &lt;strong&gt;Blueprint&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7-sao"&gt;7. &lt;strong&gt;Sao&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-plopdown"&gt;8. &lt;strong&gt;Plopdown&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#9-jolt"&gt;9. &lt;strong&gt;Jolt&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-boilr"&gt;10. &lt;strong&gt;Boilr&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendations-for-various-use-cases"&gt;Recommendations for various use-cases&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#use-case-1-rapid-prototyping-and-small-projects---plop"&gt;Use Case 1: Rapid Prototyping and Small Projects - Plop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case-2-large-scale-projects-with-opinionated-conventions---yeoman"&gt;Use Case 2: Large-Scale Projects with Opinionated Conventions - Yeoman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-case-3-advanced-file-processing-and-task-automation---slush"&gt;Use Case 3: Advanced File Processing and Task Automation - Slush&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="alternative-tools-to-cookiecutter-for-scaffolding-projects"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Alternative Tools to Cookiecutter for Scaffolding Projects&lt;/h2&gt;
&lt;p&gt;Scaffolding tools are essential for accelerating the process of project setup and code generation by providing predefined templates and structures. One of the popular tools for this purpose is Cookiecutter, which allows developers to create projects from project templates. However, the software development ecosystem is diverse, and there are several alternative tools to Cookiecutter, each with unique features and characteristics that differentiate them from one another.&lt;/p&gt;
&lt;p&gt;In this article, we will explore ten alternative tools to Cookiecutter and highlight their standout features and best-suited use cases.&lt;/p&gt;
&lt;p&gt;&lt;a id="1-yeoman"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;1. &lt;strong&gt;Yeoman&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Yeoman is a robust scaffolding tool that offers a vast collection of generators to create projects across various languages and frameworks. It provides a strong community support and an extensive library of community-contributed generators.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, Yeoman focuses on a more opinionated approach, meaning it enforces best practices and conventions for specific frameworks, which can speed up development. Additionally, it supports interactive user prompts, making project setup more user-friendly.&lt;/p&gt;
&lt;p&gt;Yeoman's wide range of generators and its integration with popular build tools like Grunt and Gulp make it suitable for large-scale projects and complex workflows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Yeoman is best suited for developers who want a structured and opinionated approach to project generation, especially in scenarios where adherence to specific conventions is crucial.&lt;/p&gt;
&lt;p&gt;&lt;a id="2-hygen"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2. &lt;strong&gt;Hygen&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Hygen is a fast and flexible code generator that allows developers to create custom templates for their projects. It offers a template language with conditional logic and supports both built-in and custom helpers.&lt;/p&gt;
&lt;p&gt;Hygen focuses on simplicity and allows developers to create templates using their preferred language, making it highly customizable. Unlike Cookiecutter, which relies on Jinja2 templates, Hygen's customizability extends to both the template language and directory structure.&lt;/p&gt;
&lt;p&gt;The ability to generate code snippets and templates quickly and effortlessly makes Hygen ideal for scenarios where rapid prototyping and iterative development are essential.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Hygen is best suited for developers who need a lightweight, customizable, and language-agnostic solution for scaffolding projects.&lt;/p&gt;
&lt;p&gt;&lt;a id="3-plop"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;3. &lt;strong&gt;Plop&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Plop is a simple yet powerful micro-generator tool that focuses on creating small and reusable templates. It allows developers to define custom generators with ease, making it a popular choice for smaller projects.&lt;/p&gt;
&lt;p&gt;Plop stands out from Cookiecutter due to its minimalistic approach and single-purpose philosophy. Instead of managing complex project structures, Plop concentrates on code generation for specific components or modules.&lt;/p&gt;
&lt;p&gt;Plop's ability to create small, self-contained generators with custom logic and prompts is ideal for developers who require lightweight scaffolding tools for repetitive tasks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Plop is best suited for developers who work on component-based architectures and require a quick and straightforward way to generate components, modules, or boilerplate code.&lt;/p&gt;
&lt;p&gt;&lt;a id="4-hyde"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;4. &lt;strong&gt;Hyde&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Hyde is a lightweight scaffolding tool that allows developers to create projects using a simple YAML configuration file. It offers a minimalist approach to project generation, making it easy to use and understand.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, which relies on templates and prompts, Hyde uses a declarative configuration file to define project structures. This simplicity enables developers to get started quickly without the need for a dedicated template engine.&lt;/p&gt;
&lt;p&gt;Hyde's unique feature lies in its simplicity, making it an excellent choice for small to medium-sized projects and developers who prefer a configuration-driven approach.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Hyde is best suited for developers who want a straightforward and lightweight solution for setting up projects without the complexity of template languages.&lt;/p&gt;
&lt;p&gt;&lt;a id="5-slush"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;5. &lt;strong&gt;Slush&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Slush is a streaming scaffolding tool built on top of Gulp.js, providing a pipeline-based approach to project generation. It allows developers to compose complex generators using Gulp plugins, offering powerful customization capabilities.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, which operates on static templates, Slush leverages Gulp's streaming capabilities to process files, enabling developers to manipulate and modify the project structure during generation.&lt;/p&gt;
&lt;p&gt;Slush's streaming nature and its compatibility with Gulp plugins make it stand out for projects that require advanced file processing and task automation during scaffolding.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Slush is best suited for developers who are already familiar with Gulp and need to integrate project generation with complex build processes.&lt;/p&gt;
&lt;p&gt;&lt;a id="6-blueprint"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;6. &lt;strong&gt;Blueprint&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Blueprint is a modern scaffolding tool designed for simplicity and flexibility. It allows developers to create project templates using Handlebars templates, YAML configuration, or JavaScript code, providing multiple options for customizing templates.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, which mainly relies on Jinja2 templates, Blueprint gives developers the freedom to choose their preferred template language. It also offers a straightforward CLI interface for generating projects.&lt;/p&gt;
&lt;p&gt;Blueprint's versatility and support for various template creation methods make it suitable for developers who have existing Handlebars or JavaScript templates they wish to reuse for project generation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Blueprint is best suited for developers who want a lightweight and flexible scaffolding tool with support for multiple template languages.&lt;/p&gt;
&lt;p&gt;&lt;a id="7-sao"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;7. &lt;strong&gt;Sao&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sao is a pluggable and customizable scaffolding tool that provides a simple JSON-based template definition. It enables developers to create their own template plugins and extend existing ones seamlessly.&lt;/p&gt;
&lt;p&gt;Sao's plugin system and JSON-based templates offer a high level of customization, allowing developers to tailor project generation to their specific requirements without being tied to a specific template language.&lt;/p&gt;
&lt;p&gt;The ability to create custom plugins and extend existing templates makes Sao a powerful choice for developers who value modularity and plugin support.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Sao is best suited for developers who need a versatile and extensible scaffolding tool with the option to create and share their custom plugins.&lt;/p&gt;
&lt;p&gt;&lt;a id="8-plopdown"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;8. &lt;strong&gt;Plopdown&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Plopdown is a powerful scaffolding tool that generates templates using a JSON configuration file. It offers advanced features like dynamic prompts, glob pattern matching, and custom logic for template generation.&lt;/p&gt;
&lt;p&gt;Plopdown's support for dynamic prompts and glob patterns sets it apart from Cookiecutter. It allows developers to generate project files based on complex conditions and patterns, making it suitable for projects with dynamic requirements.&lt;/p&gt;
&lt;p&gt;Plopdown's ability to handle dynamic inputs and patterns make it ideal for projects that require a high degree of customization and flexibility during the scaffolding process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Plopdown is best suited for developers who need a flexible and powerful scaffolding tool capable of handling dynamic inputs and complex project structures.&lt;/p&gt;
&lt;p&gt;&lt;a id="9-jolt"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;9. &lt;strong&gt;Jolt&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Jolt is a lightweight and straightforward scaffolding tool that allows developers to create templates using a concise YAML syntax. It emphasizes minimal configuration and aims to reduce boilerplate code.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, which may require extensive configuration, Jolt's YAML syntax simplifies the template creation process, making it a fast and efficient choice for smaller projects.&lt;/p&gt;
&lt;p&gt;Jolt's simplicity and focus on reducing boilerplate code make it stand out for quick prototyping and smaller projects with straightforward requirements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Jolt is best suited for developers who prefer a lightweight and minimalistic scaffolding tool for rapid project setup.&lt;/p&gt;
&lt;p&gt;&lt;a id="10-boilr"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;10. &lt;strong&gt;Boilr&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Boilr is a command-line scaffolding tool that utilizes a template registry, allowing developers to share and discover templates easily. It provides a curated list of templates for various languages and frameworks.&lt;/p&gt;
&lt;p&gt;Unlike Cookiecutter, Boilr's template registry simplifies the process of finding and using project templates, making it an excellent choice for developers who want a seamless experience with pre-built templates.&lt;/p&gt;
&lt;p&gt;Boilr's extensive template registry and its command-line interface make it stand out for its accessibility and ease of use.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best Use Case:&lt;/strong&gt; Boilr is best suited for developers who prefer a command-line tool with access to a wide variety of pre-built templates for different project types.&lt;/p&gt;
&lt;p&gt;&lt;a id="recommendations-for-various-use-cases"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Recommendations for various use-cases&lt;/h2&gt;
&lt;p&gt;Sure! Here are three distinct use cases with specific requirements, along with recommended tools for each use case:&lt;/p&gt;
&lt;p&gt;&lt;a id="use-case-1-rapid-prototyping-and-small-projects---plop"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Use Case 1: Rapid Prototyping and Small Projects - Plop&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lightweight and easy-to-use tool.&lt;/li&gt;
&lt;li&gt;Minimal configuration and setup.&lt;/li&gt;
&lt;li&gt;Ability to quickly generate boilerplate code and components.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recommended Tool: Plop&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Plop is an excellent choice for rapid prototyping and small projects due to its simplicity and focus on generating small, reusable templates. Its straightforward YAML-based configuration allows developers to get started quickly without the overhead of extensive setup. Plop's ability to create self-contained generators with custom logic and prompts makes it perfect for generating boilerplate code and components in a fast and efficient manner.&lt;/p&gt;
&lt;p&gt;&lt;a id="use-case-2-large-scale-projects-with-opinionated-conventions---yeoman"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Use Case 2: Large-Scale Projects with Opinionated Conventions - Yeoman&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Strong community support and a wide range of templates.&lt;/li&gt;
&lt;li&gt;Ability to enforce best practices and conventions for specific frameworks.&lt;/li&gt;
&lt;li&gt;Interactive user prompts for customizable project setups.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recommended Tool: Yeoman&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Yeoman is a powerful scaffolding tool with an extensive library of community-contributed generators, making it suitable for large-scale projects. It enforces opinionated conventions, which is beneficial for maintaining consistency and best practices across the codebase. Yeoman's interactive user prompts make project setup user-friendly, allowing developers to customize the generated code according to their specific requirements.&lt;/p&gt;
&lt;p&gt;&lt;a id="use-case-3-advanced-file-processing-and-task-automation---slush"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Use Case 3: Advanced File Processing and Task Automation - Slush&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integration with build tools for advanced file processing.&lt;/li&gt;
&lt;li&gt;Flexibility to manipulate and modify project structure during generation.&lt;/li&gt;
&lt;li&gt;Support for custom plugins and extensibility.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recommended Tool: Slush&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reasoning:&lt;/strong&gt; Slush is an ideal choice for projects that require advanced file processing and task automation during scaffolding. Built on top of Gulp.js, Slush leverages Gulp's streaming capabilities to process files, allowing developers to manipulate and modify the project structure during generation. Its pipeline-based approach and compatibility with Gulp plugins provide high flexibility and customization possibilities. Developers who are already familiar with Gulp will find Slush seamless to integrate into their existing build processes.&lt;/p&gt;
&lt;p&gt;These recommended tools cater to different use cases, ensuring that developers can find the most suitable scaffolding tool based on their project requirements and preferences.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While Cookiecutter is a popular choice for scaffolding projects, developers have several alternative tools to consider, each with its own unique features and characteristics. Depending on the project requirements, preferences, and familiarity with specific tools, developers can choose the one that best fits their needs. Whether it's Yeoman's opinionated approach, Plop's focus on micro-generators, or Sao's pluggable architecture, there is a suitable alternative for every scenario. Experimenting with these tools can significantly enhance the development workflow and productivity.&lt;/p&gt;</content><category term="note"></category><category term="cookiecutter"></category><category term="scaffolding"></category><category term="templates"></category><category term="python-project"></category></entry><entry><title>Lesser-known Python Package Repository Managers</title><link href="https://www.safjan.com/lesser-known-python-package-repository-managers/" rel="alternate"></link><published>2023-08-12T00:00:00+02:00</published><updated>2023-08-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-12:/lesser-known-python-package-repository-managers/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/Create Self-Hosted Python Package Repository/"&gt;Create Self-Hosted Python Package Repository - General Guide&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/storing-private-python-packages-with-local-nas-and-lightweight-servers/"&gt;Storing Private Python Packages with Local NAS and Lightweight Servers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://jfrog.com/artifactory/"&gt;Artifactory&lt;/a&gt; (paid) and &lt;a href="https://devpi.net/docs/devpi/devpi/stable/%2Bd/index.html"&gt;Devpi&lt;/a&gt; (free, open source) are most widely used python package repository managers, but there are some other interesting projects …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/Create Self-Hosted Python Package Repository/"&gt;Create Self-Hosted Python Package Repository - General Guide&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/storing-private-python-packages-with-local-nas-and-lightweight-servers/"&gt;Storing Private Python Packages with Local NAS and Lightweight Servers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://jfrog.com/artifactory/"&gt;Artifactory&lt;/a&gt; (paid) and &lt;a href="https://devpi.net/docs/devpi/devpi/stable/%2Bd/index.html"&gt;Devpi&lt;/a&gt; (free, open source) are most widely used python package repository managers, but there are some other interesting projects. Here are a few lesser-known Python package repository managers along with links to their source code or home websites.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#warehouse"&gt;Warehouse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pypiserver"&gt;pypiserver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bandersnatch"&gt;Bandersnatch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eggbasket"&gt;EggBasket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="warehouse"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Warehouse&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/pypa/warehouse.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;The current codebase behind the Python Package Index (PyPI). While not lesser-known, it's worth mentioning as an alternative to the official PyPI implementation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source Code: &lt;a href="https://github.com/pypa/warehouse"&gt;https://github.com/pypa/warehouse&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="pypiserver"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;pypiserver&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/pypiserver/pypiserver.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;PyHockey is a minimal Python package server that's easy to set up and use for hosting private packages.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source Code: &lt;a href="https://github.com/pypiserver/pypiserver"&gt;https://github.com/pypiserver/pypiserver&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="bandersnatch"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Bandersnatch&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/pypa/bandersnatch.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;A PyPI mirror client that can be used to create a complete copy of the Python Package Index (PyPI) locally or in a private network.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Home: &lt;a href="https://pypi.org/project/bandersnatch/"&gt;https://pypi.org/project/bandersnatch/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Source Code: &lt;a href="https://github.com/pypa/bandersnatch"&gt;https://github.com/pypa/bandersnatch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="eggbasket"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;EggBasket&lt;/h2&gt;
&lt;p&gt;EggBasket is a lightweight, easily-configurable Python package server designed for simplicity and ease of use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Home: &lt;a href="https://pypi.org/project/eggbasket/"&gt;https://pypi.org/project/eggbasket/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the popularity and maintenance status of these repositories may vary, so it's a good idea to review the documentation and GitHub repositories to ensure they meet your requirements before setting up a self-hosted package repository.&lt;/p&gt;</content><category term="note"></category><category term="pypi"></category><category term="python"></category><category term="python-package"></category><category term="package-repository"></category><category term="artifactory"></category><category term="devpi"></category></entry><entry><title>Split glued or joined words</title><link href="https://www.safjan.com/split-glued-or-joined-words/" rel="alternate"></link><published>2023-08-12T00:00:00+02:00</published><updated>2023-08-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-12:/split-glued-or-joined-words/</id><summary type="html">&lt;h2&gt;wordninja package&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/keredson/wordninja.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;install &lt;a href="https://github.com/keredson/wordninja"&gt;wordninja&lt;/a&gt; package: &lt;code&gt;pip install wordnija&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wordninja&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;wordninja&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bettergood&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;better&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;good&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;wordsegment package&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/grantjenks/python-wordsegment.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;install the &lt;a href="https://github.com/grantjenks/python-wordsegment"&gt;wordsegment&lt;/a&gt; package: &lt;code&gt;pip install wordsegment&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;use programatically:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;wordsegment&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segment&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;segment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;thisisatest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;this&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;or from CLI&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;echo …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h2&gt;wordninja package&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/keredson/wordninja.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;install &lt;a href="https://github.com/keredson/wordninja"&gt;wordninja&lt;/a&gt; package: &lt;code&gt;pip install wordnija&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wordninja&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;wordninja&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;bettergood&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;better&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;good&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;wordsegment package&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/grantjenks/python-wordsegment.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;install the &lt;a href="https://github.com/grantjenks/python-wordsegment"&gt;wordsegment&lt;/a&gt; package: &lt;code&gt;pip install wordsegment&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;use programatically:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;wordsegment&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segment&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;segment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;thisisatest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;this&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;or from CLI&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;thisisatest&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;python&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;wordsegment
this&lt;span class="w"&gt; &lt;/span&gt;is&lt;span class="w"&gt; &lt;/span&gt;a&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Solutions from: &lt;a href="https://stackoverflow.com/a/58010290"&gt;string - How can I split multiple joined words? - Stack Overflow&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="nlp"></category><category term="text-preprocessing"></category><category term="split-text"></category></entry><entry><title>Storing Private Python Packages with Local NAS and Lightweight Servers</title><link href="https://www.safjan.com/storing-private-python-packages-with-local-nas-and-lightweight-servers/" rel="alternate"></link><published>2023-08-12T00:00:00+02:00</published><updated>2023-08-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-12:/storing-private-python-packages-with-local-nas-and-lightweight-servers/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/Create Self-Hosted Python Package Repository/"&gt;Create Self-Hosted Python Package Repository - General Guide&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/lesser-known-python-package-repository-managers/"&gt;Lesser-known Python Package Repository Managers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are simple ways to store private Python packages on a local NAS (Network Attached Storage) without setting up a full-fledged package repository manager like Devpi or Artifactory …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/Create Self-Hosted Python Package Repository/"&gt;Create Self-Hosted Python Package Repository - General Guide&lt;/a&gt;
X::&lt;a href="https://www.safjan.com/lesser-known-python-package-repository-managers/"&gt;Lesser-known Python Package Repository Managers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are simple ways to store private Python packages on a local NAS (Network Attached Storage) without setting up a full-fledged package repository manager like Devpi or Artifactory. Here are a couple of straightforward alternatives:&lt;/p&gt;
&lt;h3&gt;Option 1: Local File System Repository&lt;/h3&gt;
&lt;p&gt;This approach involves creating a directory on your NAS to store your Python packages. You can use the &lt;code&gt;pip&lt;/code&gt; command's &lt;code&gt;--find-links&lt;/code&gt; option to specify the location of your custom package directory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Very simple setup and usage.&lt;/li&gt;
&lt;li&gt;Well-suited for small teams or personal projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of advanced features like access control, versioning, and replication.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Create a Packages Directory on NAS&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a directory on your NAS where you will store your Python packages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upload Packages to NAS&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy or move your Python packages into the NAS directory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Packages from NAS&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install packages from your NAS using the &lt;code&gt;pip&lt;/code&gt; command with the &lt;code&gt;--find-links&lt;/code&gt; option:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install --find-links=file:///path/to/nas/packages/ &amp;lt;package&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Option 2: Local PyPI Server&lt;/h3&gt;
&lt;p&gt;You can set up a lightweight local PyPI server like &lt;code&gt;pypiserver&lt;/code&gt; to serve your private Python packages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple setup with basic package management features.&lt;/li&gt;
&lt;li&gt;Suitable for small teams and projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;May lack advanced features like access control and versioning compared to full repository managers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;code&gt;pypiserver&lt;/code&gt;&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install &lt;code&gt;pypiserver&lt;/code&gt; using pip:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install pypiserver&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create a Packages Directory&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a directory to store your Python packages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start &lt;code&gt;pypiserver&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the &lt;code&gt;pypiserver&lt;/code&gt; with the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pypi-server -p 8080 /path/to/packages/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upload and Install Packages&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Copy your Python packages to the packages directory.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install packages using the &lt;code&gt;pip&lt;/code&gt; command with the local PyPI server URL:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install --index-url=http://localhost:8080/simple/ &amp;lt;package&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These simpler approaches provide a way to store private Python packages on a local NAS without the overhead of setting up a comprehensive repository manager. Choose the option that best fits your needs and resources. Keep in mind that while these methods are simpler, they lack some advanced features and may not be as scalable or secure as full repository managers.&lt;/p&gt;</content><category term="note"></category><category term="pypi"></category><category term="python"></category><category term="python-package"></category><category term="package-repository"></category><category term="nas"></category></entry><entry><title>Prompt Discovery in the Context of Large Language Models (LLMs) and Prompt Engineering</title><link href="https://www.safjan.com/prompt_discivery-large-language-models-llms-prompt-engineering/" rel="alternate"></link><published>2023-08-08T00:00:00+02:00</published><updated>2023-08-08T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-08:/prompt_discivery-large-language-models-llms-prompt-engineering/</id><summary type="html">&lt;p&gt;Prompt discovery in the context of large language models refers to the systematic process of identifying and optimizing prompts to elicit desired responses from the model. It involves formulating prompts in a way that effectively guides the model's generation towards accurate, relevant …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Prompt discovery in the context of large language models refers to the systematic process of identifying and optimizing prompts to elicit desired responses from the model. It involves formulating prompts in a way that effectively guides the model's generation towards accurate, relevant, and high-quality outputs. Prompt engineering is a critical component of this process, as it encompasses the design and refinement of prompts to achieve specific tasks or goals.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#technical-aspects-of-prompt-discovery"&gt;Technical Aspects of Prompt Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#activities-and-challenges-in-prompt-discovery"&gt;Activities and Challenges in Prompt Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#types-of-tools-and-technologies-for-prompt-discovery"&gt;Types of Tools and Technologies for Prompt Discovery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="technical-aspects-of-prompt-discovery"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Technical Aspects of Prompt Discovery&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Formulation and Structure&lt;/strong&gt;: This involves crafting prompts using appropriate syntax, keywords, and context to provide clear instructions to the model. Experimentation with different sentence structures, question formats, and contextual cues can impact the model's understanding and response.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semantic Representation&lt;/strong&gt;: Developing prompts that capture the desired semantic meaning and intent is crucial. This may involve exploring semantic role labeling, syntactic analysis, and dependency parsing to create prompts that effectively guide the model's reasoning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Permutations&lt;/strong&gt;: Generating a diverse set of prompt variations can help in identifying which phrasings or formulations yield the best results. This could involve systematically modifying sentence structure, word order, or incorporating synonyms and paraphrases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Length and Complexity&lt;/strong&gt;: Analyzing the impact of prompt length and complexity on model performance. Longer prompts may provide more context but risk confusing the model, while shorter prompts might lack necessary context.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multi-step Prompts&lt;/strong&gt;: Crafting prompts that involve multi-step instructions or conditional logic to guide the model through a series of steps to reach a desired conclusion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Contextualization&lt;/strong&gt;: Incorporating relevant context or domain-specific information within prompts to enhance the model's knowledge and improve response quality.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Targeting&lt;/strong&gt;: Experimenting with prompts that explicitly mention the desired answer or output, guiding the model toward a specific response.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="activities-and-challenges-in-prompt-discovery"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Activities and Challenges in Prompt Discovery&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Effectiveness Evaluation&lt;/strong&gt;: Developing methodologies to quantitatively and qualitatively assess the effectiveness of different prompts in eliciting accurate and relevant responses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Generalization&lt;/strong&gt;: Investigating how well a well-optimized prompt can generalize across different models, architectures, and datasets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Adaptation&lt;/strong&gt;: Identifying techniques to adapt prompts for various domains, languages, or tasks, considering nuances in language and context.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Prompt Design&lt;/strong&gt;: Exploring methods to create prompts that challenge the model's limitations and encourage robustness against adversarial inputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Active Learning for Prompt Refinement&lt;/strong&gt;: Developing algorithms that iteratively learn and refine prompts based on model performance, aiming to reduce human intervention in the prompt engineering process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Diversity Exploration&lt;/strong&gt;: Analyzing the impact of diverse prompts on model behavior, uncovering potential biases, and ensuring fairness in responses.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="types-of-tools-and-technologies-for-prompt-discovery"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Types of Tools and Technologies for Prompt Discovery&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Generation Assistants&lt;/strong&gt;: AI-driven tools that provide prompt suggestions, permutations, and optimizations based on user-defined criteria and objectives.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Evaluation Metrics&lt;/strong&gt;: Novel metrics that quantitatively measure the quality, relevance, and correctness of model responses based on different prompts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Semantic Prompt Analysis&lt;/strong&gt;: Advanced natural language understanding tools capable of dissecting prompt semantics, identifying key components, and suggesting improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Optimization Algorithms&lt;/strong&gt;: Algorithms that leverage reinforcement learning, genetic algorithms, or neural architecture search to automatically discover effective prompts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt-Aware Model Architectures&lt;/strong&gt;: Model architectures explicitly designed to leverage and incorporate prompt information effectively during the generation process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Contextualization Modules&lt;/strong&gt;: Modules that enhance prompts with contextual information, leveraging external knowledge sources or domain-specific databases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bias and Fairness Detection Tools&lt;/strong&gt;: Tools that analyze prompts for potential bias and fairness issues, ensuring the generated responses align with ethical and unbiased standards.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interactive Prompt Refinement Interfaces&lt;/strong&gt;: Interfaces allowing users to interactively refine and experiment with prompts, providing real-time feedback on model responses.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As the field of prompt engineering and large language models evolves, these tools and techniques will likely become more sophisticated, enabling more efficient and effective prompt discovery processes. There are few tools available at the time of writing (Aug 2023):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ianarawjo/ChainForge"&gt;ianarawjo/ChainForge&lt;/a&gt; - An open-source visual programming environment for LLM experimentation and prompt evaluation.
&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/ianarawjo/ChainForge.svg?logo=github"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/logspace-ai/langflow"&gt;logspace-ai/langflow&lt;/a&gt; - Langflow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.
&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/logspace-ai/langflow.svg?logo=github"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/FlowiseAI/Flowise"&gt;FlowiseAI/Flowise&lt;/a&gt; - Drag &amp;amp; drop UI to build your customized LLM flow
&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/FlowiseAI/Flowise.svg?logo=github"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="prompt-engineering"></category><category term="prompting"></category><category term="large-language-models"></category><category term="llm"></category></entry><entry><title>Azure OpenAI Langchain configuration</title><link href="https://www.safjan.com/azure-openai-langchain-configuration/" rel="alternate"></link><published>2023-08-02T00:00:00+02:00</published><updated>2023-10-23T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-08-02:/azure-openai-langchain-configuration/</id><summary type="html">&lt;p&gt;This note contains a recipe for how to configure LangChain to use Azure OpenAI.&lt;/p&gt;
&lt;p&gt;NOTE: requires &lt;code&gt;python-dotenv&lt;/code&gt; python package installed&lt;/p&gt;
&lt;h2&gt;create &lt;code&gt;.env&lt;/code&gt; with configuration and secrets&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;OPENAI_API_TYPE=&amp;quot;azure&amp;quot;
OPENAI_API_KEY=&amp;quot;***&amp;quot;
OPENAI_API_BASE=&amp;quot;***&amp;quot;
OPENAI_API_VERSION=&amp;quot;***&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;initialize langchain&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dotenv&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;find_dotenv&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;langchain.llms&lt;/span&gt; &lt;span class="kn"&gt;import …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;This note contains a recipe for how to configure LangChain to use Azure OpenAI.&lt;/p&gt;
&lt;p&gt;NOTE: requires &lt;code&gt;python-dotenv&lt;/code&gt; python package installed&lt;/p&gt;
&lt;h2&gt;create &lt;code&gt;.env&lt;/code&gt; with configuration and secrets&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;OPENAI_API_TYPE=&amp;quot;azure&amp;quot;
OPENAI_API_KEY=&amp;quot;***&amp;quot;
OPENAI_API_BASE=&amp;quot;***&amp;quot;
OPENAI_API_VERSION=&amp;quot;***&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;initialize langchain&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dotenv&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;find_dotenv&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;langchain.llms&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AzureOpenAI&lt;/span&gt;

&lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;find_dotenv&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;deployment_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;text-davinci-003&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;model_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;text-davinci-003&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;llm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AzureOpenAI&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;deployment_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;deployment_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# check if it works&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;llm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;What is the capital of France?&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;NOTE: &lt;code&gt;find_dotenv&lt;/code&gt; -  its purpose is to locate the &lt;code&gt;.env&lt;/code&gt; file in your project directory or its parent directories. It starts the search from the current working directory and recursively moves up the directory tree until it finds the &lt;code&gt;.env&lt;/code&gt; file. If no &lt;code&gt;.env&lt;/code&gt; file is found, it returns the path of the current working directory. This function is beneficial because it ensures your code can locate the &lt;code&gt;.env&lt;/code&gt; file regardless of the directory from which your script is executed.&lt;/p&gt;</content><category term="note"></category><category term="langchain"></category><category term="azure"></category><category term="openai"></category></entry><entry><title>Rank Fusion Algorithms - From Simple to Advanced</title><link href="https://www.safjan.com/Rank-fusion-algorithms-from-simple-to-advanced/" rel="alternate"></link><published>2023-07-28T00:00:00+02:00</published><updated>2024-07-14T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-28:/Rank-fusion-algorithms-from-simple-to-advanced/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Rank fusion is a fundamental technique used in various domains, including data science and search engine optimization, to combine multiple ranked lists into a single, more reliable ranking. This process aims to exploit the strengths of individual ranking algorithms and mitigate …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Rank fusion is a fundamental technique used in various domains, including data science and search engine optimization, to combine multiple ranked lists into a single, more reliable ranking. This process aims to exploit the strengths of individual ranking algorithms and mitigate their weaknesses, leading to improved overall performance. In this blog post, we will explore a range of rank fusion algorithms, starting from simple yet effective methods to advanced techniques employed by tech giants to achieve state-of-the-art results. If you want to analyse rank changes over time in a visual manner, you might be interested in using &lt;a href="https://www.safjan.com/rankflow-plot-for-retriever-visual-evaluation/"&gt;RankFlow plot for retriever visual evaluation&lt;/a&gt; package.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#algorithms"&gt;Algorithms&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#borda-algorithm"&gt;Borda Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#combining-probability-mass-function-cpmf"&gt;Combining Probability Mass Function (CPMF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rank-biased-precision-rbp"&gt;Rank-Biased Precision (RBP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lambdamart"&gt;LambdaMART&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#neural-rank-fusion"&gt;Neural Rank Fusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reciprocal-rank-fusion"&gt;Reciprocal rank fusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#references"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="algorithms"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Algorithms&lt;/h2&gt;
&lt;p&gt;&lt;a id="borda-algorithm"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Borda Algorithm&lt;/h3&gt;
&lt;p&gt;The Borda algorithm is one of the simplest rank fusion techniques. It assigns scores to items based on their positions in the individual rankings and then combines these scores to obtain a fused ranking. In the context of search engine results, each document receives points based on its position in the ranked lists. The points are then summed up to form the final rank.&lt;/p&gt;
&lt;p&gt;Consider &lt;span class="math"&gt;\(n\)&lt;/span&gt; ranked lists &lt;span class="math"&gt;\(\{R_1, R_2, \ldots, R_n\}\)&lt;/span&gt; with &lt;span class="math"&gt;\(m\)&lt;/span&gt; items. The Borda algorithm assigns points to each item &lt;span class="math"&gt;\(i\)&lt;/span&gt; in the following way:&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{Borda Score}(i) = \sum_{j=1}^{n} (m - \text{rank}_j(i))
$$&lt;/div&gt;
&lt;p&gt;
Where &lt;span class="math"&gt;\(\text{rank}_j(i)\)&lt;/span&gt; denotes the position of item &lt;span class="math"&gt;\(i\)&lt;/span&gt; in the &lt;span class="math"&gt;\(j\)&lt;/span&gt;th ranked list.&lt;/p&gt;
&lt;p&gt;The Borda algorithm is easy to implement, but it might lag in performance for large datasets or when the individual rankings are significantly diverse. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;See also: &lt;a href="https://www.safjan.com/borda-count-vs-reciprocal-rank/"&gt;Borda Count vs. Reciprocal Rank - Choosing the Right Ranking Method for Your Data&lt;/a&gt; for algorithm characterization and examples.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="combining-probability-mass-function-cpmf"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Combining Probability Mass Function (CPMF)&lt;/h3&gt;
&lt;p&gt;CPMF is a probabilistic rank fusion method that incorporates the probability of an item being at a certain rank in individual lists. It assumes that the rankings are probabilistic and uses the Probability Mass Function (PMF) to calculate the fused ranking. CPMF outperforms Borda for diverse and noisy datasets.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt; be the probability that item &lt;span class="math"&gt;\(i\)&lt;/span&gt; appears at rank &lt;span class="math"&gt;\(j\)&lt;/span&gt; in the &lt;span class="math"&gt;\(n\)&lt;/span&gt; lists. The CPMF score for item &lt;span class="math"&gt;\(i\)&lt;/span&gt; is given by:&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{CPMF Score}(i) = \sum_{j=1}^{m} p_{ij}
$$&lt;/div&gt;
&lt;p&gt;The probabilities &lt;span class="math"&gt;\(p_{ij}\)&lt;/span&gt; can be estimated using techniques like the &lt;a href="https://hturner.github.io/PlackettLuce/articles/Overview.html"&gt;Plackett-Luce model&lt;/a&gt; or the Thurstone-Mosteller model.&lt;/p&gt;
&lt;p&gt;&lt;a id="rank-biased-precision-rbp"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Rank-Biased Precision (RBP)&lt;/h3&gt;
&lt;p&gt;RBP is a rank fusion method widely used in information retrieval systems. It incorporates a user-defined persistence parameter &lt;span class="math"&gt;\(p\)&lt;/span&gt; to reflect the probability that a user will examine the search results up to a certain rank. This parameter allows the search engine to optimize rankings based on user behavior.&lt;/p&gt;
&lt;p&gt;For a given ranked list &lt;span class="math"&gt;\(R_j\)&lt;/span&gt;, the RBP score is calculated as follows:&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{RBP Score}(R_j) = (1 - p) \sum_{k=1}^{m} p^{k-1} \text{rel}(R_j[k])
$$&lt;/div&gt;
&lt;p&gt;
Where &lt;span class="math"&gt;\(\text{rel}(R_j[k])\)&lt;/span&gt; is an indicator function representing the relevance of the item at rank &lt;span class="math"&gt;\(k\)&lt;/span&gt; in list &lt;span class="math"&gt;\(R_j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;RBP provides more flexibility in tuning the importance of different ranks based on user preferences.&lt;/p&gt;
&lt;p&gt;&lt;a id="lambdamart"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;LambdaMART&lt;/h3&gt;
&lt;p&gt;LambdaMART is an advanced algorithm used by tech giants like Microsoft and Yahoo for learning-to-rank tasks. It is based on the gradient boosting framework and employs LambdaRank, which optimizes the ListNet loss function using gradient descent.&lt;/p&gt;
&lt;p&gt;The LambdaMART algorithm involves constructing a set of weak rankers (usually decision trees) that are iteratively refined to minimize the LambdaRank objective, which directly measures the pairwise disagreement between ranks.&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{LambdaRank Objective} = \sum_{i=1}^{m} \sum_{j=1}^{m} \text{DCG gain}(i, j) \cdot \text{Lambda}(i, j)
$$&lt;/div&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(\text{DCG gain}(i, j)\)&lt;/span&gt; is the gain of swapping items at ranks &lt;span class="math"&gt;\(i\)&lt;/span&gt; and &lt;span class="math"&gt;\(j\)&lt;/span&gt; in the ranking, and &lt;span class="math"&gt;\(\text{Lambda}(i, j)\)&lt;/span&gt; is a weight function that depends on the gradients of the individual models.&lt;/p&gt;
&lt;p&gt;LambdaMART's ability to optimize for ranking measures directly contributes to its superior performance in learning-to-rank scenarios.&lt;/p&gt;
&lt;p&gt;&lt;a id="neural-rank-fusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Neural Rank Fusion&lt;/h3&gt;
&lt;p&gt;With the rise of deep learning, neural rank fusion methods have gained popularity due to their ability to learn complex patterns from data. Neural rank fusion models typically employ techniques like siamese networks or transformer-based architectures to process individual rankings and generate a fused ranking.&lt;/p&gt;
&lt;p&gt;In a siamese network-based approach, the individual rankings are fed into two parallel networks with shared weights. The networks learn to map the rankings into a common embedding space, where the fused ranking is generated based on similarity scores.&lt;/p&gt;
&lt;p&gt;On the other hand, transformer-based rank fusion models utilize attention mechanisms to process and combine individual rankings effectively.&lt;/p&gt;
&lt;p&gt;Neural rank fusion methods often outperform traditional algorithms when sufficient training data is available, but they may require substantial computational resources.&lt;/p&gt;
&lt;p&gt;&lt;a id="reciprocal-rank-fusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Reciprocal Rank Fusion&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf"&gt;Reciprocal Rank Fusion (RRF)&lt;/a&gt; is an advanced algorithmic technique designed to amalgamate multiple result sets, each having distinct relevance indicators, into a unified result set. One of the key advantages of RRF is its ability to deliver high-quality results without the necessity for any tuning. Moreover, it does not mandate the relevance indicators to be interconnected or similar in nature.&lt;/p&gt;
&lt;p&gt;Diving deeper into the algorithm, RRF is based on the concept of reciprocal rank. The reciprocal rank of a document is the multiplicative inverse of its rank. In the context of information retrieval, the rank of a document is its position in a list of documents sorted by relevance. The reciprocal rank is used to give higher weight to documents that appear earlier in the list.&lt;/p&gt;
&lt;p&gt;The RRF algorithm combines the reciprocal ranks of the same document from different result sets to compute a combined score. The combined score is then used to rank the documents in the final result set. The formula used in the RRF algorithm is as follows:&lt;/p&gt;
&lt;div class="math"&gt;$$
\text{RRF Score} = \frac{1}{k + rank}
$$&lt;/div&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(k\)&lt;/span&gt; is a constant (usually set to 60), and &lt;span class="math"&gt;\(rank\)&lt;/span&gt; is the rank of the document in a particular result set. The RRF score is calculated for each document in each result set, and the scores are then summed up to get the final score for each document.&lt;/p&gt;
&lt;p&gt;The properties of the RRF algorithm include its simplicity, effectiveness, and robustness. It is simple because it only requires the ranks of the documents and does not need any tuning. It is effective because it can combine result sets with different relevance indicators and still produce high-quality results. It is robust because it is not sensitive to the choice of &lt;span class="math"&gt;\(k\)&lt;/span&gt; and can handle a large number of result sets.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;See also &lt;a href="https://www.safjan.com/borda-count-vs-reciprocal-rank/"&gt;Borda Count vs. Reciprocal Rank - Choosing the Right Ranking Method for Your Data&lt;/a&gt; for algorithm characterization and examples and &lt;a href="https://www.safjan.com/implementing-rank-fusion-in-python/"&gt;Implementing Reciprocal Rank Fusion (RRF) in Python&lt;/a&gt;.
&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Rank fusion serves as a potent tool in the arsenal of data scientists and search engine experts, enhancing the efficacy of ranking performance. The spectrum of rank fusion algorithms ranges from the &lt;strong&gt;straightforward Borda algorithm&lt;/strong&gt; to the more complex Neural Rank Fusion, each tailored to meet specific scenarios and data attributes. While the &lt;strong&gt;Borda&lt;/strong&gt; algorithm is &lt;strong&gt;appreciated&lt;/strong&gt; for its &lt;strong&gt;simplicity&lt;/strong&gt; and &lt;strong&gt;ease of implementation&lt;/strong&gt;, more advanced techniques like &lt;strong&gt;LambdaMART&lt;/strong&gt; and &lt;strong&gt;Neural Rank Fusion&lt;/strong&gt; are capable of delivering &lt;strong&gt;cutting-edge results for large-scale applications&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Incorporating the Reciprocal Rank Fusion (RRF) into this discussion, it stands out for its ability to &lt;strong&gt;combine multiple result sets with varying relevance indicators&lt;/strong&gt; &lt;strong&gt;without the need for tuning&lt;/strong&gt;. This makes it a robust and effective choice for many applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edits&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2024-07-15 - Added cross-link to borda vs reciprocal rank comparison and reciprocal rank implementation in Python.&lt;/li&gt;
&lt;li&gt;2024-07-14 - Added reference to rankflow (ranks plotting)&lt;/li&gt;
&lt;li&gt;2024-03-06 - Added Panjete/rankAggr to references&lt;/li&gt;
&lt;li&gt;2023-10-09 - Added "Reciprocal Rank Fusion", rewrite conclusion
&lt;a id="references"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Wikipedia article: &lt;a href="https://en.wikipedia.org/wiki/Borda_count"&gt;Borda algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/"&gt;From RankNet to LambdaRank to LambdaMART: An Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/"&gt;Burges, Christopher. "From RankNet to LambdaRank to LambdaMART: An overview." Learning 11.23-581 (2010): 81.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.eng.unimelb.edu.au/jzobel/fulltext/acmtois08.pdf"&gt;Rank-Biased Precision for Measurement of Retrieval Effectiveness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf"&gt;Reciprocal rank fusion (RRF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Panjete/rankAggr"&gt;GitHub - Panjete/rankAggr: Analysis and implementational details of rank aggregation methods for combing results of multiple engines to achieve best mAP and P@5,10 values&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/borda-count-vs-reciprocal-rank/"&gt;Borda Count vs. Reciprocal Rank - Choosing the Right Ranking Method for Your Data&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="rank-fusion"></category><category term="rank"></category><category term="search"></category><category term="hybrid-search"></category><category term="borda"></category><category term="combining-probability-mass-function"></category><category term="rank-biased-precision"></category><category term="neural-rank-fusion"></category><category term="reciprocal-rank-fusion"></category></entry><entry><title>Implementing Reciprocal Rank Fusion (RRF) in Python</title><link href="https://www.safjan.com/implementing-rank-fusion-in-python/" rel="alternate"></link><published>2023-07-28T00:00:00+02:00</published><updated>2024-07-14T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-28:/implementing-rank-fusion-in-python/</id><summary type="html">&lt;p&gt;In the Information Retrieval, ranking is one of the most crucial aspects. It prioritizes the matching information according to its relevancy. In many cases, having a single ranking model may not satisfy the diverse needs of users. This is where the idea …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the Information Retrieval, ranking is one of the most crucial aspects. It prioritizes the matching information according to its relevancy. In many cases, having a single ranking model may not satisfy the diverse needs of users. This is where the idea of Rank Fusion comes in; combining various ranking models to enhance the retrieval performance.
Let's learn how to implement a simple rank fusion approach in Python.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE:  If you want to analyse rank changes over time in a visual manner, you might be interested in using &lt;a href="https://www.safjan.com/rankflow-plot-for-retriever-visual-evaluation/"&gt;RankFlow plot for retriever visual evaluation&lt;/a&gt; package.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Understanding the RRF Ranking Process&lt;/h2&gt;
&lt;p&gt;The Reciprocal Rank Fusion (RRF) operates by collecting search outcomes from various strategies, assigning each document in the results a reciprocal rank score, and subsequently merging these scores to generate a new ranking. The underlying principle is that documents that consistently appear in top positions across diverse search strategies are likely more pertinent and should thus receive a higher rank in the consolidated result.&lt;/p&gt;
&lt;h3&gt;A simplified breakdown of the RRF process&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Collect ranked search outcomes&lt;/strong&gt; from multiple simultaneous queries. E.g. one query to semantic search and one query to text search.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assign reciprocal rank scores to each result in the ranked lists.&lt;/strong&gt; The RRF process generates a new search score for each match in each result set. For each document in the search results, the algorithm assigns a reciprocal rank score based on its position in the list. This score is computed as &lt;span class="math"&gt;\(1/(rank + k)\)&lt;/span&gt;, where &lt;span class="math"&gt;\(rank\)&lt;/span&gt; is the document's position in the list, and &lt;span class="math"&gt;\(k\)&lt;/span&gt; is a constant. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Choosing the k constant&lt;/strong&gt;
Empirical observation suggests that &lt;span class="math"&gt;\(k\)&lt;/span&gt; performs best when set to a small value, such as &lt;code&gt;60&lt;/code&gt;. Note that this &lt;span class="math"&gt;\(k\)&lt;/span&gt; value is a constant in the RRF algorithm and is entirely distinct from the &lt;code&gt;k&lt;/code&gt; that regulates the number of nearest neighbours.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Combine scores.&lt;/strong&gt; The algorithm adds up the reciprocal rank scores acquired from each search strategy for each document, thereby generating a combined score for each document.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The algorithm ranks documents based on the combined scores and arranges them accordingly. The resulting list constitutes the fused ranking.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To depict the Reciprocal Rank Fusion (RRF) process, we can use a flowchart.
&lt;img alt="Reciprocal Rank Fusion (RRF) process flow chart" src="/images/Reciprocal_Rank_Fusion/Reciprocal_Rank_Fusion.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*Figure 1:&lt;/strong&gt; Reciprocal Rank Fusion (RRF) Process Flowchart. The diagram illustrates the steps involved in the RRF ranking process.&lt;/p&gt;
&lt;h2&gt;Implementing Reciprocal Rank Fusion&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf"&gt;Reciprocal Rank Fusion (RRF)&lt;/a&gt; is an advanced algorithmic technique designed to amalgamate multiple result sets, each having distinct relevance indicators, into a unified result set. One of the key advantages of RRF is its ability to deliver high-quality results without the necessity for any tuning. Moreover, it does not mandate the relevance indicators to be interconnected or similar in nature.&lt;/p&gt;
&lt;p&gt;RRF uses the following formula to determine the score for ranking each document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;queries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# loop over queries send to different search engines &lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;

&lt;span class="c1"&gt;# where&lt;/span&gt;
&lt;span class="c1"&gt;# k is a ranking constant&lt;/span&gt;
&lt;span class="c1"&gt;# q is a query in the set of queries&lt;/span&gt;
&lt;span class="c1"&gt;# d is a document in the result set of q&lt;/span&gt;
&lt;span class="c1"&gt;# result(q) is the result set of q&lt;/span&gt;
&lt;span class="c1"&gt;# rank( result(q), d ) is d&amp;#39;s rank within the result(q) starting from 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(code from &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html"&gt;Elasticsearch documentation&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;You could significantly improve performance by using maps and list comprehensions -  referred to as "vectorizing" in overlapping contexts.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reciprocal_rank_fusion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;queries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rank_func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;rank_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;result_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;queries&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function takes as arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A collection of queries&lt;/li&gt;
&lt;li&gt;A document &lt;code&gt;d&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A ranking constant &lt;code&gt;k&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A function &lt;code&gt;result_func&lt;/code&gt; that represents the &lt;code&gt;result(q)&lt;/code&gt; operation in your original code.&lt;/li&gt;
&lt;li&gt;A function &lt;code&gt;rank_func&lt;/code&gt; that represents the &lt;code&gt;rank(result(q), d)&lt;/code&gt; operation in your original code.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; list comprehension is used to perform the operations that for-loop did, allowing Python to compute the results in a more optimized way. However, this isn't truly "vectorized" computing as you would find in libraries like NumPy or in languages like R, where computations are performed concurrently rather than sequentially.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;code&gt;result_func&lt;/code&gt; function takes a query &lt;code&gt;q&lt;/code&gt;, and returns a list of documents that are the results of the query. For simplicity, let's assume that each query corresponds to a list of documents in a dictionary called &lt;code&gt;database&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rank_func&lt;/code&gt; function takes a list of documents (results of a query) and a specific document &lt;code&gt;d&lt;/code&gt;, and returns the rank of &lt;code&gt;d&lt;/code&gt; in the list.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;database&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;   &lt;span class="c1"&gt;# assuming your queries and results are stored in a dictionary&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;query1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;doc1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;doc2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;doc3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;query2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;doc3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;doc1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;doc2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="c1"&gt;# more queries and their document results...&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;result_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;database&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rank_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;# adding 1 because ranks start from 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the &lt;code&gt;reciprocal_rank_fusion&lt;/code&gt; function can be called like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; 
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;doc1&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;queries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;query1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;query2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# fill this with your actual query keys&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reciprocal_rank_fusion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;queries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rank_func&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This assumes that queries and their corresponding results are uniquely stored in a dictionary, and that your document ranks are determined by their order in the list of results.&lt;/p&gt;
&lt;p&gt;Please modify the functions &lt;code&gt;result_func&lt;/code&gt;, &lt;code&gt;rank_func&lt;/code&gt;, and &lt;code&gt;database&lt;/code&gt; to fit your specific application details and data.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The concept of Rank Fusion, particularly the Reciprocal Rank Fusion (RRF) method, offers a promising approach to amalgamate multiple result sets into a unified one. This article has demonstrated how to implement a simple RRF in Python.&lt;/p&gt;
&lt;p&gt;While the example provided in this article is simplified, it provides a solid foundation for understanding the RRF process and how to implement it in Python. Depending on the specific application and data, the functions and database structure may need to be modified. However, the core concept and approach remain the same.&lt;/p&gt;
&lt;p&gt;The RRF method is a powerful tool in the field of Information Retrieval, providing a robust and efficient way to combine multiple ranking models to enhance retrieval performance. By understanding and implementing this method, one can significantly improve the quality and relevance of search results, thereby enhancing user satisfaction and system effectiveness.&lt;/p&gt;
&lt;h2&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Condorcet Fuse (&lt;a href="https://www.khoury.northeastern.edu/~jaa/IS4200.10X1/resources/condorcet.pdf"&gt;pdf&lt;/a&gt;) Montague, M., and Aslam, J. A. Condorcet fusion for improved retrieval. In CIKM (2002).)&lt;/li&gt;
&lt;li&gt;CombMNZ:&lt;ul&gt;
&lt;li&gt;Gopalan, N.P., Batri, K. Adaptive Selection of Top-m Retrieval Strategies for Data Fusion in Information Retrieval. In: International Journal of Soft Computing, 2(1):11-16, 2007.&lt;/li&gt;
&lt;li&gt;Hsu, D.F., Taksa, I. Comparing Rank and Score Combination Methods for Data Fusion in Information Retrieval. In: Information Retrieval 8(3):449-480, 2005.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Edits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2024-07-14: Added reference to the rankflow plotting package&lt;/li&gt;
&lt;li&gt;2023-11-06: Changed title to: Implementing Reciprocal Rank Fusion and Borda Count in Python&lt;/li&gt;
&lt;li&gt;2023-11-06: Added RRF description&lt;/li&gt;
&lt;li&gt;2023-11-06: Added optimized implementation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;X::&lt;a href="https://www.safjan.com/Rank-fusion-algorithms-from-simple-to-advanced/"&gt;Rank Fusion Algorithms - From Simple to Advanced&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="rank-fusion"></category><category term="hybrid-search"></category><category term="rank"></category><category term="search"></category><category term="python"></category></entry><entry><title>gitignore-style exclusion for restic</title><link href="https://www.safjan.com/gitignore-style-exclusion-for-restic/" rel="alternate"></link><published>2023-07-27T00:00:00+02:00</published><updated>2023-07-27T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-27:/gitignore-style-exclusion-for-restic/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/verify-backups-restic-example/"&gt;Don't Just Create Backups, Verify Them - How Restic Can Help?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Restic is a popular backup tool that supports the use of &lt;code&gt;.gitignore&lt;/code&gt;-style exclusion patterns to ignore certain files and directories during the backup process. This feature is useful when you …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/verify-backups-restic-example/"&gt;Don't Just Create Backups, Verify Them - How Restic Can Help?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Restic is a popular backup tool that supports the use of &lt;code&gt;.gitignore&lt;/code&gt;-style exclusion patterns to ignore certain files and directories during the backup process. This feature is useful when you want to exclude specific files or directories from being backed up, such as temporary files, caches, or build artifacts.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;ignore&lt;/code&gt; with Restic, you can create a file called &lt;code&gt;.resticignore&lt;/code&gt; in the root of your repository (where you run Restic). This file should contain the patterns for the files and directories you want to ignore, just like you would do with a &lt;code&gt;.gitignore&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Here's how you can use &lt;code&gt;ignore&lt;/code&gt; in Restic:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;code&gt;.resticignore&lt;/code&gt; file:
   Inside your project's root directory (or the directory you're backing up), create a file named &lt;code&gt;.resticignore&lt;/code&gt;. You can use any text editor to create this file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add patterns to ignore:
   In the &lt;code&gt;.resticignore&lt;/code&gt; file, list the files and directories you want to ignore during the backup. Each pattern should be on a separate line. You can use the same syntax as you would in a &lt;code&gt;.gitignore&lt;/code&gt; file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For example, a simple &lt;code&gt;.resticignore&lt;/code&gt; file might look like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;*.log
   temp/
   cache/
   build/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The above example would ignore all files with the &lt;code&gt;.log&lt;/code&gt; extension and the &lt;code&gt;temp&lt;/code&gt;, &lt;code&gt;cache&lt;/code&gt;, and &lt;code&gt;build&lt;/code&gt; directories.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Run Restic backup with &lt;code&gt;--ignore-file&lt;/code&gt; option:
   When running Restic to perform the backup, specify the &lt;code&gt;.resticignore&lt;/code&gt; file using the &lt;code&gt;--ignore-file&lt;/code&gt; option. This tells Restic to use the patterns in that file to exclude certain files and directories.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here's an example command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;restic backup /path/to/your/data --ignore-file /path/to/.resticignore&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Replace &lt;code&gt;/path/to/your/data&lt;/code&gt; with the actual path of the data you want to back up and &lt;code&gt;/path/to/.resticignore&lt;/code&gt; with the path to your &lt;code&gt;.resticignore&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;By using the &lt;code&gt;.resticignore&lt;/code&gt; file, you can customize what gets backed up and what gets excluded. This can be particularly useful to avoid backing up large or unnecessary files, reducing storage space and backup time.&lt;/p&gt;</content><category term="note"></category><category term="restic"></category><category term="ignore"></category><category term="gitignore"></category></entry><entry><title>Location of Python Virtual Environments - Choosing Between Project-Folder and Centralized Folder</title><link href="https://www.safjan.com/location-of-python-virtual-environments-choosing-between-project-folder-and-central-folder/" rel="alternate"></link><published>2023-07-27T00:00:00+02:00</published><updated>2023-07-27T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-27:/location-of-python-virtual-environments-choosing-between-project-folder-and-central-folder/</id><summary type="html">&lt;h2&gt;Project-folder Virtual Environments&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this approach, you create a virtual environment &lt;strong&gt;within the project directory&lt;/strong&gt; itself. This means that each project has its isolated Python environment, and you manage dependencies specific to that project.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this approach you have clarity where the …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Project-folder Virtual Environments&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this approach, you create a virtual environment &lt;strong&gt;within the project directory&lt;/strong&gt; itself. This means that each project has its isolated Python environment, and you manage dependencies specific to that project.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this approach you have clarity where the associated venv resides - helpful when doing cleanup or backup.&lt;/p&gt;
&lt;h2&gt;Centralized Location for Virtual Environments&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In this approach, you create a &lt;strong&gt;centralized directory&lt;/strong&gt; where &lt;strong&gt;all virtual environments reside&lt;/strong&gt;. This directory can be outside your projects, e.g., &lt;code&gt;~/.virtualenvs&lt;/code&gt; or any other location you prefer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this approach you keep project directory containing mainly code - the other, replicable content - virtual environment files - are located somewhere outside the project. This helps to e.g. backup whole directory without worrying about excluding virtualenv which is typically not worth backing-up.&lt;/p&gt;
&lt;p&gt;X: &lt;a href="https://www.safjan.com/python-create-virtualenv-methods/"&gt;Creating Virtual Environments in Python&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="virtualenv"></category><category term="location"></category><category term="venv-dir"></category></entry><entry><title>Cookiecutters for the python package with poetry</title><link href="https://www.safjan.com/cookiecutter-for-the-python-package-with-poetry/" rel="alternate"></link><published>2023-07-26T00:00:00+02:00</published><updated>2023-07-26T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-26:/cookiecutter-for-the-python-package-with-poetry/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutter-and-poetry-for-python-project-scaffolding"&gt;Cookiecutter and Poetry for Python Project Scaffolding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#benefits-of-using-cookiecutter-for-project-scaffolding"&gt;Benefits of Using Cookiecutter for Project Scaffolding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advantages-of-using-poetry-for-dependency-management"&gt;Advantages of Using Poetry for Dependency Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutters"&gt;Cookiecutters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cjolowiczcookiecutter-hypermodern-python"&gt;cjolowicz/cookiecutter-hypermodern-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fpgmaascookiecutter-poetry"&gt;fpgmaas/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#radix-aipoetry-cookiecutter"&gt;radix-ai/poetry-cookiecutter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#albertorioscookiecutter-poetry-pypackage"&gt;albertorios/cookiecutter-poetry-pypackage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#timhughescookiecutter-poetry"&gt;timhughes/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#johanvergeercookiecutter-poetry"&gt;johanvergeer/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#elbakramercookiecutter-poetry"&gt;elbakramer/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wboxx1cookiecutter-pypackage-poetry"&gt;wboxx1/cookiecutter-pypackage-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutter-wrapper"&gt;cookiecutter wrapper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools-and-services-often-used-in-python-project-cookiecutters"&gt;Tools …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutter-and-poetry-for-python-project-scaffolding"&gt;Cookiecutter and Poetry for Python Project Scaffolding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#benefits-of-using-cookiecutter-for-project-scaffolding"&gt;Benefits of Using Cookiecutter for Project Scaffolding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advantages-of-using-poetry-for-dependency-management"&gt;Advantages of Using Poetry for Dependency Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutters"&gt;Cookiecutters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cjolowiczcookiecutter-hypermodern-python"&gt;cjolowicz/cookiecutter-hypermodern-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fpgmaascookiecutter-poetry"&gt;fpgmaas/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#radix-aipoetry-cookiecutter"&gt;radix-ai/poetry-cookiecutter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#albertorioscookiecutter-poetry-pypackage"&gt;albertorios/cookiecutter-poetry-pypackage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#timhughescookiecutter-poetry"&gt;timhughes/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#johanvergeercookiecutter-poetry"&gt;johanvergeer/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#elbakramercookiecutter-poetry"&gt;elbakramer/cookiecutter-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wboxx1cookiecutter-pypackage-poetry"&gt;wboxx1/cookiecutter-pypackage-poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cookiecutter-wrapper"&gt;cookiecutter wrapper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools-and-services-often-used-in-python-project-cookiecutters"&gt;Tools and services often used in python project cookiecutters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="introduction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a id="cookiecutter-and-poetry-for-python-project-scaffolding"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Cookiecutter and Poetry for Python Project Scaffolding&lt;/h3&gt;
&lt;p&gt;In the world of Python development, efficient project setup and management are essential for streamlined and successful software development. Two powerful tools that aid in this process are &lt;strong&gt;Cookiecutter&lt;/strong&gt; and &lt;strong&gt;Poetry&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cookiecutter&lt;/strong&gt; is a command-line utility that enables developers to create project templates, or "cookiecutters," which serve as scaffolds for new projects. These cookiecutters are pre-configured templates that include project structures, file layouts, and even code snippets to kickstart the development process. With its simplicity and flexibility, Cookiecutter allows developers to easily generate consistent and well-organized projects without reinventing the wheel each time.&lt;/p&gt;
&lt;p&gt;On the other hand, &lt;strong&gt;Poetry&lt;/strong&gt; is a modern package manager and build tool for Python projects. It simplifies dependency management, packaging, and publishing while ensuring reproducible builds and version control. Poetry provides a user-friendly interface for managing project dependencies and virtual environments, making it a valuable asset for Python developers looking for an efficient way to manage their project's requirements.&lt;/p&gt;
&lt;p&gt;&lt;a id="benefits-of-using-cookiecutter-for-project-scaffolding"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Benefits of Using Cookiecutter for Project Scaffolding&lt;/h3&gt;
&lt;p&gt;Using Cookiecutter for project scaffolding offers several key advantages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Cookiecutter promotes consistency across projects by providing a standardized and repeatable starting point. This consistency ensures that developers adhere to best practices and maintain a clean project structure throughout the development process.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Time Savings&lt;/strong&gt;: With Cookiecutter, developers can avoid the repetitive and time-consuming task of setting up a new project from scratch. By using pre-defined templates, the initial project setup becomes quick and hassle-free, allowing developers to focus on writing code and implementing features.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Community-Driven Templates&lt;/strong&gt;: The open-source nature of Cookiecutter means that developers can access a vast repository of community-contributed templates. This diverse collection covers various project types and frameworks, making it easy to find a suitable starting point for almost any Python project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flexibility and Customization&lt;/strong&gt;: While offering pre-configured templates, Cookiecutter also allows developers to customize their project scaffolds. This flexibility ensures that developers can tailor the project structure to fit their specific needs and project requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="advantages-of-using-poetry-for-dependency-management"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Advantages of Using Poetry for Dependency Management&lt;/h3&gt;
&lt;p&gt;Poetry's features complement the benefits of Cookiecutter, making it an ideal companion for Python project development:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dependency Management Made Easy&lt;/strong&gt;: Poetry simplifies the management of project dependencies, handling both direct dependencies and their dependencies, providing a single-source-of-truth for the project's requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Virtual Environments&lt;/strong&gt;: Poetry creates isolated virtual environments for projects, ensuring that each project has its own set of dependencies, avoiding version conflicts and promoting project stability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Publication and Distribution&lt;/strong&gt;: Poetry streamlines the process of publishing packages to the Python Package Index (PyPI), simplifying the distribution of Python packages and making them accessible to a wider audience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Version Control and Reproducibility&lt;/strong&gt;: Poetry's &lt;code&gt;pyproject.toml&lt;/code&gt; file allows for clear specification of package versions, ensuring reproducible builds and making it easier to manage version updates.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="cookiecutters"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Cookiecutters&lt;/h2&gt;
&lt;p&gt;&lt;a id="cjolowiczcookiecutter-hypermodern-python"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;cjolowicz/cookiecutter-hypermodern-python&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/cjolowicz/cookiecutter-hypermodern-python"&gt;https://github.com/cjolowicz/cookiecutter-hypermodern-python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/cjolowicz/cookiecutter-hypermodern-python.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://cookiecutter-hypermodern-python.readthedocs.io/en/2021.3.14/guide.html"&gt;User Guide — Hypermodern Python Cookiecutter documentation&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Packaging and dependency management with &lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Test automation with &lt;a href="https://nox.thea.codes/"&gt;Nox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linting with &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; and &lt;a href="http://flake8.pycqa.org/"&gt;Flake8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Continuous integration with &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Documentation with &lt;a href="http://www.sphinx-doc.org/"&gt;Sphinx&lt;/a&gt; and &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automated uploads to &lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt; and &lt;a href="https://test.pypi.org/"&gt;TestPyPI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automated release notes with &lt;a href="https://github.com/release-drafter/release-drafter"&gt;Release Drafter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automated dependency updates with &lt;a href="https://dependabot.com/"&gt;Dependabot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code formatting with &lt;a href="https://github.com/psf/black"&gt;Black&lt;/a&gt; and &lt;a href="https://prettier.io/"&gt;Prettier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Testing with &lt;a href="https://docs.pytest.org/en/latest/"&gt;pytest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code coverage with &lt;a href="https://coverage.readthedocs.io/"&gt;Coverage.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Coverage reporting with &lt;a href="https://codecov.io/"&gt;Codecov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Command-line interface with &lt;a href="https://click.palletsprojects.com/"&gt;Click&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Static type-checking with &lt;a href="http://mypy-lang.org/"&gt;mypy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Runtime type-checking with &lt;a href="https://github.com/agronholm/typeguard"&gt;Typeguard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Security audit with &lt;a href="https://github.com/PyCQA/bandit"&gt;Bandit&lt;/a&gt; and &lt;a href="https://github.com/pyupio/safety"&gt;Safety&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Check documentation examples with &lt;a href="https://github.com/Erotemic/xdoctest"&gt;xdoctest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generate API documentation with &lt;a href="https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html"&gt;autodoc&lt;/a&gt; and &lt;a href="https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html"&gt;napoleon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Generate command-line reference with &lt;a href="https://sphinx-click.readthedocs.io/"&gt;sphinx-click&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manage project labels with &lt;a href="https://github.com/marketplace/actions/github-labeler"&gt;GitHub Labeler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="fpgmaascookiecutter-poetry"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;fpgmaas/cookiecutter-poetry&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/fpgmaas/cookiecutter-poetry"&gt;https://github.com/fpgmaas/cookiecutter-poetry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/fpgmaas/cookiecutter-poetry.svg?logo=github"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt; for dependency management&lt;/li&gt;
&lt;li&gt;CI/CD with &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pre-commit hooks with &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code quality with &lt;a href="https://pypi.org/project/black/"&gt;black&lt;/a&gt;, &lt;a href="https://github.com/charliermarsh/ruff"&gt;ruff&lt;/a&gt;, &lt;a href="https://mypy.readthedocs.io/en/stable/"&gt;mypy&lt;/a&gt;, and &lt;a href="https://github.com/fpgmaas/deptry/"&gt;deptry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Publishing to &lt;a href="https://pypi.org/"&gt;Pypi&lt;/a&gt; or &lt;a href="https://jfrog.com/artifactory"&gt;Artifactory&lt;/a&gt; by creating a new release on GitHub&lt;/li&gt;
&lt;li&gt;Testing and coverage with &lt;a href="https://docs.pytest.org/en/7.1.x/"&gt;pytest&lt;/a&gt; and &lt;a href="https://about.codecov.io/"&gt;codecov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Documentation with &lt;a href="https://www.mkdocs.org/"&gt;MkDocs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Compatibility testing for multiple versions of Python with &lt;a href="https://tox.wiki/en/latest/"&gt;Tox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Containerization with &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="radix-aipoetry-cookiecutter"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;radix-ai/poetry-cookiecutter&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/radix-ai/poetry-cookiecutter"&gt;https://github.com/radix-ai/poetry-cookiecutter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/radix-ai/poetry-cookiecutter.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="albertorioscookiecutter-poetry-pypackage"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;albertorios/cookiecutter-poetry-pypackage&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/albertorios/cookiecutter-poetry-pypackage"&gt;https://github.com/albertorios/cookiecutter-poetry-pypackage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/albertorios/cookiecutter-poetry-pypackage.svg?logo=github"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Develop, build, and release Python packages using via &lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Test against multiple Python versions via &lt;a href="https://tox.readthedocs.io/en/latest/"&gt;Tox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bump semantic version via &lt;a href="https://github.com/c4urself/bump2version"&gt;bump2version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Optional command-line interface via &lt;a href="https://click.palletsprojects.com/"&gt;Click&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Repeatable build environments via &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="timhughescookiecutter-poetry"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;timhughes/cookiecutter-poetry&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/timhughes/cookiecutter-poetry"&gt;https://github.com/timhughes/cookiecutter-poetry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/timhughes/cookiecutter-poetry.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Cookiecutter template configured with the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;poetry&lt;/li&gt;
&lt;li&gt;pytest&lt;/li&gt;
&lt;li&gt;black&lt;/li&gt;
&lt;li&gt;bandit&lt;/li&gt;
&lt;li&gt;pyinstaller&lt;/li&gt;
&lt;li&gt;jupyterlab&lt;/li&gt;
&lt;li&gt;click&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="johanvergeercookiecutter-poetry"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;johanvergeer/cookiecutter-poetry&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/johanvergeer/cookiecutter-poetry"&gt;https://github.com/johanvergeer/cookiecutter-poetry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/johanvergeer/cookiecutter-poetry.svg?logo=github"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Testing setup with &lt;code&gt;pytest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;: Ready for GitHub actions&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sphinx-doc.org/"&gt;Sphinx&lt;/a&gt; docs: Documentation ready for generation with, for example, &lt;a href="https://readthedocs.io/"&gt;ReadTheDocs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Auto-release to &lt;a href="https://pypi.python.org/pypi"&gt;PyPI&lt;/a&gt; when you push a new tag to master (optional)&lt;/li&gt;
&lt;li&gt;Command-line interface using Click (optional)&lt;/li&gt;
&lt;li&gt;GitHub Issue templates for bug reports and feature requests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="elbakramercookiecutter-poetry"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;elbakramer/cookiecutter-poetry&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/elbakramer/cookiecutter-poetry"&gt;https://github.com/elbakramer/cookiecutter-poetry&lt;/a&gt;
(fork from johanvergeer/cookiecutter-poetry)&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/elbakramer/cookiecutter-poetry.svg?logo=github"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Package and dependency management using &lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Has the option to stick with setuptools (setup.py)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;: Ready for GitHub Actions&lt;/li&gt;
&lt;li&gt;Build and test on push or pull request for continuous integration (CI) (+badge)&lt;/li&gt;
&lt;li&gt;Build documentation on push, publish the built documentation to Github Pages (+badge)&lt;/li&gt;
&lt;li&gt;Draft release on push, this draft can be published manually or even automatically when a new tag is pushed&lt;/li&gt;
&lt;li&gt;Build and release Python package to &lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt; when a new release tag is published on GitHub&lt;/li&gt;
&lt;li&gt;Many &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; hook-based formatting, linting, testing tools&lt;/li&gt;
&lt;li&gt;Upgrade syntax for newer Python with &lt;a href="https://github.com/asottile/pyupgrade"&gt;pyupgrade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Formatting with &lt;a href="https://github.com/psf/black"&gt;black&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Import sorting with &lt;a href="https://github.com/PyCQA/isort"&gt;isort&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linting with &lt;a href="https://github.com/PyCQA/flake8"&gt;flake8&lt;/a&gt; and &lt;a href="https://github.com/PyCQA/pylint/"&gt;pylint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Static typing with &lt;a href="https://github.com/python/mypy"&gt;mypy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Testing with &lt;a href="https://docs.pytest.org/en/stable/contents.html"&gt;pytest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Git hooks that run all the above with &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Other integrations with external sites/services&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sphinx-doc.org/"&gt;Sphinx&lt;/a&gt; docs serving with &lt;a href="https://readthedocs.io/"&gt;ReadTheDocs&lt;/a&gt; (+badge)&lt;/li&gt;
&lt;li&gt;Coverage report with &lt;a href="https://about.codecov.io/"&gt;Codecov&lt;/a&gt; (+badge)&lt;/li&gt;
&lt;li&gt;Monitoring dependency version updates with &lt;a href="https://requires.io/"&gt;Requires.io&lt;/a&gt; or &lt;a href="https://pyup.io/"&gt;PyUp&lt;/a&gt; (+badge)&lt;/li&gt;
&lt;li&gt;Version bumping using &lt;a href="https://github.com/c4urself/bump2version"&gt;bump2version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dynamic versioning using &lt;a href="https://github.com/mtkennerly/dunamai"&gt;dunamai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Command-line interface using &lt;a href="https://click.palletsprojects.com/en/7.x/"&gt;Click&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="wboxx1cookiecutter-pypackage-poetry"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;wboxx1/cookiecutter-pypackage-poetry&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/wboxx1/cookiecutter-pypackage-poetry"&gt;https://github.com/wboxx1/cookiecutter-pypackage-poetry&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/wboxx1/cookiecutter-pypackage-poetry.svg?logo=github"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Testing setup with &lt;code&gt;unittest&lt;/code&gt; and &lt;code&gt;python setup.py test&lt;/code&gt; or &lt;code&gt;pytest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://travis-ci.org/"&gt;Travis-CI&lt;/a&gt;: Ready for Travis Continuous Integration testing&lt;/li&gt;
&lt;li&gt;&lt;a href="http://appveyor.com/"&gt;Appveyor&lt;/a&gt;: Ready for Appveyor Continuous Integration testing&lt;/li&gt;
&lt;li&gt;&lt;a href="http://testrun.org/tox/"&gt;Tox&lt;/a&gt; testing: Setup to easily test for Python 2.7, 3.4, 3.5, 3.6, 3.7&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sphinx-doc.org/"&gt;Sphinx&lt;/a&gt; docs: Documentation ready for generation with, for example, &lt;a href="https://readthedocs.io/"&gt;ReadTheDocs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/c4urself/bump2version"&gt;Bump2version&lt;/a&gt;: Pre-configured version bumping with a single command&lt;/li&gt;
&lt;li&gt;Auto-release to &lt;a href="https://pypi.python.org/pypi"&gt;PyPI&lt;/a&gt; when you push a new tag to master (optional)&lt;/li&gt;
&lt;li&gt;Command-line interface using Click (optional)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="cookiecutter-wrapper"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;cookiecutter wrapper&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://pypi.org/project/cookiecutter-poetry/"&gt;https://pypi.org/project/cookiecutter-poetry/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Please note that the actual number of GitHub stars would be fetched dynamically when viewing the article in real-time. The badge URL with the GitHub stars includes a placeholder (&lt;code&gt;{shield}&lt;/code&gt;) for the dynamic value, and the actual number will be displayed when the badge is rendered on the page.&lt;/p&gt;
&lt;p&gt;&lt;a id="tools-and-services-often-used-in-python-project-cookiecutters"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tools and services often used in python project cookiecutters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cookiecutter.readthedocs.io/"&gt;Cookiecutter&lt;/a&gt;: Command-line utility for creating project templates.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;: Package manager and build tool for Python projects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pre-commit.com/"&gt;Pre-commit&lt;/a&gt;: Framework for managing and maintaining multi-language pre-commit hooks.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/psf/black"&gt;Black&lt;/a&gt;: Opinionated code formatter for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tox.readthedocs.io/"&gt;Tox&lt;/a&gt;: Generic virtualenv management and test command line tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nox.thea.codes/"&gt;Nox&lt;/a&gt;: Flexible test automation tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/charliermarsh/ruff"&gt;Ruff&lt;/a&gt;: Fast Linter, code quality tool for Python projects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;: Continuous integration and continuous deployment service by GitHub.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://about.codecov.io/"&gt;Codecov&lt;/a&gt;: Code coverage reporting tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/c4urself/bump2version"&gt;Bump2version&lt;/a&gt;: Version-bumping utility for software projects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;: Platform for building, shipping, and running applications in containers.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sphinx-doc.org/"&gt;Sphinx&lt;/a&gt;: Documentation generator for Python projects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt;: Hosting service for software documentation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/release-drafter/release-drafter"&gt;Release Drafter&lt;/a&gt;: Automated release notes generation tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dependabot.com/"&gt;Dependabot&lt;/a&gt;: Automated dependency updates tool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://prettier.io/"&gt;Prettier&lt;/a&gt;: Opinionated code formatter for various languages, including Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pytest.org/en/latest/"&gt;pytest&lt;/a&gt;: Framework for writing and running Python tests.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://coverage.readthedocs.io/"&gt;Coverage.py&lt;/a&gt;: Code coverage measurement tool for Python.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/agronholm/typeguard"&gt;Typeguard&lt;/a&gt;: Runtime type checking for Python functions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PyCQA/bandit"&gt;Bandit&lt;/a&gt;: Security linter for Python code.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pyupio/safety"&gt;Safety&lt;/a&gt;: Security dependency checker for Python packages.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Erotemic/xdoctest"&gt;xdoctest&lt;/a&gt;: Tool for running code examples in docstrings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html"&gt;autodoc&lt;/a&gt;: Sphinx extension for automatic documentation generation from docstrings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html"&gt;napoleon&lt;/a&gt;: Sphinx extension for NumPy and Google style docstrings.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sphinx-click.readthedocs.io/"&gt;sphinx-click&lt;/a&gt;: Sphinx extension for Click-based command-line interfaces.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/marketplace/actions/github-labeler"&gt;GitHub Labeler&lt;/a&gt;: GitHub Action for managing project labels.&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="cookiecutter"></category><category term="poetry"></category><category term="python-project"></category><category term="hypermodern"></category><category term="nox"></category><category term="shpinx"></category><category term="pypi"></category><category term="python-package"></category><category term="python/package"></category></entry><entry><title>Simplifying Data Download from Google Drive in Google Colab Using gdown</title><link href="https://www.safjan.com/download-data-google-drive-colab-gdown/" rel="alternate"></link><published>2023-07-24T00:00:00+02:00</published><updated>2023-07-24T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-24:/download-data-google-drive-colab-gdown/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this blog post, we will explore a straightforward method to download data from Google Drive into your Google Colab notebook using the 'gdown' command. Google Colab is a popular platform for running Python code, especially for machine learning and data …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this blog post, we will explore a straightforward method to download data from Google Drive into your Google Colab notebook using the 'gdown' command. Google Colab is a popular platform for running Python code, especially for machine learning and data analysis tasks. By leveraging 'gdown,' a handy Python library, you can seamlessly access your files stored on Google Drive without any hassle. Let's dive right into the process!&lt;/p&gt;
&lt;h2&gt;Steps&lt;/h2&gt;
&lt;h3&gt;Step 1: Import gdown and Authenticate Google Drive&lt;/h3&gt;
&lt;p&gt;To begin, ensure you have 'gdown' installed in your Colab environment. If it isn't pre-installed, you can do so using the following code snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;gdown&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Step 2: Obtain the File's Shareable Link&lt;/h3&gt;
&lt;p&gt;To download data from your Google Drive, you must first ensure the file or folder is publicly accessible. To do this, right-click on the file or folder in your Google Drive, select "Get Shareable Link," and set the sharing settings to "Anyone with the link."&lt;/p&gt;
&lt;h3&gt;Step 3: Retrieve the ID from the Shareable Link&lt;/h3&gt;
&lt;p&gt;Upon obtaining the shareable link, extract the file's ID from the link. The ID is typically found after "&lt;a href="https://drive.google.com/file/d/"&gt;https://drive.google.com/file/d/&lt;/a&gt;". For instance, if your link is "&lt;a href="https://drive.google.com/file/d/ABC12345XYZ/view"&gt;https://drive.google.com/file/d/ABC12345XYZ/view&lt;/a&gt;," then "ABC12345XYZ" is the file's ID.&lt;/p&gt;
&lt;p&gt;Step 4: Download the Data
Using the gdown command, you can now effortlessly download the data from your Google Drive into your Colab notebook. The following code demonstrates how to do this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;gdown&lt;/span&gt;

&lt;span class="n"&gt;file_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ABC12345XYZ&amp;quot;&lt;/span&gt;  &lt;span class="c1"&gt;# Replace this with your file&amp;#39;s ID&lt;/span&gt;
&lt;span class="n"&gt;output_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;data_file.ext&amp;quot;&lt;/span&gt;  &lt;span class="c1"&gt;# Replace &amp;quot;data_file.ext&amp;quot; with the desired output filename and extension&lt;/span&gt;

&lt;span class="n"&gt;gdown&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https://drive.google.com/uc?id=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;file_id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this brief guide, we have explored the process of downloading data from Google Drive into Google Colab using the 'gdown' command. By following these simple steps, you can seamlessly access and utilize your data for various machine learning, data analysis, or other Python-based projects in Google Colab. Happy coding!&lt;/p&gt;</content><category term="note"></category><category term="gdown"></category><category term="colab"></category><category term="google-colab"></category><category term="data-download"></category><category term="google-drive"></category><category term="gdrive"></category></entry><entry><title>Add VSCode to PATH</title><link href="https://www.safjan.com/add-vscode-to-path/" rel="alternate"></link><published>2023-07-21T00:00:00+02:00</published><updated>2023-07-21T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-21:/add-vscode-to-path/</id><summary type="html">&lt;p&gt;If you get code command not found error but vscode  is installed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;code
zsh:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;command&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;not&lt;span class="w"&gt; &lt;/span&gt;found:&lt;span class="w"&gt; &lt;/span&gt;code
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;it means, that, &lt;code&gt;code&lt;/code&gt; command is not in you system PATH. You need to add it.&lt;/p&gt;
&lt;p&gt;To do that, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Launch Visual …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;If you get code command not found error but vscode  is installed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;code
zsh:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;command&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;not&lt;span class="w"&gt; &lt;/span&gt;found:&lt;span class="w"&gt; &lt;/span&gt;code
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;it means, that, &lt;code&gt;code&lt;/code&gt; command is not in you system PATH. You need to add it.&lt;/p&gt;
&lt;p&gt;To do that, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Launch Visual Studio Code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open the Command Palette by pressing &lt;code&gt;Cmd+Shift+P&lt;/code&gt; (or &lt;code&gt;Ctrl+Shift+P&lt;/code&gt; on Windows/Linux).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type "shell command" in the Command Palette search bar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You should see an option that says "Shell Command: Install 'code' command in PATH." Select it to add the &lt;code&gt;code&lt;/code&gt; command to your system PATH.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After completing these steps, you should be able to open Visual Studio Code directly from the terminal using the &lt;code&gt;code&lt;/code&gt; command.&lt;/p&gt;</content><category term="note"></category><category term="vscode"></category><category term="path"></category><category term="terminal"></category><category term="cli"></category><category term="bash"></category><category term="zsh"></category></entry><entry><title>What is downstream task</title><link href="https://www.safjan.com/what-is-downstream-task/" rel="alternate"></link><published>2023-07-21T00:00:00+02:00</published><updated>2023-07-21T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-21:/what-is-downstream-task/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;In the context of data science and business, the term "downstream task" refers to a task or process that occurs after the completion of an initial or preceding task in a data pipeline or workflow. In this data flow, information is processed …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;In the context of data science and business, the term "downstream task" refers to a task or process that occurs after the completion of an initial or preceding task in a data pipeline or workflow. In this data flow, information is processed and refined as it moves from one stage to another.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To understand the concept better, let's consider a simplified data science workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Collection&lt;/strong&gt;: The first step is to gather and collect raw data from various sources, such as databases, APIs, or files.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Preprocessing&lt;/strong&gt;: Once the data is collected, it often needs to be cleaned, transformed, and structured in a way that makes it suitable for analysis. This step is known as data preprocessing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature Engineering&lt;/strong&gt;: After preprocessing, relevant features (variables) are extracted from the data, and new features might be created to enhance the predictive power of the models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Training&lt;/strong&gt;: With the prepared data, machine learning models are trained to make predictions or classifications based on patterns found in the data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Evaluation&lt;/strong&gt;: After the models are trained, they need to be evaluated on a separate dataset to assess their performance and identify any issues such as overfitting or underfitting.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, let's introduce the notion of "downstream tasks":&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Deployment&lt;/strong&gt;: Once the trained model(s) have been evaluated and deemed satisfactory, they are deployed into a production environment where they can be used to make predictions on new, unseen data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decision Making&lt;/strong&gt;: In a business context, the model's predictions are often used as inputs for making data-driven decisions. These decisions could be related to marketing strategies, customer segmentation, risk assessment, product recommendations, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Performance Monitoring&lt;/strong&gt;: After the model has been deployed, its performance needs to be continually monitored to ensure that it maintains accuracy and relevance over time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Updating and Retraining&lt;/strong&gt;: As new data becomes available and the model's performance deteriorates or needs improvement, it might be necessary to update or retrain the model to keep it up-to-date and accurate.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this workflow, &lt;strong&gt;"downstream tasks" are those that happen after the initial data preprocessing, model training, and evaluation stages. These tasks utilize the output of the earlier stages to make informed decisions and provide value to the business.&lt;/strong&gt;&lt;/p&gt;</content><category term="note"></category><category term="data-science"></category><category term="business"></category><category term="data-preprocessing"></category><category term="data-collection"></category><category term="feature-engineering"></category><category term="model-training"></category><category term="model-evaluation"></category><category term="decision-making"></category></entry><entry><title>Alternatives for Building Python CLI Apps</title><link href="https://www.safjan.com/alternatives_for_building_python_cli_apps/" rel="alternate"></link><published>2023-07-17T00:00:00+02:00</published><updated>2023-07-17T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-17:/alternatives_for_building_python_cli_apps/</id><summary type="html">&lt;p&gt;Discover the best tools and frameworks for building Python CLI apps. Explore Click, argparse, Typer, and more. Master the art of command-line application development.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Python provides several libraries and frameworks for building command-line interface (CLI) applications, each with its own set of features and advantages. In this article, we will explore some of the popular alternatives to build Python CLI apps, including Click, argparse, and Typer, among others.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#click"&gt;Click&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#argparse"&gt;argparse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#typer"&gt;Typer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-alternatives"&gt;Other Alternatives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#fire"&gt;Fire&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cement"&gt;cement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#docopt"&gt;Docopt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#plumbum"&gt;Plumbum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="click"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Click&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/pallets/click.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Click is a powerful and widely used Python library for creating command-line interfaces. It focuses on simplicity and aims to make it easy to write and maintain CLI applications. Click provides a decorator-based approach for defining commands, options, and arguments, making it intuitive and straightforward to use. It supports complex command hierarchies, automatic help page generation, and customization options for output formatting. Click also offers advanced features such as context passing, callback handling, and parameter types. It has a large and active community, ensuring ongoing support and continuous development.&lt;/p&gt;
&lt;p&gt;Click is an excellent choice for both simple and complex CLI applications. Its simplicity and intuitive API make it a great option for beginners, while its advanced features cater to more complex use cases. Whether you are building a small script or a full-fledged CLI tool, Click provides a solid foundation for developing robust and user-friendly applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple and intuitive API.&lt;/li&gt;
&lt;li&gt;Decorator-based command definition.&lt;/li&gt;
&lt;li&gt;Support for complex command hierarchies.&lt;/li&gt;
&lt;li&gt;Automatic help page generation.&lt;/li&gt;
&lt;li&gt;Advanced features like context passing and parameter types.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
Click is suitable for a wide range of CLI applications, from small scripts to large-scale tools. It is a popular choice for building command-line interfaces in Python due to its simplicity, flexibility, and extensive feature set.&lt;/p&gt;
&lt;p&gt;To learn more about Click, visit the &lt;a href="https://click.palletsprojects.com/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/pallets/click"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="argparse"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;argparse&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/python/cpython.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;argparse is a standard library included in Python, making it readily available for CLI application development without any external dependencies. It provides a flexible and comprehensive framework for defining command-line arguments, options, and sub-commands. argparse supports automatic help generation, argument type checking, default values, and various customization options. It also handles error reporting and displays error messages with usage information. argparse's design promotes code reusability, making it easy to build CLI applications with modular components.&lt;/p&gt;
&lt;p&gt;argparse is a versatile library suitable for a wide range of CLI applications. Its standard inclusion in Python ensures compatibility and ease of use, making it a popular choice for developers. Whether you are building a simple script or a complex application with multiple sub-commands, argparse provides a robust foundation for handling command-line arguments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standard library inclusion, no external dependencies.&lt;/li&gt;
&lt;li&gt;Comprehensive framework for defining arguments and options.&lt;/li&gt;
&lt;li&gt;Automatic help generation.&lt;/li&gt;
&lt;li&gt;Error reporting and usage information display.&lt;/li&gt;
&lt;li&gt;Code reusability and modular design.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
argparse is well-suited for a variety of CLI applications, from basic scripts to more complex tools with sub-commands. Its standard library nature and comprehensive feature set make it a reliable choice for command-line argument handling in Python.&lt;/p&gt;
&lt;p&gt;For detailed information about argparse, refer to the &lt;a href="https://docs.python.org/3/library/argparse.html"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/python/cpython"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="typer"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Typer&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/tiangolo/typer.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Typer is a modern, fast, and efficient CLI framework built on top of Click. It offers a simple and concise API for building command-line interfaces in Python, with an emphasis on code readability and type hints. Typer automatically infers the types of arguments and options from their default values or annotations, reducing the need for boilerplate code. It provides features such as automatic help generation, completion generation for shells, and support for asynchronous execution.&lt;/p&gt;
&lt;p&gt;Typer's simplicity and seamless integration with Click make it an appealing choice for developers who prioritize code clarity and conciseness. It leverages Python's type hints to improve developer productivity and reduce the likelihood of runtime errors. With its performance optimizations, Typer can handle large CLI applications efficiently.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple and concise API with emphasis on code readability.&lt;/li&gt;
&lt;li&gt;Automatic type inference from default values or annotations.&lt;/li&gt;
&lt;li&gt;Automatic help and completion generation.&lt;/li&gt;
&lt;li&gt;Asynchronous execution support.&lt;/li&gt;
&lt;li&gt;Performance optimizations for handling large applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
Typer is particularly well-suited for developers who value code readability and conciseness. It is a great choice for building CLI applications of any size, ranging from small scripts to complex tools, with a focus on leveraging Python's type hints.&lt;/p&gt;
&lt;p&gt;To learn more about Typer, refer to the &lt;a href="https://typer.tiangolo.com/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/tiangolo/typer"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="fire"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Fire&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/google/python-fire.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Fire is a library developed by Google that automatically generates a command-line interface from Python objects. It allows you to turn any Python class or module into a CLI application without the need for explicit command definitions. Fire uses introspection to infer the available methods and attributes of an object, which are then exposed as CLI commands and arguments. This automatic generation of the CLI interface makes Fire incredibly convenient for quickly building command-line tools from existing code.&lt;/p&gt;
&lt;p&gt;Fire's simplicity and automatic CLI generation make it an excellent choice for rapidly prototyping CLI applications. It eliminates the need for manually defining command structures and allows you to focus on the core functionality of your Python objects. While it may not offer the same level of customization as some other libraries, Fire excels in its ability to generate a functional CLI interface with minimal effort.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatic CLI generation from Python objects.&lt;/li&gt;
&lt;li&gt;No explicit command definitions required.&lt;/li&gt;
&lt;li&gt;Rapid prototyping of CLI applications.&lt;/li&gt;
&lt;li&gt;Eliminates the need for manual command structure definitions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
Fire is best suited for quickly creating simple CLI tools based on existing Python code. It is ideal for situations where you want to expose the functionality of your Python objects through a command-line interface without the need for explicit command definitions.&lt;/p&gt;
&lt;p&gt;To learn more about Fire, refer to the &lt;a href="https://google.github.io/python-fire/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/google/python-fire"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="cement"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;cement&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/datafolklabs/cement.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;cement is a powerful and extensible CLI framework for Python. It provides a complete set of features for building CLI applications, including command-line argument parsing, command line completion, output rendering, and plugin support. cement follows a modular design, allowing you to choose and configure only the components you need for your application. It offers support for both single-command and multi-command applications, making it versatile and adaptable to various use cases.&lt;/p&gt;
&lt;p&gt;One of the standout features of cement is its plugin architecture, which enables easy integration of third-party functionality into your CLI application. It also provides a powerful and customizable output handler system, allowing you to define how the application's output is rendered and formatted. cement's extensive documentation and active community make it a reliable choice for developing robust CLI applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comprehensive CLI framework with modular design.&lt;/li&gt;
&lt;li&gt;Command-line argument parsing.&lt;/li&gt;
&lt;li&gt;Command line completion.&lt;/li&gt;
&lt;li&gt;Customizable output rendering.&lt;/li&gt;
&lt;li&gt;Plugin architecture for easy integration of third-party functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
cement is suitable for building CLI applications of any complexity. Its modular design and extensive feature set make it an excellent choice for projects that require advanced customization, plugin support, and flexible output rendering.&lt;/p&gt;
&lt;p&gt;For detailed information about cement, refer to the &lt;a href="https://builtoncement.com/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/datafolklabs/cement"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="docopt"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Docopt&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/docopt/docopt.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Docopt is a command-line interface description language and Python library that generates a CLI parser from human-readable usage patterns. It allows you to define the command-line interface by writing usage patterns and associated descriptions. Docopt then automatically generates a parser based on these patterns, handling argument parsing and help generation.&lt;/p&gt;
&lt;p&gt;The simplicity and readability of Docopt's usage patterns make it a unique and user-friendly approach to building CLI applications. By using natural language to describe the command-line interface, Docopt simplifies the process of defining and maintaining CLI specifications. It supports both positional arguments and options and provides support for complex command hierarchies.&lt;/p&gt;
&lt;p&gt;Docopt is an excellent choice for projects where a human-readable and self-documenting CLI interface is a priority. It allows developers to focus on writing clear usage patterns while leaving the parsing and help generation to the library.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Command-line interface description language.&lt;/li&gt;
&lt;li&gt;Automatic parser generation from human-readable usage patterns.&lt;/li&gt;
&lt;li&gt;Simplifies the process of defining and maintaining CLI specifications.&lt;/li&gt;
&lt;li&gt;Support for positional arguments and options.&lt;/li&gt;
&lt;li&gt;Natural language approach for clear usage patterns.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
Docopt is best suited for projects where a human-readable and self-documenting CLI interface is desired. It is a good choice for developers who prefer a more descriptive and expressive way of defining the command-line interface.&lt;/p&gt;
&lt;p&gt;For more information about Docopt, refer to the &lt;a href="http://docopt.org/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/docopt/docopt"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="plumbum"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Plumbum&lt;/h2&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/tomerfiliba/plumbum.svg?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Plumbum is a library that aims to simplify the process of writing shell-like scripts and command-line tools in Python. It provides an intuitive and concise API for executing shell commands, capturing their output, and handling command-line arguments. Plumbum allows you to seamlessly mix shell-like syntax and Python code, providing a powerful and flexible approach to command-line application development.&lt;/p&gt;
&lt;p&gt;One of Plumbum's standout features is its ability to create reusable command templates. These templates encapsulate the common functionality of a command, allowing you to easily define and reuse complex command structures. Plumbum also offers support for input/output redirection, background execution, and shell pipeline operations.&lt;/p&gt;
&lt;p&gt;Plumbum is an excellent choice for developers who want to combine the power of shell commands with the flexibility and expressiveness of Python. It simplifies the process of interacting with the command line and enables the creation of robust and maintainable CLI applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stand-out Features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intuitive and concise API for executing shell commands.&lt;/li&gt;
&lt;li&gt;Seamless integration of shell-like syntax and Python code.&lt;/li&gt;
&lt;li&gt;Reusable command templates for defining complex command structures.&lt;/li&gt;
&lt;li&gt;Support for input/output redirection, background execution, and shell pipelines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Use-case:&lt;/strong&gt;
Plumbum is suitable for developers who want to leverage the power of shell commands while maintaining the flexibility and expressiveness of Python. It is a good choice for building command-line applications that require extensive interaction with the command line and complex command structures.&lt;/p&gt;
&lt;p&gt;To learn more about Plumbum, refer to the &lt;a href="https://plumbum.readthedocs.io/"&gt;official documentation&lt;/a&gt; or explore the &lt;a href="https://github.com/tomerfiliba/plumbum"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Which Tool Should I Use in My Case?&lt;/h2&gt;
&lt;p&gt;When choosing a tool for building Python CLI apps, it's important to consider the specific requirements of your project. Different tools excel in different scenarios. Here, we'll discuss three common use-cases with divergent requirements and suggest the best tools for each case along with justifications.&lt;/p&gt;
&lt;h3&gt;1. Simple Script or Rapid Prototyping&lt;/h3&gt;
&lt;p&gt;If you're building a simple script or need to rapidly prototype a CLI application, &lt;strong&gt;Click&lt;/strong&gt; and &lt;strong&gt;Fire&lt;/strong&gt; are excellent choices.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Click&lt;/strong&gt; offers a simple and intuitive API with decorator-based command definition, making it easy to create CLI apps quickly. It provides advanced features like context passing and parameter types, which can enhance the functionality of your script. Additionally, Click's extensive documentation and active community support make it a reliable choice.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fire&lt;/strong&gt; is perfect for converting existing Python code into a CLI application effortlessly. With Fire, you can generate a command-line interface from any Python object without explicit command definitions. It prioritizes simplicity and allows you to focus on the core functionality of your code, making it ideal for rapid prototyping.&lt;/p&gt;
&lt;h3&gt;2. Complex CLI Application with Advanced Customization&lt;/h3&gt;
&lt;p&gt;For complex CLI applications that require advanced customization, &lt;strong&gt;argparse&lt;/strong&gt; and &lt;strong&gt;cement&lt;/strong&gt; are robust options.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;argparse&lt;/strong&gt; is a Python standard library, providing a comprehensive framework for defining command-line arguments, options, and sub-commands. It supports automatic help generation, type checking, and error reporting. argparse's modular design promotes code reusability and is suitable for projects with multiple sub-commands and extensive customization requirements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cement&lt;/strong&gt; is a powerful CLI framework that offers a complete set of features, including argument parsing, command line completion, output rendering, and plugin support. It follows a modular design, allowing you to choose the components you need. cement's plugin architecture enables easy integration of third-party functionality, and its customizable output rendering system provides flexibility.&lt;/p&gt;
&lt;h3&gt;3. Human-Readable CLI Interface&lt;/h3&gt;
&lt;p&gt;If you prioritize a human-readable and self-documenting CLI interface, consider &lt;strong&gt;Typer&lt;/strong&gt; and &lt;strong&gt;Docopt&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Typer&lt;/strong&gt; is a modern CLI framework built on top of Click, emphasizing code readability and type hints. It automatically infers argument types, reducing boilerplate code. Typer's simplicity and integration with Python's type hints make it an appealing choice for developers who value code clarity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Docopt&lt;/strong&gt; takes a unique approach, allowing you to define the command-line interface using human-readable usage patterns. It automatically generates a parser based on these patterns, handling argument parsing and help generation. Docopt's natural language approach simplifies the process of defining and maintaining CLI specifications, resulting in a clear and readable CLI interface.&lt;/p&gt;</content><category term="note"></category><category term="python-cli-apps"></category><category term="command-line-interface"></category><category term="click"></category><category term="argparse"></category><category term="typer"></category><category term="fire"></category><category term="cement"></category><category term="docopt"></category><category term="plumbum"></category><category term="code-readability"></category><category term="code-conciseness"></category><category term="command-line-tools"></category><category term="cli-frameworks"></category><category term="command-line-argument-parsing"></category><category term="shell-like-scripts"></category><category term="output-rendering"></category><category term="plugin-support"></category><category term="command-line-completion"></category><category term="python-standard-library"></category><category term="type-hints"></category></entry><entry><title>Creating a PowerPoint Presentation with a Language Model</title><link href="https://www.safjan.com/creating-a-powerpoint-presentation-with-a-language-model/" rel="alternate"></link><published>2023-07-17T00:00:00+02:00</published><updated>2023-07-17T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-17:/creating-a-powerpoint-presentation-with-a-language-model/</id><summary type="html">&lt;p&gt;In this article, we'll explore how to generate a PowerPoint presentation using the OpenAI Azure API and provide additional advanced features to enhance the process.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before we begin, make sure you have the following prerequisites set up:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.x installed …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;In this article, we'll explore how to generate a PowerPoint presentation using the OpenAI Azure API and provide additional advanced features to enhance the process.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Before we begin, make sure you have the following prerequisites set up:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.x installed on your machine&lt;/li&gt;
&lt;li&gt;OpenAI API key&lt;/li&gt;
&lt;li&gt;Required Python libraries: &lt;code&gt;python-pptx&lt;/code&gt; and &lt;code&gt;openai&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can install the libraries using the &lt;code&gt;pip&lt;/code&gt; package manager:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;python-pptx&lt;span class="w"&gt; &lt;/span&gt;openai
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Step 1: Setting up the OpenAI API&lt;/h2&gt;
&lt;p&gt;To get started, you'll need to sign up for the OpenAI API and obtain an API key. The API key allows you to interact with the GPT model. Follow the instructions in the OpenAI documentation to sign up and retrieve your API key.&lt;/p&gt;
&lt;h2&gt;Step 2: Importing the Required Modules&lt;/h2&gt;
&lt;p&gt;To work with PowerPoint and the OpenAI API, we need to import the necessary modules in our Python script. Specifically, we'll import the &lt;code&gt;Presentation&lt;/code&gt; class from the &lt;code&gt;python-pptx&lt;/code&gt; library and the &lt;code&gt;openai&lt;/code&gt; module.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pptx&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Presentation&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;openai&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Step 3: Authenticating with the OpenAI API&lt;/h2&gt;
&lt;p&gt;Next, we need to authenticate with the OpenAI API by providing our API key. This step ensures that we have the necessary permissions to access and utilize the GPT model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;openai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;api_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;YOUR_API_KEY&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;'YOUR_API_KEY'&lt;/code&gt; with the API key you obtained in Step 1.&lt;/p&gt;
&lt;h2&gt;Step 4: Generating the Presentation Outline with ChatGPT&lt;/h2&gt;
&lt;p&gt;With the necessary setup complete, we can now use the ChatGPT model to generate an outline for our PowerPoint presentation. We'll provide a description of the presentation as input and receive a list of slides as output. The slides will form the basis of our presentation structure.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;description&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;This presentation is about the benefits of exercise.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;openai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Completion&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;text-davinci-003&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;max_tokens&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# Number of slides in the outline&lt;/span&gt;
    &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;slides&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choices&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this example, the &lt;code&gt;description&lt;/code&gt; variable contains the input description for the presentation. The &lt;code&gt;max_tokens&lt;/code&gt; parameter limits the response length, and the &lt;code&gt;n&lt;/code&gt; parameter determines the number of slides in the outline. Feel free to adjust these parameters based on your specific needs.&lt;/p&gt;
&lt;h2&gt;Step 5: Generating Content for Each Slide&lt;/h2&gt;
&lt;p&gt;To make our presentation informative, we'll use the ChatGPT model to generate content for each slide in the outline. For each slide, we'll iterate through the &lt;code&gt;slides&lt;/code&gt; list and generate the content using the ChatGPT model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;slides&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;openai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Completion&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;text-davinci-003&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;max_tokens&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choices&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# Store the content for the slide&lt;/span&gt;
    &lt;span class="n"&gt;slides&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here, we iterate through each slide in the &lt;code&gt;slides&lt;/code&gt; list, generate the content using the ChatGPT model, and store the title and content in a dictionary. Adjust the &lt;code&gt;max_tokens&lt;/code&gt; parameter based on the desired length of each slide's content.&lt;/p&gt;
&lt;h2&gt;Step 6: Creating the PowerPoint Presentation&lt;/h2&gt;
&lt;p&gt;With the slide titles and content generated, it's time to create the PowerPoint presentation using the &lt;code&gt;python-pptx&lt;/code&gt; library. We'll iterate through the slides and add them to the presentation with the appropriate titles and content.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;presentation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Presentation&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;slides&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;slide_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;slide_content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;slide_layout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;presentation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;slide_layouts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;# Choose the layout for the slide&lt;/span&gt;
    &lt;span class="n"&gt;slide&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;presentation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;slides&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_slide&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;slide_layout&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shapes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholders&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide_title&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slide_content&lt;/span&gt;

&lt;span class="n"&gt;presentation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;generated_presentation.pptx&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this example, we create a new slide for each item in the &lt;code&gt;slides&lt;/code&gt; list. We set the title and content for each slide and save the presentation as a PowerPoint file named "generated_presentation.pptx". You can adjust the slide layout by choosing a different index from the &lt;code&gt;slide_layouts&lt;/code&gt; list.&lt;/p&gt;
&lt;h2&gt;Possible Next Features for the Presentation Generation Script&lt;/h2&gt;
&lt;p&gt;While the script we've created is already capable of generating PowerPoint presentations, we can enhance it further with additional features. Here are a few possible next steps to consider:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Slide Customization&lt;/strong&gt;: Allow users to specify different slide layouts, fonts, colors, and background images to customize the visual appearance of their presentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Image Integration&lt;/strong&gt;: Extend the script to generate slides with images. This can involve using AI models to automatically search and retrieve relevant images based on the content of each slide.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interactive Presentations&lt;/strong&gt;: Utilize technologies like Jupyter Notebook or web-based frameworks to create interactive presentations that allow viewers to engage with the content dynamically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;: Incorporate natural language processing techniques to analyze the generated content and provide suggestions for improvements, such as grammar corrections, more concise wording, or alternative phrasing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By implementing these features, the presentation generation script can become more versatile and provide a richer experience for users.&lt;/p&gt;
&lt;h2&gt;Alternative approach - let LLM generate VisualBasic script&lt;/h2&gt;
&lt;p&gt;In this article we use python to generate the slides. You can also ask model (ChatGPT) for a VisualBasic script that will generate presentation for you. You can learn this approach from the video: &lt;a href="https://www.youtube.com/watch?v=JoedhPPi3O0"&gt;Create Beautiful PowerPoint Slides with ChatGPT + VBA: Quick Tip! - YouTube&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this article, we've explored how to create a PowerPoint presentation using a language model, specifically OpenAI's GPT model through the Azure API. We've covered the steps from setting up the OpenAI API to generating an outline and filling the slides with content. Additionally, we discussed possible next features to enhance the script, such as slide customization, image integration, interactive presentations, and natural language processing. By expanding upon these features, you can create powerful presentation automation tools tailored to your specific needs.&lt;/p&gt;
&lt;p&gt;Automating presentation generation not only saves time and effort but also opens up new possibilities for creating engaging and informative presentations. With the help of AI and language models, we can revolutionize the way presentations are created, allowing presenters to focus more on refining their ideas and delivering impactful content.&lt;/p&gt;</content><category term="note"></category><category term="powerpoint-presentation"></category><category term="language-model"></category><category term="OpenAI-API"></category><category term="automation"></category><category term="artificial-intelligence"></category><category term="python-script"></category><category term="ChatGPT"></category><category term="presentation-outline"></category><category term="content-generation"></category><category term="python-pptx"></category><category term="openai"></category><category term="authentication"></category><category term="slide-customization"></category><category term="image-integration"></category><category term="interactive-presentations"></category><category term="natural-language-processing"></category><category term="advanced-features"></category></entry><entry><title>Time Travel in Git - Creating a Branch from the Past and Crafting a New Future</title><link href="https://www.safjan.com/time-travel-in-git-creating-a-branch-from-the-past-and-crafting-a-new%20future/" rel="alternate"></link><published>2023-07-14T00:00:00+02:00</published><updated>2023-07-14T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-14:/time-travel-in-git-creating-a-branch-from-the-past-and-crafting-a-new future/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this guide, we will learn how to create a new branch in a Git repository based on a previous commit. We have commit history as below.
&lt;img alt="before" src="images/git_time_travel/git-time-travel-1.png"&gt;&lt;/p&gt;
&lt;!--

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gitGraph
    commit id: &amp;quot;A&amp;quot;
    commit id: &amp;quot;B&amp;quot;
    commit id: &amp;quot;C&amp;quot;
    commit id: &amp;quot;D&amp;quot;
    commit id: &amp;quot;E&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


--&gt;
&lt;p&gt;We are not happy with the changes C, D and E. We would like …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this guide, we will learn how to create a new branch in a Git repository based on a previous commit. We have commit history as below.
&lt;img alt="before" src="images/git_time_travel/git-time-travel-1.png"&gt;&lt;/p&gt;
&lt;!--

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gitGraph
    commit id: &amp;quot;A&amp;quot;
    commit id: &amp;quot;B&amp;quot;
    commit id: &amp;quot;C&amp;quot;
    commit id: &amp;quot;D&amp;quot;
    commit id: &amp;quot;E&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


--&gt;
&lt;p&gt;We are not happy with the changes C, D and E. We would like to start again from B, but we want to keep changes C, D and E in a new branch. Specifically, we will create a new branch starting from commit B in the main branch. We'll move the subsequent commits C, D, and E to the new branch and continue working on the main branch from the state of commit B - new commits F and G.
&lt;img alt="after" src="images/git_time_travel/git-time-travel-2.png"&gt;&lt;/p&gt;
&lt;!--

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;gitGraph
    commit id: &amp;quot;A&amp;quot;
    commit id: &amp;quot;B&amp;quot;
    branch feature-1
    commit id: &amp;quot;C&amp;quot;
    commit id: &amp;quot;D&amp;quot;
    commit id: &amp;quot;E&amp;quot;
    checkout main
    commit id: &amp;quot;F&amp;quot;
    commit id: &amp;quot;G&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


--&gt;

&lt;p&gt;This guide assumes you have a basic understanding of Git commands and are familiar with the command line interface.&lt;/p&gt;
&lt;h2&gt;Step-by-Step Guide&lt;/h2&gt;
&lt;h3&gt;Determine the current branch and commit&lt;/h3&gt;
&lt;p&gt;Open the terminal and navigate to the Git repository where you want to perform this operation. Use the following command to display the current branch and commit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Create a new branch from commit B&lt;/h3&gt;
&lt;p&gt;To create a new branch at commit B, use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;branch&lt;span class="w"&gt; &lt;/span&gt;new-branch-name&lt;span class="w"&gt; &lt;/span&gt;commit-B-hash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;new-branch-name&lt;/code&gt; with the desired name for your new branch and &lt;code&gt;commit-B-hash&lt;/code&gt; with the hash or unique identifier of commit B. This command creates a new branch without switching to it.&lt;/p&gt;
&lt;h3&gt;Move commits C, D, and E to the new branch&lt;/h3&gt;
&lt;p&gt;Switch to the new branch using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;checkout&lt;span class="w"&gt; &lt;/span&gt;new-branch-name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command switches your working directory to the new branch. Commits C, D, and E will be moved to this branch while leaving the main branch unaffected.&lt;/p&gt;
&lt;p&gt;To move commits C, D, and E to the new branch, use the interactive rebase command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;rebase&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;commit-B-hash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;commit-B-hash&lt;/code&gt; with the hash or unique identifier of commit B. An interactive rebase will open, displaying a list of commits.&lt;/p&gt;
&lt;h3&gt;Rearrange the commits in the interactive rebase&lt;/h3&gt;
&lt;p&gt;In the interactive rebase interface, locate the lines representing commits C, D, and E. Rearrange their order by moving them above commit B. Save and close the file to continue.&lt;/p&gt;
&lt;h3&gt;Update the main branch&lt;/h3&gt;
&lt;p&gt;Switch back to the main branch using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;checkout&lt;span class="w"&gt; &lt;/span&gt;main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Your working directory will now be on the main branch.&lt;/p&gt;
&lt;h3&gt;Make changes to the main branch based on commit B&lt;/h3&gt;
&lt;p&gt;You are now on the main branch, as it was at commit B. Make the necessary changes or improvements.&lt;/p&gt;
&lt;h3&gt;Commit the changes on the main branch&lt;/h3&gt;
&lt;p&gt;Stage your changes using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Commit the changes with a descriptive message using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;commit&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Describe your changes or improvements&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Continue development on the main branch&lt;/h3&gt;
&lt;p&gt;At this point, you can continue making new commits on the main branch, just as you would in any normal development workflow.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: perhaps it is not a best practice to run development on the main branch - you can learn more about it from various branching strategies. We use such a schema here for sake of simplicity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Congratulations! You have successfully created a new branch starting from commit B and moved the subsequent commits C, D, and E to the new branch. The develop branch has been reverted to its state at commit B, allowing you to continue development from that point. Remember to use Git commands with caution and make sure to create backups or push your changes to a remote repository for safety.&lt;/p&gt;</content><category term="note"></category><category term="git"></category><category term="branching"></category><category term="git-history"></category><category term="software-development"></category><category term="howto"></category><category term="git-rebase"></category></entry><entry><title>Mastering Temporary Files and Directories with Python's tempfile Module</title><link href="https://www.safjan.com/mastering-temporary-files-and-directories-with-python-tempfile-module/" rel="alternate"></link><published>2023-07-13T00:00:00+02:00</published><updated>2023-07-13T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-13:/mastering-temporary-files-and-directories-with-python-tempfile-module/</id><summary type="html">&lt;p&gt;"Explore Python's tempfile module and learn how to create, manage, and customize temporary files and directories with ease. Master common use-cases and uncover lesser-known features of this powerful tool."&lt;/p&gt;</summary><content type="html">&lt;p&gt;Python's &lt;a href="https://docs.python.org/3/library/tempfile.html"&gt;tempfile&lt;/a&gt; module is an incredibly powerful tool that allows you to create and manage temporary files and directories with ease. In this article, we'll dive deep into the most common use-cases and explore some lesser-known, but highly useful features of this versatile module.&lt;/p&gt;
&lt;h2&gt;Why Use Temporary Files and Directories?&lt;/h2&gt;
&lt;p&gt;Temporary files and directories are essential when you need to store intermediate results, cache data, or hold information during the execution of a program. They can help you minimize memory usage and improve performance by reducing the need to recompute expensive operations. Moreover, temporary files can be useful in scenarios like &lt;a href="https://en.wikipedia.org/wiki/Unit_testing"&gt;unit testing&lt;/a&gt;, where you need to create mock files and directories for testing purposes.&lt;/p&gt;
&lt;h2&gt;Creating Temporary Files&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;tempfile&lt;/code&gt; module provides several functions to create temporary files, including &lt;code&gt;TemporaryFile&lt;/code&gt;, &lt;code&gt;NamedTemporaryFile&lt;/code&gt;, and &lt;code&gt;SpooledTemporaryFile&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;TemporaryFile&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryFile"&gt;&lt;code&gt;TemporaryFile&lt;/code&gt;&lt;/a&gt; function creates an anonymous temporary file that is deleted when it is closed. This function returns a file-like object that can be used with Python's standard I/O operations:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TemporaryFile&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;This is a temporary file.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;NamedTemporaryFile&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile"&gt;&lt;code&gt;NamedTemporaryFile&lt;/code&gt;&lt;/a&gt; function is similar to &lt;code&gt;TemporaryFile&lt;/code&gt;, but the file has a visible name in the file system. The file is deleted when it is closed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NamedTemporaryFile&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;This is a named temporary file.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;SpooledTemporaryFile&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.SpooledTemporaryFile"&gt;&lt;code&gt;SpooledTemporaryFile&lt;/code&gt;&lt;/a&gt; function creates a temporary file that is stored in memory (using &lt;code&gt;io.BytesIO&lt;/code&gt; or &lt;code&gt;io.StringIO&lt;/code&gt;) until it reaches a specified size. Once the size is exceeded, the data is automatically written to disk:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SpooledTemporaryFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;This is a spooled temporary file.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Creating Temporary Directories&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;tempfile&lt;/code&gt; module provides the &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryDirectory"&gt;&lt;code&gt;TemporaryDirectory&lt;/code&gt;&lt;/a&gt; function to create temporary directories. These directories, along with their contents, are automatically deleted when the context manager exits:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TemporaryDirectory&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Temporary directory: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;temp_file.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;This file is inside the temporary directory.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Temporary directory and file have been deleted.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Customizing Temporary File and Directory Names&lt;/h2&gt;
&lt;p&gt;You can customize the names of temporary files and directories using the &lt;code&gt;prefix&lt;/code&gt;, &lt;code&gt;suffix&lt;/code&gt;, and &lt;code&gt;dir&lt;/code&gt; arguments. For example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NamedTemporaryFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;my_temp_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suffix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/tmp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Temporary file path: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Managing File and Directory Lifetimes&lt;/h2&gt;
&lt;p&gt;By default, temporary files and directories are deleted when their corresponding file-like objects are closed. However, you can use the &lt;code&gt;delete&lt;/code&gt; argument to control this behavior:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NamedTemporaryFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;This temporary file will not be deleted.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Securely Generating Random Strings&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;tempfile&lt;/code&gt; module also provides the &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.mkstemp"&gt;&lt;code&gt;mkstemp&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://docs.python.org/3/library/tempfile.html#tempfile.mkdtemp"&gt;&lt;code&gt;mkdtemp&lt;/code&gt;&lt;/a&gt; functions, which generate random strings for file and directory names, respectively. These functions can be useful when you need to generate unique names for your application:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;

&lt;span class="n"&gt;temp_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;temp_file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkstemp&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Temporary file path: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_file_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;temp_dir_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdtemp&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Temporary directory path: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this article, we've explored the powerful features of Python's &lt;code&gt;tempfile&lt;/code&gt; module, covering common use-cases and some lesser-known features. With these tools at your disposal, you can easily create and manage temporary files and directories in your Python applications.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="temporary-file"></category><category term="temp"></category><category term="tempfile"></category></entry><entry><title>Exploring Python Packages for Loading and Processing YAML Front Matter in Markdown Documents</title><link href="https://www.safjan.com/python-packages-yaml-front-matter-markdown/" rel="alternate"></link><published>2023-07-11T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-11:/python-packages-yaml-front-matter-markdown/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pyyaml"&gt;PyYAML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#frontmatter"&gt;Frontmatter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#yaml-front-matter"&gt;YAML Front Matter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-markdown"&gt;Python Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mistune"&gt;mistune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commonmark"&gt;Commonmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#which-one-to-use-in-my-case"&gt;Which one to use in my case?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#simple-front-matter-extraction"&gt;Simple Front Matter Extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advanced-front-matter-manipulation"&gt;Advanced Front Matter Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#seamless-integration-with-markdown-parsing"&gt;Seamless Integration with Markdown Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance-and-speed"&gt;Performance and Speed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commonmark-compliance"&gt;CommonMark Compliance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#minimalistic-approach"&gt;Minimalistic Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="introduction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Markdown has gained …&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pyyaml"&gt;PyYAML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#frontmatter"&gt;Frontmatter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#yaml-front-matter"&gt;YAML Front Matter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-markdown"&gt;Python Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mistune"&gt;mistune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commonmark"&gt;Commonmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#which-one-to-use-in-my-case"&gt;Which one to use in my case?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#simple-front-matter-extraction"&gt;Simple Front Matter Extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advanced-front-matter-manipulation"&gt;Advanced Front Matter Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#seamless-integration-with-markdown-parsing"&gt;Seamless Integration with Markdown Parsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#performance-and-speed"&gt;Performance and Speed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#commonmark-compliance"&gt;CommonMark Compliance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#minimalistic-approach"&gt;Minimalistic Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="introduction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Markdown has gained popularity as a lightweight markup language for creating structured documents. It is widely used in various domains, including blogging, documentation, and note-taking. Markdown documents often include front matter, which is a metadata section at the beginning of the document. This front matter typically contains YAML (YAML Ain't Markup Language) formatted data that provides additional information about the document. In this blog post, we will explore several Python packages that can help you load and process YAML front matter in Markdown documents, providing you with the necessary tools to extract and work with this valuable metadata.&lt;/p&gt;
&lt;p&gt;&lt;a id="pyyaml"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;PyYAML&lt;/h3&gt;
&lt;p&gt;PyYAML is a powerful YAML parser and emitter for Python. It allows you to easily read and write YAML files, making it a suitable choice for extracting YAML front matter from Markdown documents.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyPI: &lt;a href="https://pypi.org/project/PyYAML/"&gt;PyYAML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/yaml/pyyaml"&gt;PyYAML on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on how to load, modify and save front matter to markdown document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yaml&lt;/span&gt;

&lt;span class="c1"&gt;# Read front matter from a Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;front_matter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;safe_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;front_matter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Modify front matter&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Modified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2023-07-12&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Write front matter back to the Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_flow_style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="frontmatter"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;python-frontmatter&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://jekyllrb.com/"&gt;Jekyll&lt;/a&gt;-style YAML front matter offers a useful way to add arbitrary, structured metadata to text documents, regardless of type.
This is a small package to load and parse files (or just text) with YAML (or JSON, TOML or other) front matter.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyPI: &lt;a href="https://pypi.org/project/python-frontmatter/"&gt;python-frontmatter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/eyeseast/python-frontmatter"&gt;python-frontmatter on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on how to load, modify and save front matter to markdown document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;frontmatter&lt;/span&gt;

&lt;span class="c1"&gt;# Read front matter from a Markdown file&lt;/span&gt;
&lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;frontmatter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Modify front matter&lt;/span&gt;
&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;modified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2023-07-12&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Write front matter back to the Markdown file&lt;/span&gt;
&lt;span class="n"&gt;frontmatter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="python-markdown"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Python Markdown&lt;/h3&gt;
&lt;p&gt;Python Markdown is a popular package for parsing and rendering Markdown documents. While its primary focus is on converting Markdown to HTML, it also provides support for custom extensions, including front matter parsing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyPI: &lt;a href="https://pypi.org/project/Markdown/"&gt;Python Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/Python-Markdown/markdown"&gt;Python Markdown on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on how to load, modify and save front matter to markdown document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;markdown.extensions&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;meta&lt;/span&gt;

&lt;span class="c1"&gt;# Read front matter from a Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;md&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MetaExtension&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Modify front matter&lt;/span&gt;
&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Meta&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Modified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;2023-07-12&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Write front matter back to the Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Meta&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pformat&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="mistune"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;mistune&lt;/h3&gt;
&lt;p&gt;Description: mistune is a fast and extensible Markdown parser implemented in pure Python. It aims to be compatible with the Markdown specification while offering various customization options, including support for front matter parsing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyPI: &lt;a href="https://pypi.org/project/mistune/"&gt;mistune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/lepture/mistune"&gt;mistune on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on how to load, modify and save front matter to markdown document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;mistune&lt;/span&gt;

&lt;span class="c1"&gt;# Read front matter from a Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;md&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mistune&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Markdown&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;renderer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mistune&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AstRenderer&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="c1"&gt;# Modify front matter&lt;/span&gt;
&lt;span class="n"&gt;front_matter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;renderer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;front_matter&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;front_matter&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Modified&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;2023-07-12&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Write front matter back to the Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;renderer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="commonmark"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Commonmark&lt;/h3&gt;
&lt;p&gt;Commonmark is a comprehensive Markdown parsing and rendering library for Python. It adheres to the CommonMark specification and offers a wide range of features, including support for parsing YAML front matter.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyPI: &lt;a href="https://pypi.org/project/commonmark/"&gt;Commonmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href="https://github.com/commonmark/commonmark-python"&gt;Commonmark on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example on how to load, modify and save front matter to markdown document:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;commonmark&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="c1"&gt;# Read front matter from a Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Extract front matter&lt;/span&gt;
&lt;span class="n"&gt;front_matter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;^---\n(.*?)\n---\n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DOTALL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;safe_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;front_matter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Modify front matter&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Modified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2023-07-12&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Write front matter back to the Markdown file&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;article.md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_flow_style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;---&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;front_matter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="which-one-to-use-in-my-case"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Which one to use in my case?&lt;/h2&gt;
&lt;p&gt;Here are distinct use cases related to loading and processing YAML front matter in Markdown documents, along with recommended libraries for each case and the justifications for the recommendations:&lt;/p&gt;
&lt;p&gt;&lt;a id="simple-front-matter-extraction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Simple Front Matter Extraction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;Frontmatter&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Frontmatter is a dedicated Python package designed specifically for working with front matter in Markdown documents. It provides a simple and intuitive API for extracting front matter data, making it a suitable choice for straightforward front matter extraction needs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="advanced-front-matter-manipulation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Advanced Front Matter Manipulation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;PyYAML&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;PyYAML is a powerful YAML parser and emitter for Python. If you require advanced manipulation and processing of YAML front matter, PyYAML offers extensive functionality and flexibility. It allows you to read and write YAML files, making it a robust choice for complex front matter handling.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="seamless-integration-with-markdown-parsing"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Seamless Integration with Markdown Parsing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;Python Markdown&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;If your focus is on seamless integration with Markdown parsing, Python Markdown is a widely-used and feature-rich package. It supports custom extensions, including front matter parsing, allowing you to extract front matter while parsing the Markdown content. This integration can simplify your workflow when working with Markdown documents.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="performance-and-speed"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Performance and Speed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;mistune&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;mistune is a fast and extensible Markdown parser implemented in pure Python. If performance and speed are crucial factors in your use case, mistune's efficient parsing capabilities make it an ideal choice. It provides customization options, including support for front matter parsing, while maintaining high performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="commonmark-compliance"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;CommonMark Compliance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;Commonmark&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If adhering to the CommonMark specification is essential, Commonmark is a comprehensive Markdown parsing and rendering library that aligns with the specification. It supports front matter parsing while ensuring compliance with the CommonMark standard, providing a reliable solution for standardized Markdown processing.&lt;/p&gt;
&lt;p&gt;&lt;a id="minimalistic-approach"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Minimalistic Approach&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Recommended Library: &lt;strong&gt;YAML Front Matter&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;YAML Front Matter is a minimalistic package that focuses on simplicity and ease of use. If you prefer a lightweight solution for extracting YAML front matter from Markdown files without additional complexity, YAML Front Matter provides a straightforward and efficient approach.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post, we explored several Python packages that can load and process YAML front matter in Markdown documents. These packages provide convenient and efficient methods for extracting metadata from the front matter section, enabling you to access and manipulate this valuable information.&lt;/p&gt;</content><category term="Note"></category><category term="python"></category><category term="markdown"></category><category term="front matter"></category><category term="YAML"></category><category term="packages"></category></entry><entry><title>Boosting Productivity and Automation With AppleScript on macOS</title><link href="https://www.safjan.com/Boosting%20Productivity%20and%20Automation%20with%20AppleScript%20on%20macOS/" rel="alternate"></link><published>2023-07-10T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-10:/Boosting Productivity and Automation with AppleScript on macOS/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In today's fast-paced digital world, maximizing productivity and finding ways to automate tasks are essential skills. macOS provides a powerful tool called AppleScript, which allows users to write scripts and automate various processes. In this blog post, we will explore the …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In today's fast-paced digital world, maximizing productivity and finding ways to automate tasks are essential skills. macOS provides a powerful tool called AppleScript, which allows users to write scripts and automate various processes. In this blog post, we will explore the capabilities of AppleScript, discuss cool tricks, and highlight its alternatives.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3,4" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#getting-started-with-applescript"&gt;Getting Started with AppleScript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#increasing-productivity-with-applescript"&gt;Increasing Productivity with AppleScript&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#customized-workflow"&gt;Customized Workflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#application-control"&gt;Application Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#system-automation"&gt;System Automation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#cool-tricks-with-applescript"&gt;Cool Tricks with AppleScript&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#displaying-notifications"&gt;Displaying Notifications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#text-manipulation"&gt;Text Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gui-automation"&gt;GUI Automation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#alternatives-to-applescript"&gt;Alternatives to AppleScript&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#automator"&gt;Automator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hammerspoon"&gt;Hammerspoon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#keyboard-maestro"&gt;Keyboard Maestro&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="getting-started-with-applescript"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Getting Started with AppleScript&lt;/h3&gt;
&lt;p&gt;AppleScript is a scripting language that enables users to control applications and perform tasks on macOS. It utilizes the &lt;code&gt;osascript&lt;/code&gt; command-line utility to execute AppleScript code. To begin using AppleScript, open the Terminal on your Mac and enter the desired commands preceded by &lt;code&gt;osascript -e&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The osascript website provide examples:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Open&lt;span class="w"&gt; &lt;/span&gt;or&lt;span class="w"&gt; &lt;/span&gt;switch&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;Safari:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tell app &amp;quot;Safari&amp;quot; to activate&amp;#39;&lt;/span&gt;

Close&lt;span class="w"&gt; &lt;/span&gt;safari:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;quit app &amp;quot;safari.app&amp;quot;&amp;#39;&lt;/span&gt;

Empty&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;trash:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tell application &amp;quot;Finder&amp;quot; to empty trash&amp;#39;&lt;/span&gt;

Set&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;output&lt;span class="w"&gt; &lt;/span&gt;volume&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;%&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set volume output volume 50&amp;#39;&lt;/span&gt;

Input&lt;span class="w"&gt; &lt;/span&gt;volume&lt;span class="w"&gt; &lt;/span&gt;and&lt;span class="w"&gt; &lt;/span&gt;Alert&lt;span class="w"&gt; &lt;/span&gt;volume&lt;span class="w"&gt; &lt;/span&gt;can&lt;span class="w"&gt; &lt;/span&gt;also&lt;span class="w"&gt; &lt;/span&gt;be&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;from&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;%:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set volume input volume 40&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set volume alert volume 75&amp;#39;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;

Mute&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;output&lt;span class="w"&gt; &lt;/span&gt;volume&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;True/False&lt;span class="o"&gt;)&lt;/span&gt;:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set volume output muted TRUE&amp;#39;&lt;/span&gt;

Toggle&lt;span class="w"&gt; &lt;/span&gt;volume&lt;span class="w"&gt; &lt;/span&gt;muting:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set volume output muted not (output muted of (get volume settings))&amp;#39;&lt;/span&gt;

Toggle&lt;span class="w"&gt; &lt;/span&gt;system&lt;span class="w"&gt; &lt;/span&gt;theme:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tell application &amp;quot;System Events&amp;quot; to tell appearance preferences to set dark mode to not dark mode&amp;#39;&lt;/span&gt;

Shut&lt;span class="w"&gt; &lt;/span&gt;down&lt;span class="w"&gt; &lt;/span&gt;without&lt;span class="w"&gt; &lt;/span&gt;asking&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;confirmation:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tell app &amp;quot;System Events&amp;quot; to shut down&amp;#39;&lt;/span&gt;

Restart&lt;span class="w"&gt; &lt;/span&gt;without&lt;span class="w"&gt; &lt;/span&gt;asking&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;confirmation:&lt;span class="w"&gt;  &lt;/span&gt;
$&lt;span class="w"&gt; &lt;/span&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tell app &amp;quot;System Events&amp;quot; to restart&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="increasing-productivity-with-applescript"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Increasing Productivity with AppleScript&lt;/h3&gt;
&lt;p&gt;&lt;a id="customized-workflow"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Customized Workflow&lt;/h4&gt;
&lt;p&gt;AppleScript enables you to create personalized workflows by automating repetitive tasks. For example, you can write a script that renames and moves files based on specific criteria, saving you time and effort.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 1: &lt;strong&gt;Automating File Organization&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Finder&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sourceFolder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;choose&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;folder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;prompt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Select the source folder&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;destinationFolder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;choose&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;folder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;prompt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Select the destination folder&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fileList&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;every&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sourceFolder&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;repeat&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fileList&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;move&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;destinationFolder&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;repeat&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script allows you to select a source folder and a destination folder. It moves all files from the source folder to the destination folder, simplifying your file organization process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="application-control"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Application Control&lt;/h4&gt;
&lt;p&gt;With AppleScript, you can interact with various macOS applications. You could automate tasks like sending emails, creating documents, or extracting data from spreadsheets, helping streamline your workflow.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 2: Creating New Email in Apple Mail&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Mail&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;newMessage&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;make&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;outgoing&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;message&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;properties&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;subject&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;content&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Just wanted to say hi!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;newMessage&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;make&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;recipient&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;at&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;recipients&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;properties&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;address&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;example@email.com&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;open&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;tell&lt;/span&gt;
&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;tell&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script automates the process of creating a new email in Apple Mail. It sets the subject and content of the email and adds a recipient, ready for you to send your message swiftly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="system-automation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;System Automation&lt;/h4&gt;
&lt;p&gt;AppleScript allows you to control system settings and perform actions like changing the display resolution, adjusting volume, or toggling Wi-Fi—all with a single script.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 3: Adjusting Display Brightness&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;System Preferences&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;reveal&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;anchor&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;displaysDisplayTab&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;pane&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;com.apple.preference.displays&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;activate&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;

&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;System Events&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;process&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;System Preferences&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;slider&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;window&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;75&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Change&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;brightness&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;level&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;

&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;System Preferences&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;quit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script opens the Display preferences in System Preferences, adjusts the brightness slider to the desired level, and then closes System Preferences. This allows you to quickly customize your display brightness without navigating through menus.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="cool-tricks-with-applescript"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Cool Tricks with AppleScript&lt;/h3&gt;
&lt;p&gt;&lt;a id="displaying-notifications"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Displaying Notifications&lt;/h4&gt;
&lt;p&gt;As discussed earlier, you can use AppleScript to display notifications on the screen. This feature is particularly useful for receiving alerts or reminders during time-sensitive tasks.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 4: Notifying Important Task Deadlines&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;display notification &amp;quot;Don&amp;#39;t forget to submit the report by 5 PM!&amp;quot; with title &amp;quot;Task Reminder&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script displays a notification with a reminder for an important task deadline. You can set up similar notifications for time-sensitive activities to keep you on track.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="text-manipulation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Text Manipulation&lt;/h4&gt;
&lt;p&gt;AppleScript offers powerful text manipulation capabilities. You can automate tasks such as extracting specific information from a text file, finding and replacing text across multiple documents, or formatting text according to predefined rules.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 5: Find and Replace Text in Multiple Files&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;searchText&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;oldText&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;replaceText&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;newText&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Finder&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;folderPath&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;choose&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;folder&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;prompt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Select the folder&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fileList&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;every&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;folderPath&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;repeat&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fileList&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fileContents&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;read&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;«&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;utf8&lt;/span&gt;»
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;modifiedContents&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;replaceTextInString&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;fileContents&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;searchText&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;replaceText&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;writeResult&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;write&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;modifiedContents&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aFile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;«&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;utf8&lt;/span&gt;»
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;repeat&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;tell&lt;/span&gt;

&lt;span class="nv"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;replaceTextInString&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;textString&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;oldText&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;newText&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;AppleScript&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;s text item delimiters to the oldText&lt;/span&gt;
&lt;span class="err"&gt;    set textItems to every text item of textString&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;AppleScript&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;s text item delimiters to the newText&lt;/span&gt;
&lt;span class="err"&gt;    return textItems as text&lt;/span&gt;
&lt;span class="err"&gt;end replaceTextInString&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script prompts you to select a folder and replaces all occurrences of "oldText" with "newText" in the contents of every file within that folder. This can be useful for batch text replacements across multiple documents.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="gui-automation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;GUI Automation&lt;/h4&gt;
&lt;p&gt;AppleScript can simulate user interactions with graphical user interfaces (GUI). You can automate tasks that involve clicking buttons, selecting options from menus, or filling out forms in applications, saving you from repetitive manual operations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example Script 6: Automating Safari Website Login&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Safari&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;location&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https://example.com/login&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;needed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;load&lt;/span&gt;
&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tell&lt;/span&gt;

&lt;span class="n"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;application&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;System Events&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;tell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Safari&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;frontmost&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="bp"&gt;true&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;keystroke&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;username&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;keystroke&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tab&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;keystroke&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;password&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;keystroke&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tell&lt;/span&gt;
&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tell&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;This script automates the process of opening a specific website in Safari, entering a username, password, and submitting the login form. You can adapt this script to automate various web-based actions.
&lt;a id="alternatives-to-applescript"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Alternatives to AppleScript&lt;/h3&gt;
&lt;p&gt;While AppleScript is a robust tool, other alternatives can also help achieve automation and productivity on macOS:&lt;/p&gt;
&lt;p&gt;&lt;a id="automator"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Automator&lt;/h4&gt;
&lt;p&gt;&lt;img alt="automator logo" src="https://help.apple.com/assets/61E87B255FBFB2628709732E/61E87B275FBFB26287097336/en_GB/573f95d708cbb258343f5c78cc439bcb.png"&gt;
&lt;a href="https://support.apple.com/en-gb/guide/automator/welcome/mac"&gt;Automator&lt;/a&gt; is a visual automation tool built into macOS. It provides a drag-and-drop interface to create workflows without writing code. Automator supports a wide range of actions and can be an excellent choice for users who prefer a more intuitive approach.
&lt;a id="hammerspoon"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Hammerspoon&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Hammerspoon logo" src="https://www.hammerspoon.org/images/hammerspoon.png"&gt;
&lt;a href="https://www.hammerspoon.org/"&gt;Hammerspoon&lt;/a&gt; is a powerful automation tool that uses the Lua scripting language. It offers extensive customization and control over macOS, allowing users to create complex workflows and automation routines.&lt;/p&gt;
&lt;p&gt;&lt;a id="keyboard-maestro"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Keyboard Maestro&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Keyboard Maestro logo" src="https://www.keyboardmaestro.com/img/keyboardmaestro-64.png"&gt;
&lt;a href="https://www.keyboardmaestro.com/main/"&gt;Keyboard Maestro&lt;/a&gt; is a comprehensive automation tool that focuses on keyboard and mouse automation. It provides a user-friendly interface to create macros, trigger actions based on specific events, and automate repetitive tasks efficiently.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;AppleScript is a versatile tool for increasing productivity and automating tasks on macOS. Its ability to control applications, system settings, and perform various actions make it a valuable asset. Additionally, cool tricks like displaying notifications and GUI automation enhance the overall experience. However, alternatives like Automator, Hammerspoon, and Keyboard Maestro offer different approaches to automation, catering to diverse user preferences. Explore these tools and find the one that best fits your workflow to unlock new levels of productivity and efficiency on your Mac.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://developer.apple.com/library/archive/documentation/AppleScript/Conceptual/AppleScriptLangGuide/introduction/ASLR_intro.html"&gt;Introduction to AppleScript Language Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ss64.com/osx/osascript.html"&gt;osascript Man Page - macOS - SS64.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ss64.com/osx/osacompile.html"&gt;osacompile&lt;/a&gt; - Compile AppleScripts and other OSA language scripts.&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="macos"></category><category term="automation"></category><category term="script"></category><category term="osascropt"></category><category term="applescript"></category></entry><entry><title>Display a Notification on the Screen in macOS</title><link href="https://www.safjan.com/display-a-notification-on-the-screen-in-macos/" rel="alternate"></link><published>2023-07-10T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-10:/display-a-notification-on-the-screen-in-macos/</id><summary type="html">&lt;p&gt;To display a notification on the screen near the menu bar in macOS using the terminal, you can make use of the &lt;code&gt;osascript&lt;/code&gt; command to execute AppleScript code. Here's an example command you can run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;display notification &amp;quot;Hello, World!&amp;quot; with …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;To display a notification on the screen near the menu bar in macOS using the terminal, you can make use of the &lt;code&gt;osascript&lt;/code&gt; command to execute AppleScript code. Here's an example command you can run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;osascript&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;display notification &amp;quot;Hello, World!&amp;quot; with title &amp;quot;Notification&amp;quot;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will display a notification with the message "Hello, World!" and the title "Notification" near the menu bar on macOS.&lt;/p&gt;
&lt;p&gt;You can customize the message and title by modifying the strings inside the double quotes in the &lt;code&gt;osascript&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Note that starting from macOS Big Sur (11.0), AppleScript-based notifications require user authorization. The first time you run this command, you will be prompted to grant permission to Terminal (or whichever application you are using) to send notifications.&lt;/p&gt;
&lt;h2&gt;reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://victorscholz.medium.com/what-is-osascript-e48f11b8dec6"&gt;What is Osascript?. Learning about Osascript started with… | by Victor Scholz | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ss64.com/osx/osascript.html"&gt;osascript Man Page - macOS - SS64.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="note"></category><category term="macos"></category><category term="notification"></category><category term="pop-up-window"></category></entry><entry><title>Software Versioning Schemes</title><link href="https://www.safjan.com/software-versioning-schemes/" rel="alternate"></link><published>2023-07-08T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-08:/software-versioning-schemes/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Software versioning schemes are essential in the world of programming, as they help developers, users, and collaborators keep track of various versions of a software product. A proper versioning scheme enables easy identification of the current release, the changes made in …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Software versioning schemes are essential in the world of programming, as they help developers, users, and collaborators keep track of various versions of a software product. A proper versioning scheme enables easy identification of the current release, the changes made in each version, and the compatibility of a version with previous ones. In this blog post, we will discuss some of the most popular versioning schemes used in the software industry, along with a few lesser-known but useful alternatives.  &lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#semantic-versioning"&gt;Semantic Versioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#calendar-versioning-calver"&gt;Calendar Versioning (CalVer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#zerover-0-based-versioning"&gt;ZeroVer: 0-based Versioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lesser-known-versioning-schemes"&gt;Lesser-known Versioning Schemes&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#romantic-versioning"&gt;Romantic Versioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hash-based-versioning"&gt;Hash-based Versioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#custom-versioning-schemes"&gt;Custom Versioning Schemes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="semantic-versioning"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Semantic Versioning (SemVer)&lt;/h2&gt;
&lt;p&gt;Semantic versioning, also known as &lt;a href="https://semver.org/"&gt;SemVer&lt;/a&gt;, is a widely adopted versioning scheme that emphasizes the importance of clear and meaningful version numbers. In SemVer, a version number consists of three parts: MAJOR.MINOR.PATCH. Each part represents the following:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MAJOR version: incremented when you make incompatible API changes,  &lt;/li&gt;
&lt;li&gt;MINOR version: incremented when you add functionality in a backwards-compatible manner, and  &lt;/li&gt;
&lt;li&gt;PATCH version: incremented when you make backwards-compatible bug fixes.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these three parts, SemVer allows for additional labels for pre-release and build metadata as extensions to the MAJOR.MINOR.PATCH format. This makes it easier for developers to communicate the scope of changes in each release and helps users understand if an update will break their existing setup or not.  &lt;/p&gt;
&lt;p&gt;&lt;a id="calendar-versioning-calver"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Calendar Versioning (CalVer)&lt;/h2&gt;
&lt;p&gt;Another popular versioning scheme is Calendar Versioning or &lt;a href="https://calver.org/"&gt;CalVer&lt;/a&gt;. CalVer uses a combination of the release date and a project-specific version number to create a unique identifier for each release. The format typically looks like this: YYYY.MM.DD.MICRO.  &lt;/p&gt;
&lt;p&gt;The advantages of CalVer include its simplicity and the ability to quickly determine the age of a release. However, unlike SemVer, CalVer does not provide explicit information about API changes or compatibility between versions.  &lt;/p&gt;
&lt;p&gt;&lt;a id="zerover-0-based-versioning"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;ZeroVer: 0-based Versioning (0ver)&lt;/h2&gt;
&lt;p&gt;ZeroVer, also known as &lt;a href="https://0ver.org/"&gt;0ver&lt;/a&gt; is a unique and simple versioning scheme that asserts that your software's major version should never exceed the first and most important number in computing: zero.  This is in contrast to other versioning schemes like Semantic Versioning and Calendar Versioning.  &lt;/p&gt;
&lt;p&gt;The rationale behind ZeroVer is that software is never truly "finished" and will always be subject to improvements, bug fixes, and new features. By keeping the major version at zero, developers acknowledge the ever-evolving nature of their software and avoid the pressures associated with "final" releases.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: in the &lt;code&gt;0ver&lt;/code&gt; there is a zero in front of the name, do not confuse with capital letter O&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="lesser-known-versioning-schemes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Lesser-known Versioning Schemes&lt;/h2&gt;
&lt;p&gt;In addition to the popular versioning schemes mentioned above, there are other lesser-known but equally useful alternatives. Some of these include:  &lt;/p&gt;
&lt;p&gt;&lt;a id="romantic-versioning"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Romantic Versioning&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/romversioning/romver"&gt;Romantic Versioning&lt;/a&gt; is a light-hearted, informal versioning scheme that uses popular culture references or personal milestones as version numbers. While not suitable for all projects, Romantic Versioning can be a fun way to engage users and make software updates more memorable.  &lt;/p&gt;
&lt;p&gt;The Romantic Versioning specification was authored by &lt;a href="http://blog.legacyteam.info/2015/12/romver-romantic-versioning/"&gt;Daniel V from the Legacy Blog crew&lt;/a&gt; in 2015. This open and public repository has the task of maintenance and visibility, cooperation with others.&lt;/p&gt;
&lt;p&gt;See also: &lt;a href="http://sentimentalversioning.org/"&gt;sentimentalversioning.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="hash-based-versioning"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Hash-based Versioning&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://miniscruff.github.io/hashver/"&gt;Hash-based Versioning&lt;/a&gt;is a versioning scheme that uses the unique hash of a particular commit in a version control system (such as Git) as the version number. This approach ensures that each release is directly tied to a specific point in the development history, making it easy to track and revert changes if needed.  &lt;/p&gt;
&lt;p&gt;&lt;a id="custom-versioning-schemes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Custom Versioning Schemes&lt;/h3&gt;
&lt;p&gt;Some projects may benefit from a custom versioning scheme tailored to their specific needs. This could involve combining elements from various existing schemes or developing an entirely new approach. When creating a custom versioning scheme, it's essential to ensure that it is clear, consistent, and easy to understand for all stakeholders.  &lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Choosing the right versioning scheme for your software project is crucial for effective communication and collaboration among developers, users, and other stakeholders. While Semantic Versioning and Calendar Versioning are popular choices, alternative schemes like ZeroVer, Romantic Versioning, Hash-based Versioning, or even custom schemes can also be appropriate depending on your project's unique requirements. Ultimately, the ideal versioning scheme should be easy to understand, provide meaningful information about each release, and facilitate the management of software updates.&lt;/p&gt;</content><category term="note"></category><category term="versioning"></category><category term="semantic-versioning"></category><category term="semver"></category><category term="calver"></category><category term="calendar-versioning"></category><category term="zerover"></category><category term="0ver"></category></entry><entry><title>How to install Faiss on Google Colab</title><link href="https://www.safjan.com/how-to-install-faiss-on-google-colab/" rel="alternate"></link><published>2023-07-04T00:00:00+02:00</published><updated>2023-07-04T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-04:/how-to-install-faiss-on-google-colab/</id><content type="html">&lt;h2&gt;"X:": "2023-06-08-Similarity_search_using_IVFPQ"&lt;/h2&gt;
&lt;p&gt;To install &lt;a href="https://github.com/facebookresearch/faiss"&gt;faiss&lt;/a&gt; on Colab use:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="sx"&gt;!pip install faiss-cpu --no-cache&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="faiss"></category><category term="colab"></category><category term="pip-install"></category><category term="vectordb"></category><category term="IVFPQ"></category></entry><entry><title>Easy Text Vectorization With VectorHub and Sentence Transformers</title><link href="https://www.safjan.com/text-vectorization-with-vectorhub-and-sentence-transformers/" rel="alternate"></link><published>2023-07-04T00:00:00+02:00</published><updated>2023-07-04T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-04:/text-vectorization-with-vectorhub-and-sentence-transformers/</id><summary type="html">&lt;p&gt;Learn how to use Sentence Transformers for text vectorization with different models using consistent API.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Text is heavily inspired by part of the e-book: &lt;a href="https://learn.getvectorai.com/vector-ai-documentation/semantic-nlp-search-with-faiss-and-vectorhub"&gt;Semantic NLP search with FAISS and VectorHub - Guide To Vectors (getvectorai.com)&lt;/a&gt; - which was using VectorHub as an interface to the models.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: VectorHub is deprecated and no longer maintained. The authors of VectorHub recommend using &lt;a href="https://www.sbert.net/"&gt;Sentence Transformers&lt;/a&gt;, TFHub, and Huggingface directly for text vectorization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This article demonstrates a similar process as the original article but uses a sentence transformers package.&lt;/p&gt;
&lt;h3&gt;Encoding Data Using Sentence Transformers&lt;/h3&gt;
&lt;p&gt;To encode models easily, we will utilize the &lt;a href="https://www.sbert.net/"&gt;Sentence Transformers&lt;/a&gt; library. SentenceTransformers is a Python framework for state-of-the-art sentence, text, and image embeddings. It provides a variety of pre-trained models that can convert sentences into meaningful numerical representations.&lt;/p&gt;
&lt;p&gt;First, we need to install the &lt;code&gt;sentence-transformers&lt;/code&gt; package, which includes the necessary dependencies for using Sentence Transformers. This library offers a wide range of pre-trained models, such as &lt;a href="https://en.wikipedia.org/wiki/BERT_(Language_model)"&gt;BERT&lt;/a&gt;, &lt;a href="https://huggingface.co/docs/transformers/model_doc/roberta"&gt;RoBERTa&lt;/a&gt;, and &lt;a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"&gt;MiniLM&lt;/a&gt;, that can be used for text encoding. More information about Sentence Transformers can be found &lt;a href="https://www.sbert.net/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;sentence-transformers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, we will instantiate our model and start the encoding process. In this example, we will use the "all-MiniLM-L6-v2" model, which is a variant of the MiniLM model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sentence_transformers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SentenceTransformer&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SentenceTransformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;all-MiniLM-L6-v2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Sentences to be encoded&lt;/span&gt;
&lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;This framework generates embeddings for each input sentence&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;Sentences are passed as a list of strings.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;The quick brown fox jumps over the lazy dog.&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Encode sentences using the Sentence Transformers model&lt;/span&gt;
&lt;span class="n"&gt;embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Print the embeddings&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Sentence:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Embedding:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the code snippet above, we begin by installing the &lt;code&gt;sentence-transformers&lt;/code&gt; package, which provides the necessary tools for working with Sentence Transformers. This library offers various pre-trained models that can convert sentences into meaningful vector representations.&lt;/p&gt;
&lt;p&gt;After the installation, we import the &lt;code&gt;SentenceTransformer&lt;/code&gt; class from the &lt;code&gt;sentence_transformers&lt;/code&gt; module. We instantiate the model using the &lt;code&gt;all-MiniLM-L6-v2&lt;/code&gt; variant, which will be used for encoding our sentences.&lt;/p&gt;
&lt;p&gt;We define a list of sentences that we want to encode using the Sentence Transformers model. In this case, we have three exemplary sentences: "This framework generates embeddings for each input sentence," "Sentences are passed as a list of strings," and "The quick brown fox jumps over the lazy dog."&lt;/p&gt;
&lt;p&gt;To perform the encoding, we use the &lt;code&gt;encode&lt;/code&gt; method of the &lt;code&gt;model&lt;/code&gt; object, passing in the &lt;code&gt;sentences&lt;/code&gt; list. This method returns the corresponding embeddings for each sentence, which we store in the &lt;code&gt;embeddings&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;Finally, we iterate over the &lt;code&gt;sentences&lt;/code&gt; and &lt;code&gt;embeddings&lt;/code&gt; lists together using &lt;code&gt;zip&lt;/code&gt;. For each sentence and its corresponding embedding, we print them out to visualize the results.&lt;/p&gt;
&lt;p&gt;Please note that the code snippet above uses the "all-MiniLM-L6-v2" model as an example. You can explore and choose from a wide range of models provided by Sentence Transformers according to your specific requirements.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/RelevanceAI/vectorhub"&gt;GitHub - RelevanceAI/vectorhub: Vector Hub - Library for easy discovery, and consumption of State-of-the-art models to turn data into vectors. (text2vec, image2vec, video2vec, graph2vec, bert, inception, etc)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learn.getvectorai.com/"&gt;Introduction - Guide To Vectors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><category term="Generative AI"></category><category term="embeddings"></category><category term="nlp"></category><category term="vectorhub"></category><category term="bert"></category><category term="sentence-transformers"></category></entry><entry><title>Introducing a Python Module for Splitting Text Into Parts Based on Token Limit</title><link href="https://www.safjan.com/token-split-text/" rel="alternate"></link><published>2023-07-03T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-07-03:/token-split-text/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the realm of natural language processing and text analysis, it is often necessary to split a large piece of text into smaller parts while ensuring that the split does not break words or disrupt the meaning of the text. This …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the realm of natural language processing and text analysis, it is often necessary to split a large piece of text into smaller parts while ensuring that the split does not break words or disrupt the meaning of the text. This task can be challenging, especially when dealing with the tokenization. However, with the help of the Tiktoken library and a custom Python module, splitting text based on a specified number of tokens can be an easy task.&lt;/p&gt;
&lt;h2&gt;Understanding the Tiktoken Library&lt;/h2&gt;
&lt;p&gt;Tiktoken is a powerful Python library for tokenization, which is the process of splitting text into individual tokens such as words or subwords. The library provides various tokenization encodings and functions that enable developers to process text data in a tokenized format. It offers support for different languages and tokenization models, making it a versatile tool for a wide range of text processing tasks. Tiktoken is a fast &lt;a href="https://en.wikipedia.org/wiki/Byte_pair_encoding"&gt;BPE&lt;/a&gt; tokeniser for use with OpenAI's models.&lt;/p&gt;
&lt;h2&gt;Introducing the Python Module: split_string_with_limit&lt;/h2&gt;
&lt;p&gt;The provided Python module: &lt;a href="https://gist.github.com/izikeros/17d9c8ab644bd2762acf6b19dd0cea39"&gt;split_string_with_limit.py&lt;/a&gt; (GitHub Gist), leverages the capabilities of the Tiktoken library to split a string into parts with a specified limit on the number of tokens per part. The module takes three parameters: &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;limit&lt;/code&gt;, and &lt;code&gt;encoding&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;text&lt;/code&gt;: The input string that needs to be split.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;limit&lt;/code&gt;: The maximum number of tokens allowed per part.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;encoding&lt;/code&gt;: The tokenization encoding to be used, which determines how the text is tokenized.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The module proceeds as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It tokenizes the input text using the specified encoding from Tiktoken.&lt;/li&gt;
&lt;li&gt;It creates an empty list, &lt;code&gt;parts&lt;/code&gt;, to store the tokenized parts.&lt;/li&gt;
&lt;li&gt;It initializes a &lt;code&gt;current_part&lt;/code&gt; list and a &lt;code&gt;current_count&lt;/code&gt; variable to keep track of the tokens in the current part.&lt;/li&gt;
&lt;li&gt;It iterates over each token in the tokenized text.&lt;/li&gt;
&lt;li&gt;For each token, it appends it to the &lt;code&gt;current_part&lt;/code&gt; list and increments the &lt;code&gt;current_count&lt;/code&gt; by 1.&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;current_count&lt;/code&gt; exceeds the specified limit, it adds the &lt;code&gt;current_part&lt;/code&gt; to the &lt;code&gt;parts&lt;/code&gt; list, resets the &lt;code&gt;current_part&lt;/code&gt; and &lt;code&gt;current_count&lt;/code&gt; to empty values, and continues with the next tokens.&lt;/li&gt;
&lt;li&gt;Once all the tokens have been processed, the module checks if there is any remaining &lt;code&gt;current_part&lt;/code&gt; and adds it to the &lt;code&gt;parts&lt;/code&gt; list.&lt;/li&gt;
&lt;li&gt;Finally, it converts each tokenized part back into text format by decoding the individual tokens and joins them together. The resulting text parts are stored in the &lt;code&gt;text_parts&lt;/code&gt; list.&lt;/li&gt;
&lt;li&gt;The module returns the &lt;code&gt;text_parts&lt;/code&gt; list as the output.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Example Usage&lt;/h2&gt;
&lt;p&gt;To demonstrate the usage of the &lt;code&gt;split_string_with_limit&lt;/code&gt; module, let's consider an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python&lt;span class="w"&gt; &lt;/span&gt;split_string_with_limit.py&lt;span class="w"&gt; &lt;/span&gt;input_file.txt&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;cl100k_base
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this example, we provide three arguments:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;input_file.txt&lt;/code&gt;: The path to the input text file that contains the text to be split.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;100&lt;/code&gt;: The maximum number of tokens allowed per part. You can adjust this value based on your requirements.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cl100k_base&lt;/code&gt;: The encoding name. This determines how the text will be tokenized. Tiktoken provides various encoding options, and you can experiment with different encodings to achieve the desired results.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The module reads the text from the input file, tokenizes it using the specified encoding, and splits it into parts based on the token limit. The resulting text parts are then printed in a JSON format, providing a structured representation of the split text.&lt;/p&gt;
&lt;h2&gt;Approximate approach&lt;/h2&gt;
&lt;p&gt;While the &lt;code&gt;split_string_with_limit&lt;/code&gt; module offers a convenient solution for splitting text based on a token limit, it's worth mentioning alternative algorithms or approaches that can achieve similar results. One of these can be a &lt;strong&gt;Fixed-Length Split&lt;/strong&gt;: instead of splitting based on the number of tokens, we could split the text into fixed-length segments based on counting words or characters. One can use &lt;a href="https://platform.openai.com/tokenizer"&gt;rule of thumb&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;to have approximate of the split into parts of equal length without doing actual tokenization.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post, we introduced the &lt;code&gt;split_string_with_limit&lt;/code&gt; Python module, which leverages the power of the Tiktoken library to split a string into parts based on a specified token limit. We discussed the functionality of the module, its parameters, and how it can be used in practice. Furthermore, we explored alternative algorithms and approaches for splitting text based on the number of tokens. By combining the flexibility of Tiktoken and the convenience of the &lt;code&gt;split_string_with_limit&lt;/code&gt; module, developers can efficiently process and analyze text data without compromising on accuracy or readability.&lt;/p&gt;</content><category term="note"></category><category term="tokenization"></category><category term="tiktoken"></category><category term="prompt-chunking"></category><category term="split-text"></category><category term="text-partitioning"></category><category term="openai"></category><category term="gpt-4"></category></entry><entry><title>Demystifying Perplexity - Assessing Dimensionality Reduction With PCA</title><link href="https://www.safjan.com/demystifying-perplexity-assessing-dimensionality-reduction-with-pca/" rel="alternate"></link><published>2023-06-30T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-30:/demystifying-perplexity-assessing-dimensionality-reduction-with-pca/</id><summary type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/measure-quality-of-embeddings-intrinsic-vs-extrinsic/"&gt;Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perplexity is a measure commonly used in machine learning, particularly in the field of dimensionality reduction techniques such as Principal Component Analysis (PCA). It provides a way to evaluate …&lt;/p&gt;</summary><content type="html">&lt;p&gt;X::&lt;a href="https://www.safjan.com/measure-quality-of-embeddings-intrinsic-vs-extrinsic/"&gt;Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Perplexity is a measure commonly used in machine learning, particularly in the field of dimensionality reduction techniques such as Principal Component Analysis (PCA). It provides a way to evaluate and compare the quality of dimensionality reduction algorithms by quantifying how well they preserve the structure of the original data.&lt;/p&gt;
&lt;p&gt;In this blog post, we will delve into the concept of perplexity, its application in PCA, and its importance in assessing the performance of dimensionality reduction methods. We will also provide code examples in Python to demonstrate its practical implementation.&lt;/p&gt;
&lt;h2&gt;Understanding Perplexity&lt;/h2&gt;
&lt;p&gt;Perplexity is a measure originally developed for evaluating probabilistic models, particularly in the field of natural language processing. It represents the level of uncertainty or confusion in predicting the next item in a sequence. In the context of dimensionality reduction, perplexity provides an estimation of the number of nearest neighbors that should be considered when reconstructing a data point in a lower-dimensional space.&lt;/p&gt;
&lt;p&gt;Given a high-dimensional dataset, PCA aims to find a lower-dimensional representation that captures the most significant features or patterns of the original data. The idea behind perplexity is to preserve the local structure of the data, ensuring that neighboring points in the high-dimensional space remain close to each other in the reduced space.&lt;/p&gt;
&lt;h2&gt;Perplexity in PCA&lt;/h2&gt;
&lt;p&gt;To understand how perplexity is used in PCA, let's consider a high-dimensional dataset with 𝑁 data points. PCA involves projecting this dataset onto a lower-dimensional space while retaining the maximum amount of variance. The reduced dataset can be represented by 𝑀 principal components, where 𝑀 &amp;lt; 𝑁.&lt;/p&gt;
&lt;p&gt;In PCA, the perplexity of a data point 𝑥𝑖 is calculated based on the conditional probability distribution of its neighbors given a particular variance or similarity scale. This distribution can be modeled using a Gaussian kernel centered at 𝑥𝑖:&lt;/p&gt;
&lt;div class="math"&gt;$$
P(\mathbf{y}_j|\mathbf{x}_i) = \frac{{\exp\left(-\frac{{\|\mathbf{y}_j - \mathbf{x}_i\|^2}}{{2\sigma_i^2}}\right)}}{{\sum_{k\neq j}\exp\left(-\frac{{\|\mathbf{y}_k - \mathbf{x}_i\|^2}}{{2\sigma_i^2}}\right)}}
$$&lt;/div&gt;
&lt;p&gt;Here, 𝑃(𝑦𝑗|𝑥𝑖) represents the conditional probability of observing data point 𝑦𝑗 as a neighbor of 𝑥𝑖 in the lower-dimensional space. The variance or similarity scale 𝜎𝑖 determines the spread of the Gaussian kernel for each data point 𝑥𝑖.&lt;/p&gt;
&lt;p&gt;The perplexity of 𝑥𝑖, denoted as 𝑃𝑖, is then defined as the Shannon entropy of the conditional distribution:&lt;/p&gt;
&lt;div class="math"&gt;$$
P_i = 2^{-\sum_j P(\mathbf{y}_j|\mathbf{x}_i)\log_2 P(\mathbf{y}_j|\mathbf{x}_i)}
$$&lt;/div&gt;
&lt;p&gt;In practice, finding the optimal variance scale 𝜎𝑖 that results in the desired perplexity can be challenging. One common approach is to perform a binary search to find the value of 𝜎𝑖 that achieves a target perplexity value. The binary search is performed by iteratively adjusting the value of 𝜎𝑖 until the entropy of the conditional distribution matches the target perplexity.&lt;/p&gt;
&lt;h2&gt;Evaluating Dimensionality Reduction with Perplexity&lt;/h2&gt;
&lt;p&gt;Perplexity is a crucial metric for evaluating the performance of dimensionality reduction techniques, including PCA. By preserving the local structure of the data, a good dimensionality reduction method should ensure that neighboring points remain close to each other in the lower-dimensional space.&lt;/p&gt;
&lt;p&gt;To evaluate the effectiveness of a dimensionality reduction algorithm, we can compare the perplexity of the original high-dimensional data with the perplexity of the reduced data. If the perplexity remains similar after dimensionality reduction, it suggests that the algorithm successfully preserves the local structure of the data.&lt;/p&gt;
&lt;p&gt;In practice, perplexity is often used in conjunction with other evaluation metrics, such as visualization techniques like t-SNE (t-Distributed Stochastic Neighbor Embedding). t-SNE is a nonlinear dimensionality reduction method that can be used to visualize high-dimensional data in two or three dimensions while preserving the local structure. By comparing the perplexity of t-SNE embeddings with the perplexity of the original data, we can gain insights into the quality of the dimensionality reduction.&lt;/p&gt;
&lt;h2&gt;Implementation in Python&lt;/h2&gt;
&lt;p&gt;Let's now demonstrate the calculation of perplexity and its application in evaluating dimensionality reduction using PCA in Python. We will use the scikit-learn library, which provides a simple and efficient implementation of PCA and other machine learning algorithms.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pairwise_distances&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;perplexity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perplexity_value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pairwise_distances&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metric&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;euclidean&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;P&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;sigmas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;beta_min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt;
        &lt;span class="n"&gt;beta_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt;
        &lt;span class="n"&gt;betas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;affinities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;sum_affinities&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;affinities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;entropy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;affinities&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;sum_affinities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;affinities&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;sum_affinities&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;perplexity_diff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entropy&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;perplexity_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;perplexity_diff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;1e-5&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;break&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;perplexity_diff&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;beta_min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;beta_max&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;beta_max&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta_max&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;beta_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;beta_min&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;beta_min&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;betas&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;beta_min&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

        &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;affinities&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;affinities&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;

&lt;span class="c1"&gt;# Generate random high-dimensional data&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Apply PCA&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X_reduced&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Calculate perplexity of original data&lt;/span&gt;
&lt;span class="n"&gt;original_perplexity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;perplexity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perplexity_value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Calculate perplexity of reduced data&lt;/span&gt;
&lt;span class="n"&gt;reduced_perplexity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;perplexity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_reduced&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perplexity_value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Perplexity of original data:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;original_perplexity&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Perplexity of reduced data:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reduced_perplexity&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above example, we generate a random high-dimensional dataset using NumPy and apply PCA to reduce its dimensionality to 2. We then calculate the perplexity of the original data and the reduced data using the &lt;code&gt;perplexity&lt;/code&gt; function. Finally, we print the mean perplexity values for comparison.&lt;/p&gt;
&lt;p&gt;By examining the perplexity values, we can gain insights into how well PCA preserves the local structure of the data. If the perplexity of the reduced data is close to the perplexity of the original data, it suggests that PCA successfully retains the essential information during dimensionality reduction.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post, we explored the concept of perplexity in the context of dimensionality reduction, specifically in PCA. Perplexity provides a measure of the level of uncertainty or confusion in predicting the neighbors of a data point in a lower-dimensional space. It is used to assess the quality of dimensionality reduction algorithms by evaluating how well they preserve the local structure of the data.&lt;/p&gt;
&lt;p&gt;We also provided a Python implementation to calculate perplexity and demonstrated its application in evaluating dimensionality reduction using PCA. By comparing the perplexity of the original data with the perplexity of the reduced data, we can assess the effectiveness of PCA in preserving the essential information.&lt;/p&gt;
&lt;p&gt;Perplexity is a valuable tool in the evaluation and comparison of dimensionality reduction methods. It offers insights into the preservation of the local structure and can guide the selection of appropriate techniques for different datasets and applications.&lt;/p&gt;
&lt;p&gt;See also:
&lt;a href="https://distill.pub/2016/misread-tsne/"&gt;How to Use t-SNE Effectively&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="pca"></category><category term="perplexity"></category><category term="dimensionality-reduction"></category><category term="probability"></category><category term="TSNE"></category><category term="distance"></category></entry><entry><title>Understanding Bhattacharyya Distance and Coefficient for Probability Distributions</title><link href="https://www.safjan.com/understanding-bhattacharyya-distance-and-coefficient-for-probability-distributions/" rel="alternate"></link><published>2023-06-30T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-30:/understanding-bhattacharyya-distance-and-coefficient-for-probability-distributions/</id><summary type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In the fields of statistics, machine learning, and data science, measuring the similarity between probability distributions is crucial for various tasks. One commonly used measure for this purpose is the &lt;a href="https://en.wikipedia.org/wiki/Bhattacharyya_distance"&gt;Bhattacharyya distance&lt;/a&gt;, which quantifies the dissimilarity between two distributions. The Bhattacharyya …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In the fields of statistics, machine learning, and data science, measuring the similarity between probability distributions is crucial for various tasks. One commonly used measure for this purpose is the &lt;a href="https://en.wikipedia.org/wiki/Bhattacharyya_distance"&gt;Bhattacharyya distance&lt;/a&gt;, which quantifies the dissimilarity between two distributions. The Bhattacharyya coefficient, on the other hand, provides a measure of the overlap between two statistical samples or populations. In this blog post, we will delve into the concepts of Bhattacharyya distance and coefficient, discuss their applications, and provide Python code examples for better understanding.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#bhattacharyya-distance"&gt;Bhattacharyya Distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bhattacharyya-coefficient"&gt;Bhattacharyya Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#applications-of-bhattacharyya-distance-and-coefficient"&gt;Applications of Bhattacharyya Distance and Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-implementation"&gt;Python Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-metrics"&gt;Other metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="bhattacharyya-distance"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Bhattacharyya Distance&lt;/h2&gt;
&lt;p&gt;The Bhattacharyya distance is a statistical measure that quantifies the similarity between two probability distributions. It is named after Anil Kumar Bhattacharyya, an Indian-American statistician. The distance is defined for continuous probability distributions and is based on the Bhattacharyya coefficient (which we will discuss later).&lt;/p&gt;
&lt;p&gt;Mathematically, the Bhattacharyya distance between two continuous probability density functions (PDFs) or discrete probability mass functions (PMFs) is defined as follows:&lt;/p&gt;
&lt;div class="math"&gt;$$
D_B(P,Q) = -\ln \left( BC(P,Q) \right) = -\ln \left( \sum_{i} \sqrt{P(i)Q(i)} \right)
$$&lt;/div&gt;
&lt;p&gt;where ( P ) and ( Q ) are the probability distributions being compared, ( P(i) ) and ( Q(i) ) represent the probabilities of occurrence for the ( i )th event or sample, and ( BC(P,Q) ) denotes the Bhattacharyya coefficient.&lt;/p&gt;
&lt;p&gt;The Bhattacharyya distance ranges from 0 to infinity, where 0 indicates perfect similarity and higher values indicate increasing dissimilarity. It is important to note that the Bhattacharyya distance is a symmetric measure, meaning ( D_B(P,Q) = D_B(Q,P) ).&lt;/p&gt;
&lt;p&gt;&lt;a id="bhattacharyya-coefficient"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Bhattacharyya Coefficient&lt;/h2&gt;
&lt;p&gt;The Bhattacharyya coefficient is a measure of overlap between two statistical samples or populations. It quantifies the similarity between two probability distributions and is often used as a precursor to computing the Bhattacharyya distance.&lt;/p&gt;
&lt;p&gt;Mathematically, the Bhattacharyya coefficient between two discrete probability distributions can be calculated as follows:&lt;/p&gt;
&lt;div class="math"&gt;$$
BC(P,Q) = \sum_{i} \sqrt{P(i)Q(i)}
$$&lt;/div&gt;
&lt;p&gt;For continuous probability distributions, the Bhattacharyya coefficient can be expressed as an integral:&lt;/p&gt;
&lt;div class="math"&gt;$$
BC(P,Q) = \int \sqrt{p(x) q(x)} \, dx
$$&lt;/div&gt;
&lt;p&gt;where ( p(x) ) and ( q(x) ) represent the probability density functions (PDFs) of distributions ( P ) and ( Q ), respectively.&lt;/p&gt;
&lt;p&gt;The Bhattacharyya coefficient ranges from 0 to 1, where 1 indicates complete overlap and 0 indicates no overlap. The coefficient measures the similarity of two distributions by taking into account the square root of the product of their probabilities at corresponding events or samples.&lt;/p&gt;
&lt;p&gt;&lt;a id="applications-of-bhattacharyya-distance-and-coefficient"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Applications of Bhattacharyya Distance and Coefficient&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Pattern recognition: Bhattacharyya distance is often used to compare feature vectors or histograms in pattern recognition tasks. It helps in identifying similarities or dissimilarities between different classes or clusters of data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Image processing: Bhattacharyya distance can be used to compare image histograms, aiding in tasks such as image segmentation, object recognition, and image retrieval.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Document classification: Bhattacharyya distance can be employed to measure the similarity between document feature vectors, enabling document clustering and categorization.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="python-implementation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Python Implementation&lt;/h2&gt;
&lt;p&gt;To demonstrate the computation of Bhattacharyya distance and coefficient, we will use the SciPy library in Python.&lt;/p&gt;
&lt;p&gt;Let's assume we have two discrete probability distributions, ( P ) and ( Q ), represented as arrays.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;distance&lt;/span&gt;

&lt;span class="c1"&gt;# Probability distributions&lt;/span&gt;
&lt;span class="n"&gt;P&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;Q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# Bhattacharyya distance&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bhattacharyya&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Bhattacharyya coefficient&lt;/span&gt;
&lt;span class="n"&gt;bc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bhattacharyya&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Bhattacharyya Distance: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Bhattacharyya Coefficient: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Bhattacharyya Distance: 0.0632593256263896
Bhattacharyya Coefficient: 0.9367406743736104
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the code snippet above, we utilize the &lt;code&gt;bhattacharyya&lt;/code&gt; function from the &lt;code&gt;scipy.spatial.distance&lt;/code&gt; module to compute the Bhattacharyya distance and coefficient. The resulting values are printed, providing the measure of dissimilarity and overlap, respectively.&lt;/p&gt;
&lt;p&gt;&lt;a id="other-metrics"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Other metrics&lt;/h2&gt;
&lt;p&gt;The Bhattacharyya distance metric has both similarities and differences compared to other related distance metrics used in statistics, machine learning, and data science. Let's explore the similarities and differences with some commonly used distance metrics.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Distance Metric&lt;/th&gt;
&lt;th&gt;Similarities&lt;/th&gt;
&lt;th&gt;Differences&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Euclidean&lt;/td&gt;
&lt;td&gt;- Applicable to both continuous and discrete data.&lt;/td&gt;
&lt;td&gt;- Measures geometric distance between points in a multi-dimensional space.&lt;br&gt;- Does not consider probability information of the data.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Manhattan&lt;/td&gt;
&lt;td&gt;- Similar to Euclidean, applicable to both continuous and discrete data.&lt;/td&gt;
&lt;td&gt;- Measures distance between points as the sum of absolute differences in their coordinates.&lt;br&gt;- Does not consider probability distributions.&lt;br&gt;- Not suitable for measuring similarity between distributions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kullback-Leibler&lt;/td&gt;
&lt;td&gt;- Measures dissimilarity between probability distributions.&lt;/td&gt;
&lt;td&gt;- Quantifies information lost when one distribution is used to approximate the other.&lt;br&gt;- Does not directly measure overlap or similarity between distributions.&lt;br&gt;- Asymmetric measure.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jensen-Shannon&lt;/td&gt;
&lt;td&gt;- Variation of KL divergence, measures dissimilarity between probability distributions.&lt;/td&gt;
&lt;td&gt;- Calculates average of KL divergences between distributions and their average.&lt;br&gt;- Does not directly measure overlap or similarity between distributions.&lt;br&gt;- Symmetric measure.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cosine Similarity&lt;/td&gt;
&lt;td&gt;- Measures similarity between vector representations of data.&lt;/td&gt;
&lt;td&gt;- Measures cosine of the angle between two vectors, indicating similarity in direction or orientation.&lt;br&gt;- Primarily used for comparing vector representations, such as text documents or high-dimensional feature vectors.&lt;br&gt;- Does not capture probabilistic nature of distributions or specifically designed for comparing probability distributions.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In summary, the Bhattacharyya distance stands out as a measure explicitly designed for comparing probability distributions. It considers the probability information of the data and provides a measure of dissimilarity based on the overlap between distributions. Other distance metrics, such as Euclidean distance, Manhattan distance, KL divergence, Jensen-Shannon divergence, and cosine similarity, have different focuses and may not capture the probabilistic nature or similarity between distributions as effectively as the Bhattacharyya distance.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The Bhattacharyya distance and coefficient are valuable tools for quantifying the similarity and dissimilarity between probability distributions. By leveraging these measures, we can compare distributions in various fields, including statistics, machine learning, and data science. Understanding and utilizing these concepts can aid in solving diverse tasks, such as pattern recognition, image processing, and document classification. Python implementations, as showcased in this blog post, allow for straightforward calculations and application of Bhattacharyya distance and coefficient to real-world scenarios.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="note"></category><category term="tag1"></category><category term="tag2"></category></entry><entry><title>Script to Python Package Using Poetry (And PyCharm)</title><link href="https://www.safjan.com/script-to-python-package-using-poetry-and-pycharm/" rel="alternate"></link><published>2023-06-28T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-28:/script-to-python-package-using-poetry-and-pycharm/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#the-task"&gt;The task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#steps-for-package-creation"&gt;Steps for Package Creation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-project-directory"&gt;Create Project Directory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open-the-project-in-pycharm"&gt;Open the Project in PyCharm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-poetry-virtual-environment"&gt;Configure Poetry Virtual Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-pycharm-interpreter"&gt;Configure PyCharm Interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#initialize-git-repository"&gt;Initialize Git Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-package-structure"&gt;Create Package Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#move-script-and-files"&gt;Move Script and Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-__init__py"&gt;Create &lt;code&gt;__init__.py&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#update-pyprojecttoml"&gt;Update &lt;code&gt;pyproject.toml&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-readmemd-file"&gt;Add README.md …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#the-task"&gt;The task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#steps-for-package-creation"&gt;Steps for Package Creation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-project-directory"&gt;Create Project Directory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#open-the-project-in-pycharm"&gt;Open the Project in PyCharm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-poetry-virtual-environment"&gt;Configure Poetry Virtual Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configure-pycharm-interpreter"&gt;Configure PyCharm Interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#initialize-git-repository"&gt;Initialize Git Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-package-structure"&gt;Create Package Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#move-script-and-files"&gt;Move Script and Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#create-__init__py"&gt;Create &lt;code&gt;__init__.py&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#update-pyprojecttoml"&gt;Update &lt;code&gt;pyproject.toml&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-readmemd-file"&gt;Add README.md file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#test-the-script"&gt;Test the Script&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#package-the-project"&gt;Package the Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#publish-the-package"&gt;Publish the Package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#versioning-and-updates"&gt;Versioning and Updates&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="the-task"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;The task&lt;/h2&gt;
&lt;p&gt;Let's assume that you have simple script that count tokens in provided text file. Below is the  script that accepts a positional input argument, which is the file name, and can be run from the command-line interface (CLI). See also the note on &lt;a href="https://safjan.com/how-to-count-tokens/"&gt;How to count tokens?&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tiktoken&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;num_tokens_from_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding_name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;cl100k_base&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Returns the number of tokens in a text string.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tiktoken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoding_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;num_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_tokens&lt;/span&gt;


&lt;span class="n"&gt;num_tokens_from_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;tiktoken is great!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;count_tokens&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_tokens_from_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Count the number of tokens in a text file.&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;file&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Path to the input text file&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;

    &lt;span class="n"&gt;num_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_tokens&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Number of tokens: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;num_tokens&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this script, the &lt;code&gt;argparse&lt;/code&gt; module is used to handle command-line arguments. The script defines a single positional argument, &lt;code&gt;file&lt;/code&gt;, which represents the file name of the input text file.&lt;/p&gt;
&lt;p&gt;When the script is executed from the command line, it will parse the command-line arguments and retrieve the file path provided by the user. The &lt;code&gt;count_tokens&lt;/code&gt; function will then be called with the file path, and the number of tokens will be printed.&lt;/p&gt;
&lt;p&gt;To run the script from the CLI, use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python&lt;span class="w"&gt; &lt;/span&gt;script_name.py&lt;span class="w"&gt; &lt;/span&gt;file_path
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;script_name.py&lt;/code&gt; with the actual name of your script file, and &lt;code&gt;file_path&lt;/code&gt; with the path to the input text file you want to analyze. The script will then tokenize the text file and print the number of tokens.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; you need &lt;code&gt;tiktoken&lt;/code&gt; package installed before running the script. You can install it using pip:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;tiktoken
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="steps-for-package-creation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Steps for Package Creation&lt;/h2&gt;
&lt;p&gt;To create and publish a Python package based on the provided script, you can follow the steps below:&lt;/p&gt;
&lt;p&gt;&lt;a id="create-project-directory"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Create Project Directory&lt;/h3&gt;
&lt;p&gt;Start by creating a new directory for your project. You can choose an appropriate name for the directory.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initialize the Project with Poetry&lt;/strong&gt;: Open your command-line interface and navigate to the project directory you created. Run the following command to initialize the project using Poetry:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;poetry&lt;span class="w"&gt; &lt;/span&gt;init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will prompt you to fill in information about your package, such as the package name, version, description, author details, and more. Fill in the required information as prompted.&lt;/p&gt;
&lt;p&gt;&lt;a id="open-the-project-in-pycharm"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Open the Project in PyCharm&lt;/h3&gt;
&lt;p&gt;Open PyCharm and select "Open" from the welcome screen or go to "File" &amp;gt; "Open" and choose the project directory you created.&lt;/p&gt;
&lt;p&gt;&lt;a id="configure-poetry-virtual-environment"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Configure Poetry Virtual Environment&lt;/h3&gt;
&lt;p&gt;When opening the project in PyCharm for the first time, it will detect the presence of Poetry. You will be prompted to either allow PyCharm to create a Poetry virtual environment or create it manually. Select the option to create the virtual environment.&lt;/p&gt;
&lt;p&gt;If you already have a Poetry virtual environment set up manually, you can skip this step.&lt;/p&gt;
&lt;p&gt;&lt;a id="install-dependencies"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Install Dependencies&lt;/h3&gt;
&lt;p&gt;In your command-line interface, navigate to the project directory if you're not already there. Run the following command to install the necessary dependencies using Poetry:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;poetry&lt;span class="w"&gt; &lt;/span&gt;install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will create a virtual environment and install the required packages specified in your project's &lt;code&gt;pyproject.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;&lt;a id="configure-pycharm-interpreter"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Configure PyCharm Interpreter&lt;/h3&gt;
&lt;p&gt;In PyCharm, go to "File" &amp;gt; "Settings" &amp;gt; "Project: &lt;project_name&gt;" &amp;gt; "Python Interpreter". Click on the gear icon and choose "Add...".&lt;/p&gt;
&lt;p&gt;Select "Poetry Environment" and choose the existing local Poetry interpreter associated with your project's virtual environment. Click "OK" to apply the changes.&lt;/p&gt;
&lt;p&gt;&lt;a id="initialize-git-repository"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Initialize Git Repository&lt;/h3&gt;
&lt;p&gt;In your command-line interface, navigate to the project directory if you're not already there. Run the following command to initialize a Git repository:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will set up a new Git repository for version control.&lt;/p&gt;
&lt;p&gt;At this point, you have set up the project structure, initialized Poetry, configured the virtual environment in PyCharm, installed dependencies, and initialized a Git repository. Now, you can proceed with packaging and publishing your Python script.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: you might want to add &lt;code&gt;.gitignore&lt;/code&gt; file at this stage
Minimal &lt;code&gt;.gitignore&lt;/code&gt; can be:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Compiled&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Python&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;
&lt;span class="n"&gt;__pycache__&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cod&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Distribution&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;packaging&lt;/span&gt;
&lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;egg&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;egg&lt;/span&gt;

&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Virtual&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;environments&lt;/span&gt;
&lt;span class="n"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;

&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;IDEs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;editors&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;idea&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="create-package-structure"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Create Package Structure&lt;/h3&gt;
&lt;p&gt;Inside your project directory, create a package structure that follows Python's best practices. For example, you can create a directory named &lt;code&gt;my_package&lt;/code&gt; that will contain your script and other necessary files.&lt;/p&gt;
&lt;p&gt;&lt;a id="move-script-and-files"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Move Script and Files&lt;/h3&gt;
&lt;p&gt;Move your script file and any other relevant files into the package directory (&lt;code&gt;my_package&lt;/code&gt; in this example).&lt;/p&gt;
&lt;p&gt;&lt;a id="create-__init__py"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Create &lt;code&gt;__init__.py&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Inside the package directory (&lt;code&gt;my_package&lt;/code&gt;), create an empty file named &lt;code&gt;__init__.py&lt;/code&gt;. This file is required to make the directory a Python package.&lt;/p&gt;
&lt;p&gt;&lt;a id="update-pyprojecttoml"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Update &lt;code&gt;pyproject.toml&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Open your project's &lt;code&gt;pyproject.toml&lt;/code&gt; file. Under the &lt;code&gt;[tool.poetry]&lt;/code&gt; section, add the script file and any additional files that need to be included in the package. For example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[tool.poetry]&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="k"&gt;[tool.poetry.scripts]&lt;/span&gt;
&lt;span class="n"&gt;my_script&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;my_package.my_script:main&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;my_script&lt;/code&gt; with the desired command name for your script, and &lt;code&gt;my_package.my_script:main&lt;/code&gt; with the correct import path to your script and its main function.&lt;/p&gt;
&lt;p&gt;&lt;a id="add-readmemd-file"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Add README.md file&lt;/h3&gt;
&lt;p&gt;In the root of the project directory create &lt;code&gt;README.md&lt;/code&gt; and fill it with useful information. See also:writing_good_readme&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: You can add some badges relate to your pypi package, e.g.:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shields&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pypi&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;package_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;svg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="err"&gt;![]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shields&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pypi&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pyversions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;package_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;svg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="err"&gt;![]&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shields&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pypi&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dm&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;package_name&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;svg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Add LICENSE file&lt;/h3&gt;
&lt;p&gt;You can create a LICENSE file manually. Here's how you can do it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a new file in your project root directory named &lt;code&gt;LICENSE&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go to the &lt;a href="https://opensource.org/licenses/MIT"&gt;MIT License template&lt;/a&gt;, copy the text.&lt;/li&gt;
&lt;li&gt;Paste the copied text into your &lt;code&gt;LICENSE&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Replace &lt;code&gt;[year]&lt;/code&gt; with the current year and &lt;code&gt;[fullname]&lt;/code&gt; with your name or your organization's name.&lt;/li&gt;
&lt;li&gt;Save the file.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="test-the-script"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Test the Script&lt;/h3&gt;
&lt;p&gt;Before publishing your package, it's essential to test your script to ensure it works as expected. You can execute the script locally to verify its functionality.&lt;/p&gt;
&lt;p&gt;If you want to use pytest for testing add it as development dependency and install:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;poetry&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;--group&lt;span class="w"&gt; &lt;/span&gt;dev&lt;span class="w"&gt; &lt;/span&gt;poetry
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="package-the-project"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Package the Project&lt;/h3&gt;
&lt;p&gt;In your command-line interface, navigate to the project directory. Run the following command to create a distributable package:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;poetry&lt;span class="w"&gt; &lt;/span&gt;build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will generate a distributable package (e.g., a &lt;code&gt;.tar.gz&lt;/code&gt; file) in the &lt;code&gt;dist&lt;/code&gt; directory within your project.&lt;/p&gt;
&lt;p&gt;&lt;a id="publish-the-package"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Publish the Package&lt;/h3&gt;
&lt;p&gt;To publish your package, you can use a package index such as PyPI (Python Package Index). First, you need to create an account on PyPI if you haven't already. Once you have an account, run the following command to publish your package:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;poetry&lt;span class="w"&gt; &lt;/span&gt;publish
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command will guide you through the process of publishing your package to PyPI. You'll be prompted to enter your PyPI credentials and confirm the publication.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Make sure your package has a unique name to avoid conflicts with existing packages on PyPI.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="versioning-and-updates"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Versioning and Updates&lt;/h3&gt;
&lt;p&gt;When you make updates to your package, ensure to increment the version number in the &lt;code&gt;pyproject.toml&lt;/code&gt; file under the &lt;code&gt;[tool.poetry.version]&lt;/code&gt; section. This helps to track and manage different versions of your package.&lt;/p&gt;
&lt;p&gt;That's it! You have now packaged and published your Python script using Poetry. Users can install your package using pip and use your script as a command-line tool.&lt;/p&gt;
&lt;p&gt;Please note that publishing a package is a significant step, and it's essential to review and test your code thoroughly before sharing it with others.&lt;/p&gt;
&lt;h2&gt;Correcting metadata&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;authors&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;&amp;quot;Krystian Safjan &amp;lt;ksafjan@gmail.com&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;keywords&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;&amp;quot;keyword1&amp;quot;, &amp;quot;keyword2&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;homepage&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;https://github.com/user/repo&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;https://github.com/user/repo&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;documentation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;https://github.com/user/repo&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="python"></category><category term="poetry"></category><category term="package"></category><category term="package-publish"></category><category term="pypi"></category><category term="git"></category><category term="tiktoken"></category></entry><entry><title>Bash - Rename Multiple Image Files to Match Pattern With Sequence Number</title><link href="https://www.safjan.com/bash-rename-mutliple-image-files-to-match-pattern-with-sequence-number/" rel="alternate"></link><published>2023-06-27T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-27:/bash-rename-mutliple-image-files-to-match-pattern-with-sequence-number/</id><summary type="html">&lt;p&gt;The use case for the provided script is to rename multiple image files in a directory while maintaining their original file extensions. This script can be handy in situations where you have a collection of image files with different formats or extensions …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The use case for the provided script is to rename multiple image files in a directory while maintaining their original file extensions. This script can be handy in situations where you have a collection of image files with different formats or extensions, and you want to standardize their names for better organization or consistency.&lt;/p&gt;
&lt;p&gt;By executing the script, all image files with extensions such as &lt;code&gt;.jpg&lt;/code&gt;, &lt;code&gt;.jpeg&lt;/code&gt;, &lt;code&gt;.png&lt;/code&gt;, &lt;code&gt;.gif&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;, &lt;code&gt;.heic&lt;/code&gt;, and &lt;code&gt;.heif&lt;/code&gt; in the current directory will be renamed. The new names will follow the pattern "img_xxx.ext", where "xxx" represents a sequence number starting from 000, and "ext" represents the original file extension.&lt;/p&gt;
&lt;p&gt;For example, if you have the following image files in the directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;photo1.jpg
picture.png
image2.jpeg
snapshot.tiff
capture.heic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Running the script will rename them as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;img_000.jpg
img_001.png
img_002.jpeg
img_003.tiff
img_004.heic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This allows for consistent naming and easier identification of the image files in the directory.&lt;/p&gt;
&lt;p&gt;Here's the Bash script that supports multiple image formats and preserves the original file extension while renaming the files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;file&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;*.&lt;span class="o"&gt;{&lt;/span&gt;jpg,jpeg,png,gif,tiff,heic,heif&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;extension&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="p"&gt;##*.&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;newname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;img_%03d.%s&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$counter&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$extension&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;mv&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$newname&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;counter++&lt;span class="o"&gt;))&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this script:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;for&lt;/code&gt; loop uses brace expansion &lt;code&gt;{}&lt;/code&gt; to iterate over multiple file extensions: &lt;code&gt;jpg&lt;/code&gt;, &lt;code&gt;jpeg&lt;/code&gt;, &lt;code&gt;png&lt;/code&gt;, &lt;code&gt;gif&lt;/code&gt;, &lt;code&gt;tiff&lt;/code&gt;, &lt;code&gt;heic&lt;/code&gt;, and &lt;code&gt;heif&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Inside the loop, the script checks if the current file is a regular file using the &lt;code&gt;-f&lt;/code&gt; test.&lt;/li&gt;
&lt;li&gt;If it's a regular file, it extracts the original file extension using the &lt;code&gt;${file##*.}&lt;/code&gt; syntax.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;newname&lt;/code&gt; variable is generated using &lt;code&gt;printf&lt;/code&gt; with the current value of the &lt;code&gt;counter&lt;/code&gt; variable and the extracted extension.&lt;/li&gt;
&lt;li&gt;Finally, the file is renamed using the &lt;code&gt;mv&lt;/code&gt; command, preserving the original extension.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To use this script, follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a text editor and paste the script into a new file.&lt;/li&gt;
&lt;li&gt;Save the file with a &lt;code&gt;.sh&lt;/code&gt; extension, for example, &lt;code&gt;rename_images.sh&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Open a terminal and navigate to the directory where the image files are located.&lt;/li&gt;
&lt;li&gt;Make the script executable by running the following command: &lt;code&gt;chmod +x rename_images.sh&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Run the script using the command &lt;code&gt;./rename_images.sh&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After running the script, all the image files in the directory should be renamed according to the pattern you specified.&lt;/p&gt;
&lt;h2&gt;Oneliner&lt;/h2&gt;
&lt;p&gt;Here's a one-liner Bash command that renames all image files in the current directory to match the pattern "img_xxx.jpg" where "xxx" is a sequence number starting from 000:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;file&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;*.jpg&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;newname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;img_%03d.jpg&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$counter&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;mv&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$newname&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;counter++&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command combines the same logic as the previous script into a single line. The &lt;code&gt;counter&lt;/code&gt; variable is set to 0, and then the &lt;code&gt;for&lt;/code&gt; loop iterates over the &lt;code&gt;.jpg&lt;/code&gt; files in the directory. The rest of the logic remains the same.&lt;/p&gt;
&lt;p&gt;To use this one-liner, open a terminal, navigate to the directory containing the image files, and run the command. The image files will be renamed accordingly.&lt;/p&gt;
&lt;p&gt;To create a Bash alias for the one-liner version of the last script, you can add the following line to your &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.bash_aliases&lt;/code&gt; (&lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;~/.zsh_aliases&lt;/code&gt; if using zsh) file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;alias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;rename_images&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;counter=0; for file in *.{jpg,jpeg,png,gif,tiff,heic,heif}; do if -f &amp;quot;$file&amp;quot;; then extension=&amp;quot;${file##*.}&amp;quot;; newname=$(printf &amp;quot;img_%03d.%s&amp;quot; &amp;quot;$counter&amp;quot; &amp;quot;$extension&amp;quot;); mv &amp;quot;$file&amp;quot; &amp;quot;$newname&amp;quot;; ((counter++)); fi; done&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Save the file and then run &lt;code&gt;source ~/.bashrc&lt;/code&gt; or &lt;code&gt;source ~/.bash_aliases&lt;/code&gt; to apply the changes.&lt;/p&gt;
&lt;p&gt;Afterward, you can use the &lt;code&gt;rename_images&lt;/code&gt; command in your terminal to execute the one-liner script and rename the image files in the current directory accordingly.&lt;/p&gt;
&lt;h2&gt;Python version&lt;/h2&gt;
&lt;p&gt;Here's a Python script that achieves the same functionality as the Bash script, renaming image files while preserving their original extensions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;extensions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.jpg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.jpeg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.gif&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.tiff&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.heic&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.heif&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isfile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;file_parts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;newname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;img_&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;03d&lt;/span&gt;&lt;span class="si"&gt;}{&lt;/span&gt;&lt;span class="n"&gt;file_parts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;newname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;counter&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this Python script:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;code&gt;counter&lt;/code&gt; variable keeps track of the sequence number for renaming the files.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;extensions&lt;/code&gt; list contains the supported image extensions.&lt;/li&gt;
&lt;li&gt;The script iterates over each file in the current directory using &lt;code&gt;os.listdir(".")&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For each file, it checks if the filename has a matching extension and if it is a regular file.&lt;/li&gt;
&lt;li&gt;If both conditions are satisfied, it extracts the file's extension and uses &lt;code&gt;os.rename()&lt;/code&gt; to perform the renaming operation.&lt;/li&gt;
&lt;li&gt;The new name is constructed using the desired pattern "img_xxx.ext", where "xxx" represents the sequence number and "ext" represents the original file extension.&lt;/li&gt;
&lt;li&gt;Finally, the &lt;code&gt;counter&lt;/code&gt; is incremented for the next file.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can save this Python script to a file with a &lt;code&gt;.py&lt;/code&gt; extension, for example, &lt;code&gt;rename_images.py&lt;/code&gt;, and then run it using a Python interpreter. The image files in the directory will be renamed accordingly, following the specified pattern while preserving their original extensions.&lt;/p&gt;</content><category term="note"></category><category term="bash"></category><category term="python"></category><category term="bash-script"></category><category term="python-script"></category><category term="alias"></category><category term="image-rename"></category><category term="utility script"></category></entry><entry><title>Harnessing the Power of Dependency Injection for Improved Testability in Python</title><link href="https://www.safjan.com/python-dependency-injection-for-the-testability/" rel="alternate"></link><published>2023-06-21T00:00:00+02:00</published><updated>2023-06-21T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-21:/python-dependency-injection-for-the-testability/</id><summary type="html">&lt;p&gt;Learn how to use dependency injection to decouple dependencies from our functions, methods, or classes, making it easier to test and maintain our code.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In software development, testability is a crucial aspect that helps ensure the reliability and maintainability of our code. One effective technique for enhancing testability is dependency injection (DI). Dependency injection allows us to decouple dependencies from our functions, methods, or classes, making it easier to test and maintain our code. In this blog post, we will explore various techniques, use cases, and lesser-known tricks for using dependency injection in Python.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-dependency-injection"&gt;What is Dependency Injection?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#benefits-of-dependency-injection"&gt;Benefits of Dependency Injection:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#techniques-for-dependency-injection"&gt;Techniques for Dependency Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#constructor-injection"&gt;Constructor Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#setter-injection"&gt;Setter Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interface-injection"&gt;Interface Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#use-cases-for-dependency-injection"&gt;Use Cases for Dependency Injection:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing-legacy-code"&gt;Testing Legacy Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mocking-dependencies"&gt;Mocking Dependencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#improving-code-reusability"&gt;Improving Code Reusability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#parameter-injection"&gt;Parameter Injection:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#context-managers-and-dependency-injection"&gt;Context Managers and Dependency Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#dependency-injection-containers"&gt;Dependency Injection Containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="what-is-dependency-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What is Dependency Injection?&lt;/h2&gt;
&lt;p&gt;Dependency injection is a design pattern that allows us to inject dependencies into a class or function from external sources rather than creating them internally. By doing so, we reduce the coupling between components and make them more flexible, reusable, and testable.&lt;/p&gt;
&lt;p&gt;&lt;a id="benefits-of-dependency-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Benefits of Dependency Injection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Improved testability&lt;/strong&gt;: By injecting dependencies, we can easily replace them with mocks or stubs during testing, making our tests more isolated and focused.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoupled code&lt;/strong&gt;: Dependency injection reduces the tight coupling between components, promoting better separation of concerns and modular design.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code reusability&lt;/strong&gt;: With dependency injection, components become more reusable as they rely on abstractions rather than concrete implementations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Easier maintenance&lt;/strong&gt;: By externalizing dependencies, we can modify or extend their behavior without affecting the code that uses them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="techniques-for-dependency-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Techniques for Dependency Injection&lt;/h2&gt;
&lt;p&gt;&lt;a id="constructor-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Constructor Injection&lt;/h3&gt;
&lt;p&gt;Constructor injection involves passing dependencies through a class's constructor. It ensures that the required dependencies are available before an object is created.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;UserService&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="setter-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Setter Injection&lt;/h3&gt;
&lt;p&gt;Setter injection involves setting the dependencies using setter methods. This technique allows for more flexibility, as dependencies can be changed or updated after object initialization.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;NotificationService&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_email_service&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;email_service&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email_service&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;email_service&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;send_notification&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email_service&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;New notification!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="interface-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Interface Injection&lt;/h3&gt;
&lt;p&gt;Interface injection is a technique where a dependency is injected by providing an interface or an abstract base class. This allows for the injection of different implementations of the same interface, providing flexibility and extensibility.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;abc&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ABC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;abstractmethod&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Database&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ABC&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nd"&gt;@abstractmethod&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MySQLDatabase&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Database&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Perform MySQL query&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PostgresDatabase&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Database&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Perform Postgres query&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="use-cases-for-dependency-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Use Cases for Dependency Injection&lt;/h2&gt;
&lt;p&gt;&lt;a id="testing-legacy-code"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Testing Legacy Code&lt;/h3&gt;
&lt;p&gt;When working with legacy code that has tightly coupled dependencies, dependency injection can be used to introduce testability by replacing or mocking those dependencies during testing.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;legacy_function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# ...&lt;/span&gt;
    &lt;span class="n"&gt;db_connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MySQLDatabase&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# Tightly coupled dependency&lt;/span&gt;
    &lt;span class="c1"&gt;# ...&lt;/span&gt;

&lt;span class="c1"&gt;# Using dependency injection to test legacy_function&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_legacy_function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;mock_db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MockMySQLDatabase&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;legacy_function&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inject_dependencies&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db_connection&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mock_db&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Test the function&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="mocking-dependencies"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Mocking Dependencies&lt;/h3&gt;
&lt;p&gt;In unit testing, dependency injection allows us to replace real dependencies with mock objects, enabling us to focus on testing the behavior of the unit under test in isolation.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;UserService&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_user&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Testing UserService with a mock user repository&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_get_user&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;mock_repository&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MockUserRepository&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;service&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;UserService&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;mock_repository&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Test the method using the mock repository&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="improving-code-reusability"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Improving Code Reusability&lt;/h3&gt;
&lt;p&gt;Dependency injection promotes code reusability by relying on abstractions rather than concrete implementations. This allows different implementations to be injected based on specific requirements.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PaymentGateway&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ABC&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nd"&gt;@abstractmethod&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_payment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PayPalGateway&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PaymentGateway&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_payment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Process payment via PayPal&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;StripeGateway&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PaymentGateway&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_payment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Process payment via Stripe&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Lesser-Known Techniques and Tricks:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="parameter-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Parameter Injection&lt;/h3&gt;
&lt;p&gt;In addition to constructor, setter, and interface injection, parameter injection is a technique where dependencies are passed directly as parameters to functions or methods. This can be useful in situations where direct injection is preferred over using class instances.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Processing data...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Process the data&lt;/span&gt;

&lt;span class="c1"&gt;# Calling the function with injected dependencies&lt;/span&gt;
&lt;span class="n"&gt;logger&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="context-managers-and-dependency-injection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Context Managers and Dependency Injection&lt;/h3&gt;
&lt;p&gt;Context managers can be combined with dependency injection to provide resources or dependencies within a specific scope, ensuring their proper initialization and cleanup.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;contextlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;contextmanager&lt;/span&gt;

&lt;span class="nd"&gt;@contextmanager&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;db_connection&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MySQLDatabase&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# Dependency initialization&lt;/span&gt;
    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;
    &lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# Cleanup&lt;/span&gt;

&lt;span class="c1"&gt;# Using the context manager with dependency injection&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;db_connection&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# Use the database connection within the context&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="dependency-injection-containers"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Dependency Injection Containers&lt;/h3&gt;
&lt;p&gt;Dependency injection containers or frameworks provide a centralized way to manage dependencies, their configurations, and their lifetime. Popular Python DI frameworks include &lt;code&gt;injector&lt;/code&gt;, &lt;code&gt;DInjector&lt;/code&gt;, and &lt;code&gt;inject&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;injector&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;inject&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Injector&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;UserService&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nd"&gt;@inject&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_repository&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;user_repository&lt;/span&gt;

&lt;span class="c1"&gt;# Creating and using an injector&lt;/span&gt;
&lt;span class="n"&gt;injector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Injector&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;user_service&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;UserService&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Dependency injection is a powerful technique for improving testability, code modularity, and reusability in Python. By applying various injection techniques and exploring different use cases, you can design more robust and maintainable code. Additionally, the lesser-known tricks and techniques covered in this blog post can further enhance your understanding and application of dependency injection in various scenarios.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><category term="Machine Learning"></category><category term="machine-learning"></category><category term="python"></category><category term="testing"></category><category term="dependency-injection"></category><category term="software-development"></category></entry><entry><title>Efficient Workflow for Reviewing Changes in Git before Pulling from Remote Branch</title><link href="https://www.safjan.com/git-workflow-reviewing-changes-before-pulling-remote-branch/" rel="alternate"></link><published>2023-06-20T00:00:00+02:00</published><updated>2023-06-20T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-20:/git-workflow-reviewing-changes-before-pulling-remote-branch/</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When working with Git, it is essential to have a streamlined workflow that ensures you &lt;strong&gt;review the changes made by others&lt;/strong&gt; before pulling them into your local branch. This practice helps &lt;strong&gt;prevent conflicts&lt;/strong&gt; and ensures that your local repository remains in …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When working with Git, it is essential to have a streamlined workflow that ensures you &lt;strong&gt;review the changes made by others&lt;/strong&gt; before pulling them into your local branch. This practice helps &lt;strong&gt;prevent conflicts&lt;/strong&gt; and ensures that your local repository remains in sync with the remote branch. In this blog post, we will outline a few simple steps to check the changes introduced by others in the remote branch before performing a &lt;code&gt;git pull&lt;/code&gt;.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#step-1-fetch-remote-changes"&gt;Step 1: Fetch Remote Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-3-review-changes"&gt;Step 3: Review Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-4-resolve-conflicts-if-any"&gt;Step 4: Resolve Conflicts (if any)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#step-5-pull-changes"&gt;Step 5: Pull Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="step-1-fetch-remote-changes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Step 1: Fetch Remote Changes&lt;/h3&gt;
&lt;p&gt;Before reviewing any changes, it is crucial to fetch the latest updates from the remote repository. This step ensures that your local repository has the most up-to-date information. To fetch changes, run the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;fetch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command retrieves all the latest changes from the remote repository without automatically merging them into your local branch.&lt;/p&gt;
&lt;h3&gt;Step 2: Inspect Remote Branch&lt;/h3&gt;
&lt;p&gt;After fetching the remote changes, you can inspect the remote branch to see the modifications made by others. This step helps you understand the nature and scope of the changes before merging them into your branch. To view the remote branch, use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git log origin/branch-name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;branch-name&lt;/code&gt; with the name of the remote branch you want to review. This command displays a list of commits made to the remote branch, showing the commit hash, author, timestamp, and commit message.&lt;/p&gt;
&lt;p&gt;&lt;a id="step-3-review-changes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Step 3: Review Changes&lt;/h3&gt;
&lt;p&gt;Now that you have a clear view of the commits in the remote branch, it's time to review the changes introduced. There are several ways to inspect the individual commits, depending on your preferred Git tooling. Here are a few common options:&lt;/p&gt;
&lt;h4&gt;Option 1: Using Git Diff&lt;/h4&gt;
&lt;p&gt;To review the changes introduced by a specific commit, you can use the &lt;code&gt;git diff&lt;/code&gt; command. Run the following command, replacing &lt;code&gt;commit-hash&lt;/code&gt; with the actual commit hash you want to inspect:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt; &lt;/span&gt;commit-hash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command displays a detailed diff of the changes made in that specific commit, allowing you to analyze the modifications line by line.&lt;/p&gt;
&lt;h4&gt;Option 2: Utilizing Visual Git Tools&lt;/h4&gt;
&lt;p&gt;If you prefer a more visual representation of changes, you can leverage Git GUI tools like GitKraken, Sourcetree, Git Cola or tig. These tools provide an intuitive interface that allows you to navigate through commits, inspect changes, and even visualize branching patterns.&lt;/p&gt;
&lt;h5&gt;tig&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;tig test..master&lt;/code&gt; - Show difference between two branches &lt;code&gt;test&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="step-4-resolve-conflicts-if-any"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Step 4: Resolve Conflicts (if any)&lt;/h2&gt;
&lt;p&gt;During your review, you may encounter conflicts between the changes made by others and your local modifications. Conflicts arise when Git cannot automatically merge two sets of changes. If conflicts occur, it is crucial to resolve them before pulling the changes into your branch.&lt;/p&gt;
&lt;p&gt;To resolve conflicts, you can use Git's built-in merge tools or a visual Git tool like those mentioned earlier. These tools provide a side-by-side view of conflicting changes, enabling you to choose which modifications to keep and how to combine them effectively.&lt;/p&gt;
&lt;p&gt;&lt;a id="step-5-pull-changes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Step 5: Pull Changes&lt;/h3&gt;
&lt;p&gt;After reviewing the changes, ensuring there are no conflicts or addressing any conflicts that arise, you can proceed with pulling the changes from the remote branch into your local branch. To pull the changes, use the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git&lt;span class="w"&gt; &lt;/span&gt;pull&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;branch-name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Replace &lt;code&gt;branch-name&lt;/code&gt; with the name of the remote branch from which you want to pull the changes. This command automatically merges the changes into your branch, keeping your local repository up to date.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post, we discussed a streamlined workflow for reviewing changes in Git before pulling them from a remote branch. By following these steps, you can ensure that you have a clear understanding of the modifications introduced by others, address conflicts if necessary, and maintain a synchronized local repository. Adopting this workflow will help you avoid potential&lt;/p&gt;</content><category term="note"></category><category term="git"></category><category term="workflow"></category></entry><entry><title>Extracting Keywords From the User Query</title><link href="https://www.safjan.com/extracting-keywords-from-the-user-query/" rel="alternate"></link><published>2023-06-09T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-09:/extracting-keywords-from-the-user-query/</id><summary type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#rule-based-approach"&gt;Rule-Based Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linguistic-analysis"&gt;Linguistic Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine-learning-ml-and-statistical-methods"&gt;Machine Learning (ML) and Statistical Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hybrid-approaches"&gt;Hybrid Approaches:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-about-using-large-language-models"&gt;What about using (large) language models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pros"&gt;Pros:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cons"&gt;Cons:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#more-on-machine-learning-and-statistical-methods-for-keywords-extraction"&gt;More on Machine Learning and statistical Methods for Keywords Extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exemplary-implementation"&gt;Exemplary implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;When it comes to extracting keywords or key terms from …&lt;/p&gt;</summary><content type="html">&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#rule-based-approach"&gt;Rule-Based Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linguistic-analysis"&gt;Linguistic Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#machine-learning-ml-and-statistical-methods"&gt;Machine Learning (ML) and Statistical Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hybrid-approaches"&gt;Hybrid Approaches:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-about-using-large-language-models"&gt;What about using (large) language models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pros"&gt;Pros:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cons"&gt;Cons:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#more-on-machine-learning-and-statistical-methods-for-keywords-extraction"&gt;More on Machine Learning and statistical Methods for Keywords Extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exemplary-implementation"&gt;Exemplary implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;When it comes to extracting keywords or key terms from a user query, there are several approaches that can be used. Each approach has its own set of pros and cons, which I will discuss below:&lt;/p&gt;
&lt;p&gt;&lt;a id="rule-based-approach"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Rule-Based Approach&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: This approach involves defining a set of rules or patterns to identify keywords based on specific criteria. It can be effective for simple queries and known patterns, allowing for precise keyword extraction.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Rule-based approaches can be limited in their flexibility and scalability. They require manual effort to create and maintain the rules, making them less suitable for handling complex or evolving queries. Additionally, they may not perform well when faced with ambiguous or unstructured input.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="linguistic-analysis"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Linguistic Analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: Linguistic analysis techniques utilize natural language processing (NLP) algorithms to analyze the grammatical structure and semantics of a query. By considering parts of speech, syntactic relationships, and semantic associations, they can extract relevant keywords effectively.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: This approach can be computationally expensive and may require substantial linguistic resources such as parsers, lexicons, and ontologies. Handling languages with complex grammar or processing highly contextual queries can be challenging. It might also struggle with ambiguous phrases or idiomatic expressions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="machine-learning-ml-and-statistical-methods"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Machine Learning (ML) and Statistical Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: ML techniques, such as supervised or unsupervised learning, can automatically learn patterns and extract keywords based on training data. They can adapt to different query types and improve over time with more data. Statistical methods, such as term frequency-inverse document frequency (TF-IDF), can also identify important keywords based on their prevalence and relevance within a dataset.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Building ML models requires labeled training data, which can be time-consuming and expensive to create. Models may struggle with rare or domain-specific queries if not adequately trained. They can also be susceptible to biases present in the training data, and their performance may degrade when faced with queries significantly different from the training distribution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id="hybrid-approaches"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Hybrid Approaches&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pros&lt;/strong&gt;: Hybrid approaches combine multiple techniques, leveraging the strengths of each to improve keyword extraction. For example, combining rule-based methods with ML models can enhance accuracy and handle a wider range of queries.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cons&lt;/strong&gt;: Designing and implementing hybrid approaches can be complex and require expertise in multiple areas. Combining different techniques may introduce additional computational overhead, impacting performance and response time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's important to note that the effectiveness of these approaches can vary depending on factors such as the nature of the queries, available resources, and the desired level of accuracy. A well-designed solution often involves a combination of techniques to achieve the best results.&lt;/p&gt;
&lt;p&gt;&lt;a id="what-about-using-large-language-models"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What about using (large) language models?&lt;/h2&gt;
&lt;p&gt;Using language models, such as GPT-3.5, can be a powerful approach for extracting keywords or key terms from a user query. Language models are trained on vast amounts of text data and have the ability to understand and generate human-like language.&lt;/p&gt;
&lt;p&gt;Here are the pros and cons of using language models for keyword extraction:&lt;/p&gt;
&lt;p&gt;&lt;a id="pros"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Contextual Understanding&lt;/strong&gt;: Language models can capture the contextual meaning of words and phrases in a query. They can consider the surrounding words and sentences to extract keywords that are most relevant to the overall query.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Handling Ambiguity&lt;/strong&gt;: Language models can handle ambiguous queries by considering the broader context. They can interpret the query based on available information and generate keywords that make the most sense in the given context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generalization&lt;/strong&gt;: Language models have the ability to generalize from the training data and can extract keywords effectively even for queries that are slightly different from what they have seen before.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Learning&lt;/strong&gt;: Language models can be fine-tuned on specific domains or datasets to improve their keyword extraction capabilities. This allows them to adapt to specific contexts and improve their accuracy over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="cons"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Cons&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Lack of Control&lt;/strong&gt;: Language models generate keywords based on their learned patterns and training data, which may not always align with specific user requirements or domain-specific terminology. They may produce keywords that are technically correct but not exactly what the user intended.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over-reliance on Training Data&lt;/strong&gt;: Language models heavily depend on the data they were trained on. If the training data contains biases or limitations, the model may exhibit the same biases or struggle with specific types of queries that were underrepresented in the training data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computational Overhead&lt;/strong&gt;: Language models can be computationally expensive to run, especially for real-time applications. The time required for keyword extraction using a language model might not be suitable for scenarios that demand low latency or high throughput.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lack of Explanation&lt;/strong&gt;: Language models can provide keyword outputs, but they may not offer clear explanations for why certain words were selected as keywords. This lack of interpretability can make it challenging to understand the reasoning behind the chosen keywords.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While language models can be effective for keyword extraction, it's important to consider these pros and cons and carefully evaluate the trade-offs before integrating them into a production system. It may be necessary to fine-tune the language model or combine it with other techniques to address specific limitations or requirements.&lt;/p&gt;
&lt;p&gt;&lt;a id="more-on-machine-learning-and-statistical-methods-for-keywords-extraction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;More on Machine Learning and statistical Methods for Keywords Extraction&lt;/h2&gt;
&lt;p&gt;There are several machine learning and statistical methods commonly used for keyword extraction from text. Here are some popular techniques:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Term Frequency-Inverse Document Frequency (TF-IDF)&lt;/strong&gt;: TF-IDF is a statistical method that measures the importance of a term within a document and across a collection of documents. It calculates a weight for each term based on its frequency in the document and inversely proportional to its frequency in the entire document collection. Keywords with higher TF-IDF scores are considered more significant.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TextRank&lt;/strong&gt;: TextRank is an algorithm inspired by Google's PageRank algorithm for ranking web pages. It applies a graph-based ranking approach to identify important keywords in a text. In this method, the text is represented as a graph, where each word is a node, and edges represent the co-occurrence or semantic similarity between words. TextRank assigns scores to words based on their centrality in the graph, with higher scores indicating more important keywords.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Latent Dirichlet Allocation (LDA)&lt;/strong&gt;: LDA is a generative probabilistic model that represents a collection of documents as a mixture of topics. It assumes that each document contains a distribution of topics, and each topic is characterized by a distribution of words. LDA can be used for keyword extraction by identifying the most probable words associated with each topic. Keywords are then selected based on their relevance to the document's topics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Support Vector Machines (SVM)&lt;/strong&gt;: SVM is a supervised learning algorithm that can be used for keyword extraction by treating it as a binary classification problem. Training data is labeled with keywords and non-keywords, and SVM learns a decision boundary to separate the two classes. New text can be classified using the trained SVM model, and the words contributing most to the classification decision are considered keywords.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt;: Various neural network architectures can be employed for keyword extraction, such as recurrent neural networks (RNNs), convolutional neural networks (CNNs), and transformers. These models can learn representations of words and capture complex relationships between them. They can be trained using labeled data or trained in an unsupervised manner by formulating the problem as an autoencoder or sequence-to-sequence learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Rule-based methods&lt;/strong&gt;: Rule-based approaches define a set of linguistic rules or patterns to identify keywords based on specific criteria such as part-of-speech tags, syntactic structures, or domain-specific rules. These methods can be effective when the domain or language has well-defined patterns for keywords.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="exemplary-implementation"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Exemplary implementation&lt;/h2&gt;
&lt;p&gt;One state-of-the-art solution for keyword extraction from short texts is the TextRank algorithm, which is an unsupervised approach based on the PageRank algorithm. It has been proven to be highly effective in identifying important keywords in a text.&lt;/p&gt;
&lt;p&gt;Here's a Python implementation using the &lt;code&gt;nltk&lt;/code&gt; library, which provides an implementation of the TextRank algorithm:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pos_tag&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;wordnet&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;preprocess_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Tokenize the text into sentences&lt;/span&gt;
    &lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Tokenize each sentence into words and perform part-of-speech tagging&lt;/span&gt;
    &lt;span class="n"&gt;tagged_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tagged_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Lemmatize the words and remove stopwords&lt;/span&gt;
    &lt;span class="n"&gt;lemmatizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;stop_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;preprocessed_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tagged_words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# Consider only nouns, verbs, adjectives, and adverbs&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;VB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;JJ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;RB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="c1"&gt;# Lemmatize the word&lt;/span&gt;
            &lt;span class="n"&gt;lemma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lemmatizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;get_wordnet_pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

            &lt;span class="c1"&gt;# Convert to lowercase and remove stopwords&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;lemma&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;preprocessed_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lemma&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;preprocessed_words&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_wordnet_pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NOUN&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;V&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VERB&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;J&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADJ&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;R&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ADV&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calculate_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;synsets1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;synsets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;synsets2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;synsets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;synsets1&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;synsets2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;max_sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;wn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s1&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;synsets1&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;synsets2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;max_sim&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;textrank_keywords&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;top_n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Preprocess the text&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;preprocess_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Build the word co-occurrence graph&lt;/span&gt;
    &lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word1&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Apply the TextRank algorithm&lt;/span&gt;
    &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;damping_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.85&lt;/span&gt;
    &lt;span class="n"&gt;max_iterations&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_iterations&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;prev_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word1&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;damping_factor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;damping_factor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prev_scores&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;

    &lt;span class="c1"&gt;# Get the top keywords&lt;/span&gt;
    &lt;span class="n"&gt;top_keywords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="n"&gt;top_n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;top_keywords&lt;/span&gt;

&lt;span class="c1"&gt;# Example usage&lt;/span&gt;
&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;What are the benefits of exercise for mental health?&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;keywords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;textrank_keywords&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;keywords&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;NOTE: before you can start using it you will need to download certain data resources from NLTK (Natural Language Toolkit) in order to use it for keyword extraction. Specifically, you will need to download the stopwords corpus and WordNet data.&lt;/p&gt;
&lt;p&gt;To download the necessary data, you can use the following code snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;

&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;stopwords&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;averaged_perceptron_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;punkt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;wordnet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="note"></category><category term="keywords"></category><category term="keyword-extraction"></category><category term="tfidf"></category></entry><entry><title>The Role and Responsibilities of a Forward Deployed Engineer - Bridging the Gap Between Software Products and Customer Needs</title><link href="https://www.safjan.com/the-role-and-responsibilities-of-a-forward-deployed-engineer/" rel="alternate"></link><published>2023-06-09T00:00:00+02:00</published><updated>2023-06-09T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-09:/the-role-and-responsibilities-of-a-forward-deployed-engineer/</id><summary type="html">&lt;p&gt;Bridging the gap between software products and customer needs, Forward Deployed Engineers are the game-changers of enterprise software. Discover their unique role in driving success and why it's in high demand. Don't miss out!&lt;/p&gt;</summary><content type="html">&lt;h2&gt;prompt: null&lt;/h2&gt;
&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;A Forward Deployed Engineer (FDE) is a versatile software engineer who works closely with customers to bridge the gap between enterprise software products and their specific implementation needs. FDEs collaborate with engineering teams, provide technical support, partner with product teams, assist in revenue growth activities, and lead customer success efforts. With a mix of technical skills, an entrepreneurial mindset, and product intuition, FDEs play a crucial role in ensuring successful product deployment and customer satisfaction.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#understanding-the-role-of-fdes"&gt;Understanding the Role of FDEs&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#collaboration-with-engineering"&gt;Collaboration with Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#partnership-with-product-teams"&gt;Partnership with Product Teams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#support-for-revenue-growth"&gt;Support for Revenue Growth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#leadership-in-customer-success"&gt;Leadership in Customer Success&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-forward-deployed-engineers-are-in-high-demand"&gt;Why Forward Deployed Engineers are in High Demand?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#technical-expertise-and-customer-focus"&gt;Technical Expertise and Customer Focus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#agile-problem-solvers"&gt;Agile Problem Solvers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#product-intuition"&gt;Product Intuition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="introduction"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the fast-paced world of enterprise software, there is an increasing demand for versatile engineers who can seamlessly integrate complex products into customers' specific implementation needs. This demand has given rise to the role of Forward Deployed Engineer (FDE). FDEs play a crucial role in ensuring successful technical integration and ongoing product deployment, acting as a bridge between the product suite and the unique requirements of each customer. This blog post will delve into the responsibilities of FDEs and shed light on why this role is in high demand.&lt;/p&gt;
&lt;p&gt;&lt;a id="understanding-the-role-of-fdes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Understanding the Role of FDEs&lt;/h2&gt;
&lt;p&gt;Forward Deployed Engineers are software engineers with broad skill sets that enable them to work closely with customers and iterate on enterprise software products. They possess technical expertise while being customer-facing, making them a valuable asset in various areas of an enterprise software organization.&lt;/p&gt;
&lt;p&gt;&lt;a id="collaboration-with-engineering"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Collaboration with Engineering&lt;/h3&gt;
&lt;p&gt;Forward Deployed Engineers (FDEs) play a crucial role in fostering collaboration between engineering teams and external stakeholders. By actively contributing to internal codebases and working closely with core engineering teams, FDEs ensure that customer feedback and implementation needs are effectively communicated and addressed.&lt;/p&gt;
&lt;p&gt;FDEs act as the bridge between the technical complexities of the product and the understanding of external stakeholders. They have a deep understanding of the product's architecture, functionalities, and underlying technologies. This expertise allows them to effectively communicate technical topics to non-technical stakeholders, such as customers or business executives.&lt;/p&gt;
&lt;p&gt;When customers encounter challenges or require customizations to the product suite, FDEs work closely with the engineering team to find viable solutions. They provide valuable insights on the implementation needs and collaborate with engineers to identify the best approach. FDEs act as advocates for customers, ensuring that their requirements are properly understood and addressed within the product's capabilities.&lt;/p&gt;
&lt;p&gt;Through this collaboration, FDEs contribute to the improvement of internal codebases. They provide feedback to engineering teams regarding areas that require enhancements or optimizations based on real-world customer experiences. This feedback loop helps create a continuous improvement process for the product, making it more robust and aligned with customer needs.&lt;/p&gt;
&lt;p&gt;Furthermore, FDEs actively participate in cross-functional meetings, bringing the perspective of external stakeholders to the engineering team. This collaboration helps align engineering efforts with customer requirements and provides valuable context for decision-making.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Collaboration with engineering is a critical aspect of the FDE role. By effectively communicating technical topics to external stakeholders and working closely with the engineering team, FDEs ensure that customer feedback is accurately relayed, implementation needs are addressed, and the product continues to evolve to meet customer expectations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="partnership-with-product-teams"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Partnership with Product Teams&lt;/h3&gt;
&lt;p&gt;Forward Deployed Engineers (FDEs) play a pivotal role in establishing a strong partnership between external stakeholders and the product teams. By leveraging their customer-facing experience and technical expertise, FDEs bring valuable insights to the table, shaping the product roadmap and driving its evolution.&lt;/p&gt;
&lt;p&gt;FDEs act as the voice of the customer within the organization. They gather feedback, requirements, and feature requests directly from customers and effectively communicate these insights to the product teams. By understanding the customers' pain points, desired features, and use cases, FDEs provide invaluable information that helps shape the product's direction.&lt;/p&gt;
&lt;p&gt;Throughout the engineering lifecycle, FDEs collaborate closely with the product teams to iterate on existing features and deliver new use cases. They work in tandem with product managers, developers, and designers to ensure that the product roadmap aligns with the specific needs of customers. FDEs provide real-world context and technical expertise, enabling product teams to make informed decisions regarding prioritization, feature enhancements, and trade-offs.&lt;/p&gt;
&lt;p&gt;FDEs also act as a bridge between product teams and customers during the implementation phase. They facilitate ongoing communication, ensuring that the product is implemented effectively and meets customers' expectations. FDEs provide guidance on technical integration, address any gaps between the product suite and customer requirements, and offer insights on best practices for successful deployment.&lt;/p&gt;
&lt;p&gt;Additionally, FDEs actively participate in testing and validation processes, providing feedback on new features and enhancements from the customer's perspective. They collaborate with product teams to conduct user acceptance testing, gather feedback, and ensure that the product meets the desired outcomes.&lt;/p&gt;
&lt;p&gt;By establishing a strong partnership with product teams, FDEs contribute to the overall success of the product. Their unique position allows them to bridge the gap between customer needs and product development, ensuring that the product remains relevant, competitive, and aligned with the evolving market landscape.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The partnership between FDEs and product teams is essential for driving innovation, customer satisfaction, and product evolution. FDEs bring customer insights, technical expertise, and a deep understanding of implementation needs to collaborate closely with product teams, influencing the product roadmap, and delivering value-driven solutions to customers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="support-for-revenue-growth"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Support for Revenue Growth&lt;/h3&gt;
&lt;p&gt;Forward Deployed Engineers (FDEs) contribute significantly to revenue growth by providing technical expertise and support in various revenue-related activities. Their role extends beyond engineering and involves actively participating in sales meetings, leading technical discussions, and completing Requests for Proposal (RFPs).&lt;/p&gt;
&lt;p&gt;As technical advisors, FDEs join sales meetings with non-technical external stakeholders, such as executives or business leaders. In this capacity, they provide valuable insights into the product's capabilities, technical requirements, and implementation process. By bridging the gap between the product suite and the customers' specific needs, FDEs help potential clients understand the value proposition and make informed purchasing decisions.&lt;/p&gt;
&lt;p&gt;Moreover, FDEs take the lead in technical sales calls and meetings with external technical stakeholders. They are responsible for communicating the technical aspects of the product, answering complex inquiries, and addressing any technical concerns potential customers may have. FDEs play a crucial role in building trust and confidence in the product's ability to meet the customers' requirements.&lt;/p&gt;
&lt;p&gt;FDEs also contribute to revenue growth by completing RFPs. These documents are often requested by potential customers to evaluate software solutions for their specific needs. FDEs leverage their technical knowledge and customer insights to provide comprehensive and accurate responses to these RFPs. By effectively showcasing the product's capabilities and aligning them with customer requirements, FDEs play a key role in unlocking new revenue opportunities.&lt;/p&gt;
&lt;p&gt;Additionally, FDEs collaborate with the sales and marketing teams to develop technical collateral, such as case studies, technical whitepapers, and solution guides. These resources help articulate the product's value proposition, highlight successful customer implementations, and provide technical details to support the sales process. FDEs actively contribute to these materials, ensuring they are accurate, relevant, and impactful.&lt;/p&gt;
&lt;p&gt;By supporting revenue growth initiatives, FDEs contribute to the overall success of the organization. Their technical expertise, customer-centric mindset, and ability to effectively communicate the value of the product position them as trusted advisors and advocates for both the customers and the sales teams. FDEs help drive new business opportunities, enhance customer satisfaction, and ultimately contribute to the financial growth of the company.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;FDEs play a crucial role in supporting revenue growth by providing technical support, leading sales discussions, completing RFPs, and developing collateral. Their ability to bridge the gap between technical complexities and customer needs helps build trust, accelerate sales cycles, and unlock new revenue streams. FDEs are instrumental in driving the financial success of the organization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="leadership-in-customer-success"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Leadership in Customer Success&lt;/h3&gt;
&lt;p&gt;Forward Deployed Engineers (FDEs) take on a leadership role in ensuring customer success throughout the implementation and deployment of the product. They act as technical leads and provide critical support to customers, facilitating onboarding, and driving the adoption of new features into customers' production environments.&lt;/p&gt;
&lt;p&gt;FDEs serve as the primary point of contact for customers during the implementation phase. They work closely with customer success teams to understand the customers' specific requirements and develop tailored implementation plans. FDEs leverage their technical expertise to guide customers through the integration process, ensuring a smooth and successful onboarding experience.&lt;/p&gt;
&lt;p&gt;As technical leads, FDEs provide ongoing support to customers, addressing any technical issues or challenges they may encounter. They troubleshoot and resolve complex technical problems, acting as a bridge between the customers and the engineering team. FDEs leverage their deep understanding of the product to provide timely and effective solutions, ensuring that customers can fully leverage the capabilities of the software.&lt;/p&gt;
&lt;p&gt;In addition to technical support, FDEs play a critical role in driving the adoption of new features and enhancements. They collaborate with customers to understand their specific use cases and provide guidance on how to best utilize the product's functionality to achieve their desired outcomes. FDEs conduct training sessions, create documentation, and offer best practices to ensure that customers can maximize the value they derive from the product.&lt;/p&gt;
&lt;p&gt;FDEs also act as advocates for customers within the organization. They actively collect feedback, feature requests, and insights from customers and communicate them to the product teams. By representing the customers' voice, FDEs contribute to the continuous improvement of the product, ensuring that it evolves to meet their changing needs.&lt;/p&gt;
&lt;p&gt;Building strong relationships with customers is a key aspect of the FDE role. FDEs engage in regular communication, conduct business reviews, and seek opportunities to deepen customer engagement. By understanding the customers' goals, challenges, and aspirations, FDEs can provide personalized recommendations and strategic guidance, ultimately fostering long-term customer satisfaction and loyalty.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;FDEs assume a leadership role in customer success by providing technical guidance, support, and advocacy throughout the implementation and deployment process. Their deep technical expertise, customer-centric approach, and ability to build strong relationships position them as trusted partners for customers. FDEs play a crucial role in driving customer success, ensuring that customers achieve their desired outcomes and maximizing the value they derive from the product.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a id="why-forward-deployed-engineers-are-in-high-demand"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Why Forward Deployed Engineers are in High Demand?&lt;/h2&gt;
&lt;p&gt;The increasing complexity of enterprise software products and the variability in customer requirements have created a significant demand for FDEs. Here are some reasons why this role is sought after:&lt;/p&gt;
&lt;p&gt;&lt;a id="technical-expertise-and-customer-focus"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Technical Expertise and Customer Focus&lt;/h3&gt;
&lt;p&gt;FDEs possess a unique mix of technical skills and customer-centricity. They understand the intricacies of the product and can effectively communicate its value to both technical and non-technical stakeholders. Their ability to bridge the gap between engineering and customer needs is invaluable in ensuring successful deployments.&lt;/p&gt;
&lt;p&gt;&lt;a id="agile-problem-solvers"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Agile Problem Solvers&lt;/h3&gt;
&lt;p&gt;FDEs exhibit an entrepreneurial mindset, allowing them to adapt quickly to evolving customer requirements. They are adept at identifying challenges, proposing solutions, and iterating on product features. This agility is essential in a rapidly changing technological landscape, where customers' needs evolve at a fast pace.&lt;/p&gt;
&lt;p&gt;&lt;a id="product-intuition"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Product Intuition&lt;/h3&gt;
&lt;p&gt;By working closely with customers, FDEs develop a deep understanding of their pain points and aspirations. This product intuition enables them to provide valuable insights to product teams, helping shape the product roadmap and prioritize features that align with customer needs. FDEs contribute to the development of customer-centric software solutions.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Forward Deployed Engineers play a vital role in enterprise software organizations, acting as the bridge between products and customer implementations. Their broad skill set, technical expertise, entrepreneurial mindset, and product intuition make them invaluable assets in driving customer success, revenue growth, and product evolution. As enterprise software continues to evolve, the demand for FDEs will likely increase, providing software engineers with a customer-facing path that allows them to thrive in both technical and business domains&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><category term="Howto"></category><category term="machine-learning"></category><category term="python"></category><category term="career"></category><category term="roles"></category><category term="software-development"></category></entry><entry><title>How to Count Tokens - Tokenization With Tiktoken.</title><link href="https://www.safjan.com/how-to-count-tokens/" rel="alternate"></link><published>2023-06-08T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-08:/how-to-count-tokens/</id><summary type="html">&lt;p&gt;Counting tokens is a useful task in natural language processing (NLP) that allows us to measure the length and complexity of a text. The two important use cases for counting the tokens are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;controlling the length of the prompt&lt;/strong&gt; -  models has limit …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Counting tokens is a useful task in natural language processing (NLP) that allows us to measure the length and complexity of a text. The two important use cases for counting the tokens are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;controlling the length of the prompt&lt;/strong&gt; -  models has limit on the number of input tokens - it is good to have control if you don't exceed the limits for the model&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cost awareness&lt;/strong&gt;  - when you know how many tokens you pass as input, you know the cost related to the prompt.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this blog post, we will explore how to count the number of tokens in a given text using OpenAI's tokenizer, called &lt;code&gt;tiktoken&lt;/code&gt;. Whether you're a seasoned Python developer or just getting started with NLP, this guide will provide you with a step-by-step process to accurately determine the token count of your text.&lt;/p&gt;
&lt;h3&gt;Introduction to &lt;code&gt;tiktoken&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To begin with, we need to install the &lt;code&gt;tiktoken&lt;/code&gt; library, which is a powerful tokenizer developed by OpenAI. It offers efficient tokenization capabilities and supports a wide range of languages. You can find the library on GitHub at &lt;a href="https://github.com/openai/tiktoken"&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Code Example&lt;/h3&gt;
&lt;p&gt;Let's dive into a code example that demonstrates how to count tokens using &lt;code&gt;tiktoken&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tiktoken&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;num_tokens_from_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding_name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Returns the number of tokens in a text string.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tiktoken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoding_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;num_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_tokens&lt;/span&gt;

&lt;span class="n"&gt;num_tokens_from_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;tiktoken is great!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;cl100k_base&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the example above, we import the &lt;code&gt;tiktoken&lt;/code&gt; library and define a function called &lt;code&gt;num_tokens_from_string&lt;/code&gt;. This function takes a text string and an encoding name as input parameters. It returns the number of tokens in the given text string.&lt;/p&gt;
&lt;p&gt;To count the tokens, we first obtain the encoding using &lt;code&gt;tiktoken.get_encoding(encoding_name)&lt;/code&gt;. The &lt;code&gt;encoding_name&lt;/code&gt; specifies the type of encoding we want to use. In this case, we use the &lt;code&gt;cl100k_base&lt;/code&gt; encoding, which is suitable for second-generation embedding models like &lt;code&gt;text-embedding-ada-002&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, we encode the input string using &lt;code&gt;encoding.encode(string)&lt;/code&gt; and calculate the number of tokens by taking the length of the encoded sequence. The final result is the total number of tokens in the text string.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tiktoken&lt;/code&gt; supports three encodings used by OpenAI models:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Encoding name&lt;/th&gt;
&lt;th&gt;OpenAI models&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cl100k_base&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;gpt-4&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;text-embedding-ada-002&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;p50k_base&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Codex models, &lt;code&gt;text-davinci-002&lt;/code&gt;, &lt;code&gt;text-davinci-003&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;r50k_base&lt;/code&gt; (or &lt;code&gt;gpt2&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;GPT-3 models like &lt;code&gt;davinci&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;OpenAI Cookbook Guide&lt;/h3&gt;
&lt;p&gt;For a more detailed explanation and additional examples, you can refer to the OpenAI Cookbook guide on &lt;a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"&gt;how to count tokens with tiktoken&lt;/a&gt;. The guide provides comprehensive instructions on token counting and offers insights into various use cases.&lt;/p&gt;
&lt;h3&gt;Tokenization Sandbox&lt;/h3&gt;
&lt;p&gt;If you're looking to experiment with text tokenization, OpenAI provides a convenient web application called the Tokenization Sandbox. You can access it &lt;a href="https://platform.openai.com/tokenizer"&gt;here&lt;/a&gt;. The sandbox allows you to input text and observe the resulting tokens, helping you better understand the tokenization process.&lt;/p&gt;
&lt;h3&gt;Text splitter module&lt;/h3&gt;
&lt;p&gt;A Python script for splitting text into parts with controlled (limited) length in tokens. This script utilizes the &lt;code&gt;tiktoken&lt;/code&gt; library for encoding and decoding text.:
&lt;a href="https://gist.github.com/izikeros/17d9c8ab644bd2762acf6b19dd0cea39"&gt;https://gist.github.com/izikeros/17d9c8ab644bd2762acf6b19dd0cea39&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Count tokens cli tool&lt;/h3&gt;
&lt;p&gt;Check this simple CLI tool that have one purpose - count tokens in a text file:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/izikeros/count_tokens"&gt;izikeros/count_tokens: Count tokens in a text file.&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Rule of thumb&lt;/h3&gt;
&lt;p&gt;OpenAI on the &lt;a href="https://platform.openai.com/tokenizer"&gt;website&lt;/a&gt; with the tokenizer sandbox provides rule of thumb that helps to estimate approximate number of tokens in given text.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;To develop this guide, we drew inspiration from the token counting instructions provided by OpenAI. You can find additional information in the &lt;a href="https://platform.openai.com/docs/guides/embeddings/limitations-risks"&gt;OpenAI documentation&lt;/a&gt;, where they discuss the limitations and risks associated with embeddings.&lt;/p&gt;
&lt;p&gt;Token counting is essential when working with NLP, enabling us to analyze and process text effectively. By leveraging OpenAI's &lt;code&gt;tiktoken&lt;/code&gt; library and following the guidelines outlined in this blog post, you'll be well-equipped to count tokens accurately and efficiently.&lt;/p&gt;
&lt;p&gt;See also: &lt;a href="https://omarkama.li/blog/tokens-the-secret-language-of-ai"&gt;Tokens, the secret language of AI | Omar Kamali&lt;/a&gt;&lt;/p&gt;</content><category term="note"></category><category term="tokenizers"></category><category term="token"></category><category term="tokenization"></category><category term="tiktoken"></category><category term="openai"></category><category term="NLP"></category></entry><entry><title>The Best Vector Databases for Storing Embeddings</title><link href="https://www.safjan.com/the-best-vector-databases-for-storing-embeddings/" rel="alternate"></link><published>2023-06-05T00:00:00+02:00</published><updated>2023-06-05T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-06-05:/the-best-vector-databases-for-storing-embeddings/</id><summary type="html">&lt;p&gt;Delve into the World of Vector Databases Fueling NLP's Transformative Journey.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Best Vector Databases for Storing Embeddings in NLP&lt;/h2&gt;
&lt;p&gt;As natural language processing (NLP) continues to advance, the need for efficient storage and retrieval of vector representations, or embeddings, has become paramount.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Vector databases are purpose-built databases that excel in storing and querying high-dimensional vector data, such as word embeddings or document representations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This article explores the best vector databases available, their unique features, and the crucial parameters that differentiate them.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#tldr"&gt;TLDR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-vector-databases-are-and-why-there-is-demand-for-them"&gt;What vector databases are, and why there is demand for them?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#understanding-tradeoffs-and-identifying-the-specific-requirements-to-choose-the-best-tool"&gt;Understanding tradeoffs and identifying the specific requirements to choose the best tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vector-databases"&gt;Vector databases&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#chroma"&gt;Chroma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#haystack-by-deepsetai"&gt;Haystack by DeepsetAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#faiss-by-facebook"&gt;Faiss by Facebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#milvus"&gt;Milvus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pgvector"&gt;pgvector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pinecone"&gt;Pinecone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#supabase"&gt;Supabase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#qdrant"&gt;Qdrant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vespa"&gt;Vespa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#weaviate"&gt;Weaviate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#deeplake"&gt;DeepLake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vectorstore-from-langchain"&gt;VectorStore from LangChain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#other-relevant-vector-databases"&gt;Other Relevant Vector Databases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tabular-summary-of-the-features"&gt;Tabular summary of the features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recommendations"&gt;Recommendations&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#easy-start-and-user-friendliness---good-for-poc"&gt;Easy Start and User-Friendliness - good for PoC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#advanced-capabilities-and-performance"&gt;Advanced Capabilities and Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#customization-and-advanced-use-cases"&gt;Customization and Advanced Use Cases&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#related-reading"&gt;Related reading&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="tldr"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;TLDR&lt;/h2&gt;
&lt;p&gt;If you don't want to spent time on reading about each solution, you might want to head directly for the &lt;a href="#recommendations"&gt;recommendations&lt;/a&gt; section where solutions for various use cases are proposed.
&lt;a id="what-vector-databases-are-and-why-there-is-demand-for-them"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What vector databases are, and why there is demand for them?&lt;/h2&gt;
&lt;p&gt;Vector databases are specialized databases designed for efficient storage, retrieval, and manipulation of vector representations, particularly in the context of Natural Language Processing (NLP) and machine learning applications. They are optimized for handling high-dimensional embeddings that represent textual or numerical data in a vectorized format.&lt;/p&gt;
&lt;p&gt;While traditional databases like PostgreSQL are versatile and battle-tested, they are not specifically optimized for vector operations. Vector databases, on the other hand, provide a set of features and optimizations tailored to the unique requirements of working with vector embeddings. Here are some reasons why vector databases are in demand despite the existence of other types of databases:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Vector databases are built to handle large-scale datasets and can scale horizontally to accommodate growing data volumes. They distribute the storage and processing of vectors across multiple machines, enabling efficient handling of massive amounts of embedding data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Query Speed&lt;/strong&gt;: Vector databases employ advanced indexing structures and search algorithms, such as approximate nearest neighbor (ANN) search, to achieve fast and accurate similarity searches. These optimizations enable rapid retrieval of vectors based on their similarity to a given query vector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accuracy of Search Results&lt;/strong&gt;: Vector databases focus on preserving the accuracy of similarity search results. They leverage techniques like space partitioning, dimensionality reduction, and quantization to ensure that similar vectors are efficiently identified, even in high-dimensional spaces.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: Vector databases offer flexibility in terms of supported vector operations and indexing methods. They often provide a range of indexing algorithms, allowing users to choose the one that best suits their specific use case. Additionally, vector databases may support additional functionality like filtering, ranking, and semantic search.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Persistence and Durability&lt;/strong&gt;: Vector databases prioritize data persistence and durability, ensuring that vector embeddings are reliably stored and protected against data loss. They often integrate with existing storage solutions or provide mechanisms for backup and replication.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Storage Location&lt;/strong&gt;: Vector databases can be deployed either on-premises or in the cloud, providing flexibility in terms of infrastructure choices. Cloud-based vector databases offer the advantage of managed services, offloading the operational overhead of maintaining and scaling the database infrastructure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Direct Library vs. Abstraction&lt;/strong&gt;: Vector databases come in two main forms: those that offer a direct library interface for integration into existing systems and those that provide a higher-level abstraction, such as RESTful APIs or query languages. This flexibility allows developers to choose the level of control and integration that best fits their requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While traditional databases like PostgreSQL can handle various data types, including vectors, they may lack the specialized optimizations and features provided by vector databases. Vector databases excel in efficiently storing and querying high-dimensional embeddings, enabling faster similarity search and supporting specific vector-related operations. By leveraging these optimizations, vector databases streamline the development and deployment of NLP and machine learning applications.&lt;/p&gt;
&lt;p&gt;&lt;a id="understanding-tradeoffs-and-identifying-the-specific-requirements-to-choose-the-best-tool"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Understanding tradeoffs and identifying the specific requirements to choose the best tool&lt;/h2&gt;
&lt;p&gt;When choosing a vector database, there are several tradeoffs and potentially contradicting requirements that developers need to consider. Here are some typical tradeoffs and contradictions related to selecting a vector database:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalability vs. Query Speed&lt;/strong&gt;: Achieving high scalability often requires distributing data across multiple nodes, which can impact query speed due to network communication. Balancing the need for scalability with the requirement for fast query response times can be a tradeoff when selecting a vector database.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search Accuracy vs. Query Speed&lt;/strong&gt;: Algorithms that provide high search accuracy, such as exact nearest neighbor search, can be computationally expensive and impact query speed. Approximate algorithms, while faster, might sacrifice some accuracy. The tradeoff lies in finding the right balance between search accuracy and query speed based on the specific use case.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Flexibility vs. Performance&lt;/strong&gt;: Some vector databases offer extensive customization options, allowing users to tailor the system to their specific requirements. However, the more flexibility provided, the more overhead might be introduced, potentially impacting overall performance. Balancing the need for flexibility with performance considerations is crucial.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Persistence and Durability vs. Query Performance&lt;/strong&gt;: Ensuring data persistence and durability typically involves additional disk I/O operations, which can impact query performance. The tradeoff here is finding the right level of data persistence and durability while maintaining satisfactory query performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Storage Location vs. Data Security&lt;/strong&gt;: Storing vector embeddings locally provides faster access, but it may introduce data security risks. Cloud-based storage solutions offer scalability and redundancy but may raise concerns about data privacy and compliance. The choice between local and cloud storage involves weighing the benefits of each option against data security requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Direct Library vs. Abstraction&lt;/strong&gt;: Some vector databases offer direct library interfaces for seamless integration into existing systems, while others provide higher-level abstractions like APIs or query languages for ease of use. The tradeoff here is between the level of control and integration required versus the simplicity of implementation and maintenance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ease of Use vs. Advanced Features&lt;/strong&gt;: Vector databases that prioritize ease of use often sacrifice some advanced features and optimization techniques. Developers must consider the complexity of their use case and weigh the need for advanced features against the simplicity of the database.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Understanding these tradeoffs and identifying the specific requirements of a project is crucial in selecting a vector database that best aligns with the desired tradeoff priorities. It requires carefully evaluating the tradeoffs and making informed decisions based on the unique needs of the application or system being developed.&lt;/p&gt;
&lt;p&gt;&lt;a id="vector-databases"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Vector databases&lt;/h2&gt;
&lt;p&gt;&lt;a id="chroma"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Chroma&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/chroma-core/chroma?logo=github"&gt;
&lt;img alt="chroma logo" src="https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png"&gt;
&lt;a href="https://www.trychroma.com/"&gt;Chroma&lt;/a&gt; is an open-source vector database developed by Chroma.ai. It focuses on scalability, providing robust support for storing and querying large-scale embedding datasets efficiently. Chroma offers a distributed architecture with horizontal scalability, enabling it to handle massive volumes of vector data. It leverages Apache Cassandra for high availability and fault tolerance, ensuring data persistence and durability.&lt;/p&gt;
&lt;p&gt;One unique aspect of Chroma is its &lt;strong&gt;flexible indexing system&lt;/strong&gt;. It supports &lt;strong&gt;multiple indexing strategies&lt;/strong&gt;, such as &lt;a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximation_methods"&gt;approximate nearest neighbors&lt;/a&gt; (ANN) algorithms like &lt;a href="https://arxiv.org/abs/1603.09320"&gt;HNSW&lt;/a&gt; and &lt;a href="https://towardsdatascience.com/similarity-search-with-ivfpq-9c6348fd4db3"&gt;IVFPQ&lt;/a&gt;, enabling fast and accurate similarity searches. Chroma also provides comprehensive &lt;strong&gt;Python and RESTful APIs&lt;/strong&gt;, making it &lt;strong&gt;easily integratable&lt;/strong&gt; into NLP pipelines. With its emphasis on &lt;strong&gt;scalability&lt;/strong&gt; and &lt;strong&gt;speed&lt;/strong&gt;, Chroma is an excellent choice for applications that require high-performance vector storage and retrieval.&lt;/p&gt;
&lt;p&gt;They have &lt;a href="https://colab.research.google.com/drive/1QEzFyqnoFxq7LUGyP1vzR4iLt9PpCDXv?usp=sharing"&gt;Colab&lt;/a&gt; notebook with the demo.&lt;/p&gt;
&lt;p&gt;The core API commands (from the product page)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;chromadb&lt;/span&gt;

&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chromadb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_collection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# add embeddings and documents&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# get back similar ones&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note: there are plugins for LangChain, LlamaIndex, OpenAI and others.
&lt;a id="haystack-by-deepsetai"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Haystack by DeepsetAI&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/deepset-ai/haystack?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="haystack logo" src="images/vectordb/haystack.png"&gt;
DeepsetAI's &lt;a href="https://haystack.deepset.ai/"&gt;Haystack&lt;/a&gt; is another popular vector database designed specifically for NLP applications. It offers a range of features tailored to support end-to-end development of search systems using embeddings. Haystack integrates well with popular transformer models like BERT, allowing users to extract embeddings directly from pre-trained models. It leverages &lt;a href="https://www.elastic.co/what-is/elasticsearch"&gt;Elasticsearch&lt;/a&gt; as its underlying storage engine, providing powerful indexing and querying capabilities.&lt;/p&gt;
&lt;p&gt;Haystack stands out with its &lt;strong&gt;intuitive query language&lt;/strong&gt;, which supports complex &lt;strong&gt;semantic searches&lt;/strong&gt; and &lt;strong&gt;filtering&lt;/strong&gt; based on various parameters. Additionally, it offers a &lt;strong&gt;modular pipeline&lt;/strong&gt; architecture for preprocessing, &lt;strong&gt;embedding extraction&lt;/strong&gt;, and querying, making it &lt;strong&gt;highly customizable and adaptable&lt;/strong&gt; to different NLP use cases. With its &lt;strong&gt;user-friendly interface&lt;/strong&gt; and comprehensive functionality, DeepsetAI's Haystack is an excellent choice for developers seeking a flexible and feature-rich vector database for NLP.&lt;/p&gt;
&lt;p&gt;&lt;a id="faiss-by-facebook"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Faiss by Facebook&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/facebookresearch/faiss?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://faiss.ai/"&gt;Faiss logo&lt;/a&gt;, developed by Facebook AI Research, is a widely-used vector database renowned for its high-performance similarity search capabilities. It provides a range of indexing methods optimized for efficient retrieval of nearest neighbors, including IVF (Inverted File) and HNSW (Hierarchical Navigable Small World). Faiss also supports GPU acceleration, enabling fast computation on large-scale embeddings.&lt;/p&gt;
&lt;p&gt;One of Faiss' notable features is its support for &lt;strong&gt;multi-index search&lt;/strong&gt;, which combines different indexing methods to improve search accuracy and speed. Additionally, Faiss offers a &lt;strong&gt;Python interface&lt;/strong&gt;, making it easy to integrate with existing NLP pipelines and frameworks. With its focus on &lt;strong&gt;search performance and versatility&lt;/strong&gt;, Faiss is a go-to choice for projects demanding fast and accurate similarity &lt;strong&gt;search over vast embedding collections&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="milvus"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Milvus&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/milvus-io/milvus?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Milvus logo" src="/images/vectordb/milvus.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://milvus.io/"&gt;Milvus&lt;/a&gt; is an open-source vector database developed by Zilliz, designed for efficient storage and retrieval of large-scale embeddings. It provides high scalability and supports distributed deployment across multiple machines, making it suitable for handling massive NLP datasets. Milvus integrates with popular ANN libraries like Faiss, Annoy, and NMSLIB, offering flexible indexing options to achieve high search accuracy.&lt;/p&gt;
&lt;p&gt;One key feature of Milvus is its &lt;strong&gt;GPU support&lt;/strong&gt;, leveraging NVIDIA GPUs for accelerated computation. This makes Milvus an excellent choice &lt;strong&gt;for deep learning applications&lt;/strong&gt; that require fast vector search and similarity calculations. Furthermore, Milvus provides a user-friendly &lt;strong&gt;WebUI&lt;/strong&gt; and supports &lt;strong&gt;multiple programming languages&lt;/strong&gt;, simplifying development and deployment processes. With its focus on scalability and GPU acceleration, Milvus is an ideal vector database for large-scale NLP projects.&lt;/p&gt;
&lt;p&gt;&lt;a id="pgvector"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;pgvector&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/ankane/pgvector?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Open-source vector similarity search for Postgres. Pgvector helps to built vector database on top of PostgreSQL, a popular open-source relational database. It leverages the powerful indexing capabilities of PostgreSQL's extension system to provide efficient storage and retrieval of vector embeddings. pgvector supports both CPU and GPU inference, enabling high-performance vector operations.&lt;/p&gt;
&lt;p&gt;One key advantage of pgvector is its seamless &lt;strong&gt;integration with the broader PostgreSQL&lt;/strong&gt; ecosystem. Users can leverage the rich functionality of PostgreSQL, such as ACID compliance and support for complex queries, while benefiting from vector-specific operations. pgvector provides a PostgreSQL extension that extends the SQL syntax to handle vector operations and offers a Python library for easy integration. With its compatibility with PostgreSQL and efficient vector storage, pgvector is a reliable choice for NLP applications that require a seamless SQL integration.&lt;/p&gt;
&lt;p&gt;&lt;a id="pinecone"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Pinecone&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Pinecone logo" src="/images/vectordb/pinecone.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt; is a managed vector database built for handling large-scale embeddings in real-time applications. It focuses on low-latency search and high-throughput indexing, making it suitable for latency-sensitive NLP use cases. Pinecone's cloud-native infrastructure handles indexing, storage, and query serving, allowing developers to focus on building their applications.&lt;/p&gt;
&lt;p&gt;Pinecone offers a RESTful &lt;strong&gt;API&lt;/strong&gt; and client libraries &lt;strong&gt;for various programming languages&lt;/strong&gt;, simplifying integration with different NLP frameworks. It supports &lt;strong&gt;dynamic indexing&lt;/strong&gt;, allowing incremental updates to embeddings without rebuilding the entire index. Pinecone also provides advanced features like &lt;strong&gt;vector similarity search&lt;/strong&gt;, &lt;strong&gt;filtering&lt;/strong&gt;, and result ranking. With its &lt;strong&gt;emphasis on real-time performance&lt;/strong&gt; and ease of use, Pinecone is an excellent choice for developers seeking a fully managed vector database for NLP applications.&lt;/p&gt;
&lt;p&gt;&lt;a id="supabase"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Supabase&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/supabase/supabase?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Supabase logo" src="images/vectordb/supabase.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://supabase.com/"&gt;Supabase&lt;/a&gt;, known for its open-source data platform, offers a scalable vector storage solution designed for fast and efficient retrieval of embeddings. Supabase leverages PostgreSQL as its underlying storage engine, ensuring data durability and compatibility with standard SQL queries. It provides a range of features such as indexing, querying, and filtering, optimized for vector data.&lt;/p&gt;
&lt;p&gt;One distinctive aspect of Supabase is its &lt;strong&gt;real-time capabilities&lt;/strong&gt;, enabled by its integration with PostgREST and PostgreSQL's logical decoding feature. This allows developers to build real-time applications that can react to changes in vector data. Supabase also provides a user-friendly &lt;strong&gt;interface&lt;/strong&gt; and &lt;strong&gt;client libraries&lt;/strong&gt; for &lt;strong&gt;various programming languages&lt;/strong&gt;, making it accessible to developers with different skill sets. With its combination of vector storage and real-time capabilities, Supabase is an excellent choice for NLP projects that require both scalability and real-time updates.&lt;/p&gt;
&lt;p&gt;&lt;a id="qdrant"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Qdrant&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/qdrant/qdrant?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Qdrant logo" src="/images/vectordb/qdrant.png"&gt;&lt;/p&gt;
&lt;p&gt;Qdrant is an open-source vector database designed for similarity search and efficient storage of high-dimensional embeddings. It leverages an approximate nearest neighbor (ANN) algorithm based on Hierarchical Navigable Small World (HNSW) graphs, enabling fast and accurate similarity searches. Qdrant supports both CPU and GPU inference, allowing users to leverage hardware acceleration for faster computations.&lt;/p&gt;
&lt;p&gt;One notable feature of Qdrant is its &lt;strong&gt;RESTful API&lt;/strong&gt;, which provides a user-friendly &lt;strong&gt;interface for indexing, searching, and managing vector data&lt;/strong&gt;. Qdrant also offers &lt;strong&gt;flexible query options&lt;/strong&gt;, allowing users to specify search parameters and control the trade-off between accuracy and speed. With its focus on efficient similarity search and user-friendly API, Qdrant is a powerful vector database for various NLP applications.&lt;/p&gt;
&lt;p&gt;&lt;a id="vespa"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Vespa&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/vespa-engine/vespa?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="vespa logo" src="https://vespa.ai/assets/vespa-logo.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://vespa.ai/"&gt;Vespa&lt;/a&gt; is an open-source big data processing and serving engine developed by Verizon Media. It provides a distributed, scalable, and high-performance infrastructure for storing and querying vector embeddings. Vespa utilizes an inverted index structure combined with approximate nearest neighbor (ANN) search algorithms for efficient and accurate similarity searches.&lt;/p&gt;
&lt;p&gt;One of Vespa's key features is its &lt;strong&gt;built-in ranking framework&lt;/strong&gt;, allowing developers to define custom ranking models and apply &lt;strong&gt;complex ranking algorithms to search results&lt;/strong&gt;. Vespa also supports &lt;strong&gt;real-time updates&lt;/strong&gt;, making it suitable for &lt;strong&gt;dynamic embedding datasets&lt;/strong&gt;. Additionally, Vespa provides a &lt;strong&gt;query language&lt;/strong&gt; and a user-friendly &lt;strong&gt;WebUI&lt;/strong&gt; for managing and monitoring the vector database. With its focus on &lt;strong&gt;distributed processing&lt;/strong&gt; and advanced ranking capabilities, Vespa is a powerful tool for NLP applications that require complex ranking models and real-time updates.&lt;/p&gt;
&lt;p&gt;&lt;a id="weaviate"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Weaviate&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/semi-technologies/weaviate?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Weaviate logo" src="/images/vectordb/weaviate.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://weaviate.io/"&gt;Weaviate&lt;/a&gt; is an open-source knowledge graph and vector search engine that excels in handling high-dimensional embeddings. It combines the power of graph databases and vector search to provide efficient storage, retrieval, and exploration of vector data. Weaviate offers powerful indexing methods, including approximate nearest neighbor (ANN) algorithms like HNSW, for fast and accurate similarity searches.&lt;/p&gt;
&lt;p&gt;One unique aspect of Weaviate is its &lt;strong&gt;focus on semantics and contextual relationships&lt;/strong&gt;. It allows users to define &lt;strong&gt;custom schema and relationships between entities&lt;/strong&gt;, enabling &lt;strong&gt;complex queries that go beyond simple vector similarity&lt;/strong&gt;. Weaviate also provides a &lt;strong&gt;RESTful API&lt;/strong&gt;, client libraries, and a user-friendly &lt;strong&gt;WebUI&lt;/strong&gt; for easy integration and management. With its combination of &lt;strong&gt;graph database features&lt;/strong&gt; and vector search capabilities, Weaviate is an excellent choice &lt;strong&gt;for NLP applications that require semantic understanding and exploration of embeddings&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="deeplake"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;DeepLake&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/activeloopai/deeplake?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="DeepLake logo" src="https://camo.githubusercontent.com/d0c805affb06f5ea9ba767de06b77a04de54a7ef433fad08b2729d5e6b11112c/68747470733a2f2f692e706f7374696d672e63632f72736a63576333532f646565706c616b652d6c6f676f2e706e67"&gt;
&lt;a href="https://www.activeloop.ai/"&gt;DeepLake&lt;/a&gt; is an open-source vector database designed for efficient storage and retrieval of embeddings. It focuses on scalability and speed, making it suitable for handling large-scale NLP datasets. DeepLake provides a distributed architecture with built-in support for horizontal scalability, allowing users to handle massive volumes of vector data.&lt;/p&gt;
&lt;p&gt;One unique feature of DeepLake is its support for &lt;strong&gt;distributed vector indexing and querying&lt;/strong&gt;. It leverages an &lt;strong&gt;ANN&lt;/strong&gt; algorithm based on the Product Quantization (PQ) method, enabling fast and accurate similarity searches. DeepLake also provides a &lt;strong&gt;RESTful API&lt;/strong&gt; for easy integration with NLP pipelines and frameworks. With its emphasis on &lt;strong&gt;scalability and distributed processing&lt;/strong&gt;, DeepLake is a robust vector database for demanding NLP applications.&lt;/p&gt;
&lt;p&gt;&lt;a id="vectorstore-from-langchain"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;VectorStore from LangChain&lt;/h3&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/hwchase17/langchain?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;LangChain &lt;a href="https://docs.langchain.com/docs/components/indexing/vectorstore"&gt;VectorStore&lt;/a&gt; is an open-source vector database optimized for multilingual NLP applications. It focuses on efficient storage and retrieval of embeddings across multiple languages. VectorStore supports various indexing methods, including approximate nearest neighbor (ANN) algorithms like HNSW and Annoy, for fast similarity searches.&lt;/p&gt;
&lt;p&gt;One distinguishing feature of VectorStore is its &lt;strong&gt;language-specific indexing&lt;/strong&gt; and &lt;strong&gt;retrieval capabilities&lt;/strong&gt;. It provides &lt;strong&gt;language-specific tokenization&lt;/strong&gt; and &lt;strong&gt;indexing strategies&lt;/strong&gt; to &lt;strong&gt;optimize search accuracy for different languages&lt;/strong&gt;. VectorStore also offers a &lt;strong&gt;RESTful API&lt;/strong&gt; and client libraries for easy integration with NLP pipelines. With its multilingual support and language-specific indexing, VectorStore is an excellent choice for projects that deal with embeddings across multiple languages.&lt;/p&gt;
&lt;p&gt;&lt;a id="other-relevant-vector-databases"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Other Relevant Vector Databases&lt;/h3&gt;
&lt;p&gt;While the above tools represent some of the best vector databases available for storing embeddings in NLP, there are other notable options worth exploring:&lt;/p&gt;
&lt;h4&gt;Annoy&lt;/h4&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/spotify/annoy?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Annoy is a lightweight C++ library for approximate nearest neighbor (ANN) search, offering efficient indexing and querying of high-dimensional embeddings.&lt;/p&gt;
&lt;h4&gt;Elasticsearch&lt;/h4&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/elastic/elasticsearch?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Elasticsearch is a popular distributed search and analytics engine that can be used to store and retrieve vector embeddings efficiently.&lt;/p&gt;
&lt;h4&gt;Hnswlib&lt;/h4&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/nmslib/hnswlib?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;Hnswlib is a C++ library for efficient approximate nearest neighbor (ANN) search, providing high-performance indexing and retrieval of embeddings.&lt;/p&gt;
&lt;h4&gt;NMSLIB&lt;/h4&gt;
&lt;p&gt;&lt;img alt="github stars shield" src="https://img.shields.io/github/stars/nmslib/nmslib?logo=github"&gt;&lt;/p&gt;
&lt;p&gt;NMSLIB is an open-source library for similarity search, offering a range of indexing methods and data structures for efficient storage and retrieval of embeddings.&lt;/p&gt;
&lt;p&gt;These vector databases provide additional options and features that may suit specific requirements or preferences. Exploring these alternatives can help developers find the best fit for their NLP projects.&lt;/p&gt;
&lt;p&gt;To explore more, often lesser-known libraries you can use GitHub's topic search: &lt;a href="https://github.com/topics/vector-database"&gt;vector-database · GitHub Topics · GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id="tabular-summary-of-the-features"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tabular summary of the features&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tool&lt;/th&gt;
&lt;th&gt;Scalability&lt;/th&gt;
&lt;th&gt;Query Speed&lt;/th&gt;
&lt;th&gt;Search Accuracy&lt;/th&gt;
&lt;th&gt;Flexibility&lt;/th&gt;
&lt;th&gt;Persistence&lt;/th&gt;
&lt;th&gt;Storage Location&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chroma&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DeepsetAI&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Faiss&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Milvus&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pgvector&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinecone&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Supabase&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Qdrant&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Vespa&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Weaviate&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DeepLake&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LangChain VectorStore&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Annoy&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Elasticsearch&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Hnswlib&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NMSLIB&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Local/Cloud&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a id="recommendations"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Recommendations&lt;/h2&gt;
&lt;p&gt;Please find recommendations for three groups of use cases
&lt;a id="easy-start-and-user-friendliness---good-for-poc"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Easy Start and User-Friendliness - good for PoC&lt;/h3&gt;
&lt;p&gt;In this group, the focus is on vector databases that are easy to start with and user-friendly, even if they may sacrifice some advanced capabilities or performance.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chroma&lt;/strong&gt;: Chroma is an excellent choice for this group due to its simplicity and ease of use. It provides a straightforward API and offers out-of-the-box functionality for vector storage and retrieval. While it may not have the same level of scalability or advanced search algorithms as some other tools, it is ideal for small to medium-sized projects or beginners who want to quickly get started with vector databases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DeepsetAI&lt;/strong&gt;: DeepsetAI is another tool that prioritizes user-friendliness without compromising on essential functionalities. It offers a user-friendly interface, powerful search capabilities, and easy integration into existing NLP workflows. DeepsetAI is well-suited for developers who want a simple and efficient solution for storing and querying vector embeddings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="advanced-capabilities-and-performance"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Advanced Capabilities and Performance&lt;/h3&gt;
&lt;p&gt;In this group, we consider vector databases that provide advanced capabilities and high-performance, catering to more demanding use cases.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Faiss&lt;/strong&gt;: Faiss is a widely used and highly performant vector database that specializes in efficient similarity search. It offers a range of indexing structures and search algorithms, making it suitable for large-scale projects that require fast and accurate retrieval of embeddings. Faiss is an optimal choice when performance and search accuracy are critical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Milvus&lt;/strong&gt;: Milvus is another powerful vector database known for its scalability and performance. It provides distributed storage and indexing, allowing for efficient handling of large-scale embedding datasets. Milvus supports various indexing algorithms, including approximate nearest neighbor (ANN) search, enabling fast similarity search. It is a robust solution for projects that demand scalability, high-performance, and flexibility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a id="customization-and-advanced-use-cases"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Customization and Advanced Use Cases&lt;/h3&gt;
&lt;p&gt;In this group, we consider vector databases that offer extensive customization options and cater to advanced use cases with specific requirements.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pinecone&lt;/strong&gt;: Pinecone is a vector database that excels in providing real-time search capabilities and high scalability. It offers advanced features such as dynamic indexing, custom similarity functions, and efficient updates, making it ideal for applications that require real-time embeddings and constant model refinement.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Supabase&lt;/strong&gt;: Supabase is an open-source database platform that provides a wide range of features, including support for vector storage and retrieval. With its flexibility and customizability, Supabase is suitable for projects that require not only vector database functionality but also the benefits of a comprehensive database platform.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By considering the diverse requirements of each group, we have recommended vector databases that prioritize ease of use, advanced capabilities, and customization. These recommendations aim to assist developers in selecting the most appropriate vector database for their specific use case and level of expertise.
&lt;a id="related-reading"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Related reading&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://lunabrain.com/blog/riding-the-ai-wave-with-vector-databases-how-they-work-and-why-vcs-love-them/"&gt;Riding the AI Wave with Vector Databases: How they work (and why VCs love them) - LunaBrain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://harishgarg.com/writing/best-vector-databases-for-ai-apps/"&gt;10 Best vector databases for building AI Apps with embeddings - HarishGarg.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://thenewstack.io/vector-databases-long-term-memory-for-artificial-intelligence/"&gt;Vector Databases: Long-Term Memory for Artificial Intelligence - The New Stack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/sopmac-ai/vector-databases-as-memory-for-your-ai-agents-986288530443"&gt;Vector Databases as Memory for your AI Agents | by Ivan Campos | Sopmac AI | Apr, 2023 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://venturebeat.com/ai/how-vector-databases-can-revolutionize-our-relationship-with-generative-ai/"&gt;How vector databases can revolutionize our relationship with generative AI | VentureBeat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.forbes.com/sites/adrianbridgwater/2023/05/19/the-rise-of-vector-databases/"&gt;Vector databases provide new ways to enable search and data analytics.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433"&gt;OpenAI’s Embeddings with Vector Database | Better Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vector Databases Demystified serie by &lt;a href="https://www.linkedin.com/in/adiekaye/"&gt;Adie Kaye&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/vector-databases-demystified-part-1-introduction-world-adie-kaye%3FtrackingId=Rswjt%252BgljDJ9YTjMB08LWw%253D%253D/?trackingId=Rswjt%2BgljDJ9YTjMB08LWw%3D%3D"&gt;Part 1 - An Introduction to the World of High-Dimensional Data Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/vector-databases-demystified-part-2-building-your-own-adie-kaye?trackingId=CRILIdZ0zUFLlj3EZ69gXQ%3D%3D&amp;amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3B1s%2FDztmATJWjL%2BLIoqi0XQ%3D%3D"&gt;Part 2 - Building Your Own (Very) Simple Vector Database in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/vector-databases-demystified-part-3-build-colour-matching-adie-kaye?trackingId=sS3mR3KmPvSwcPwdMJvbFQ%3D%3D&amp;amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_content_view%3B1s%2FDztmATJWjL%2BLIoqi0XQ%3D%3D"&gt;Part 3 - Build a colour matching app with Pinecone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/vector-databases-demystified-part-4-using-sentence-pinecone-kaye?trackingId=vfLY3dFcGw%2FVygrCCFKZIQ%3D%3D"&gt;Part 4 - Using Sentence Transformers with Pinecone&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><category term="Generative AI"></category><category term="machine-learning"></category><category term="python"></category><category term="embeddings"></category><category term="vectordb"></category><category term="database"></category><category term="transformers"></category><category term="chroma"></category><category term="langchain"></category><category term="pinecone"></category><category term="haystack"></category><category term="faiss"></category><category term="milvus"></category><category term="pgvector"></category><category term="supabase"></category><category term="qdrant"></category><category term="vespa"></category><category term="weaviate"></category><category term="deeplake"></category><category term="vectorstore"></category></entry><entry><title>Mastering the Kanban Method - Unveiling the Hidden Gems of Effective Kanban Board Usage</title><link href="https://www.safjan.com/mastering-kanban-method/" rel="alternate"></link><published>2023-05-26T00:00:00+02:00</published><updated>2023-05-26T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-05-26:/mastering-kanban-method/</id><summary type="html">&lt;p&gt;Ever wondered how to supercharge your team's productivity? Say hello to Kanban, the dynamic method that brings clarity and efficiency to your projects.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In today's fast-paced and ever-evolving business landscape, organizations are constantly seeking efficient project management methodologies to enhance productivity and streamline workflows. One such approach that has gained significant popularity is the Kanban method. Kanban, originating from the Japanese word for "billboard" or "visual card," is a visual project management system that allows teams to track and manage work effectively. In this comprehensive guide, we will delve into the intricacies of the Kanban method, explore the proper utilization of Kanban boards, and reveal lesser-known tips and tricks to maximize their potential.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#understanding-the-kanban-method-principles"&gt;Understanding the Kanban Method Principles&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#visualize-your-workflow"&gt;Visualize Your Workflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#limit-work-in-progress-wip"&gt;Limit Work in Progress (WIP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#collaborate-and-encourage-flow"&gt;Collaborate and Encourage Flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#continuously-improve"&gt;Continuously Improve&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#avoiding-common-mistakes"&gt;Avoiding Common Mistakes&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#neglecting-wip-limits"&gt;Neglecting WIP Limits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lack-of-clarity-and-standardization"&gt;Lack of Clarity and Standardization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#failure-to-prioritize-and-swarm"&gt;Failure to Prioritize and Swarm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lack-of-continuous-improvement"&gt;Lack of Continuous Improvement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#unveiling-lesser-known-tips-and-tricks"&gt;Unveiling Lesser-Known Tips and Tricks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#class-of-service"&gt;Class of Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#visualizing-blocked-tasks"&gt;Visualizing Blocked Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kanban-swimlanes"&gt;Kanban Swimlanes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#implementing-agile-practices"&gt;Implementing Agile Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="understanding-the-kanban-method-principles"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Understanding the Kanban Method Principles&lt;/h2&gt;
&lt;p&gt;The Kanban method, developed by Taiichi Ohno at Toyota, is built on the principles of visualizing work, limiting work in progress (WIP), and focusing on continuous improvement. At its core, Kanban promotes transparency, flexibility, and collaboration, providing teams with a clear overview of their tasks and enabling them to optimize their workflows.&lt;/p&gt;
&lt;p&gt;&lt;a id="visualize-your-workflow"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Visualize Your Workflow&lt;/h3&gt;
&lt;p&gt;The fundamental principle of Kanban lies in visualizing your workflow. By representing each task as a card or sticky note on a Kanban board, teams gain a shared understanding of the work in progress. A typical Kanban board comprises columns that depict different stages of work, such as "To Do," "In Progress," and "Done." Visualizing tasks fosters transparency, enhances communication, and enables team members to identify bottlenecks or inefficiencies quickly.&lt;/p&gt;
&lt;p&gt;&lt;a id="limit-work-in-progress-wip"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Limit Work in Progress (WIP)&lt;/h3&gt;
&lt;p&gt;To maintain a smooth workflow and prevent overburdening team members, it is crucial to limit the number of tasks in progress simultaneously. Setting WIP limits for each column on the Kanban board ensures a manageable workload, promotes focus, and encourages completing tasks before moving on to new ones. WIP limits prevent multitasking, which can lead to reduced productivity and increased lead times.&lt;/p&gt;
&lt;p&gt;&lt;a id="collaborate-and-encourage-flow"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Collaborate and Encourage Flow&lt;/h3&gt;
&lt;p&gt;Kanban encourages collaboration and cross-functional teamwork. By eliminating silos and fostering a culture of shared responsibility, teams can achieve a seamless flow of work. Encourage frequent communication, promote knowledge sharing, and embrace a collective ownership mindset to optimize the overall efficiency of your Kanban system.&lt;/p&gt;
&lt;p&gt;&lt;a id="continuously-improve"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Continuously Improve&lt;/h3&gt;
&lt;p&gt;The Kanban method is rooted in the philosophy of continuous improvement. Encourage your team to reflect on their processes, identify areas of improvement, and implement changes accordingly. By regularly reviewing your Kanban board, analyzing cycle times, and seeking feedback from team members, you can refine your workflows, streamline processes, and enhance overall productivity.&lt;/p&gt;
&lt;p&gt;&lt;a id="avoiding-common-mistakes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Avoiding Common Mistakes&lt;/h2&gt;
&lt;p&gt;While the Kanban method offers numerous benefits, it's important to be aware of common pitfalls that can hinder its effectiveness. By recognizing and avoiding these mistakes, you can ensure your Kanban implementation is successful.&lt;/p&gt;
&lt;p&gt;&lt;a id="neglecting-wip-limits"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Neglecting WIP Limits&lt;/h3&gt;
&lt;p&gt;One common mistake is neglecting WIP limits or setting them too high. Failing to adhere to WIP limits can lead to task overload, reduced focus, and increased lead times. Regularly review and adjust WIP limits based on team capacity and project requirements.&lt;/p&gt;
&lt;p&gt;&lt;a id="lack-of-clarity-and-standardization"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Lack of Clarity and Standardization&lt;/h3&gt;
&lt;p&gt;Without clear guidelines and standardized practices, teams may interpret Kanban differently, leading to confusion and inconsistency. Establish explicit rules for how tasks should be represented on the board, how updates are communicated, and how metrics are measured. Consistency ensures everyone understands the workflow and can collaborate effectively.&lt;/p&gt;
&lt;p&gt;&lt;a id="failure-to-prioritize-and-swarm"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Failure to Prioritize and Swarm&lt;/h3&gt;
&lt;p&gt;In Kanban, it's important to prioritize tasks and encourage the team to focus on completing them one at a time. Neglecting prioritization can lead to cherry-picking tasks or tackling low-value items first. Additionally, encourage swarming, where team members collaborate to complete tasks together, rather than working individually, to maximize efficiency and knowledge sharing.&lt;/p&gt;
&lt;p&gt;&lt;a id="lack-of-continuous-improvement"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Lack of Continuous Improvement&lt;/h3&gt;
&lt;p&gt;One of the main principles of Kanban is continuous improvement. Failing to allocate time for retrospectives, process analysis, and incremental changes can hinder your team's growth and limit the full potential of your Kanban system. Regularly review and refine your workflows to ensure ongoing progress and evolution.&lt;/p&gt;
&lt;p&gt;&lt;a id="unveiling-lesser-known-tips-and-tricks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Unveiling Lesser-Known Tips and Tricks&lt;/h2&gt;
&lt;p&gt;Now, let's uncover some lesser-known tips and tricks that can take your Kanban practice to the next level, boosting your team's productivity and overall success.&lt;/p&gt;
&lt;p&gt;&lt;a id="class-of-service"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Class of Service&lt;/h3&gt;
&lt;p&gt;Introduce the concept of "Class of Service" to prioritize tasks based on their impact and urgency. By assigning different classes to tasks, such as expedite, standard, or fixed-date, teams can ensure that critical work is appropriately prioritized and expedited, while still maintaining a steady flow.&lt;/p&gt;
&lt;p&gt;&lt;a id="visualizing-blocked-tasks"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Visualizing Blocked Tasks&lt;/h3&gt;
&lt;p&gt;In addition to representing tasks in progress, leverage the Kanban board to highlight blocked or stalled tasks. Use specific indicators or flags to denote issues preventing progress, such as dependencies, resource constraints, or waiting for external feedback. This visual cue helps the team focus on resolving blockers and ensures smoother workflow management.&lt;/p&gt;
&lt;p&gt;&lt;a id="kanban-swimlanes"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Kanban Swimlanes&lt;/h3&gt;
&lt;p&gt;Introduce swimlanes on your Kanban board to categorize tasks based on different criteria, such as priority, team member, or project phase. Swimlanes provide a higher level of organization and enable teams to filter and analyze their work in a more granular manner. This approach can be particularly beneficial for larger teams or complex projects.&lt;/p&gt;
&lt;p&gt;&lt;a id="implementing-agile-practices"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Implementing Agile Practices&lt;/h3&gt;
&lt;p&gt;Combine Kanban with agile practices to amplify its impact. Techniques like daily stand-ups, sprint planning, and retrospectives can complement the visual nature of Kanban, fostering enhanced collaboration, transparency, and adaptability within your team.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The Kanban method, with its emphasis on visualization, limiting work in progress, and continuous improvement, offers organizations a powerful tool to optimize their workflows and enhance team productivity. By avoiding common mistakes and incorporating lesser-known tips and tricks, teams can unlock the full potential of Kanban, streamline their processes, and achieve remarkable results. Embrace the power of Kanban, and watch your projects flourish in an environment of transparency, collaboration, and continuous improvement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Credits&lt;/strong&gt;: heading image from &lt;a href="https://unsplash.com/photos/OXmym9cuaEY"&gt;unsplash&lt;/a&gt; by &lt;a href="https://unsplash.com/@edenconstantin0"&gt;edenconstantin0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</content><category term="Howto"></category><category term="kanban-method"></category><category term="kanban-board"></category><category term="project-management"></category><category term="workflow-management"></category><category term="productivity"></category><category term="visual-management"></category><category term="work-in-progress"></category><category term="collaboration"></category><category term="continuous-improvement"></category><category term="task-management"></category><category term="agile-methodology"></category><category term="prioritization"></category><category term="team-efficiency"></category><category term="transparency"></category><category term="WIP-limits"></category><category term="cross-functional-teamwork"></category><category term="cycle-times"></category><category term="retrospectives"></category><category term="swarming"></category><category term="class-of-service"></category><category term="blocked-tasks"></category><category term="swimlanes"></category><category term="agile-practices"></category></entry><entry><title>Getting the User's Home Directory Path in Python - A Cross-Platform Guide</title><link href="https://www.safjan.com/python-user-home-directory/" rel="alternate"></link><published>2023-04-20T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-04-20:/python-user-home-directory/</id><summary type="html">&lt;h2&gt;Use &lt;code&gt;os.path.expanduser()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;To get the user's home directory in Python, you can use the &lt;code&gt;os.path.expanduser()&lt;/code&gt; function. This function expands the initial tilde &lt;code&gt;~&lt;/code&gt; character in a file path to the user's home directory path.&lt;/p&gt;
&lt;p&gt;Here's an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h2&gt;Use &lt;code&gt;os.path.expanduser()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;To get the user's home directory in Python, you can use the &lt;code&gt;os.path.expanduser()&lt;/code&gt; function. This function expands the initial tilde &lt;code&gt;~&lt;/code&gt; character in a file path to the user's home directory path.&lt;/p&gt;
&lt;p&gt;Here's an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;home_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;~&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;home_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This should output the path to the user's home directory, which will be different depending on the operating system.&lt;/p&gt;
&lt;p&gt;For example, on a Unix-based system such as macOS or Linux, this will output something like &lt;code&gt;/Users/username&lt;/code&gt;. On a Windows system, it will output something like &lt;code&gt;C:\Users\username&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Using &lt;code&gt;os.path.expanduser()&lt;/code&gt; is a cross-platform solution because it automatically handles the differences between operating systems in how they represent home directory paths.&lt;/p&gt;
&lt;h2&gt;Use &lt;code&gt;Path.home()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;You can also use the &lt;code&gt;Path.home()&lt;/code&gt; method of the &lt;code&gt;pathlib&lt;/code&gt; module to get the user's home directory path in a platform-independent way. Here's an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="n"&gt;home_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;home_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will output the same path to the user's home directory as the previous example, but it uses the &lt;code&gt;Path&lt;/code&gt; object instead of the &lt;code&gt;os&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Path.home()&lt;/code&gt; method is a cross-platform way of getting the user's home directory path. It returns a &lt;code&gt;Path&lt;/code&gt; object representing the home directory path, which can be used with other &lt;code&gt;pathlib&lt;/code&gt; methods to manipulate file paths in a platform-independent way.&lt;/p&gt;
&lt;h2&gt;Other alternatives&lt;/h2&gt;
&lt;p&gt;There are a few other ways to get the user's home directory path in Python, some of which are platform-dependent.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;code&gt;os.environ&lt;/code&gt; dictionary:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;home_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HOME&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;home_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This works on Unix-based systems like macOS and Linux, where the &lt;code&gt;HOME&lt;/code&gt; environment variable is set to the user's home directory path.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;code&gt;os.path.expandvars()&lt;/code&gt; function:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;home_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expandvars&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;$HOME&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;home_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This also works on Unix-based systems where the &lt;code&gt;HOME&lt;/code&gt; environment variable is set, but it can also work on other systems if the appropriate environment variable is set.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the &lt;code&gt;winreg&lt;/code&gt; module on Windows:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;winreg&lt;/span&gt;

&lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;winreg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OpenKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;winreg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HKEY_CURRENT_USER&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;home_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;winreg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QueryValueEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Personal&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;home_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This works on Windows systems, but it requires the &lt;code&gt;winreg&lt;/code&gt; module and accesses the Windows Registry, so it is not as platform-independent as the other solutions.&lt;/p&gt;
&lt;p&gt;Overall, using either &lt;code&gt;os.path.expanduser()&lt;/code&gt; or &lt;code&gt;Path.home()&lt;/code&gt; is the most reliable and platform-independent way to get the user's home directory path in Python.&lt;/p&gt;</content><category term="note"></category><category term="python"></category><category term="home"></category><category term="home-dir"></category><category term="pathlib"></category></entry><entry><title>Attacking Differential Privacy Using the Correlation Between the Features</title><link href="https://www.safjan.com/attacking-differential-privacy-using-the-correlation-between-the-features/" rel="alternate"></link><published>2023-04-19T00:00:00+02:00</published><updated>2023-04-19T00:00:00+02:00</updated><author><name>Krystian Safjan</name></author><id>tag:www.safjan.com,2023-04-19:/attacking-differential-privacy-using-the-correlation-between-the-features/</id><summary type="html">&lt;p&gt;Learn how the differential privacy works by simulating attack on data protected with that technique.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Differential privacy is a technique that adds random noise to the data to protect individual privacy while still allowing for accurate data analysis. However, differential privacy can still be vulnerable to attacks that can compromise the privacy of individuals. One such attack is through the use of correlation between features. In this blog post, we will discuss how an attacker can use correlation between features to attack differential privacy and how to mitigate this attack.&lt;/p&gt;
&lt;!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#background"&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#correlation-between-features"&gt;Correlation Between Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#steps-for-the-attack-using-correlation-between-features"&gt;Steps for the attack using correlation between features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#1-identify-highly-correlated-features"&gt;1. Identify highly correlated features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2-compute-expected-values"&gt;2. Compute expected values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3-compare-expected-and-observed-values"&gt;3. Compare expected and observed values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mitigating-the-attack"&gt;Mitigating the Attack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tutorial"&gt;Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#select-a-dataset-that-requires-privacy-protection"&gt;Select a dataset that requires privacy protection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#apply-differential-privacy"&gt;Apply differential privacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#perform-the-attack---reconstruct-original-data-by-exploiting-correlation-between-features"&gt;Perform the attack - reconstruct original data by exploiting correlation between features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- /MarkdownTOC --&gt;

&lt;p&gt;&lt;a id="background"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;Differential privacy adds random noise to the data to protect the privacy of individuals. The amount of noise added depends on a parameter called the privacy budget. The higher the privacy budget, the less noise is added, and the lower the privacy budget, the more noise is added. The privacy budget is usually set based on the desired level of privacy and the size of the data set. A smaller privacy budget leads to better privacy but less accurate data analysis, while a larger privacy budget leads to less privacy but more accurate data analysis.&lt;/p&gt;
&lt;p&gt;&lt;a id="correlation-between-features"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Correlation Between Features&lt;/h2&gt;
&lt;p&gt;In many data sets, the features are not independent but are correlated with each other. Correlation between features can be measured using the correlation coefficient. The correlation coefficient between two features x and y is defined as:&lt;/p&gt;
&lt;div class="math"&gt;$$
ρ_{x,y} = cov(x,y) / (σ_x * σ_y)
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(cov(x,y)\)&lt;/span&gt; is the covariance between &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, and &lt;span class="math"&gt;\(\sigma_x\)&lt;/span&gt; and &lt;span class="math"&gt;\(\sigma_y\)&lt;/span&gt; are the standard deviations of &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Correlation between features can be used to attack differential privacy. An attacker can use the correlation between features to infer the presence or absence of an individual's data in the data set. For example, suppose an attacker knows that two features x and y are highly correlated. If the attacker sees that the value of y is very different from what they would expect based on the value of x, they can infer that the individual's data was not included in the data set.&lt;/p&gt;
&lt;p&gt;&lt;a id="steps-for-the-attack-using-correlation-between-features"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Steps for the attack using correlation between features&lt;/h2&gt;
&lt;p&gt;An attacker can use the following steps to attack differential privacy using correlation between features:&lt;/p&gt;
&lt;p&gt;&lt;a id="1-identify-highly-correlated-features"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;1. Identify highly correlated features&lt;/h3&gt;
&lt;p&gt;The attacker identifies which features in the data set are highly correlated with each other.&lt;/p&gt;
&lt;p&gt;&lt;a id="2-compute-expected-values"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2. Compute expected values&lt;/h3&gt;
&lt;p&gt;The attacker computes the expected values of the features based on the values of the other features.&lt;/p&gt;
&lt;p&gt;&lt;a id="3-compare-expected-and-observed-values"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;3. Compare expected and observed values&lt;/h3&gt;
&lt;p&gt;The attacker compares the expected values with the observed values of the features. If the observed values are significantly different from the expected values, the attacker can infer that the individual's data was not included in the data set.&lt;/p&gt;
&lt;p&gt;&lt;a id="mitigating-the-attack"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Mitigating the Attack&lt;/h2&gt;
&lt;p&gt;There are several ways to mitigate the attack using correlation between features. One approach is to &lt;strong&gt;decorrelate the features&lt;/strong&gt; by transforming the data. For example, principal component analysis (PCA) can be used to decorrelate the features. Another approach is to &lt;strong&gt;add noise to the data&lt;/strong&gt; in a way that preserves the correlation between features. This approach is called differentially private PCA (DP-PCA). DP-PCA adds noise to the data in a way that satisfies differential privacy while preserving the correlation between features.&lt;/p&gt;
&lt;p&gt;&lt;a id="summary"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Correlation between features can be used to attack differential privacy. An attacker can use the correlation between features to infer the presence or absence of an individual's data in the data set. To mitigate this attack, the features can be decorrelated or noise can be added to the data using DP-PCA. Data security experts should be aware of this attack and take appropriate measures to mitigate its effects.&lt;/p&gt;
&lt;p&gt;&lt;a id="tutorial"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Tutorial&lt;/h2&gt;
&lt;p&gt;In this tutorial, we will go through the steps of attacking differential privacy by exploiting correlations between features, using Python code to demonstrate each step.&lt;/p&gt;
&lt;p&gt;In the tutorial we will be using pydp Python library, so you need to install it first:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;python-dp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="select-a-dataset-that-requires-privacy-protection"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Select a dataset that requires privacy protection&lt;/h3&gt;
&lt;p&gt;For this tutorial, we will use the Adult dataset from the UCI Machine Learning Repository. This dataset contains information about individuals, including their age, education level, marital status, occupation, and more. The goal is to predict whether an individual earns more than $50K per year. We will load this dataset using pandas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;workclass&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;fnlwgt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;education&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;marital-status&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;occupation&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;relationship&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;race&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sex&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;capital-gain&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;capital-loss&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;hours-per-week&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;native-country&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;income&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="apply-differential-privacy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Apply differential privacy&lt;/h3&gt;
&lt;p&gt;We will use the PyDP library to apply differential privacy to the dataset. We will add Laplace noise to the age and education-num features, with a privacy budget of 1.0:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydp.algorithms.laplacian&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BoundedMean&lt;/span&gt;

&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;

&lt;span class="c1"&gt;# apply differential privacy to age&lt;/span&gt;
&lt;span class="n"&gt;bm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BoundedMean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quick_result&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# apply differential privacy to education-num&lt;/span&gt;
&lt;span class="n"&gt;bm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BoundedMean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quick_result&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a id="perform-the-attack---reconstruct-original-data-by-exploiting-correlation-between-features"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Perform the attack - reconstruct original data by exploiting correlation between features&lt;/h3&gt;
&lt;p&gt;Now that we have applied differential privacy to the dataset, we will attempt to reconstruct the original data by exploiting the correlation between features. Specifically, we will use the age and education-num features, which we know are highly correlated, to infer the values of the original data.&lt;/p&gt;
&lt;p&gt;First, we will create a copy of the dataset and remove the age and education-num features, as we will be reconstructing these features:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df_attack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, we will compute the mean and covariance matrix of the remaining features:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# compute mean and covariance of remaining features&lt;/span&gt;
&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_attack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cov&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_attack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can now use the mean and covariance matrix to generate synthetic data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# generate synthetic data&lt;/span&gt;
&lt;span class="n"&gt;synthetic_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multivariate_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;synthetic_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;synthetic_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df_attack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, we will reconstruct the age and education-num features using the generated synthetic data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# reconstruct age and education-num features&lt;/span&gt;
&lt;span class="n"&gt;reconstructed_age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;reconstructed_edu_num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# combine reconstructed features with original data&lt;/span&gt;
&lt;span class="n"&gt;reconstructed_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;reconstructed_age&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;reconstructed_edu_num&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="n"&gt;df_reconstructed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;df_attack&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reconstructed_df&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can now compare the reconstructed age and education-num features with the original features to see how well our attack worked:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# compare reconstructed age and education-num with original features print(&amp;quot;Age:&amp;quot;) &lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Original:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; 
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Reconstructed:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reconstructed_age&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; 
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; 

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Education-num:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Original:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;education-num&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Reconstructed:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reconstructed_edu_num&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Age&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="mi"&gt;38&lt;/span&gt; &lt;span class="mi"&gt;53&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="mi"&gt;37&lt;/span&gt; &lt;span class="mi"&gt;49&lt;/span&gt; &lt;span class="mi"&gt;52&lt;/span&gt; &lt;span class="mi"&gt;31&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Reconstructed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;39.38640885&lt;/span&gt; &lt;span class="mf"&gt;49.44619487&lt;/span&gt; &lt;span class="mf"&gt;38.2757904&lt;/span&gt;  &lt;span class="mf"&gt;52.75103613&lt;/span&gt; &lt;span class="mf"&gt;26.46121269&lt;/span&gt; &lt;span class="mf"&gt;37.760824&lt;/span&gt;
 &lt;span class="mf"&gt;47.88143872&lt;/span&gt; &lt;span class="mf"&gt;52.8530772&lt;/span&gt;  &lt;span class="mf"&gt;30.79760633&lt;/span&gt; &lt;span class="mf"&gt;42.56495885&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;Education&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;Original&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt;  &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Reconstructed&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;13.19164695&lt;/span&gt; &lt;span class="mf"&gt;13.19406455&lt;/span&gt;  &lt;span class="mf"&gt;9.04750693&lt;/span&gt;  &lt;span class="mf"&gt;6.8549391&lt;/span&gt;  &lt;span class="mf"&gt;13.25155432&lt;/span&gt; &lt;span class="mf"&gt;13.76664294&lt;/span&gt;
  &lt;span class="mf"&gt;5.45598348&lt;/span&gt;  &lt;span class="mf"&gt;8.72003132&lt;/span&gt; &lt;span class="mf"&gt;14.14489928&lt;/span&gt; &lt;span class="mf"&gt;12.9968581&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As we can see, the reconstructed values are quite similar to the original values. This suggests that an attacker could use the correlation between the age and education-num features to infer the original values, even with the protection of differential privacy.&lt;/p&gt;
&lt;p&gt;&lt;a id="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In this tutorial, we have demonstrated how an attacker can exploit correlations between features to attack differential privacy. We used the PyDP library to apply differential privacy to a dataset, and then showed how an attacker could use the correlation between the age and education-num features to reconstruct the original values. This highlights the importance of considering the correlations between features when applying differential privacy, and suggests that additional protections may be necessary to prevent attacks based on feature correlations.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Any comments or suggestions? &lt;a href="mailto:ksafjan@gmail.com?subject=Blog+post"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Responsible AI"></category><category term="machine-learning"></category><category term="python"></category><category term="privacy"></category><category term="xai"></category><category term="responsible-ai"></category></entry></feed>