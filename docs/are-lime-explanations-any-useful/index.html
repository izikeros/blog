
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/stylesheet/style.min.css">



        <link id="pygments-light-theme" rel="stylesheet" type="text/css"
              href="https://www.safjan.com/theme/pygments/github.min.css">



    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://www.safjan.com/theme/font-awesome/css/solid.css">

        <link rel="stylesheet" type="text/css"
              href="https://www.safjan.com/styles/custom.css">

        <link href="https://www.safjan.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Krystian Safjan's Blog Atom">

        <link href="https://www.safjan.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="Krystian Safjan's Blog RSS">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117080232-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-117080232-1');
</script>
<!-- End of Google tag (gtag.js) -->



    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Don&#39;t let black box models hold you back. With LIME, you can interpret the predictions of even the most complex machine learning models."/>
    <meta name="keywords" content="machine-learning, lime, xai, explainable-ai">
    <meta expr:content="2023-04-18 00:00:00+02:00" itemprop='datePublished'/>
    <meta expr:content="2023-04-18 00:00:00+02:00" itemprop='dateModified'/>
    <meta property="article:modified_time" content="2023-04-18 00:00:00+02:00"/>
    <meta property="article:published_time" content="2023-04-18 00:00:00+02:00"/>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Are LIME explanations any useful?",
  "datePublished": "2023-04-18 00:00:00+02:00",
  "dateModified": "2023-04-18 00:00:00+02:00"
}








    </script>



  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Are LIME explanations any useful?"/>
  <meta property="og:description" content="Don&#39;t let black box models hold you back. With LIME, you can interpret the predictions of even the most complex machine learning models."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://www.safjan.com/are-lime-explanations-any-useful/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-04-18 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2023-04-18 00:00:00+02:00"/>
  <meta property="article:author" content="https://www.safjan.com/author/krystian-safjan/">
  <meta property="article:section" content="Explainable AI"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="lime"/>
  <meta property="article:tag" content="xai"/>
  <meta property="article:tag" content="explainable-ai"/>
  <meta property="og:image" content="https://www.safjan.com//images/head/abstract_7.jpg">

    <meta name="twitter:card" content="summary"/>
    <meta property="twitter:image" content="https://www.safjan.com//images/head/abstract_7.jpg">

    <meta name="twitter:label1" content="Est. reading time"/>
    <meta name="twitter:data1" content="4 min."/>
    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:description" content="<p>Don't let black box models hold you back. With LIME, you can interpret the predictions of even the most complex machine learning models.</p>"/>
    <meta name="twitter:title" content="Are LIME explanations any useful?"/>


    <title>    Are LIME explanations any useful?
</title>


<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body class="light-theme">
<aside>
    <div>
        <a href="https://www.safjan.com/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="https://www.safjan.com/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some  <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>




        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<style>
    .button {
        background-color: yellow;
        color: black;
        border: none;
        padding: 10px 20px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
        border-radius: 20px;
    }

    .center {
        text-align: center;
    }

    .container {
        display: grid;
        grid-template-columns: 1fr 1fr;
    }

    .left-col {
    }

    .right-col {
    }

    .image {
        border-radius: 0;
        width: 100%;
    }

    .book-list {
        padding-top:0;
        padding-bottom: 0;
        text-align:left;
        box-sizing: border-box;
        display: block;
        list-style-image: url(/images/shortcode-tick.webp);
        margin-block-start: 1em;
        margin-block-end: 1em;
        margin-inline-start:0;
        margin-inline-end:0;
        padding-inline-start:40px;
    }

    .book-list li {
        font-weight: bold;
    }

    @media (max-width: 600px) {
        .container {
            grid-template-columns: 1fr;
        }
    }

</style>
<div class="container">
    <div class="left-col">
        <a href="https://ksafjanuser.gumroad.com/l/mlops">
            <img src="/images/mlop_interview_book_cover_3D_300px.jpg" class="image" alt="Interview Book Cover">
        </a>

        <div class="center">
            <a href="https://ksafjanuser.gumroad.com/l/mlops">
                <button class="button">Get for $2.99</button>
            </a>
        </div>
    </div>
    <div class="right-col">
        <div>
            <ul class="book-list">
                <li>PDF, ePUB, mobi format ebook, no DRM</li>
                <li>50 questions and answers</li>
                <li>Stories from real projects</li>
                <li>92 multiple choice quiz questions</li>
                <li>80 pages</li>
            </ul>
        </div>
    </div>
</div>
</aside>
<main>

        <nav>
            <a href="https://www.safjan.com/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/tags.html">Tags</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>

                <a href="https://www.safjan.com/feeds/all.atom.xml">Atom</a>

                <a href="https://www.safjan.com/feeds/all.rss.xml">RSS</a>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-04-18 



                    <span id="post-share-links">
    &nbsp;&nbsp;&nbsp;Share on:
    <a href="https://twitter.com/intent/tweet?text=Are%20LIME%20explanations%20any%20useful%3F&url=https%3A//www.safjan.com/are-lime-explanations-any-useful/&hashtags=machine-learning,lime,xai,explainable-ai" target="_blank" title="Share on Twitter">Twitter</a>
    |
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//www.safjan.com/are-lime-explanations-any-useful/" target="_blank" title="Share on Facebook">Facebook</a>
    |
    <a href="https://news.ycombinator.com/submitlink?t=Are%20LIME%20explanations%20any%20useful%3F&u=https%3A//www.safjan.com/are-lime-explanations-any-useful/" target="_blank" title="Share on HackerNews">HackerNews</a>
    |
    <a href="https://www.reddit.com/submit?url=https%3A//www.safjan.com/are-lime-explanations-any-useful/&title=Are%20LIME%20explanations%20any%20useful%3F" target="_blank" title="Share via Reddit">Reddit</a>
  </span>
                <br/>
            </p>
            <h1 id="are-lime-explanations-any-useful">Are LIME explanations any useful?</h1>
            <div class="header-underline"></div>
                <p class="summary"><p>Don't let black box models hold you back. With LIME, you can interpret the predictions of even the most complex machine learning models.</p></p>

                <div style="width: 100%; padding-bottom: 30px; position: relative;">
                    <a href="https://www.safjan.com/are-lime-explanations-any-useful/">
                        <img style="width: 100%; "
                             src="/images/head/abstract_7.jpg" alt="">
                    </a>
                </div>


        </header>


        <div>
            <p>LIME (Local Interpretable Model-agnostic Explanations) is a method used to interpret black box models. This technique is widely used in the field of data science to explain the predictions of complex machine learning models. By providing local explanations, LIME can help users understand the decision-making process of the models and increase their trust in the models' predictions. However, the question remains, are the local explanations obtained with LIME method useful? And what are the practical use cases when using LIME gave tangible results?</p>
<p>In this article, we will delve into the concept of LIME, its practical applications, and how it can be used to provide interpretable machine learning models.</p>
<h2>What is LIME?</h2>
<p>LIME is a model-agnostic technique used to explain the predictions of machine learning models. The idea behind LIME is to explain the predictions of a black box model by training a local, interpretable model around the data point of interest. The interpretable model is trained to mimic the behavior of the black box model around that data point. Once the local model is trained, it can be used to generate an explanation of the prediction, highlighting the most important features that contributed to the prediction.</p>
<p>The LIME algorithm consists of the following steps:</p>
<ol>
<li>Select a data point of interest.</li>
<li>Generate a dataset of perturbed instances around the selected data point.</li>
<li>Evaluate the black box model on the perturbed instances to obtain a set of weights that indicate the importance of each feature for the prediction.</li>
<li>Train an interpretable model (such as a linear regression model) on the perturbed instances, using the weights obtained in step 3 as feature weights.</li>
<li>Use the trained interpretable model to generate an explanation of the prediction for the selected data point.</li>
</ol>
<h2>Practical applications of LIME</h2>
<p>LIME has been successfully applied in various domains, including healthcare, finance, and image recognition. Here are some practical use cases where LIME has been used to provide interpretable machine learning models:</p>
<ol>
<li>
<p><strong>Healthcare</strong>: LIME has been used to interpret the predictions of machine learning models that diagnose diseases. For example, in a study conducted by Zech et al., LIME was used to interpret the predictions of a deep learning model that diagnosed pneumonia from chest X-rays. The LIME explanations provided by the study helped radiologists understand the decision-making process of the model and identify areas of the X-rays that contributed the most to the diagnosis.</p>
</li>
<li>
<p><strong>Finance</strong>: LIME has also been used to interpret the predictions of machine learning models that predict financial outcomes. For example, in a study conducted by Chen et al., LIME was used to interpret the predictions of a machine learning model that predicted the credit risk of borrowers. The LIME explanations provided by the study helped lenders understand the factors that contributed to the credit risk prediction and make informed lending decisions.</p>
</li>
<li>
<p><strong>Image recognition</strong>: LIME has been used to interpret the predictions of machine learning models that recognize images. For example, in a study conducted by Selvaraju et al., LIME was used to interpret the predictions of a deep learning model that recognized objects in images. The LIME explanations provided by the study helped users understand which parts of the image were important for the prediction and identify areas of improvement for the model.</p>
</li>
</ol>
<h2>Benefits and limitations of LIME</h2>
<p>LIME provides several <strong>benefits</strong> to data scientists and machine learning practitioners. </p>
<p>First, LIME <strong>can help increase the trust of users in machine learning models by providing interpretable explanations of the models' predictions</strong>. This can be especially useful in high-stakes domains, such as healthcare and finance, where decisions based on machine learning predictions can have significant consequences.
Second, LIME <strong>can help users identify areas of improvement for machine learning models</strong>. By providing explanations of the models' predictions, LIME can help users identify which features were important for the prediction and which ones were not. This can help users refine their feature engineering process and improve the performance of their models.</p>
<p>However, LIME also has some <strong>limitations</strong> that data scientists and machine learning practitioners should be aware of. </p>
<p>First, LIME provides local explanations, which means that <strong>the explanations are only valid for the selected data point of interest</strong>. Therefore, the explanations generated by LIME may not generalize to other data points.</p>
<p>Second, LIME <strong>requires a significant amount of computational resources</strong> to generate the perturbed instances and train the interpretable model. This can be a limitation when working with large datasets or computationally expensive models.</p>
<h2>Conclusion</h2>
<p>In conclusion, LIME is a useful technique for interpreting the predictions of machine learning models. LIME can help increase the trust of users in machine learning models and identify areas of improvement for the models. LIME has been successfully applied in various domains, including healthcare, finance, and image recognition. However, LIME also has some limitations, such as providing local explanations and requiring significant computational resources. Therefore, data scientists and machine learning practitioners should carefully consider the use of LIME and its limitations when interpreting the predictions of their models.</p>
        </div>




            <div class="bibtex-note">
                <p><b>To cite this article:</b></p>
                <pre>@article{Saf2023Are,
    author  = {Krystian Safjan},
    title   = {Are LIME explanations any useful?},
    journal = {Krystian's Safjan Blog},
    year    = {2023},
}</pre>
            </div>
        <div class="tag-cloud">
            <p>
                    <br/><br/>Tags:&nbsp;
                        <a href="https://www.safjan.com/tag/machine-learning/">machine-learning</a>
                        <a href="https://www.safjan.com/tag/lime/">lime</a>
                        <a href="https://www.safjan.com/tag/xai/">xai</a>
                        <a href="https://www.safjan.com/tag/explainable-ai/">explainable-ai</a>
            </p>
        </div>








            <div class="related-posts">
                <h4>You might enjoy</h4>
                <ul class="related-posts">
                        <li><a href="https://www.safjan.com/how-the-lime-method-for-explainable-ai-works/">LIME - Understanding How This Method for Explainable AI Works</a></li>
                        <li><a href="https://www.safjan.com/how-the-shap-method-for-explainable-ai-works/">SHAP - Understanding How This Method for Explainable AI Works</a></li>
                        <li><a href="https://www.safjan.com/lime-tutorial/">LIME Tutorial</a></li>
                        <li><a href="https://www.safjan.com/anchor-explanations/">Explainable AI - Anchor Explanations</a></li>
                        <li><a href="https://www.safjan.com/eli5-tutorial/">Understanding AI with ELI5 - Demystifying Decisions (tutorial)</a></li>
                </ul>
            </div>

  <div class="neighbors">
    <a class="btn float-left" href="https://www.safjan.com/measure-quality-of-embeddings/" title="Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?">
      <i class="fa fa-angle-left"></i> Previous Post
    </a>
    <a class="btn float-right" href="https://www.safjan.com/python-regex-named-groups/" title="Python regex named groups">
      Next Post <i class="fa fa-angle-right"></i>
    </a>
  </div>


    </article>

    <footer>
<p>
  &copy; 2023 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
</main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Krystian Safjan's Blog ",
  "url" : "https://www.safjan.com",
  "image": "/images/profile_new.jpg",
  "description": ""
}
</script>

</body>
</html>