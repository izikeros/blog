
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="color-scheme" content="light dark"/>
    <script>
      (function() {
        var theme = localStorage.getItem('theme-preference');
        if (theme === 'dark' || theme === 'light') {
          document.documentElement.setAttribute('data-theme', theme);
        }
      })();
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="HandheldFriendly" content="True"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"/>
        <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
              rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/stylesheet/style.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/pygments/github.min.css">


    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="http://127.0.0.1:8000/theme/font-awesome/css/solid.css">

    <link rel="stylesheet" href="http://127.0.0.1:8000/pagefind/pagefind-ui.css">

        <link rel="stylesheet" type="text/css"
              href="http://127.0.0.1:8000/styles/custom.css">




    <link rel="apple-touch-icon" sizes="180x180" href="http://127.0.0.1:8000/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="http://127.0.0.1:8000/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="http://127.0.0.1:8000/favicon-16x16.png">
    <link rel="shortcut icon" href="http://127.0.0.1:8000/favicon.ico">
    <link rel="manifest" href="http://127.0.0.1:8000/site.webmanifest">
    <meta name="theme-color" content="#333333">
    <meta name="apple-mobile-web-app-title" content="Krystian Safjan's Blog">





    <meta name="author" content="Krystian Safjan"/>
    <meta name="description" content="Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and their strengths and limitations."/>
    <meta name="keywords" content="machine-learning, python, embeddings, cosine-similarity, spearman-correlation, accuracy, f1-score, perplexity">


  <meta property="og:site_name" content="Krystian Safjan's Blog"/>
  <meta property="og:title" content="Intrinsic vs. Extrinsic Evaluation - What&#39;s the Best Way to Measure Embedding Quality?"/>
  <meta property="og:description" content="Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and their strengths and limitations."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="http://127.0.0.1:8000/measure-quality-of-embeddings-intrinsic-vs-extrinsic/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2023-04-18 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2023-04-18 00:00:00+02:00"/>
  <meta property="article:author" content="http://127.0.0.1:8000/author/krystian-safjan/"/>
  <meta property="article:section" content="Generative AI"/>
  <meta property="article:tag" content="machine-learning"/>
  <meta property="article:tag" content="python"/>
  <meta property="article:tag" content="embeddings"/>
  <meta property="article:tag" content="cosine-similarity"/>
  <meta property="article:tag" content="spearman-correlation"/>
  <meta property="article:tag" content="accuracy"/>
  <meta property="article:tag" content="f1-score"/>
  <meta property="article:tag" content="perplexity"/>
  <meta property="og:image" content="http://127.0.0.1:8000//images/head/intrisic_vs_ext_640px.jpg"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="http://127.0.0.1:8000//images/head/intrisic_vs_ext_640px.jpg"/>
    <meta name="twitter:image:alt" content="Intrinsic vs. Extrinsic Evaluation - What&#39;s the Best Way to Measure Embedding Quality?"/>


    <meta name="twitter:site" content="@izikeros"/>
    <meta name="twitter:creator" content="@izikeros"/>
    <meta name="twitter:title" content="Intrinsic vs. Extrinsic Evaluation - What&#39;s the Best Way to Measure Embedding Quality?"/>
    <meta name="twitter:description" content="Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and their strengths and limitations."/>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://127.0.0.1:8000/measure-quality-of-embeddings-intrinsic-vs-extrinsic/"
  },
  "headline": "Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?",
  "datePublished": "2023-04-18T00:00:00+02:00",
  "dateModified": "2023-04-18T00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Krystian Safjan",
    "url": "http://127.0.0.1:8000/author/krystian-safjan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Krystian Safjan's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/profile_new.jpg"
    }  },
"image": "http://127.0.0.1:8000//images/head/intrisic_vs_ext_640px.jpg",  "url": "http://127.0.0.1:8000/measure-quality-of-embeddings-intrinsic-vs-extrinsic/",
  "description": "Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and...",
  "articleSection": "Generative AI",
  "inLanguage": "en",
  "keywords": "machine-learning, python, embeddings, cosine-similarity, spearman-correlation, accuracy, f1-score, perplexity",
  "wordCount": 775,
  "speakable": {
    "@type": "SpeakableSpecification",
    "cssSelector": ["article h1", ".summary", ".tldr", "article \u003e p:first-of-type"]
  }}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "http://127.0.0.1:8000/"
    },
    {
      "@type": "ListItem",
      "position": 2,
      "name": "Generative AI",
      "item": "http://127.0.0.1:8000/category/generative-ai.html"
    },
    {
      "@type": "ListItem",
      "position": 3,
      "name": "Intrinsic vs. Extrinsic Evaluation - What's..."
    }
  ]
}
</script>



<meta name="ai:summary" content="Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and their strengths and limitations.">

<meta name="ai:topics" content="machine-learning, python, embeddings, cosine-similarity, spearman-correlation, accuracy, f1-score, perplexity">



<meta name="ai:word-count" content="775">
<meta name="ai:reading-time" content="3 min">

<meta name="ai:section" content="Generative AI">



<meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">

    <title>    Intrinsic vs. Extrinsic Evaluation - What&#39;s the Best Way to Measure Embedding Quality?
</title>



<!-- Google Automatic Ads -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9767732578835199"
     crossorigin="anonymous"></script>
<!-- End of Google Automatic Ads -->


</head>
<body>
<div id="reading-progress" class="reading-progress"></div>
<aside>
    <div>
        <a href="http://127.0.0.1:8000/">
                <img src="/images/profile_new.jpg" alt="Krystian Safjan's Blog" title="Krystian Safjan's Blog" width="140" height="140">
        </a>

        <h1>
            <a href="http://127.0.0.1:8000/">Krystian Safjan's Blog</a>
        </h1>

<p>Data Scientist | Researcher | Team Leader<br><br> working at Ernst &amp; Young and writing about <a href="/category/machine-learning.html">Data Science and Visualization</a>, on <a href="/category/machine-learning.html">Machine Learning, Deep Learning</a> and <a href="/tag/nlp/">NLP</a>. There are also some <a href="/category/howto.html">howto</a> posts on tools and workflows.</p>


        <ul class="social">
                <li>
                    <a  class="sc-linkedin" href="https://pl.linkedin.com/in/krystiansafjan"
                       target="_blank">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/izikeros"
                       target="_blank">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-envelope" href="mailto:ksafjan@gmail.com"
                       target="_blank">
                        <i class="fas fa-envelope"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-graduation-cap" href="https://scholar.google.pl/citations?user=UlNJgMoAAAAJ"
                       target="_blank">
                        <i class="fas fa-graduation-cap"></i>
                    </a>
                </li>
                <li>
                    <a  class="sc-rss" href="/feeds/all.rss.xml"
                       target="_blank">
                        <i class="fas fa-rss"></i>
                    </a>
                </li>
        </ul>
    </div>

<div class="promo-box">
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-image">
        <img src="/images/mlop_interview_book_cover_3D_300px.jpg" alt="MLOps Interview Book Cover">
    </a>
    
    <p class="promo-box-headline">Ace Your MLOps Interview</p>
    
    <a href="https://ksafjanuser.gumroad.com/l/mlops" class="promo-box-cta">
        Get for $2.99
    </a>
    
    <p class="promo-box-features">50 Q&A â€¢ PDF/ePUB/mobi</p>
</div>
</aside>
<main>

        <nav aria-label="Main navigation">
            <a href="http://127.0.0.1:8000/">Home</a>

                <a href="/archives.html">Articles</a>
                <a href="/til.html">Notes</a>
                <a href="/categories.html">Categories</a>
                <a href="/pdfs/Krystian_Safjan_resume_priv.pdf">Resume</a>



            <div id="search" class="nav-search"></div>
            <button type="button" id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">
                <i class="fas fa-sun"></i>
                <i class="fas fa-moon"></i>
            </button>
        </nav>

    <article class="single">
        <header>
                
            <p>
                <!-- Posted on: -->
                2023-04-18 


                <br/>
            </p>
            <h1>Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?</h1>
            <div class="header-underline"></div>
                <div class="summary"><p>Learn how to measure the quality of word and sentence embeddings in natural language processing (NLP), including intrinsic and extrinsic evaluation, and their strengths and limitations.</p></div>

                <div style="width: 100%; padding-bottom: 30px; position: relative;">
                    <a href="http://127.0.0.1:8000/measure-quality-of-embeddings-intrinsic-vs-extrinsic/">
                        <img style="width: 100%; "
                             src="/images/head/intrisic_vs_ext_640px.jpg" alt="Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?">
                    </a>
                </div>


        </header>




        <div class="article-content">
            <p><a href="http://127.0.0.1:8000/demystifying-perplexity-assessing-dimensionality-reduction-with-pca/">Demystifying Perplexity - Assessing Dimensionality Reduction With PCA</a></p>
<h2 id="introduction">Introduction</h2>
<p>Let's start with the concept of embedding vectors. In natural language processing (NLP), an embedding vector is a mathematical representation of words or phrases. It's a way to convert text data into numerical values that can be processed by machine learning algorithms. Word embeddings and sentence embeddings are widely used in natural language processing (NLP) for a variety of tasks, such as text classification, named entity recognition, machine translation, and sentiment analysis. However, it is not always straightforward to evaluate the quality of embeddings, and different evaluation metrics may be appropriate for different use cases. In this blog post, we will explore several ways to measure the quality of embeddings, including intrinsic and extrinsic evaluation, and discuss their strengths and limitations.</p>
<!-- MarkdownTOC levels="2,3" autolink="true" autoanchor="true" -->

<ul>
<li><a href="#intrinsic-evaluation">Intrinsic Evaluation</a></li>
<li><a href="#cosine-similarity">Cosine Similarity</a></li>
<li><a href="#spearman-correlation">Spearman Correlation</a></li>
<li><a href="#accuracy">Accuracy</a></li>
<li><a href="#extrinsic-evaluation">Extrinsic Evaluation</a></li>
<li><a href="#f1-score">F1 Score</a></li>
<li><a href="#perplexity">Perplexity</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<!-- /MarkdownTOC -->

<h2 id="intrinsic-evaluation">Intrinsic Evaluation</h2>
<blockquote>
<p><strong>Intrinsic evaluation</strong> - aims to measure the quality of embeddings by assessing their performance on specific NLP tasks that are related to the embedding space itself, such as word similarity, analogy, and classification.</p>
</blockquote>
<p>In this section, we will discuss three commonly used intrinsic evaluation metrics: cosine similarity, Spearman correlation, and accuracy.</p>
<h3 id="cosine-similarity">Cosine Similarity</h3>
<p>Cosine similarity measures the similarity between two vectors by computing the cosine of the angle between them. In the context of embeddings, cosine similarity is often used to measure the similarity between two words, or between a word and its context. The formula for cosine similarity is as follows:</p>
<p>$$
cosine_similarity(\textbf{v}_1, \textbf{v}_2) = \frac{\textbf{v}_1 \cdot \textbf{v}_2}{|\textbf{v}_1||\textbf{v}_2|}
$$</p>
<p>where $\textbf{v}_1$ and $\textbf{v}_2$ are the embeddings of two words, and $|\cdot|$ denotes the Euclidean norm.</p>
<h3 id="spearman-correlation">Spearman Correlation</h3>
<p>Spearman correlation measures the monotonic relationship between two variables, which can be the similarity scores of two sets of words or phrases computed by humans and by embeddings. A high Spearman correlation indicates that the embeddings are able to capture the semantic relationships between words that humans perceive. The formula for Spearman correlation is as follows:</p>
<p>$$
\text{Spearman's correlation} = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}</p>
<p>$$</p>
<p>where $d_i$ is the difference between the ranks of the $i$-th pair of similarity scores, and $n$ is the number of pairs.</p>
<h3 id="accuracy">Accuracy</h3>
<p>Accuracy measures the performance of embeddings on classification tasks, such as sentiment analysis or topic classification. Given a dataset of labeled examples, the embeddings are used to represent each example, and a classifier is trained on these representations. The accuracy of the classifier on a held-out test set is then used as a measure of the quality of the embeddings.</p>
<h2 id="extrinsic-evaluation">Extrinsic Evaluation</h2>
<blockquote>
<p><strong>Extrinsic evaluation</strong> - aims to measure the quality of embeddings by assessing their performance on downstream NLP tasks, such as machine translation or text classification, that are not directly related to the embedding space itself.</p>
</blockquote>
<p>In this section, we will discuss two commonly used extrinsic evaluation metrics: F1 score and perplexity.</p>
<h3 id="f1-score">F1 Score</h3>
<p>F1 score is a metric commonly used in binary classification problems, such as sentiment analysis or named entity recognition. It combines precision and recall into a single score that ranges from 0 to 1. A high F1 score indicates that the embeddings are able to capture the relevant features of the input data. The formula for F1 score is as follows:</p>
<p>$$
F1 = \frac{2 \cdot \text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}
$$</p>
<p>where precision is the fraction of true positives among the predicted positives, and recall is the fraction of true positives among the actual positives.</p>
<h3 id="perplexity">Perplexity</h3>
<p>Perplexity is a metric commonly used in language modeling tasks, such as machine translation or text generation. It measures how well a language model can predict a held-out test set of text, given the embeddings as input. A low perplexity indicates that the embeddings  are able to capture the semantic and syntactic structures of the language. The formula for perplexity is as follows:</p>
<p>$$
\text{perplexity} = 2^{-\frac{1}{N}\sum_{i=1}^{N} \log_2 p(w_i | \textbf{e}_i)}
$$</p>
<p>where $N$ is the number of tokens in the test set, $\textbf{e}_i$ is the embedding of the $i$-th token, and $p(w_i | \textbf{e}_i)$ is the conditional probability of the $i$-th token given its embedding.</p>
<h2 id="limitations">Limitations</h2>
<p>While intrinsic and extrinsic evaluation metrics can provide useful insights into the quality of embeddings, they also have some limitations. Intrinsic evaluation may not always reflect the performance of embeddings on downstream tasks, and extrinsic evaluation may not always isolate the contribution of embeddings from other factors, such as the choice of model architecture or the quality of the training data. Moreover, the choice of evaluation metrics may depend on the specific use case and the available resources, and there is no one-size-fits-all solution.</p>
<p><em>Any comments or suggestions? <a href="mailto:ksafjan@gmail.com?subject=Blog+post">Let me know</a>.</em></p>
        </div>




            <div class="bibtex-note">
                <p><b>To cite this article:</b></p>
                <pre>@article{Saf2023Intrinsic,
    author  = {Krystian Safjan},
    title   = {Intrinsic vs. Extrinsic Evaluation - What's the Best Way to Measure Embedding Quality?},
    journal = {Krystian's Safjan Blog},
    year    = {2023},
}</pre>
            </div>
        <div class="article-tags">
            <span class="tags-label">Tags:</span>
                <a href="http://127.0.0.1:8000/tag/machine-learning/" class="article-tag">machine-learning</a>
                <a href="http://127.0.0.1:8000/tag/python/" class="article-tag">python</a>
                <a href="http://127.0.0.1:8000/tag/embeddings/" class="article-tag">embeddings</a>
                <a href="http://127.0.0.1:8000/tag/cosine-similarity/" class="article-tag">cosine-similarity</a>
                <a href="http://127.0.0.1:8000/tag/spearman-correlation/" class="article-tag">spearman-correlation</a>
                <a href="http://127.0.0.1:8000/tag/accuracy/" class="article-tag">accuracy</a>
                <a href="http://127.0.0.1:8000/tag/f1-score/" class="article-tag">f1-score</a>
                <a href="http://127.0.0.1:8000/tag/perplexity/" class="article-tag">perplexity</a>
        </div>











    </article>

    <footer>
<p>
  &copy; 2026 Krystian Safjan - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>    </footer>
</main>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Blog",
  "name": "Krystian Safjan's Blog",
  "url": "http://127.0.0.1:8000",
"image": "/images/profile_new.jpg",  "description": ""
}
</script>


<script src="http://127.0.0.1:8000/pagefind/pagefind-ui.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', function() {
        new PagefindUI({
            element: "#search",
            showSubResults: false,
            showImages: false,
            basePath: "http://127.0.0.1:8000/pagefind/"
        });
    });
</script>

<script src="http://127.0.0.1:8000/theme/js/theme-switcher.js"></script>

<style>
.youtube-embed {
    position: relative;
    width: 100%;
    padding-bottom: 56.25%;
    background: #000;
    border-radius: 0.375rem;
    overflow: hidden;
}
.youtube-embed iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border: 0;
}
.youtube-embed-wrapper {
    margin-bottom: 1rem;
}
.youtube-embed-info {
    padding: 0.5rem 0.75rem;
    background: var(--color-bg-secondary, #f6f8fa);
    border-radius: 0 0 0.375rem 0.375rem;
    font-size: 0.875rem;
    margin-top: -0.375rem;
}
.youtube-embed-info a {
    text-decoration: none;
    color: inherit;
}
.youtube-embed-info a:hover {
    text-decoration: underline;
}
</style>
<script>
document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('pre > code').forEach(function(code) {
        var text = code.textContent.trim();
        if (!text.match(/^https?:\/\/(www\.)?(youtube\.com|youtu\.be)/)) return;

        var lines = text.split('\n');
        var url = lines[0].trim();
        var match = url.match(/(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([a-zA-Z0-9_-]{11})/);
        if (!match) return;
        var videoId = match[1];

        var meta = {};
        lines.slice(1).forEach(function(line) {
            var m = line.match(/^(\w+):\s*(.+)$/);
            if (m) meta[m[1].toLowerCase()] = m[2].trim();
        });

        var wrapper = document.createElement('div');
        wrapper.className = 'youtube-embed-wrapper';

        var embed = document.createElement('div');
        embed.className = 'youtube-embed';
        embed.innerHTML = '<iframe src="https://www.youtube-nocookie.com/embed/' + videoId +
            '" allowfullscreen loading="lazy" title="' + (meta.title || 'YouTube video').replace(/"/g, '&quot;') + '"></iframe>';
        wrapper.appendChild(embed);

        if (meta.title || meta.author) {
            var info = document.createElement('div');
            info.className = 'youtube-embed-info';
            var html = meta.title ? '<strong>' + meta.title + '</strong>' : '';
            if (meta.author) {
                html += (meta.title ? ' &bull; ' : '');
                html += meta.authorurl ? '<a href="' + meta.authorurl + '" target="_blank" rel="noopener">' + meta.author + '</a>' : meta.author;
            }
            info.innerHTML = html;
            wrapper.appendChild(info);
        }
        code.closest('pre').replaceWith(wrapper);
    });
});
</script>
</body>
</html>