---
Title: Best Small Models for Fine Tuning
Slug: best-small-models-for-fine-tuning
Date: 2024-07-03
Modified: 2024-08-01
Status: published
tags: predibase, evaluation, llm, slm, small-language-models
Category: note
---
X:[[fine_tune_large_language_models_LLM]]
X::[[RAG_evaluation]]

## Best models to fine-tune
![[Pasted image 20240708122914.png]]

**Ranking:**
1. llama-3-8b
2. phi-3-4k
3. zephyr-7b-beta
4. llama-3-8b-instruct
5. mistral-7b

Source: [The Fine-tuning Index - Predibase](https://predibase.com/fine-tuning-index)

## Related Webinar
```vid
https://www.youtube.com/watch?v=kFdfDJ1fQxY
```

[https://pbase.ai/3x4JB6G](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa1NGYXVWNTY1aEI0cV9Qb2F0aGVHdUZWRjVFUXxBQ3Jtc0tsZGJfTFl5SEV0SlZMOXBSRWNiZERxWlA0Q2Zvd0gzSVRSSXY1WnV0eGRFV2w0VGE0WnB2QkFhY3R2YVBMZlM0aVpHb0daMjd4R1dLVkxDeFhJZjMwcDkzWHczcVFleU05aGg2QUExaDhndzZtN1ZIWQ&q=https%3A%2F%2Fpbase.ai%2F3x4JB6G&v=kFdfDJ1fQxY)

In this on-demand webinar, Staff Software Engineer Justin Zhao, and ML Engineer Timothy Wang, lead an in-depth discussion on our findings: 

• How we fine-tuned open-source LLMs that rival GPT-4 
• How you can implement Parameter-Efficient Fine-Tuning (PEFT) methods like Low Rank Adaptation (LoRA) 
• Which tasks are best suited for fine-tuning based on our benchmarks 
• Which popular LLMs—namely Phi, Gemma, and Mistral—perform best and worst across tasks 
• How we implemented an evaluation harness for fine-tuning at scale